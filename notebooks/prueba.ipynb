{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6804aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /home/cesar/proyectos/TFM_SNN\n",
      "Añadido a sys.path y PYTHONPATH\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys, os\n",
    "\n",
    "# Detecta la raíz del repo según dónde ejecutes el notebook\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "\n",
    "# Asegura que existe src/ y añade ROOT al sys.path y PYTHONPATH\n",
    "assert (ROOT / \"src\").exists(), f\"No existe {ROOT/'src'}\"\n",
    "sys.path.insert(0, str(ROOT))\n",
    "os.environ[\"PYTHONPATH\"] = str(ROOT)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"Añadido a sys.path y PYTHONPATH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3345e233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /home/cesar/proyectos/TFM_SNN\n",
      "Torch: 2.8.0+cu129\n",
      "CUDA available: True\n",
      "Device: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "TF32 matmul: False\n",
      "TF32 cudnn: True\n",
      "Helpers OK\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Raíz del repo (igual que en runner)\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "print(\"ROOT:\", ROOT)\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "print(\"TF32 matmul:\", torch.backends.cuda.matmul.allow_tf32)\n",
    "print(\"TF32 cudnn:\", torch.backends.cudnn.allow_tf32)\n",
    "\n",
    "# Helpers clave\n",
    "from src.training import _forward_with_cached_orientation, set_encode_runtime, _align_target_shape\n",
    "from src.eval import eval_loader\n",
    "print(\"Helpers OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb66f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks file: /home/cesar/proyectos/TFM_SNN/data/processed/tasks_balanced.json\n",
      "Task usada: circuito1\n",
      "Batch train shapes: (10, 32, 1, 66, 200) (32, 1)\n",
      "Forward sin runtime -> y_hat: (32, 1)\n",
      "Forward con runtime -> y_hat: (32, 1)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from src.utils import load_preset, build_components_for, build_task_list_for\n",
    "\n",
    "PRESET = \"fast\"  # humo rápido antes de accurate\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "tfm, make_loader_fn, make_model_fn = build_components_for(CFG, ROOT)\n",
    "task_list, tasks_file = build_task_list_for(CFG, ROOT)\n",
    "print(\"Tasks file:\", tasks_file)\n",
    "\n",
    "# 1er recorrido para el humo\n",
    "task = task_list[0]\n",
    "print(\"Task usada:\", task[\"name\"])\n",
    "\n",
    "# Loaders con la cfg real\n",
    "tr, va, te = make_loader_fn(\n",
    "    task=task,\n",
    "    batch_size=min(32, int(CFG[\"optim\"][\"batch_size\"])),\n",
    "    encoder=CFG[\"data\"][\"encoder\"],\n",
    "    T=CFG[\"data\"][\"T\"],\n",
    "    gain=CFG[\"data\"][\"gain\"],\n",
    "    tfm=tfm,\n",
    "    seed=CFG[\"data\"][\"seed\"],\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(tr))\n",
    "print(\"Batch train shapes:\", tuple(xb.shape), tuple(yb.shape))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = make_model_fn(tfm).to(device).eval()\n",
    "\n",
    "# 2.1) Forward sin runtime-encode\n",
    "set_encode_runtime(None)\n",
    "y_hat = _forward_with_cached_orientation(\n",
    "    model=model, x=xb, y=yb, device=device, use_amp=False,\n",
    "    phase_hint={\"train\": None}, phase=\"train\"\n",
    ")\n",
    "print(\"Forward sin runtime -> y_hat:\", tuple(y_hat.shape))\n",
    "\n",
    "# 2.2) Forward con runtime-encode (solo tendrá efecto si xb es 4D)\n",
    "set_encode_runtime(CFG[\"data\"][\"encoder\"], T=int(CFG[\"data\"][\"T\"]), gain=float(CFG[\"data\"][\"gain\"]))\n",
    "y_hat_rt = _forward_with_cached_orientation(\n",
    "    model=model, x=xb, y=yb, device=device, use_amp=False,\n",
    "    phase_hint={\"train\": None}, phase=\"train\"\n",
    ")\n",
    "print(\"Forward con runtime -> y_hat:\", tuple(y_hat_rt.shape))\n",
    "\n",
    "# Limpieza\n",
    "set_encode_runtime(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "933e992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loader OK (2 batches): MAE=0.592529 | MSE=0.369934\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def take(loader, n=2):\n",
    "    for i, batch in enumerate(loader):\n",
    "        if i >= n:\n",
    "            break\n",
    "        yield batch\n",
    "\n",
    "mae, mse = eval_loader(take(te, 2), model, device)\n",
    "print(f\"eval_loader OK (2 batches): MAE={mae:.6f} | MSE={mse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3414950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC Fisher (2 batches) OK\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from src.methods.ewc import EWCMethod\n",
    "\n",
    "model_ewc = make_model_fn(tfm).to(device)  # modelo “limpio”\n",
    "method_ewc = EWCMethod(\n",
    "    model=model_ewc,\n",
    "    lambd=1e6,            # valor cualquiera para el humo\n",
    "    fisher_batches=2,     # rápido\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    device=device,\n",
    ")\n",
    "# Debe terminar sin error de shapes/broadcast\n",
    "method_ewc.after_task(model_ewc, tr, va)\n",
    "print(\"EWC Fisher (2 batches) OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab966274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AS-SNN paso de entrenamiento OK | loss= 4.731475353240967\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "from src.methods.as_snn import AS_SNN\n",
    "\n",
    "model_as = make_model_fn(tfm).to(device).train()\n",
    "opt = optim.Adam(model_as.parameters(), lr=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "method_as = AS_SNN(\n",
    "    gamma_ratio=0.3, lambda_a=1.59168, ema=0.9,\n",
    "    attach_to=\"f6\", measure_at=\"modules\",\n",
    "    penalty_mode=\"l1\", do_synaptic_scaling=False,\n",
    ")\n",
    "# Registrar hooks\n",
    "method_as.before_task(model_as, tr, va)\n",
    "\n",
    "xb, yb = next(iter(tr))\n",
    "y_hat = _forward_with_cached_orientation(\n",
    "    model=model_as, x=xb, y=yb, device=device, use_amp=False,\n",
    "    phase_hint={\"train\": None}, phase=\"train\"\n",
    ")\n",
    "y_al = _align_target_shape(y_hat, yb).to(device=y_hat.device, dtype=y_hat.dtype, non_blocking=True)\n",
    "loss = loss_fn(y_hat, y_al) + method_as.penalty()\n",
    "\n",
    "opt.zero_grad(set_to_none=True)\n",
    "loss.backward()\n",
    "opt.step()\n",
    "\n",
    "print(\"AS-SNN paso de entrenamiento OK | loss=\", float(loss.detach().cpu()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee27bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast_precheck | method=as-snn_gr_0.3_lam_1.59168_att_f6_scale_on | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast_precheck | method=as-snn_gr_0.3_lam_1.59168_att_f6_scale_on | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dry run AS-SNN OK → /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_precheck_as-snn_gr_0.3_lam_1.59168_att_f6_scale_on_rate_model-PilotNetSNN_66x200_gray_seed_42\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast_precheck | method=ewc_lam_1e+06 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast_precheck | method=ewc_lam_1e+06 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dry run EWC OK → /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_precheck_ewc_lam_1e+06_lam_1e+06_rate_model-PilotNetSNN_66x200_gray_seed_42\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from src.runner import run_continual\n",
    "# (si no lo tenías ya) build_components_for / build_task_list_for importados donde corresponda\n",
    "\n",
    "# --- Dry run AS-SNN ---\n",
    "cfg_dry = deepcopy(CFG)\n",
    "cfg_dry[\"optim\"][\"epochs\"] = 1\n",
    "cfg_dry[\"optim\"][\"batch_size\"] = min(64, int(CFG[\"optim\"][\"batch_size\"]))\n",
    "cfg_dry[\"continual\"][\"params\"] = {\n",
    "    \"gamma_ratio\": 0.3, \"lambda_a\": 1.59168, \"ema\": 0.9,\n",
    "    \"attach_to\": \"f6\", \"measure_at\": \"modules\", \"penalty_mode\": \"l1\",\n",
    "    \"do_synaptic_scaling\": True, \"scale_clip\": (0.5, 2.0), \"scale_bias\": False\n",
    "}\n",
    "cfg_dry[\"continual\"][\"method\"] = \"as-snn\"\n",
    "\n",
    "tfm_d, mk_loader_d, mk_model_d = build_components_for(cfg_dry, ROOT)\n",
    "task_list_d, _ = build_task_list_for(cfg_dry, ROOT)\n",
    "\n",
    "# si quieres conservar el alias, hazlo aquí; NO dentro de la llamada\n",
    "cdf_dry = cfg_dry\n",
    "\n",
    "out_dir, res = run_continual(\n",
    "    task_list=task_list_d[:2],  # 2 tareas\n",
    "    make_loader_fn=mk_loader_d,\n",
    "    make_model_fn=mk_model_d,\n",
    "    tfm=tfm_d,\n",
    "    cfg=cfg_dry,                # <- sin walrus\n",
    "    preset_name=f\"{PRESET}_precheck\",\n",
    "    out_root=ROOT / \"outputs\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"Dry run AS-SNN OK →\", out_dir)\n",
    "\n",
    "# --- Dry run EWC (Fisher pequeño) ---\n",
    "cfg_dry2 = deepcopy(cfg_dry)\n",
    "cfg_dry2[\"continual\"][\"method\"] = \"ewc\"\n",
    "cfg_dry2[\"continual\"][\"params\"] = {\"lam\": 1e6, \"fisher_batches\": 2}\n",
    "\n",
    "tfm_d2, mk_loader_d2, mk_model_d2 = build_components_for(cfg_dry2, ROOT)\n",
    "out_dir2, res2 = run_continual(\n",
    "    task_list=task_list_d[:2],\n",
    "    make_loader_fn=mk_loader_d2,\n",
    "    make_model_fn=mk_model_d2,\n",
    "    tfm=tfm_d2,\n",
    "    cfg=cfg_dry2,               # <- sin walrus\n",
    "    preset_name=f\"{PRESET}_precheck\",\n",
    "    out_root=ROOT / \"outputs\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"Dry run EWC OK →\", out_dir2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
