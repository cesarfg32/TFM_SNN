{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c448d5",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# 03_TRAIN_CONTINUAL ‚Äî Entrenamiento Continual con *presets*\n",
    "\n",
    "**Qu√© hace este notebook**  \n",
    "Entrena y eval√∫a modelos en **aprendizaje continual** (secuencia de tareas) usando una **configuraci√≥n unificada** desde `configs/presets.yaml`. Permite:  \n",
    "1) lanzar un *run* base con el m√©todo del preset,  \n",
    "2) **comparar m√©todos** manteniendo fijos datos/modelo, y  \n",
    "3) generar un **resumen agregado** de resultados en `outputs/summary/`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Centralizar la configuraci√≥n de **modelo**, **datos/codificaci√≥n temporal**, **optimizador** y **m√©todo continual** v√≠a `presets.yaml`.\n",
    "- Soportar **H5 offline** (si `use_offline_spikes: true`) o **CSV + codificaci√≥n en runtime** (si `encode_runtime: true`), seleccion√°ndolo de forma coherente con el preset.\n",
    "- Comparar m√©todos (`naive`, `ewc`, `rehearsal`, `rehearsal+ewc`, y los bio-inspirados previstos: `as-snn`, `sa-snn`, `sca-snn`, `colanet`) con **id√©ntica preparaci√≥n de datos**.\n",
    "- Exportar un **CSV de agregados** con m√©tricas clave (MAE/MSE por tarea, olvido absoluto/relativo, etc.).\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "- Haber generado `data/processed/tasks.json` (y opcionalmente `tasks_balanced.json`) con **01_DATA_QC_PREP** o **01A_PREP_BALANCED**.\n",
    "- Si el preset usa **offline** (`use_offline_spikes: true`), haber creado los H5 compatibles con **02_ENCODE_OFFLINE** (mismo `encoder/T/gain/size/to_gray` que el preset).\n",
    "- Revisar `configs/presets.yaml` (secciones `model`, `data`, `optim`, `continual`, `prep`).\n",
    "\n",
    "## ‚ö†Ô∏è Notas importantes\n",
    "- **No combines** `use_offline_spikes: true` y `encode_runtime: true`. El notebook lo detecta y lanza error.\n",
    "- La **semilla** global se toma de `CFG[\"data\"][\"seed\"]` para reproducibilidad.\n",
    "- La carpeta de salida incluye en el nombre preset, m√©todo, *encoder*, modelo, *seed*, etc., para facilitar trazabilidad.\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "\n",
    "- [1) Setup del entorno y paths](#sec-01)  \n",
    "- [2) Carga del preset unificado (`configs/presets.yaml`)](#sec-02)  \n",
    "- [3) Verificaci√≥n de datos y selecci√≥n de `tasks.json`](#sec-03)  \n",
    "- [4) Factories DataLoaders + Modelo (+ tasks)](#sec-04)  \n",
    "- [5) Ejecuci√≥n base con el preset (eco de config + run)](#sec-06)  \n",
    "- [6) Comparativa de m√©todos (mismo preset/semilla/datos)](#sec-07)  \n",
    "- [7) Barrido de combinaciones (opcional)](#sec-08)  \n",
    "- [8) Resumen completo: inventario ‚Üí parseo ‚Üí agregados ‚Üí tabla](#sec-09)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668cb21",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "## 1) Setup del entorno y paths\n",
    "\n",
    "**Objetivo**  \n",
    "Preparar el entorno: limitar hilos BLAS (evitar *oversubscription*), detectar `ROOT` (ra√≠z del repo) y a√±adirlo a `sys.path`, importar utilidades del proyecto y seleccionar dispositivo (`cuda` si est√° disponible). Se activan optimizaciones de PyTorch en GPU (TF32/cuDNN) para acelerar.\n",
    "\n",
    "> Aqu√≠ **no** se leen a√∫n los presets; solo se configura el runtime global. \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 0) Entorno (poner ANTES de importar torch)\n",
    "# =============================================================================\n",
    "import os\n",
    "\n",
    "# Logging opcional (lo usa tu training.py)\n",
    "os.environ[\"TRAIN_LOG_ITPS\"] = \"1\"\n",
    "\n",
    "# Depuraci√≥n rara de kernels (d√©jalo comentado):\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1) Setup del entorno y paths\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import sys, gc, time, json, re\n",
    "import torch\n",
    "\n",
    "# Robustez multiproceso/WSL\n",
    "try:\n",
    "    import torch.multiprocessing as mp\n",
    "    mp.set_sharing_strategy(\"file_system\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models   import build_model\n",
    "from src.utils    import load_preset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "OUT = ROOT / \"outputs\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"OUT :\", OUT)\n",
    "print(\"Device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851cb55",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "\n",
    "## 2) Carga del preset unificado (`configs/presets.yaml`)\n",
    "\n",
    "**Objetivo**  \n",
    "Cargar un **preset** (`fast` | `std` | `accurate`) y derivar toda la configuraci√≥n operativa:\n",
    "\n",
    "- **Modelo/transform**: tama√±o de imagen, escala de grises, etc.\n",
    "- **Datos/codificaci√≥n**: `encoder` (`rate|latency|raw`), `T`, `gain`, `seed`.\n",
    "- **DataLoader**: `num_workers`, `prefetch_factor`, `pin_memory`, `persistent_workers`.\n",
    "- **Augment** opcional y **balanceo online** si procede.\n",
    "\n",
    "Incluye un **guardarra√≠l**: si `use_offline_spikes: true` y `encode_runtime: true` est√°n ambos activos, se aborta con un error claro (config inv√°lida).  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232708c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2) Utils de limpieza y diagn√≥stico de memoria\n",
    "# =============================================================================\n",
    "def cuda_mem():\n",
    "    if torch.cuda.is_available():\n",
    "        try: torch.cuda.synchronize()\n",
    "        except Exception: pass\n",
    "        alloc = torch.cuda.memory_allocated() / (1024**2)\n",
    "        reserv = torch.cuda.memory_reserved() / (1024**2)\n",
    "        return f\"{alloc:.0f} MiB alloc | {reserv:.0f} MiB reserved\"\n",
    "    return \"CPU-only\"\n",
    "\n",
    "def clear_cuda():\n",
    "    try: torch.cuda.synchronize()\n",
    "    except Exception: pass\n",
    "    try: torch.cuda.empty_cache()\n",
    "    except Exception: pass\n",
    "    try: torch.cuda.ipc_collect()\n",
    "    except Exception: pass\n",
    "    gc.collect()\n",
    "\n",
    "def detach_method_like(obj):\n",
    "    \"\"\"Desengancha hooks si existen (detach/close).\"\"\"\n",
    "    if obj is None:\n",
    "        return\n",
    "    for attr in (\"detach\", \"close\"):\n",
    "        if hasattr(obj, attr):\n",
    "            try: getattr(obj, attr)()\n",
    "            except Exception: pass\n",
    "\n",
    "def teardown_run(tfm_obj, extras=()):\n",
    "    \"\"\"Suelta m√©todo/tfm, borra refs grandes y limpia CUDA.\"\"\"\n",
    "    try:\n",
    "        # Por si tfm_obj expone m√©todo/continual con hooks\n",
    "        detach_method_like(tfm_obj)\n",
    "        for maybe in (getattr(tfm_obj, \"method\", None),\n",
    "                      getattr(tfm_obj, \"continual\", None)):\n",
    "            detach_method_like(maybe)\n",
    "    except Exception:\n",
    "        pass\n",
    "    for x in extras:\n",
    "        try: del x\n",
    "        except Exception: pass\n",
    "    clear_cuda()\n",
    "\n",
    "print(\"CUDA mem @start:\", cuda_mem())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5de0d",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "\n",
    "## 3) Verificaci√≥n de datos y selecci√≥n de `tasks.json`\n",
    "\n",
    "**Objetivo**  \n",
    "Construir `task_list` y verificar que existen los *splits* por tarea:\n",
    "\n",
    "- Si el preset pide **balanced** (`prep.use_balanced_tasks: true`) y existe `tasks_balanced.json`, se usa; en caso contrario, se cae a `tasks.json` (se informa).\n",
    "- Se valida que `train/val/test.csv` existen para cada *run*.  \n",
    "- Si entrenas con **H5 offline**, se comprueba que est√°n presentes los H5 con **nomenclatura compatible** con el preset (`encoder/T/gain/size/to_gray`).\n",
    "\n",
    "> Si falta alg√∫n H5 requerido, genera primero con **02_ENCODE_OFFLINE**.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c673a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3) Carga del preset (configs/presets.yaml)\n",
    "# =============================================================================\n",
    "PRESET = \"accurate\"  # \"fast\" para humo, \"accurate\" para resultados\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# ---- Modelo / Transform ----\n",
    "MODEL_NAME = CFG[\"model\"][\"name\"]\n",
    "tfm = ImageTransform(\n",
    "    CFG[\"model\"][\"img_w\"],\n",
    "    CFG[\"model\"][\"img_h\"],\n",
    "    to_gray=bool(CFG[\"model\"][\"to_gray\"]),\n",
    "    crop_top=None,\n",
    ")\n",
    "\n",
    "# ---- Datos / codificaci√≥n ----\n",
    "ENCODER = CFG[\"data\"][\"encoder\"]\n",
    "T       = int(CFG[\"data\"][\"T\"])\n",
    "GAIN    = float(CFG[\"data\"][\"gain\"])\n",
    "SEED    = int(CFG[\"data\"][\"seed\"])\n",
    "\n",
    "USE_OFFLINE_SPIKES = bool(CFG[\"data\"].get(\"use_offline_spikes\", False))\n",
    "RUNTIME_ENCODE     = bool(CFG[\"data\"].get(\"encode_runtime\", False))\n",
    "\n",
    "# ---- Loader / augment / balanceo ----\n",
    "NUM_WORKERS = int(CFG[\"data\"].get(\"num_workers\") or 0)\n",
    "PREFETCH    = int(CFG[\"data\"].get(\"prefetch_factor\") or 2)\n",
    "PIN_MEMORY  = bool(CFG[\"data\"].get(\"pin_memory\", True))\n",
    "PERSISTENT  = bool(CFG[\"data\"].get(\"persistent_workers\", True))\n",
    "\n",
    "AUG_CFG = AugmentConfig(**(CFG[\"data\"].get(\"aug_train\") or {})) \\\n",
    "          if CFG[\"data\"].get(\"aug_train\") else None\n",
    "\n",
    "USE_ONLINE_BALANCING = bool(CFG[\"data\"].get(\"balance_online\", False))\n",
    "BAL_BINS = int(CFG[\"data\"].get(\"balance_bins\") or 50)\n",
    "BAL_EPS  = float(CFG[\"data\"].get(\"balance_smooth_eps\") or 1e-3)\n",
    "\n",
    "if USE_OFFLINE_SPIKES and RUNTIME_ENCODE:\n",
    "    raise RuntimeError(\"Config inv√°lida: use_offline_spikes=True y encode_runtime=True a la vez.\")\n",
    "\n",
    "print(f\"[PRESET={PRESET}] model={MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] encoder={ENCODER} T={T} gain={GAIN} seed={SEED}\")\n",
    "print(f\"[LOADER] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "print(f\"[BALANCE] online={USE_ONLINE_BALANCING} bins={BAL_BINS} eps={BAL_EPS}\")\n",
    "print(f\"[RUNTIME_ENCODE] {RUNTIME_ENCODE} | [OFFLINE_SPIKES] {USE_OFFLINE_SPIKES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926bb4b",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "## 4) Factories unificados: DataLoaders + Modelo (+ tasks)\n",
    "\n",
    "**Objetivo**  \n",
    "Crear, en una sola llamada, los **componentes coherentes con el preset**:\n",
    "\n",
    "- `build_components_for(CFG, ROOT)` ‚Üí devuelve `tfm`, `make_loader_fn`, `make_model_fn`.\n",
    "  - El **loader** respeta autom√°ticamente el modo datos (H5 offline vs. CSV+encode runtime), *workers/prefetch/pin/persistent*, *augment*, y **balanceo online** si est√° activo.\n",
    "  - El **modelo** se instancia seg√∫n `model.name` y par√°metros asociados.\n",
    "- `build_task_list_for(CFG, ROOT)` ‚Üí devuelve `task_list` y el *tasks file* efectivamente usado.\n",
    "\n",
    "> Con esto evitas duplicar l√≥gica entre cuadernos y garantizas que **bench, entrenamiento y comparativa** usen la **misma** configuraci√≥n.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4) Verificaci√≥n de datos (splits y, si procede, H5)\n",
    "# =============================================================================\n",
    "import json\n",
    "from pathlib import Path as _P\n",
    "\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "USE_BALANCED = bool(CFG.get(\"prep\", {}).get(\"use_balanced_tasks\", False))\n",
    "tb_name = (CFG.get(\"prep\", {}).get(\"tasks_balanced_file_name\") or \"tasks_balanced.json\")\n",
    "t_name  = (CFG.get(\"prep\", {}).get(\"tasks_file_name\") or \"tasks.json\")\n",
    "\n",
    "cand_bal = PROC / tb_name\n",
    "cand_std = PROC / t_name\n",
    "TASKS_FILE = cand_bal if (USE_BALANCED and cand_bal.exists()) else cand_std\n",
    "\n",
    "with open(TASKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "print(\"Usando:\", TASKS_FILE.name)\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {_P(t['paths']['train']).name}\")\n",
    "\n",
    "if USE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = _P(tasks_json[\"splits\"][t[\"name\"]][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' en modo balanced, pero encontr√© '{train_path.name}'.\"\n",
    "            )\n",
    "\n",
    "if USE_OFFLINE_SPIKES:\n",
    "    mw, mh = CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"]\n",
    "    color = \"gray\" if CFG[\"model\"][\"to_gray\"] else \"rgb\"\n",
    "    gain_tag = (GAIN if ENCODER == \"rate\" else 0)\n",
    "    missing = []\n",
    "    for t in task_list:\n",
    "        base = PROC / t[\"name\"]\n",
    "        for split in (\"train\", \"val\", \"test\"):\n",
    "            expected = base / f\"{split}_{ENCODER}_T{T}_gain{gain_tag}_{color}_{mw}x{mh}.h5\"\n",
    "            if not expected.exists():\n",
    "                missing.append(str(expected))\n",
    "    if missing:\n",
    "        print(\"[WARN] Faltan H5 compatibles con el preset. Genera con 02_ENCODE_OFFLINE.\")\n",
    "print(\"OK: verificaci√≥n de splits.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bdd076",
   "metadata": {},
   "source": [
    "<a id=\"sec-05\"></a>\n",
    "## 5) Ejecuci√≥n base con el preset (eco de config + run)\n",
    "\n",
    "**Objetivo**  \n",
    "Lanzar **un experimento** con el m√©todo y par√°metros del preset (`CFG[\"continual\"]`). La celda:\n",
    "\n",
    "- Imprime un **resumen de configuraci√≥n** (modelo, datos, loader, m√©todo).\n",
    "- Ejecuta `run_continual(...)`.\n",
    "- Guarda resultados en `outputs/continual_*` (incluye `continual_results.json` y `manifest.json` por tarea).\n",
    "\n",
    "> Revisa la consola para confirmar dispositivo, *encoder/T/gain* y modo de datos (offline/ runtime).  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5) Factories: DataLoaders + Modelo + task_list\n",
    "# =============================================================================\n",
    "from src.utils import build_task_list_for, build_components_for\n",
    "\n",
    "tfm, make_loader_fn, make_model_fn = build_components_for(CFG, ROOT)\n",
    "task_list, tasks_file = build_task_list_for(CFG, ROOT)\n",
    "print(\"Tasks file:\", tasks_file.name)\n",
    "print(\"make_loader_fn listo (usa H5 si offline; si no, CSV + encode runtime).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f15dc1",
   "metadata": {},
   "source": [
    "<a id=\"sec-06\"></a>\n",
    "## 6) Comparativa de m√©todos (mismo preset / misma semilla / mismos datos)\n",
    "\n",
    "**Objetivo**  \n",
    "Ejecutar una **bater√≠a de m√©todos** cambiando **solo** `continual.method` y sus `params`, manteniendo fijos: preset, semilla, *encoder/T/gain*, tama√±o de imagen, *augment*, etc.\n",
    "\n",
    "- Se clona `CFG` por m√©todo y se invoca `run_continual(...)` con las **factories** del propio `cfg_i`.\n",
    "- El diccionario `METHODS` puede ampliarse con nombres registrados en `src/methods/`:\n",
    "  - `naive`, `ewc`, `rehearsal`, `rehearsal+ewc`\n",
    "  - (bio-inspirados previstos) `as-snn`, `sa-snn`, `sca-snn`, `colanet`\n",
    "\n",
    "**Recomendaciones**\n",
    "- Si usas **offline H5**, aseg√∫rate de que existen para el preset (`02_ENCODE_OFFLINE`).\n",
    "- Si activas *replay* (rehearsal), puedes **reducir** `persistent_workers` para evitar atascos de DataLoader en algunos entornos; la celda ya lo ajusta como precauci√≥n.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f64d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6) Barrido \"mejor por m√©todo\" (accurate, T=30, B=160)\n",
    "# =============================================================================\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from src.runner import run_continual\n",
    "from src.utils  import load_preset, build_task_list_for, build_components_for\n",
    "\n",
    "# Re-cargo preset limpio (por si tocamos el dict en el loop)\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "print(\"[SANITY] torch:\", torch.__version__, \"| cuda:\", torch.cuda.is_available(),\n",
    "      \"| dev_count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"[SANITY] device:\", torch.cuda.current_device(),\n",
    "          \"|\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print(\"[SANITY] CFG.optim.amp =\", CFG[\"optim\"].get(\"amp\", None))\n",
    "\n",
    "# === Selecci√≥n de runs (modula aqu√≠) ===\n",
    "EXPS = [\n",
    "    # SCA-SNN ganador previo (tu mejor actual)\n",
    "    dict(\n",
    "        method=\"sca-snn\",\n",
    "        params={\n",
    "            \"attach_to\": \"f6\",\n",
    "            \"flatten_spatial\": False,\n",
    "            \"num_bins\": 50,\n",
    "            \"anchor_batches\": 16,\n",
    "            \"beta\": 0.60,\n",
    "            \"bias\": 0.05,\n",
    "            \"soft_mask_temp\": 0.50,\n",
    "            \"verbose\": False,\n",
    "            \"log_every\": 65536\n",
    "        },\n",
    "        tag=\"best_sca_b060_bias005_t050_ab16\"\n",
    "    ),\n",
    "\n",
    "    # L√≠nea base naive (√∫til para sanity y comparar footprint)\n",
    "    dict(method=\"naive\", params={}, tag=\"baseline_naive\"),\n",
    "]\n",
    "\n",
    "EXPS = [\n",
    "    # ---------- SCA-SNN (Similarity/Context-Aware gating) ----------\n",
    "    # Base actual (referencia)\n",
    "    # dict(\n",
    "    #     method=\"sca-snn\",\n",
    "    #     params={\"attach_to\":\"f6\",\"flatten_spatial\":False,\"num_bins\":50,\"anchor_batches\":16,\n",
    "    #             \"beta\":0.60,\"bias\":0.05,\"soft_mask_temp\":0.50,\"verbose\":False,\"log_every\":65536},\n",
    "    #     tag=\"sca_ref_b060_bias005_t050_ab16\"\n",
    "    # ),\n",
    "    # SCA-1: gating m√°s laxo (puede reducir olvido a costa de algo de MAE)\n",
    "    dict(\n",
    "        method=\"sca-snn\",\n",
    "        params={\"attach_to\":\"f6\",\"flatten_spatial\":False,\"num_bins\":50,\"anchor_batches\":16,\n",
    "                \"beta\":0.55,\"bias\":0.00,\"soft_mask_temp\":0.30,\"verbose\":False,\"log_every\":65536},\n",
    "        tag=\"sca_looser_b055_bias000_t030_ab16\"\n",
    "    ),\n",
    "    # SCA-2: gating m√°s estricto y anclas m√°s finas (puede bajar MAE si no estrangula)\n",
    "    dict(\n",
    "        method=\"sca-snn\",\n",
    "        params={\"attach_to\":\"f6\",\"flatten_spatial\":False,\"num_bins\":80,\"anchor_batches\":16,\n",
    "                \"beta\":0.65,\"bias\":0.05,\"soft_mask_temp\":0.00,\"verbose\":False,\"log_every\":65536},\n",
    "        tag=\"sca_hard_b065_bias005_t000_bins80\"\n",
    "    ),\n",
    "    # SCA-3: m√°s anclas (estabilidad de bins), bias mayor para reuso ‚Äúconservador‚Äù\n",
    "    dict(\n",
    "        method=\"sca-snn\",\n",
    "        params={\"attach_to\":\"f6\",\"flatten_spatial\":False,\"num_bins\":50,\"anchor_batches\":24,\n",
    "                \"beta\":0.60,\"bias\":0.10,\"soft_mask_temp\":0.50,\"verbose\":False,\"log_every\":65536},\n",
    "        tag=\"sca_moreanchors_b060_bias010_t050_ab24\"\n",
    "    ),\n",
    "\n",
    "    # ---------- SA-SNN (Sparse Selective Activation) ----------\n",
    "    # Ref (tu ‚Äúbest_sa_k8_tau28_p2m‚Äù)\n",
    "    dict(\n",
    "        method=\"sa-snn\",\n",
    "        params={\"attach_to\":\"f6\",\"k\":8,\"tau\":28.0,\"th_min\":1.0,\"th_max\":2.0,\n",
    "                \"p\":2_000_000,\"vt_scale\":1.0,\"flatten_spatial\":False,\n",
    "                \"assume_binary_spikes\":False,\"reset_counters_each_task\":False},\n",
    "        tag=\"sa_ref_k8_tau28_p2m\"\n",
    "    ),\n",
    "    # SA-1: algo m√°s agresivo en selectividad (k menos, tau menor)\n",
    "    dict(\n",
    "        method=\"sa-snn\",\n",
    "        params={\"attach_to\":\"f6\",\"k\":6,\"tau\":24.0,\"th_min\":1.0,\"th_max\":2.0,\n",
    "                \"p\":2_000_000,\"vt_scale\":1.2,\"flatten_spatial\":False,\n",
    "                \"assume_binary_spikes\":False,\"reset_counters_each_task\":False},\n",
    "        tag=\"sa_k6_tau24_vt1p2\"\n",
    "    ),\n",
    "    # SA-2: k mayor + tau mayor (m√°s estabilidad, posible mejor MAE; vigilar olvido)\n",
    "    dict(\n",
    "        method=\"sa-snn\",\n",
    "        params={\"attach_to\":\"f6\",\"k\":10,\"tau\":32.0,\"th_min\":1.0,\"th_max\":2.0,\n",
    "                \"p\":5_000_000,\"vt_scale\":1.0,\"flatten_spatial\":False,\n",
    "                \"assume_binary_spikes\":False,\"reset_counters_each_task\":False},\n",
    "        tag=\"sa_k10_tau32_p5m\"\n",
    "    ),\n",
    "    # SA-3: probar flatten_spatial=True (menos memoria y distinta granularidad)\n",
    "    dict(\n",
    "        method=\"sa-snn\",\n",
    "        params={\"attach_to\":\"f6\",\"k\":8,\"tau\":28.0,\"th_min\":1.0,\"th_max\":2.0,\n",
    "                \"p\":2_000_000,\"vt_scale\":1.0,\"flatten_spatial\":True,\n",
    "                \"assume_binary_spikes\":False,\"reset_counters_each_task\":False},\n",
    "        tag=\"sa_k8_tau28_flatten\"\n",
    "    ),\n",
    "\n",
    "    # ---------- AS-SNN (Adaptive Synaptic Scaling + actividad) ----------\n",
    "    # Ref (tu mejor AS con f6/modules, L1, sin scaling)\n",
    "    dict(\n",
    "        method=\"as-snn\",\n",
    "        params={\"gamma_ratio\":0.30,\"lambda_a\":1.59168,\"ema\":0.90,\n",
    "                \"attach_to\":\"f6\",\"measure_at\":\"modules\",\"penalty_mode\":\"l1\",\n",
    "                \"do_synaptic_scaling\":False},\n",
    "        tag=\"as_ref_gr03_lam1p59168\"\n",
    "    ),\n",
    "    # AS-1: reduce gamma_ratio (menos penalizaci√≥n actividad -> menor olvido)\n",
    "    dict(\n",
    "        method=\"as-snn\",\n",
    "        params={\"gamma_ratio\":0.25,\"lambda_a\":1.20,\"ema\":0.90,\n",
    "                \"attach_to\":\"f6\",\"measure_at\":\"modules\",\"penalty_mode\":\"l1\",\n",
    "                \"do_synaptic_scaling\":False},\n",
    "        tag=\"as_soft_gr025_lam1p20\"\n",
    "    ),\n",
    "    # AS-2: activa synaptic_scaling (reajuste por tarea) + EMA m√°s alta\n",
    "    dict(\n",
    "        method=\"as-snn\",\n",
    "        params={\"gamma_ratio\":0.35,\"lambda_a\":1.80,\"ema\":0.95,\n",
    "                \"attach_to\":\"f6\",\"measure_at\":\"modules\",\"penalty_mode\":\"l1\",\n",
    "                \"do_synaptic_scaling\":True,\"scale_clip\":(0.5,2.0),\"scale_bias\":False},\n",
    "        tag=\"as_scaling_gr035_lam1p80_ema095\"\n",
    "    ),\n",
    "\n",
    "    # ---------- L√≠nea base ----------\n",
    "    dict(method=\"naive\", params={}, tag=\"baseline_naive\"),\n",
    "]\n",
    "\n",
    "\n",
    "# Dataloader ‚Äúseguro‚Äù (si a√∫n ves fugas, pon True):\n",
    "SAFE_DATALOADER_FOR_ALL = False   # si True: num_workers=0 y sin persistentes\n",
    "SLEEP_BETWEEN_RUNS_SEC  = 1.0\n",
    "\n",
    "OUT = ROOT / \"outputs\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"CUDA before loop:\", cuda_mem()); clear_cuda()\n",
    "runs_out = []\n",
    "\n",
    "for idx, exp in enumerate(EXPS, start=1):\n",
    "    method_name   = exp[\"method\"]\n",
    "    method_params = exp[\"params\"]\n",
    "\n",
    "    cfg_i = deepcopy(CFG)\n",
    "    cfg_i[\"continual\"][\"method\"] = method_name\n",
    "    cfg_i[\"continual\"][\"params\"] = method_params\n",
    "    cfg_i.setdefault(\"naming\", {})\n",
    "    cfg_i[\"naming\"][\"tag\"] = exp[\"tag\"]\n",
    "\n",
    "    # Seguridad dataloader en WSL/Windows: evita workers persistentes (fuga t√≠pica)\n",
    "    cfg_i[\"data\"][\"persistent_workers\"] = False\n",
    "    if SAFE_DATALOADER_FOR_ALL:\n",
    "        cfg_i[\"data\"][\"num_workers\"] = 0\n",
    "        cfg_i[\"data\"][\"pin_memory\"]  = False\n",
    "\n",
    "    tfm_i, make_loader_fn_i, make_model_fn_i = build_components_for(cfg_i, ROOT)\n",
    "    task_list_i, tasks_file_i = build_task_list_for(cfg_i, ROOT)\n",
    "\n",
    "    print(f\"\\n=== RUN {idx}/{len(EXPS)} preset={PRESET} : method={method_name} | tag={exp['tag']} ===\")\n",
    "    print(\"CUDA pre-run:\", cuda_mem())\n",
    "\n",
    "    try:\n",
    "        out_dir, _ = run_continual(\n",
    "            task_list=task_list_i,\n",
    "            make_loader_fn=make_loader_fn_i,\n",
    "            make_model_fn=make_model_fn_i,\n",
    "            tfm=tfm_i,\n",
    "            cfg=cfg_i,\n",
    "            preset_name=PRESET,\n",
    "            out_root=OUT,\n",
    "            verbose=True,\n",
    "        )\n",
    "        runs_out.append(out_dir)\n",
    "        print(\"[OK]\", out_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Fall√≥ method={method_name} tag={exp['tag']}: {type(e).__name__}: {e}\")\n",
    "    finally:\n",
    "        # Desmontaje FUERTE entre runs\n",
    "        teardown_run(\n",
    "            tfm_i,\n",
    "            extras=(make_loader_fn_i, make_model_fn_i, task_list_i, tasks_file_i, cfg_i)\n",
    "        )\n",
    "        print(\"CUDA post-run:\", cuda_mem())\n",
    "        time.sleep(SLEEP_BETWEEN_RUNS_SEC)\n",
    "\n",
    "print(\"\\nHecho:\", [str(p) for p in runs_out])\n",
    "print(\"CUDA after loop:\", cuda_mem())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0650365",
   "metadata": {},
   "source": [
    "<a id=\"sec-07\"></a>\n",
    "## 7) Resumen completo: inventario ‚Üí parseo ‚Üí agregados ‚Üí tabla\n",
    "\n",
    "**Objetivo**  \n",
    "Crear un **resumen reproducible** de todos los *runs*:\n",
    "\n",
    "- **Inventario** de carpetas `outputs/continual_*`.\n",
    "- **Parseo** de nombres para extraer `preset`, `m√©todo`, `encoder`, `seed`, `modelo`, y par√°metros relevantes.\n",
    "- C√°lculo de **olvido** (absoluto y relativo) y **agregados** por grupo (media, œÉ, n).\n",
    "- Export a `outputs/summary/continual_summary_agg.csv` y **tabla formateada** para la memoria.\n",
    "\n",
    "> Si no se detectan *runs*, verifica que exista `continual_results.json` dentro de cada carpeta.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7) Resumen y gr√°ficas\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.results_io import build_results_table\n",
    "from src.plots import plot_across_runs\n",
    "\n",
    "summary_dir = OUT / \"summary\"\n",
    "summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def canonical_method(s: str) -> str:\n",
    "    if not isinstance(s, str): return \"unknown\"\n",
    "    t = s.lower()\n",
    "    if (\"rehearsal\" in t) and (\"+ewc\" in t or \"_ewc\" in t): return \"rehearsal+ewc\"\n",
    "    if \"sca-snn\" in t: return \"sca-snn\"\n",
    "    if re.search(r\"\\bsa[-_]snn\\b\", t): return \"sa-snn\"\n",
    "    if re.search(r\"\\bas[-_]snn\\b\", t): return \"as-snn\"\n",
    "    if \"colanet\" in t: return \"colanet\"\n",
    "    if re.search(r\"\\bewc\\b\", t) or \"ewc_lam\" in t: return \"ewc\"\n",
    "    if \"rehearsal\" in t: return \"rehearsal\"\n",
    "    if \"naive\" in t or \"finetune\" in t or \"fine-tune\" in t: return \"naive\"\n",
    "    return t.split(\"_\")[0]\n",
    "\n",
    "df = build_results_table(OUT)\n",
    "df[\"method_base\"] = df[\"method\"].astype(str).apply(canonical_method)\n",
    "display(df)\n",
    "df.to_csv(summary_dir / \"results_table.csv\", index=False)\n",
    "print(f\"[OK] Tabla guardada en {summary_dir/'results_table.csv'}\")\n",
    "\n",
    "plots_dir = plot_across_runs(df, summary_dir / \"plots\")\n",
    "print(\"[OK] Gr√°ficas comparativas en:\", plots_dir)\n",
    "\n",
    "# (opcional) Curvas de loss del run m√°s reciente\n",
    "def plot_losses_for_run(run_dir: Path, outdir: Path):\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    task_dirs = sorted(run_dir.glob(\"task_*\"))\n",
    "    if not task_dirs:\n",
    "        print(f\"[WARN] No hay task_* en {run_dir}\")\n",
    "        return\n",
    "    for td in task_dirs:\n",
    "        man = None\n",
    "        for cand in (\"manifest.json\", \"metrics.json\"):\n",
    "            p = td / cand\n",
    "            if p.exists():\n",
    "                with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "                    man = json.load(f)\n",
    "                break\n",
    "        if man is None:\n",
    "            print(f\"[WARN] Sin manifest/metrics en {td.name}\")\n",
    "            continue\n",
    "        hist = (man.get(\"history\") or {})\n",
    "        tr = hist.get(\"train_loss\") or []\n",
    "        va = hist.get(\"val_loss\") or []\n",
    "        if not tr and not va:\n",
    "            print(f\"[WARN] {td.name}: sin 'train_loss'/'val_loss'.\")\n",
    "            continue\n",
    "        plt.figure(figsize=(7,4))\n",
    "        if tr: plt.plot(range(1, len(tr)+1), tr, label=\"train_loss\")\n",
    "        if va: plt.plot(range(1, len(va)+1), va, label=\"val_loss\")\n",
    "        plt.title(f\"{run_dir.name} ‚Äî {td.name}\")\n",
    "        plt.xlabel(\"Epoch\"); plt.ylabel(\"MSE loss\"); plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outdir / f\"{run_dir.name}__{td.name}_loss.png\", dpi=160)\n",
    "        plt.savefig(outdir / f\"{run_dir.name}__{td.name}_loss.svg\")\n",
    "        plt.show()\n",
    "\n",
    "runs = sorted(OUT.glob(\"continual_*\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if runs:\n",
    "    loss_plots_dir = summary_dir / \"loss_curves\"\n",
    "    print(\"Generando curvas de loss para:\", runs[0].name)\n",
    "    plot_losses_for_run(runs[0], loss_plots_dir)\n",
    "    print(\"[OK] Curvas de loss en:\", loss_plots_dir)\n",
    "else:\n",
    "    print(\"[INFO] No hay runs en outputs/ todav√≠a.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
