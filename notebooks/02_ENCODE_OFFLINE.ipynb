{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "# 02 ‚Äî Codificaci√≥n **offline** a H5 (formato v2)\n",
    "\n",
    "Convierte los *splits* CSV (`train/val/test`) ya preparados en **archivos H5** con codificaci√≥n temporal. Es la v√≠a recomendada cuando el preset activa `data.use_offline_spikes: true` y `data.encode_runtime: false`, porque **acelera la E/S** y fija exactamente los mismos eventos para todos los m√©todos.\n",
    "\n",
    "**Qu√© hace este notebook**\n",
    "\n",
    "- Localiza el fichero de tareas **seg√∫n el preset**: usa `tasks_balanced.json` si `prep.use_balanced_tasks: true` **y** existe; si no, cae a `tasks.json` (se avisa en consola).\n",
    "- Para cada *run* y *split*, lee el CSV correspondiente y **aplica la codificaci√≥n temporal** (`rate` | `latency` | `raw`) con los par√°metros del preset (`T`, `gain`, `img_w/img_h`, `to_gray`).\n",
    "- Escribe H5 con **formato v2** auto-descriptivo y **nomenclatura estable** (incluye `encoder`, `T`, `gain`, `gray|rgb`, `W√óH`).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "- Haber generado los CSV con **uno** de estos cuadernos:\n",
    "  - `01_DATA_QC_PREP.ipynb` (QC + *splits* sin balanceo), **o**\n",
    "  - `01A_PREP_BALANCED.ipynb` (QC + *splits* y, si lo activas, `train_balanced.csv`).\n",
    "- Estructura de datos (se admiten **m√∫ltiples vueltas** por circuito):\n",
    "    - `data/raw/udacity/<circuito>/<vuelta>/{driving_log.csv, IMG/}`\n",
    "    - `data/processed/<circuito>/{train.csv, val.csv, test.csv[, train_balanced.csv]}`\n",
    "    - `data/processed/tasks.json[, tasks_balanced.json]`\n",
    "\n",
    "\n",
    "**Salidas**\n",
    "- Un H5 por combinaci√≥n (`run`, `split`):\n",
    "- `data/processed/<run>/<split>_<encoder>T<T>gain<g><gray|rgb><W>x<H>.h5`\n",
    "\n",
    "> Convenci√≥n: si `encoder != \"rate\"`, el sufijo se fija a `gain0`.\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "\n",
    "- [1) Configuraci√≥n de codificaci√≥n (par√°metros y rutas)](#sec-01)\n",
    "- [2) Generaci√≥n de H5 para todos los `RUNS √ó SPLITS`](#sec-02)\n",
    "- [3) Inspecci√≥n QC de un H5 (atributos, formas y proyecci√≥n)](#sec-03)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35122dde",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "## 1) Configuraci√≥n de la **codificaci√≥n offline** a H5\n",
    "\n",
    "**Objetivo**  \n",
    "Dejar listos los par√°metros de codificaci√≥n temporal y las rutas base. Esta celda:\n",
    "\n",
    "- Lee el **preset** (`fast|std|accurate`) desde `configs/presets.yaml`.\n",
    "- Fija:\n",
    "- `ENCODER` (`rate` | `latency` | `raw`)\n",
    "- `T` y `GAIN` (solo afecta a `rate`)\n",
    "- `SIZE = (W, H)` y `TO_GRAY`\n",
    "- `SEED` (para reproducibilidad si la codificaci√≥n usa estocasticidad)\n",
    "- Detecta el fichero de tareas a usar (`tasks_balanced.json` o `tasks.json`) seg√∫n el preset.\n",
    "- Construye `RUNS` y `SPLITS = [\"train\",\"val\",\"test\"]`.\n",
    "\n",
    "**Consejos**\n",
    "\n",
    "- Puedes cambiar `PRESET = \"...\"` para probar distintas combinaciones (`T`, `gain`, gris/RGB).\n",
    "- El bloque **‚ÄúHelper multi-PRESET‚Äù** te permite lanzar **varios presets** seguidos sin duplicar la l√≥gica.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95715a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1) Imports & params (desde presets.yaml)\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import sys, json\n",
    "import pandas as pd  # opcional, por si inspeccionas algo\n",
    "\n",
    "# ---- STUBS para el linter (Pylance) ----\n",
    "from typing import Optional\n",
    "SAMPLE_OUT: Optional[Path] = None          # se asigna en la Celda 2\n",
    "SAMPLE_OUTS: list[tuple[str, Optional[Path]]] = []  # se rellena en la Celda 2\n",
    "# ----------------------------------------\n",
    "\n",
    "# Ra√≠z del repo y sys.path\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# APIs del proyecto\n",
    "from src.config import load_preset\n",
    "from src.prep.encode_offline import encode_csv_to_h5\n",
    "\n",
    "# --- Lee preset base ---\n",
    "PRESET = \"std\"  # fast | std | accurate (puedes cambiarlo)\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# --- Params robustos del preset ---\n",
    "ENCODER = str(CFG[\"data\"][\"encoder\"])\n",
    "T       = int(CFG[\"data\"][\"T\"])\n",
    "GAIN    = float(CFG[\"data\"][\"gain\"])\n",
    "SIZE    = (int(CFG[\"model\"][\"img_w\"]), int(CFG[\"model\"][\"img_h\"]))  # (W, H)\n",
    "TO_GRAY = bool(CFG[\"model\"][\"to_gray\"])\n",
    "SEED    = int(CFG[\"data\"][\"seed\"])\n",
    "\n",
    "# --- Rutas base ---\n",
    "RAW_ROOT  = ROOT / \"data\" / \"raw\" / \"udacity\"\n",
    "PROC_ROOT = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# --- Selecci√≥n de fichero de tasks seg√∫n preset ---\n",
    "USE_BALANCED = bool(CFG.get(\"prep\", {}).get(\"use_balanced_tasks\", False))\n",
    "tasks_balanced_name = (CFG.get(\"prep\", {}).get(\"tasks_balanced_file_name\") or \"tasks_balanced.json\")\n",
    "tasks_plain_name    = (CFG.get(\"prep\", {}).get(\"tasks_file_name\") or \"tasks.json\")\n",
    "\n",
    "candidate = PROC_ROOT / (tasks_balanced_name if USE_BALANCED else tasks_plain_name)\n",
    "if candidate.exists():\n",
    "    TASKS_PATH = candidate\n",
    "else:\n",
    "    # Fallback sensato a tasks.json si el balanced no existe\n",
    "    fallback = PROC_ROOT / tasks_plain_name\n",
    "    if candidate != fallback:\n",
    "        print(f\"[WARN] No existe {candidate.name}; usando {fallback.name} en su lugar.\")\n",
    "    TASKS_PATH = fallback\n",
    "\n",
    "TASKS  = json.loads(TASKS_PATH.read_text(encoding=\"utf-8\"))\n",
    "RUNS   = TASKS[\"tasks_order\"]\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# --- Echo de configuraci√≥n efectiva ---\n",
    "print(f\"[PRESET={PRESET}] encoder={ENCODER} T={T} gain={GAIN} | size={SIZE} gray={TO_GRAY} | seed={SEED}\")\n",
    "print(\"Usando tasks:\", TASKS_PATH.name, \"| balanced:\", USE_BALANCED)\n",
    "print(\"RUNS:\", RUNS)\n",
    "\n",
    "# =============================================================================\n",
    "# 1-bis) Helper multi-PRESET (opcional). No rompe el flujo single-PRESET.\n",
    "# =============================================================================\n",
    "EXTRA_PRESETS = []  # [\"rate_t10_gray\", \"rate_t16_rgb\", \"latency_t16_gray\"]\n",
    "\n",
    "def _encode_for_preset(preset_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Carga el preset dado y devuelve todo lo necesario para ejecutar el encode\n",
    "    sin depender de variables globales de esta celda.\n",
    "    \"\"\"\n",
    "    CFGp = load_preset(ROOT / \"configs\" / \"presets.yaml\", preset_name)\n",
    "\n",
    "    ENCODERp = str(CFGp[\"data\"][\"encoder\"])\n",
    "    Tp       = int(CFGp[\"data\"][\"T\"])\n",
    "    GAINp    = float(CFGp[\"data\"][\"gain\"])\n",
    "    SIZEp    = (int(CFGp[\"model\"][\"img_w\"]), int(CFGp[\"model\"][\"img_h\"]))  # (W,H)\n",
    "    TO_GRAYp = bool(CFGp[\"model\"][\"to_gray\"])\n",
    "    SEEDp    = int(CFGp[\"data\"][\"seed\"])\n",
    "\n",
    "    USE_BALANCEDp = bool(CFGp.get(\"prep\", {}).get(\"use_balanced_tasks\", False))\n",
    "    tasks_balanced_name_p = (CFGp.get(\"prep\", {}).get(\"tasks_balanced_file_name\") or \"tasks_balanced.json\")\n",
    "    tasks_plain_name_p    = (CFGp.get(\"prep\", {}).get(\"tasks_file_name\") or \"tasks.json\")\n",
    "\n",
    "    candidate_p  = PROC_ROOT / (tasks_balanced_name_p if USE_BALANCEDp else tasks_plain_name_p)\n",
    "    TASKS_PATHp  = candidate_p if candidate_p.exists() else (PROC_ROOT / tasks_plain_name_p)\n",
    "    TASKSp       = json.loads(TASKS_PATHp.read_text(encoding=\"utf-8\"))\n",
    "    RUNSp        = TASKSp[\"tasks_order\"]\n",
    "    SPLITSp      = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    return dict(\n",
    "        ENCODER=ENCODERp, T=Tp, GAIN=GAINp, SIZE=SIZEp, TO_GRAY=TO_GRAYp, SEED=SEEDp,\n",
    "        TASKS=TASKSp, TASKS_PATH=TASKS_PATHp, RUNS=RUNSp, SPLITS=SPLITSp, USE_BALANCED=USE_BALANCEDp\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d555f",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "## 2) Generaci√≥n de H5 (formato **v2**) para todos los RUNS √ó SPLITS\n",
    "\n",
    "**Qu√© hace**\n",
    "\n",
    "- Recorre cada `run` y `split`, comprueba la existencia de los CSV y llama a `encode_csv_to_h5(...)`.\n",
    "- Escribe un H5 por salida con **nomenclatura determinista**:\n",
    "    - `<split>_<encoder>T<T>gain<g><gray|rgb><W>x<H>.h5`\n",
    "- Guarda en `SAMPLE_OUT` el **primer H5** generado para inspecci√≥n r√°pida en la celda 3.\n",
    "- Si indicas varios presets en `EXTRA_PRESETS`, repetir√° el proceso para cada uno.\n",
    "\n",
    "**Formato H5 v2**\n",
    "\n",
    "- **Atributos** (metadatos del archivo):\n",
    "- `version = 2`\n",
    "- `encoder`, `T`, `gain`\n",
    "- `size_wh = [W, H]`\n",
    "- `to_gray`\n",
    "- `channels` (1 √≥ 3)\n",
    "- **Datasets**:\n",
    "- `/spikes`:\n",
    "  - gris ‚Üí `(N, T, H, W)`\n",
    "  - RGB  ‚Üí `(N, T, C, H, W)`\n",
    "  - tipo:\n",
    "    - `rate`/`raw` ‚Üí `uint8`\n",
    "    - `latency` ‚Üí `float32`\n",
    "- `/steering` ‚Üí `(N,)`\n",
    "- `/filenames` ‚Üí `(N,)` (rutas relativas para trazabilidad)\n",
    "\n",
    "**Idempotencia y limpieza**\n",
    "\n",
    "- **No hace falta borrar** H5 antiguos al cambiar par√°metros: el **nombre de salida cambia** (no se pisan).\n",
    "- Si quieres ahorrar espacio, elimina manualmente H5 viejos que no uses.\n",
    "- Si `tasks_balanced.json` no existe pero el preset pide usarlo, se **avisa** y se cae a `tasks.json`.\n",
    "\n",
    "**Errores t√≠picos y soluci√≥n**\n",
    "\n",
    "- *‚ÄúNo existe CSV/H5 esperado‚Äù* ‚Üí ejecuta antes `01A_PREP_BALANCED` (o `01_DATA_QC_PREP`) y revisa `tasks*.json`.\n",
    "- *‚ÄúForma inesperada‚Äù* al entrenar ‚Üí aseg√∫rate de que `to_gray` y `W√óH` del preset **coinciden** con los H5 generados.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b67176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2) Generar H5 (uno o varios PRESETs)\n",
    "# =============================================================================\n",
    "# --- STUBS para el linter (si ejecutas esta celda suelta) ---\n",
    "SAMPLE_OUTS = []   # <- stub para Pylance\n",
    "SAMPLE_OUT = None  # <- stub para Pylance\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.prep.encode_offline import encode_csv_to_h5\n",
    "\n",
    "if \"ROOT\" not in globals():\n",
    "    ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if \"RAW_ROOT\" not in globals():\n",
    "    RAW_ROOT  = ROOT / \"data\" / \"raw\" / \"udacity\"\n",
    "if \"PROC_ROOT\" not in globals():\n",
    "    PROC_ROOT = ROOT / \"data\" / \"processed\"\n",
    "if \"PRESET\" not in globals():\n",
    "    PRESET = \"fast\"\n",
    "if \"EXTRA_PRESETS\" not in globals():\n",
    "    EXTRA_PRESETS = []\n",
    "\n",
    "# --- Ejecuta encode para el preset principal y los extra (si los hay) ---\n",
    "PRESETS_TO_RUN = [PRESET] + list(EXTRA_PRESETS)\n",
    "\n",
    "for P in PRESETS_TO_RUN:\n",
    "    info = _encode_for_preset(P)\n",
    "\n",
    "    ENCODER = info[\"ENCODER\"]; T = info[\"T\"]; GAIN = info[\"GAIN\"]\n",
    "    SIZE = info[\"SIZE\"]; TO_GRAY = info[\"TO_GRAY\"]; SEED = info[\"SEED\"]\n",
    "    RUNS = info[\"RUNS\"]; SPLITS = info[\"SPLITS\"]\n",
    "\n",
    "    print(f\"\\n=== PRESET={P} | encoder={ENCODER} T={T} gain={GAIN} size={SIZE} gray={TO_GRAY} seed={SEED} ===\")\n",
    "    print(\"Usando tasks:\", info[\"TASKS_PATH\"].name, \"| balanced:\", info[\"USE_BALANCED\"])\n",
    "    print(\"RUNS:\", RUNS)\n",
    "\n",
    "    color_tag = \"gray\" if TO_GRAY else \"rgb\"\n",
    "    gain_tag  = GAIN if ENCODER == \"rate\" else 0\n",
    "    W, H = SIZE\n",
    "    SAMPLE_OUT = None\n",
    "\n",
    "    for run in RUNS:\n",
    "        base = RAW_ROOT / run\n",
    "        outdir = PROC_ROOT / run\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "        assert base.exists(), f\"No existe carpeta de im√°genes: {base}\"\n",
    "\n",
    "        paths = info[\"TASKS\"][\"splits\"][run]\n",
    "        for split in SPLITS:\n",
    "            csv = Path(paths[split])\n",
    "            if not csv.is_absolute():\n",
    "                csv = ROOT / csv\n",
    "            assert csv.exists(), f\"No existe CSV: {csv}\"\n",
    "\n",
    "            out = outdir / f\"{split}_{ENCODER}_T{T}_gain{gain_tag}_{color_tag}_{W}x{H}.h5\"\n",
    "            encode_csv_to_h5(\n",
    "                csv_df_or_path=csv, base_dir=base, out_path=out,\n",
    "                encoder=ENCODER, T=T, gain=GAIN, size_wh=(W, H),\n",
    "                to_gray=TO_GRAY, seed=SEED\n",
    "            )\n",
    "            print(\"OK:\", out)\n",
    "            if SAMPLE_OUT is None:\n",
    "                SAMPLE_OUT = out\n",
    "\n",
    "    SAMPLE_OUTS.append((P, SAMPLE_OUT))\n",
    "\n",
    "print(\"\\nHecho.\")\n",
    "for P, out in SAMPLE_OUTS:\n",
    "    print(f\"Ejemplo de salida [{P}]:\", out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabe455",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "## 3) Inspecci√≥n r√°pida del H5 generado (formato v2)\n",
    "\n",
    "**Qu√© verifica esta celda**\n",
    "\n",
    "- Abre `SAMPLE_OUT` y muestra:\n",
    "- **Atributos** (comprueba `version=2`, `encoder`, `T`, `gain`, `size_wh`, `to_gray`, `channels`).\n",
    "- **Datasets** disponibles y sus **formas/tipos**.\n",
    "- Calcula y dibuja una **proyecci√≥n acumulada** del primer ejemplo:\n",
    "- gris: `sum` sobre `T` ‚Üí `H√óW`\n",
    "- RGB: `sum` sobre `T` y `C` ‚Üí `H√óW`\n",
    "\n",
    "**C√≥mo interpretarlo**\n",
    "\n",
    "- En `rate/raw` (binario, `uint8`), la proyecci√≥n refleja **densidad de actividad** por p√≠xel.\n",
    "- En `latency` (`float32`), revisa que los valores sigan la convenci√≥n del codificador (p. ej., latencia/‚àí1).\n",
    "\n",
    "**Siguientes pasos**\n",
    "\n",
    "- Si la inspecci√≥n es correcta y tu preset pretende usar H5, aseg√∫rate de tener:\n",
    "```yaml\n",
    "  data:\n",
    "    use_offline_spikes: true\n",
    "    encode_runtime: false\n",
    "```\n",
    "\n",
    "Despu√©s puedes pasar directamente a `03_TRAIN_CONTINUAL.ipynb`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3) Inspecci√≥n del H5 (formato oficial v2)\n",
    "# =============================================================================\n",
    "# --- STUBS para el linter (si ejecutas esta celda suelta) ---\n",
    "SAMPLE_OUTS = globals().get(\"SAMPLE_OUTS\", [])\n",
    "SAMPLE_OUT = globals().get(\"SAMPLE_OUT\", None)\n",
    "\n",
    "from pathlib import Path\n",
    "import h5py, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "if SAMPLE_OUT is None and SAMPLE_OUTS:\n",
    "    SAMPLE_OUT = SAMPLE_OUTS[0][1]\n",
    "if SAMPLE_OUT is None:\n",
    "    raise RuntimeError(\"Ejecuta la Celda 2 primero para generar al menos un H5 (SAMPLE_OUT).\")\n",
    "\n",
    "print(\"Mostrando:\", SAMPLE_OUT)\n",
    "\n",
    "def _proj_img(x):\n",
    "    # (T,H,W) -> acumula T; (T,C,H,W) -> acumula T y C\n",
    "    if x.ndim == 2:\n",
    "        return x\n",
    "    if x.ndim == 3:\n",
    "        return x.sum(axis=0)\n",
    "    if x.ndim == 4:\n",
    "        return x.sum(axis=(0,1))\n",
    "    raise ValueError(x.shape)\n",
    "\n",
    "with h5py.File(SAMPLE_OUT, \"r\") as h5:\n",
    "    print(\"Atributos:\")\n",
    "    for k, v in h5.attrs.items():\n",
    "        print(f\" - {k}: {v}\")\n",
    "    print(\"Datasets:\", list(h5.keys()))\n",
    "\n",
    "    X = h5[\"spikes\"]\n",
    "    y = h5[\"steering\"]\n",
    "    print(\"spikes:\", X.shape, X.dtype, \"| steering:\", y.shape, y.dtype)\n",
    "\n",
    "    x0 = X[0]  # (T,H,W) o (T,C,H,W)\n",
    "    acc = _proj_img(x0)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.imshow(acc, cmap=\"gray\")\n",
    "plt.title(\"sample[0] ‚Äî acumulado temporal\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
