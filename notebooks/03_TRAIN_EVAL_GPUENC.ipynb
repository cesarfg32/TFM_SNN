{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9d8f4d",
   "metadata": {},
   "source": [
    "# 03 — Entrenamiento y Evaluación (SUPERVISED y CONTINUAL con EWC/NAIVE)\n",
    "\n",
    "Este notebook entrena un modelo **SNN** para **regresión del ángulo de dirección (steering)** en dos protocolos:\n",
    "\n",
    "- **Supervised** sobre `circuito1`.\n",
    "- **Continual** con dos tareas secuenciales `circuito1 → circuito2` usando:\n",
    "  - **EWC** (consolidación elástica de pesos), o\n",
    "  - **NAIVE** (baseline sin penalización; equivalente a λ=0).\n",
    "\n",
    "> **Requisitos previos**: Ejecuta `01_DATA_QC_PREP.ipynb` para generar `train/val/test.csv` y `tasks.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6fb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup\n",
    "# =============================================================================\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.utils import set_seeds, load_preset\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import SNNVisionRegressor\n",
    "from src.training import TrainConfig\n",
    "from src.eval import eval_loader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "\n",
    "tfm = ImageTransform(160, 80, True, None)\n",
    "def make_model_fn(tfm):\n",
    "    return SNNVisionRegressor(in_channels=(1 if tfm.to_gray else 3), lif_beta=0.95)\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0be0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAFE_MODE=False] workers=12 prefetch=2 pin=True persistent=True\n"
     ]
    }
   ],
   "source": [
    "GPU_ENCODE = True\n",
    "\n",
    "SAFE_MODE = False\n",
    "NUM_WORKERS    = 12\n",
    "PREFETCH       = 2\n",
    "PIN_MEMORY     = True\n",
    "PERSISTENT     = True\n",
    "\n",
    "AUG_CFG_LIGHT = AugmentConfig(prob_hflip=0.5, brightness=None, gamma=None, noise_std=0.0)\n",
    "AUG_CFG_FULL  = AugmentConfig(prob_hflip=0.5, brightness=(0.9, 1.1), gamma=(0.95, 1.05), noise_std=0.005)\n",
    "AUG_CFG = AUG_CFG_LIGHT\n",
    "\n",
    "USE_OFFLINE_BALANCED = True\n",
    "USE_ONLINE_BALANCING = False\n",
    "\n",
    "if SAFE_MODE:\n",
    "    NUM_WORKERS = 0\n",
    "    PREFETCH = None\n",
    "    PIN_MEMORY = False\n",
    "    PERSISTENT = False\n",
    "    USE_OFFLINE_BALANCED = False\n",
    "    USE_ONLINE_BALANCING = False\n",
    "    AUG_CFG = None\n",
    "\n",
    "print(f\"[SAFE_MODE={SAFE_MODE}] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5592e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ /home/cesar/proyectos/TFM_SNN/data/processed/circuito1/train_balanced.csv OK\n",
      "✓ /home/cesar/proyectos/TFM_SNN/data/processed/circuito2/train_balanced.csv OK\n",
      "OK: splits 'train/val/test' encontrados.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Verificación de datos (normal y, si existe, balanceado offline)\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "RAW  = ROOT/\"data\"/\"raw\"/\"udacity\"\n",
    "PROC = ROOT/\"data\"/\"processed\"\n",
    "\n",
    "RUNS = [\"circuito1\",\"circuito2\"]  # ajusta si hace falta\n",
    "\n",
    "missing = []\n",
    "for run in RUNS:\n",
    "    base = PROC / run\n",
    "\n",
    "    # Comprobación obligatoria: splits normales\n",
    "    for part in [\"train\",\"val\",\"test\"]:\n",
    "        p = base / f\"{part}.csv\"\n",
    "        if not p.exists():\n",
    "            missing.append(str(p))\n",
    "\n",
    "    # Comprobación opcional: train_balanced.csv (para modo OFFLINE balanceado)\n",
    "    p_bal = base / \"train_balanced.csv\"\n",
    "    if p_bal.exists():\n",
    "        print(f\"✓ {p_bal} OK\")\n",
    "    else:\n",
    "        print(f\"⚠️  Falta {p_bal}. Si más abajo pones USE_OFFLINE_BALANCED=True, \"\n",
    "              f\"ejecuta 01A_PREP_BALANCED.ipynb o el script tools/make_splits_balanced.py\")\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Faltan CSV obligatorios (ejecuta 01A_PREP_BALANCED.ipynb o tu pipeline de prep):\\n\"\n",
    "        + \"\\n\".join(\" - \" + m for m in missing)\n",
    "    )\n",
    "\n",
    "print(\"OK: splits 'train/val/test' encontrados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e27aff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo balanceo: OFFLINE (tasks_balanced.json) | Balanceo ONLINE: False\n"
     ]
    }
   ],
   "source": [
    "# ===================== Balanceo: helper =====================\n",
    "print(\n",
    "    \"Modo balanceo:\",\n",
    "    \"OFFLINE (tasks_balanced.json)\" if USE_OFFLINE_BALANCED else \"ORIGINAL (tasks.json)\",\n",
    "    \"| Balanceo ONLINE:\", USE_ONLINE_BALANCING\n",
    ")\n",
    "\n",
    "# Seguridad anti doble balanceo:\n",
    "if USE_OFFLINE_BALANCED and USE_ONLINE_BALANCING:\n",
    "    raise RuntimeError(\"Doble balanceo detectado: OFFLINE y ONLINE a la vez. \"\n",
    "                       \"Pon USE_ONLINE_BALANCING=False cuando uses train_balanced.csv.\")\n",
    "\n",
    "from pathlib import Path  # (omite esta línea si ya importaste Path arriba)\n",
    "\n",
    "def _balance_flag(train_csv_path: str | Path) -> bool:\n",
    "    \"\"\"\n",
    "    Activa balanceo ONLINE solo si:\n",
    "    - USE_ONLINE_BALANCING == True\n",
    "    - Y el CSV de train NO es 'train_balanced.csv'\n",
    "    \"\"\"\n",
    "    is_balanced_csv = Path(train_csv_path).name == \"train_balanced.csv\"\n",
    "    return bool(USE_ONLINE_BALANCING and not is_balanced_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173dd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.training as training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf988a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tareas y su TRAIN CSV:\n",
      " - circuito1: train_balanced.csv\n",
      " - circuito2: train_balanced.csv\n",
      "✔ Verificación OFFLINE balanceado superada (train_balanced.csv por tarea).\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Elegir split: normal (tasks.json) o balanceado offline (tasks_balanced.json)\n",
    "# =============================================================================\n",
    "with open(PROC / (\"tasks_balanced.json\" if USE_OFFLINE_BALANCED else \"tasks.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "# Vista rápida: muestra el CSV de train que se usará por cada tarea\n",
    "print(\"Tareas y su TRAIN CSV:\")\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {Path(t['paths']['train']).name}\")\n",
    "\n",
    "task_list[:2]  # vista rápida\n",
    "\n",
    "# Guardarraíl extra: si has activado el OFFLINE balanceado,\n",
    "# exige que el 'train' sea train_balanced.csv y que exista.\n",
    "if USE_OFFLINE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = Path(t[\"paths\"][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' pero encontré '{train_path.name}'. \"\n",
    "                \"Repite 01A_PREP_BALANCED.ipynb o ajusta USE_OFFLINE_BALANCED=False.\"\n",
    "            )\n",
    "        if not train_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"[{t['name']}] No existe {train_path}. Genera los balanceados con 01A_PREP_BALANCED.ipynb.\"\n",
    "            )\n",
    "    print(\"✔ Verificación OFFLINE balanceado superada (train_balanced.csv por tarea).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fee745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.utils import make_loaders_from_csvs\n",
    "\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed, **dl_kwargs):\n",
    "    RAW = ROOT / \"data\" / \"raw\" / \"udacity\" / task[\"name\"]\n",
    "    paths = task[\"paths\"]\n",
    "\n",
    "    # Si vamos a codificar en GPU, pedimos 4D (image) al loader;\n",
    "    # si no, dejamos el encoder temporal en el propio dataset.\n",
    "    encoder_for_loader = \"image\" if (GPU_ENCODE and encoder in {\"rate\",\"latency\",\"raw\"}) else encoder\n",
    "\n",
    "    return make_loaders_from_csvs(\n",
    "        base_dir=RAW,\n",
    "        train_csv=Path(paths[\"train\"]),\n",
    "        val_csv=Path(paths[\"val\"]),\n",
    "        test_csv=Path(paths[\"test\"]),\n",
    "        batch_size=batch_size,\n",
    "        encoder=encoder_for_loader,\n",
    "        T=T, gain=gain, tfm=tfm, seed=SEED,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        persistent_workers=PERSISTENT,\n",
    "        prefetch_factor=PREFETCH,\n",
    "        # online balancing opcional:\n",
    "        aug_train=AUG_CFG,\n",
    "        balance_train=(USE_ONLINE_BALANCING and Path(paths[\"train\"]).name != \"train_balanced.csv\"),\n",
    "        balance_bins=21,\n",
    "        balance_smooth_eps=1e-3,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a5f1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.runner import run_continual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "868d1a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ it/s por época ACTIVADO. Para desactivarlo: training.train_supervised = orig_train_supervised\n"
     ]
    }
   ],
   "source": [
    "# === Activar métrica de it/s por época (parche temporal) ===\n",
    "import time, json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "import src.training as training\n",
    "from src.utils import set_seeds  # ya lo tienes importado en el notebook\n",
    "\n",
    "# Guarda la referencia al original para poder restaurar luego\n",
    "orig_train_supervised = training.train_supervised\n",
    "\n",
    "def train_supervised_ips(model: nn.Module, train_loader, val_loader, loss_fn: nn.Module,\n",
    "                         cfg, out_dir: Path, method=None):\n",
    "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if cfg.seed is not None:\n",
    "        set_seeds(cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "    use_amp = bool(cfg.amp and torch.cuda.is_available())\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "    t0_total = time.perf_counter()\n",
    "\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        nb = 0\n",
    "        t_epoch0 = time.perf_counter()\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            # encode/permutación runtime y subida a device (usa tu helper actual)\n",
    "            x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast(\"cuda\", enabled=use_amp):\n",
    "                y_hat = model(x)\n",
    "                loss = loss_fn(y_hat, y)\n",
    "                if method is not None:\n",
    "                    loss = loss + method.penalty()\n",
    "\n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(opt); scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "            nb += 1\n",
    "\n",
    "        epoch_time = time.perf_counter() - t_epoch0\n",
    "        ips = nb / epoch_time if epoch_time > 0 else float(\"nan\")\n",
    "        print(f\"[TRAIN it/s] epoch {epoch}/{cfg.epochs}: {ips:.1f} it/s  \"\n",
    "              f\"({nb} iters en {epoch_time:.2f}s)\")\n",
    "\n",
    "        train_loss = running / max(1, nb)\n",
    "\n",
    "        # --- validación ---\n",
    "        model.eval()\n",
    "        v_running = 0.0; nvb = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                with autocast(\"cuda\", enabled=use_amp):\n",
    "                    y_hat = model(x)\n",
    "                    v_loss = loss_fn(y_hat, y)\n",
    "                v_running += v_loss.item(); nvb += 1\n",
    "        val_loss = v_running / max(1, nvb)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "    elapsed = time.perf_counter() - t0_total\n",
    "    manifest = {\n",
    "        \"epochs\": cfg.epochs, \"batch_size\": cfg.batch_size, \"lr\": cfg.lr,\n",
    "        \"amp\": cfg.amp, \"seed\": cfg.seed, \"elapsed_sec\": elapsed,\n",
    "        \"device\": str(device), \"history\": history,\n",
    "    }\n",
    "    (out_dir / \"manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    return history\n",
    "\n",
    "# Activa el parche\n",
    "training.train_supervised = train_supervised_ips\n",
    "print(\"✅ it/s por época ACTIVADO. Para desactivarlo: training.train_supervised = orig_train_supervised\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d378658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan de runs (preset, método, λ):\n",
      "     fast    ewc  λ=700000000.0\n",
      "     fast    ewc  λ=1000000000.0\n",
      "     fast    ewc  λ=1200000000.0\n",
      "     fast  naive  λ=None\n",
      "Semillas: [42]  | Encoders: ['rate']\n",
      "Fisher batches por preset: {'fast': 800, 'std': 1000, 'accurate': 1500}\n"
     ]
    }
   ],
   "source": [
    "# ====================== CONFIG POR DEFECTO PARA LAS COMPARATIVAS ======================\n",
    "# Recomendaciones acordadas:\n",
    "# - fast: EWC λ=1e9 (estable). Extra: λ=1e8 (mejor T2, algo más de olvido)\n",
    "# - std : EWC λ=1e7 (baseline estable). Extra: λ=3e7 (mejor T2, más olvido)\n",
    "\n",
    "# EWC_DEFAULTS = {\n",
    "#     \"fast\":     {\"primary\": [1e9, 3e8],      \"extra\": [3e9]},\n",
    "#     \"std\": {\"primary\": [7e8, 1e9, 1.2e9, 1.5e9], \"extra\": []},\n",
    "#     \"accurate\": {\"primary\": [1e6, 3e6, 1e7], \"extra\": []},  # ← mucho más bajo que 1e9\n",
    "# }\n",
    "\n",
    "EWC_DEFAULTS = {\n",
    "    \"fast\": {\"primary\": [7e8, 1e9, 1.2e9], \"extra\": []},\n",
    "    \"std\":  {\"primary\": [5e8, 7e8, 1e9],   \"extra\": []},\n",
    "    \"accurate\": {\"primary\": [1e6, 3e6, 1e7], \"extra\": []}, \n",
    "    # de momento accurate solo NAIVE; EWC en accurate lo aparcamos\n",
    "    # \"accurate\": {\"primary\": [], \"extra\": []},\n",
    "}\n",
    "\n",
    "INCLUDE_NAIVE    = True          # añade baseline sin EWC\n",
    "INCLUDE_EXTRAS   = False          # activa los λ \"extra\" por preset\n",
    "SEEDS            = [42]  # multisemillas para medias/σ\n",
    "# SEEDS            = [42, 43, 44]  # multisemillas para medias/σ\n",
    "ENCODERS         = [\"rate\"]      # luego podrás añadir \"latency\"\n",
    "# FISHER_BY_PRESET = {\"fast\": 200, \"std\": 600, \"accurate\": 600}  # estabiliza el cálculo de Fisher\n",
    "# FISHER_BY_PRESET = {\"fast\": 800, \"std\": 1000}  # estabiliza el cálculo de Fisher\n",
    "# Endurecemos Fisher para estabilidad; accurate necesita más por ser más largo\n",
    "# FISHER_BY_PRESET = {\"fast\": 800, \"std\": 1200, \"accurate\": 1500}\n",
    "FISHER_BY_PRESET = {\"fast\": 800, \"std\": 1000, \"accurate\": 1500}\n",
    "# Elige qué presets lanzar\n",
    "# PRESETS_TO_RUN = [\"fast\", \"std\", \"accurate\"]  # añade \"accurate\" si lo necesitas más adelante\n",
    "PRESETS_TO_RUN = [\"fast\"]  # añade \"accurate\" si lo necesitas más adelante\n",
    "\n",
    "# ---- Construcción del plan de ejecuciones ----\n",
    "runs_plan = []\n",
    "for preset_i in PRESETS_TO_RUN:\n",
    "    # EWC primary\n",
    "    for lam in EWC_DEFAULTS[preset_i][\"primary\"]:\n",
    "        runs_plan.append((preset_i, \"ewc\", lam))\n",
    "    # EWC extras (opcionales)\n",
    "    if INCLUDE_EXTRAS:\n",
    "        for lam in EWC_DEFAULTS[preset_i][\"extra\"]:\n",
    "            runs_plan.append((preset_i, \"ewc\", lam))\n",
    "    # Baseline sin EWC\n",
    "    if INCLUDE_NAIVE:\n",
    "        runs_plan.append((preset_i, \"naive\", None))\n",
    "\n",
    "print(\"Plan de runs (preset, método, λ):\")\n",
    "for preset_i, method_i, lam_i in runs_plan:\n",
    "    print(f\"  {preset_i:>7}  {method_i:>5}  λ={lam_i}\")\n",
    "print(\"Semillas:\", SEEDS, \" | Encoders:\", ENCODERS)\n",
    "print(\"Fisher batches por preset:\", FISHER_BY_PRESET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN: preset=fast | method=ewc | λ=700000000.0 | seed=42 | encoder=rate ===\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc | λ=700000000.0 | B=64 T=10 AMP=True | enc=rate ---\n",
      "  loader batch shape: (64, 1, 80, 160) | y: (64, 1)\n",
      "  runtime encode: ON (GPU)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2:  13%|█▎        | 117/909 [00:01<00:12, 62.19it/s]"
     ]
    }
   ],
   "source": [
    "# ====================== DRIVER MULTISEMILLAS (usa la CONFIG de arriba) ======================\n",
    "for enc in ENCODERS:\n",
    "    for seed in SEEDS:\n",
    "        for preset_i, method_i, lam_i in runs_plan:\n",
    "            print(f\"\\n=== RUN: preset={preset_i} | method={method_i} | λ={lam_i} | seed={seed} | encoder={enc} ===\")\n",
    "            out_path, _ = run_continual(\n",
    "                task_list=task_list,\n",
    "                make_loader_fn=make_loader_fn,\n",
    "                make_model_fn=make_model_fn,\n",
    "                tfm=tfm,\n",
    "                preset=preset_i,\n",
    "                method=method_i,\n",
    "                lam=(lam_i if method_i == \"ewc\" else None),\n",
    "                seed=seed,\n",
    "                encoder=enc,\n",
    "                fisher_batches_by_preset=FISHER_BY_PRESET,\n",
    "                runtime_encode=GPU_ENCODE,      # << importante\n",
    "                out_root=ROOT/\"outputs\",\n",
    "                verbose=True,\n",
    "            )\n",
    "            print(\"OK:\", out_path)\n",
    "\n",
    "print(\"\\n Listo. Ejecuta las celdas de resumen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9835a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>preset</th>\n",
       "      <th>method</th>\n",
       "      <th>lambda</th>\n",
       "      <th>encoder</th>\n",
       "      <th>seed</th>\n",
       "      <th>c1_name</th>\n",
       "      <th>c2_name</th>\n",
       "      <th>c1_mae</th>\n",
       "      <th>c1_after_c2_mae</th>\n",
       "      <th>c1_forgetting_mae_abs</th>\n",
       "      <th>c1_forgetting_mae_rel_%</th>\n",
       "      <th>c2_mae</th>\n",
       "      <th>lambda_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continual_accurate_ewc_lam_3e+07_rate_seed_42</td>\n",
       "      <td>accurate</td>\n",
       "      <td>ewc</td>\n",
       "      <td>3e+07</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.148162</td>\n",
       "      <td>0.138012</td>\n",
       "      <td>-0.010150</td>\n",
       "      <td>-6.850842</td>\n",
       "      <td>0.553535</td>\n",
       "      <td>3.000000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continual_accurate_ewc_lam_1e+08_rate_seed_42</td>\n",
       "      <td>accurate</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.148162</td>\n",
       "      <td>0.143491</td>\n",
       "      <td>-0.004672</td>\n",
       "      <td>-3.153023</td>\n",
       "      <td>0.719766</td>\n",
       "      <td>1.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continual_accurate_naive_rate_seed_42</td>\n",
       "      <td>accurate</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.147283</td>\n",
       "      <td>0.245344</td>\n",
       "      <td>0.098061</td>\n",
       "      <td>66.579902</td>\n",
       "      <td>0.150128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>continual_fast_ewc_lam_3e+08_rate_seed_42</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>3e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.160165</td>\n",
       "      <td>0.436087</td>\n",
       "      <td>0.275922</td>\n",
       "      <td>172.274185</td>\n",
       "      <td>0.236101</td>\n",
       "      <td>3.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_rate_seed_42</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.160165</td>\n",
       "      <td>0.177819</td>\n",
       "      <td>0.017654</td>\n",
       "      <td>11.022647</td>\n",
       "      <td>0.263249</td>\n",
       "      <td>1.000000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>continual_fast_naive_rate_seed_42</td>\n",
       "      <td>fast</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.159133</td>\n",
       "      <td>0.334430</td>\n",
       "      <td>0.175297</td>\n",
       "      <td>110.157772</td>\n",
       "      <td>0.184611</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>continual_std_ewc_lam_3e+08_rate_seed_42</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>3e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.147165</td>\n",
       "      <td>0.216826</td>\n",
       "      <td>0.069661</td>\n",
       "      <td>47.335188</td>\n",
       "      <td>0.251584</td>\n",
       "      <td>3.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>continual_std_ewc_lam_5e+08_rate_seed_42</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>5e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.147165</td>\n",
       "      <td>0.156018</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>6.015622</td>\n",
       "      <td>0.269909</td>\n",
       "      <td>5.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>continual_std_ewc_lam_7e+08_rate_seed_42</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.147165</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.122248</td>\n",
       "      <td>83.068660</td>\n",
       "      <td>0.265235</td>\n",
       "      <td>7.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>continual_std_ewc_lam_1e+09_rate_seed_42</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.147165</td>\n",
       "      <td>0.255225</td>\n",
       "      <td>0.108060</td>\n",
       "      <td>73.427554</td>\n",
       "      <td>0.266113</td>\n",
       "      <td>1.000000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>continual_std_ewc_lam_2e+09_rate_seed_42</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>2e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.135160</td>\n",
       "      <td>0.343077</td>\n",
       "      <td>0.207917</td>\n",
       "      <td>153.829926</td>\n",
       "      <td>0.223333</td>\n",
       "      <td>2.000000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>continual_std_naive_rate_seed_42</td>\n",
       "      <td>std</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.143802</td>\n",
       "      <td>0.277343</td>\n",
       "      <td>0.133542</td>\n",
       "      <td>92.865151</td>\n",
       "      <td>0.198947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              exp    preset method lambda  \\\n",
       "0   continual_accurate_ewc_lam_3e+07_rate_seed_42  accurate    ewc  3e+07   \n",
       "1   continual_accurate_ewc_lam_1e+08_rate_seed_42  accurate    ewc  1e+08   \n",
       "2           continual_accurate_naive_rate_seed_42  accurate  naive   None   \n",
       "3       continual_fast_ewc_lam_3e+08_rate_seed_42      fast    ewc  3e+08   \n",
       "4       continual_fast_ewc_lam_1e+09_rate_seed_42      fast    ewc  1e+09   \n",
       "5               continual_fast_naive_rate_seed_42      fast  naive   None   \n",
       "6        continual_std_ewc_lam_3e+08_rate_seed_42       std    ewc  3e+08   \n",
       "7        continual_std_ewc_lam_5e+08_rate_seed_42       std    ewc  5e+08   \n",
       "8        continual_std_ewc_lam_7e+08_rate_seed_42       std    ewc  7e+08   \n",
       "9        continual_std_ewc_lam_1e+09_rate_seed_42       std    ewc  1e+09   \n",
       "10       continual_std_ewc_lam_2e+09_rate_seed_42       std    ewc  2e+09   \n",
       "11               continual_std_naive_rate_seed_42       std  naive   None   \n",
       "\n",
       "   encoder  seed    c1_name    c2_name    c1_mae  c1_after_c2_mae  \\\n",
       "0     rate    42  circuito1  circuito2  0.148162         0.138012   \n",
       "1     rate    42  circuito1  circuito2  0.148162         0.143491   \n",
       "2     rate    42  circuito1  circuito2  0.147283         0.245344   \n",
       "3     rate    42  circuito1  circuito2  0.160165         0.436087   \n",
       "4     rate    42  circuito1  circuito2  0.160165         0.177819   \n",
       "5     rate    42  circuito1  circuito2  0.159133         0.334430   \n",
       "6     rate    42  circuito1  circuito2  0.147165         0.216826   \n",
       "7     rate    42  circuito1  circuito2  0.147165         0.156018   \n",
       "8     rate    42  circuito1  circuito2  0.147165         0.269413   \n",
       "9     rate    42  circuito1  circuito2  0.147165         0.255225   \n",
       "10    rate    42  circuito1  circuito2  0.135160         0.343077   \n",
       "11    rate    42  circuito1  circuito2  0.143802         0.277343   \n",
       "\n",
       "    c1_forgetting_mae_abs  c1_forgetting_mae_rel_%    c2_mae    lambda_num  \n",
       "0               -0.010150                -6.850842  0.553535  3.000000e+07  \n",
       "1               -0.004672                -3.153023  0.719766  1.000000e+08  \n",
       "2                0.098061                66.579902  0.150128           NaN  \n",
       "3                0.275922               172.274185  0.236101  3.000000e+08  \n",
       "4                0.017654                11.022647  0.263249  1.000000e+09  \n",
       "5                0.175297               110.157772  0.184611           NaN  \n",
       "6                0.069661                47.335188  0.251584  3.000000e+08  \n",
       "7                0.008853                 6.015622  0.269909  5.000000e+08  \n",
       "8                0.122248                83.068660  0.265235  7.000000e+08  \n",
       "9                0.108060                73.427554  0.266113  1.000000e+09  \n",
       "10               0.207917               153.829926  0.223333  2.000000e+09  \n",
       "11               0.133542                92.865151  0.198947           NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Resumen comparativo de todos los continual_* en outputs/\n",
    "# =============================================================================\n",
    "import re, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def parse_exp_name(name: str):\n",
    "    \"\"\"\n",
    "    Extrae preset, método, lambda, encoder y seed del nombre de carpeta:\n",
    "\n",
    "      continual_<preset>_<method>[_lam_<lambda>]_<_encoder>[_seed_<seed>]\n",
    "\n",
    "    Ejemplos:\n",
    "      continual_fast_naive_rate_seed_42\n",
    "      continual_fast_ewc_lam_1e+08_rate_seed_42\n",
    "      continual_std_ewc_lam_3e+07_latency_seed_43\n",
    "    \"\"\"\n",
    "    m = re.match(\n",
    "        r\"continual_(?P<preset>\\w+)_(?P<method>ewc|naive)\"\n",
    "        r\"(?:_lam_(?P<lambda>[^_]+))?_(?P<enc>[^_]+)\"\n",
    "        r\"(?:_seed_(?P<seed>\\d+))?$\",\n",
    "        name\n",
    "    )\n",
    "    meta = {\"preset\": None, \"method\": None, \"lambda\": None, \"encoder\": None, \"seed\": None}\n",
    "    if m:\n",
    "        d = m.groupdict()\n",
    "        meta.update({\n",
    "            \"preset\": d[\"preset\"],\n",
    "            \"method\": d[\"method\"],\n",
    "            \"lambda\": d.get(\"lambda\"),\n",
    "            \"encoder\": d.get(\"enc\"),\n",
    "            \"seed\": d.get(\"seed\"),\n",
    "        })\n",
    "    return meta\n",
    "\n",
    "rows = []\n",
    "root_out = ROOT / \"outputs\"\n",
    "\n",
    "for exp_dir in sorted(root_out.glob(\"continual_*\")):\n",
    "    name = exp_dir.name\n",
    "    meta = parse_exp_name(name)\n",
    "\n",
    "    # Saltar nombres no reconocidos (runs muy antiguos)\n",
    "    if meta[\"preset\"] is None:\n",
    "        continue\n",
    "\n",
    "    results_path = exp_dir / \"continual_results.json\"\n",
    "    if not results_path.exists():\n",
    "        continue\n",
    "\n",
    "    with open(results_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        res = json.load(f)\n",
    "\n",
    "    # Detectar tareas: la \"última\" es la que NO tiene claves 'after_*'\n",
    "    task_names = list(res.keys())\n",
    "    if len(task_names) < 2:\n",
    "        continue\n",
    "\n",
    "    def is_last(d):  # no tiene after_*\n",
    "        return not any(k.startswith(\"after_\") for k in d.keys())\n",
    "\n",
    "    last_task = None\n",
    "    first_task = None\n",
    "    for tn in task_names:\n",
    "        if is_last(res[tn]):\n",
    "            last_task = tn\n",
    "        else:\n",
    "            first_task = tn\n",
    "\n",
    "    # Fallback por si no se identifica bien\n",
    "    if first_task is None or last_task is None:\n",
    "        task_names_sorted = sorted(task_names)\n",
    "        first_task = task_names_sorted[0]\n",
    "        last_task  = task_names_sorted[-1]\n",
    "\n",
    "    c1, c2 = first_task, last_task\n",
    "\n",
    "    c1_test_mae = float(res[c1].get(\"test_mae\", float(\"nan\")))\n",
    "    c2_test_mae = float(res[c2].get(\"test_mae\", float(\"nan\")))\n",
    "    after_key_mae = f\"after_{c2}_mae\"\n",
    "    c1_after_c2_mae = float(res[c1].get(after_key_mae, float(\"nan\")))\n",
    "\n",
    "    forgetting_abs = c1_after_c2_mae - c1_test_mae\n",
    "    forgetting_rel = (forgetting_abs / c1_test_mae * 100.0) if c1_test_mae == c1_test_mae else float(\"nan\")\n",
    "\n",
    "    rows.append({\n",
    "        \"exp\": name,\n",
    "        \"preset\": meta[\"preset\"],\n",
    "        \"method\": meta[\"method\"],\n",
    "        \"lambda\": meta[\"lambda\"] if meta[\"method\"] == \"ewc\" else None,\n",
    "        \"encoder\": meta[\"encoder\"],\n",
    "        \"seed\": int(meta[\"seed\"]) if meta[\"seed\"] is not None else None,\n",
    "        \"c1_name\": c1,\n",
    "        \"c2_name\": c2,\n",
    "        \"c1_mae\": c1_test_mae,\n",
    "        \"c1_after_c2_mae\": c1_after_c2_mae,\n",
    "        \"c1_forgetting_mae_abs\": forgetting_abs,\n",
    "        \"c1_forgetting_mae_rel_%\": forgetting_rel,\n",
    "        \"c2_mae\": c2_test_mae,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Asegura columnas numéricas auxiliares\n",
    "if \"lambda_num\" not in df.columns:\n",
    "    df[\"lambda_num\"] = pd.to_numeric(df[\"lambda\"], errors=\"coerce\")  # '1e+08' -> 1e+08 ; NAIVE -> NaN\n",
    "\n",
    "# Deja 'seed' como entero y elimina 'seed_num' si existe\n",
    "df[\"seed\"] = pd.to_numeric(df[\"seed\"], errors=\"coerce\").astype(\"Int64\")\n",
    "if \"seed_num\" in df.columns:\n",
    "    df = df.drop(columns=[\"seed_num\"])\n",
    "\n",
    "# Ordenar: preset, method, encoder, lambda_num (NaN al final), seed\n",
    "df = df.sort_values(\n",
    "    by=[\"preset\", \"method\", \"encoder\", \"lambda_num\", \"seed\"],\n",
    "    na_position=\"last\",\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Vista agregada (media±std por preset/method/λ/encoder) ======================\n",
    "import pandas as pd\n",
    "\n",
    "# Métricas a agregar\n",
    "cols_metrics = [\"c1_mae\", \"c1_after_c2_mae\", \"c1_forgetting_mae_abs\", \"c1_forgetting_mae_rel_%\", \"c2_mae\"]\n",
    "\n",
    "# Copia y asegura columna numérica auxiliar para ordenar por λ\n",
    "gdf = df.copy()\n",
    "if \"lambda_num\" not in gdf.columns:\n",
    "    gdf[\"lambda_num\"] = pd.to_numeric(gdf[\"lambda\"], errors=\"coerce\")  # NA para NAIVE\n",
    "\n",
    "# Agregación: media, std y número de corridas (semillas) por combinación\n",
    "agg = (\n",
    "    gdf\n",
    "    .groupby([\"preset\", \"method\", \"encoder\", \"lambda\", \"lambda_num\"], dropna=False)[cols_metrics]\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Aplanar nombres de columnas (de MultiIndex a una sola capa)\n",
    "agg.columns = [\n",
    "    \"_\".join(filter(None, map(str, col))).rstrip(\"_\")\n",
    "    for col in agg.columns.to_flat_index()\n",
    "]\n",
    "\n",
    "# Ordena por preset/method/encoder/λ_num (NaN al final ⇒ NAIVE al final de su grupo)\n",
    "agg = agg.sort_values(\n",
    "    by=[\"preset\", \"method\", \"encoder\", \"lambda_num\"],\n",
    "    na_position=\"last\",\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# (Opcional) guardar a CSV\n",
    "summary_dir = ROOT / \"outputs\" / \"summary\"\n",
    "summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "agg.to_csv(summary_dir / \"continual_summary_agg.csv\", index=False)\n",
    "print(\"Guardado:\", summary_dir / \"continual_summary_agg.csv\")\n",
    "\n",
    "agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821024ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Formateo para la memoria (tabla compacta) ======================\n",
    "\n",
    "def fmt(x, prec=4):\n",
    "    # Redondea y gestiona NaN de forma amigable\n",
    "    import pandas as pd\n",
    "    return \"\" if pd.isna(x) else f\"{x:.{prec}f}\"\n",
    "\n",
    "show = agg.copy()\n",
    "\n",
    "# 1) Crea 'count' a partir de cualquiera de las columnas *_count\n",
    "count_cols = [c for c in show.columns if c.endswith(\"_count\")]\n",
    "if count_cols:\n",
    "    show[\"count\"] = show[count_cols[0]].astype(\"Int64\")  # todas deberían coincidir\n",
    "    # (opcional) elimina las columnas *_count individuales\n",
    "    show = show.drop(columns=count_cols)\n",
    "\n",
    "# 2) Redondea columnas de medias/desviaciones\n",
    "for c in [c for c in show.columns if c.endswith(\"_mean\") or c.endswith(\"_std\")]:\n",
    "    show[c] = show[c].map(lambda v: fmt(v, 4))\n",
    "\n",
    "# 3) Selección de columnas clave (ajusta el orden a tu gusto)\n",
    "cols = [\n",
    "    \"preset\", \"method\", \"encoder\", \"lambda\",\n",
    "    \"c1_mae_mean\", \"c1_forgetting_mae_rel_%_mean\", \"c2_mae_mean\",\n",
    "    \"c1_mae_std\",  \"c1_forgetting_mae_rel_%_std\",  \"c2_mae_std\",\n",
    "    \"count\"\n",
    "]\n",
    "\n",
    "# Si alguna columna no existiera (según tus métricas), la ignoramos con aviso\n",
    "missing = [c for c in cols if c not in show.columns]\n",
    "if missing:\n",
    "    print(\"Aviso: faltan columnas en 'show':\", missing)\n",
    "    cols = [c for c in cols if c in show.columns]\n",
    "\n",
    "show = show[cols].rename(columns={\n",
    "    \"preset\": \"preset\",\n",
    "    \"method\": \"método\",\n",
    "    \"encoder\": \"codificador\",\n",
    "    \"lambda\": \"λ\",\n",
    "    \"c1_mae_mean\": \"MAE Tarea1 (media)\",\n",
    "    \"c1_forgetting_mae_rel_%_mean\": \"Olvido T1 (%) (media)\",\n",
    "    \"c2_mae_mean\": \"MAE Tarea2 (media)\",\n",
    "    \"c1_mae_std\": \"MAE Tarea1 (σ)\",\n",
    "    \"c1_forgetting_mae_rel_%_std\": \"Olvido T1 (%) (σ)\",\n",
    "    \"c2_mae_std\": \"MAE Tarea2 (σ)\",\n",
    "    \"count\": \"n (semillas)\"\n",
    "})\n",
    "\n",
    "show\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
