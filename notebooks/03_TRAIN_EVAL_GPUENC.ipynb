{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9d8f4d",
   "metadata": {},
   "source": [
    "# 03 — Entrenamiento y Evaluación (SUPERVISED y CONTINUAL con EWC/NAIVE)\n",
    "\n",
    "Este notebook entrena un modelo **SNN** para **regresión del ángulo de dirección (steering)** en dos protocolos:\n",
    "\n",
    "- **Supervised** sobre `circuito1`.\n",
    "- **Continual** con dos tareas secuenciales `circuito1 → circuito2` usando:\n",
    "  - **EWC** (consolidación elástica de pesos), o\n",
    "  - **NAIVE** (baseline sin penalización; equivalente a λ=0).\n",
    "\n",
    "> **Requisitos previos**: Ejecuta `01_DATA_QC_PREP.ipynb` para generar `train/val/test.csv` y `tasks.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6fb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup\n",
    "# =============================================================================\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "# Detecta la raíz del repo (si estás dentro de notebooks/, sube un nivel)\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Utilidades y módulos del proyecto\n",
    "from src.datasets import AugmentConfig\n",
    "from src.utils import set_seeds, load_preset, make_loaders_from_csvs\n",
    "from src.datasets import ImageTransform\n",
    "from src.models import SNNVisionRegressor\n",
    "from src.training import TrainConfig, train_supervised, _permute_if_needed\n",
    "from src.methods.ewc import EWC, EWCConfig\n",
    "\n",
    "# Dispositivo (CUDA si disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ROOT, device\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Transformación de imagen\n",
    "# IMPORTANTE: usa argumentos **posicionales** (w, h, to_gray, crop_top)\n",
    "# Evita keywords tipo target_w/target_h porque la clase no los define.\n",
    "tfm = ImageTransform(160, 80, True, None)\n",
    "\n",
    "def make_snn_model(tfm):\n",
    "    # C = 1 si gris, 3 si color\n",
    "    return SNNVisionRegressor(in_channels=(1 if tfm.to_gray else 3), lif_beta=0.95)\n",
    "\n",
    "torch.set_num_threads(4)               # evita sobre-contención de CPU al decodificar\n",
    "torch.backends.cudnn.benchmark = True  # selecciona la mejor impl. de convs para tamaño fijo\n",
    "\n",
    "# Permite TF32 (barato y suele acelerar matmul/convs en Ampere+ sin tocar precisión de FP16)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "# Precisión alta para kernels FP32 cuando no uses AMP\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0be0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAFE_MODE=False] workers=12 prefetch=2 pin=True persistent=True\n"
     ]
    }
   ],
   "source": [
    "GPU_ENCODE = True  # activa codificación (rate/latency/raw) en GPU\n",
    "RUN_BENCH = False   # pon True para ejecutar\n",
    "\n",
    "# --- SAFE MODE: desactiva todo lo pesado para estabilizar ---\n",
    "SAFE_MODE = False  # o False cuando quieras rendimiento\n",
    "\n",
    "NUM_WORKERS   = 12\n",
    "PREFETCH      = 2\n",
    "PIN_MEMORY    = True\n",
    "PERSISTENT    = True\n",
    "\n",
    "# AUG_CFG = None\n",
    "from src.datasets import AugmentConfig\n",
    "# --- Augment: perfiles ---\n",
    "AUG_CFG_LIGHT = AugmentConfig(prob_hflip=0.5, brightness=None, gamma=None, noise_std=0.0)\n",
    "AUG_CFG_FULL  = AugmentConfig(prob_hflip=0.5, brightness=(0.9, 1.1), gamma=(0.95, 1.05), noise_std=0.005)\n",
    "\n",
    "AUG_CFG = AUG_CFG_LIGHT   # ← usa LIGHT ahora; luego prueba FULL\n",
    "\n",
    "USE_OFFLINE_BALANCED  = True\n",
    "USE_ONLINE_BALANCING  = False\n",
    "\n",
    "if SAFE_MODE:\n",
    "    NUM_WORKERS  = 0\n",
    "    PREFETCH     = None   # ← IMPORTANTÍSIMO con num_workers=0\n",
    "    PIN_MEMORY   = False\n",
    "    PERSISTENT   = False  # ← también obligatorio con num_workers=0\n",
    "    USE_OFFLINE_BALANCED = False\n",
    "    USE_ONLINE_BALANCING = False\n",
    "    AUG_CFG = None\n",
    "\n",
    "print(f\"[SAFE_MODE={SAFE_MODE}] workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "      f\"pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5592e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ /home/cesar/proyectos/TFM_SNN/data/processed/circuito1/train_balanced.csv OK\n",
      "✓ /home/cesar/proyectos/TFM_SNN/data/processed/circuito2/train_balanced.csv OK\n",
      "OK: splits 'train/val/test' encontrados.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Verificación de datos (normal y, si existe, balanceado offline)\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "RAW  = ROOT/\"data\"/\"raw\"/\"udacity\"\n",
    "PROC = ROOT/\"data\"/\"processed\"\n",
    "\n",
    "RUNS = [\"circuito1\",\"circuito2\"]  # ajusta si hace falta\n",
    "\n",
    "missing = []\n",
    "for run in RUNS:\n",
    "    base = PROC / run\n",
    "\n",
    "    # Comprobación obligatoria: splits normales\n",
    "    for part in [\"train\",\"val\",\"test\"]:\n",
    "        p = base / f\"{part}.csv\"\n",
    "        if not p.exists():\n",
    "            missing.append(str(p))\n",
    "\n",
    "    # Comprobación opcional: train_balanced.csv (para modo OFFLINE balanceado)\n",
    "    p_bal = base / \"train_balanced.csv\"\n",
    "    if p_bal.exists():\n",
    "        print(f\"✓ {p_bal} OK\")\n",
    "    else:\n",
    "        print(f\"⚠️  Falta {p_bal}. Si más abajo pones USE_OFFLINE_BALANCED=True, \"\n",
    "              f\"ejecuta 01A_PREP_BALANCED.ipynb o el script tools/make_splits_balanced.py\")\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Faltan CSV obligatorios (ejecuta 01A_PREP_BALANCED.ipynb o tu pipeline de prep):\\n\"\n",
    "        + \"\\n\".join(\" - \" + m for m in missing)\n",
    "    )\n",
    "\n",
    "print(\"OK: splits 'train/val/test' encontrados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e27aff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo balanceo: OFFLINE (tasks_balanced.json) | Balanceo ONLINE: False\n"
     ]
    }
   ],
   "source": [
    "# ===================== Balanceo: helper =====================\n",
    "print(\n",
    "    \"Modo balanceo:\",\n",
    "    \"OFFLINE (tasks_balanced.json)\" if USE_OFFLINE_BALANCED else \"ORIGINAL (tasks.json)\",\n",
    "    \"| Balanceo ONLINE:\", USE_ONLINE_BALANCING\n",
    ")\n",
    "\n",
    "# Seguridad anti doble balanceo:\n",
    "if USE_OFFLINE_BALANCED and USE_ONLINE_BALANCING:\n",
    "    raise RuntimeError(\"Doble balanceo detectado: OFFLINE y ONLINE a la vez. \"\n",
    "                       \"Pon USE_ONLINE_BALANCING=False cuando uses train_balanced.csv.\")\n",
    "\n",
    "from pathlib import Path  # (omite esta línea si ya importaste Path arriba)\n",
    "\n",
    "def _balance_flag(train_csv_path: str | Path) -> bool:\n",
    "    \"\"\"\n",
    "    Activa balanceo ONLINE solo si:\n",
    "    - USE_ONLINE_BALANCING == True\n",
    "    - Y el CSV de train NO es 'train_balanced.csv'\n",
    "    \"\"\"\n",
    "    is_balanced_csv = Path(train_csv_path).name == \"train_balanced.csv\"\n",
    "    return bool(USE_ONLINE_BALANCING and not is_balanced_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fee3eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaders] workers=12 prefetch=2 pin=True persistent=True offline_bal=True online_bal=False\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Función para crear loaders de una tarea dada (respeta cfg del preset)\n",
    "# =============================================================================\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed,\n",
    "                   num_workers=NUM_WORKERS, prefetch_factor=PREFETCH,\n",
    "                   pin_memory=PIN_MEMORY, persistent_workers=PERSISTENT):\n",
    "    from pathlib import Path\n",
    "    name  = task[\"name\"]\n",
    "    paths = task[\"paths\"]\n",
    "\n",
    "    pw = persistent_workers and (num_workers > 0)\n",
    "    pf = prefetch_factor if (num_workers > 0) else None\n",
    "\n",
    "    # CLAVE: si vamos a codificar en GPU, el loader debe dar (B,C,H,W):\n",
    "    encoder_for_loader = \"image\" if GPU_ENCODE else encoder\n",
    "\n",
    "    return make_loaders_from_csvs(\n",
    "        base_dir=RAW/name,\n",
    "        train_csv=Path(paths[\"train\"]),\n",
    "        val_csv=Path(paths[\"val\"]),\n",
    "        test_csv=Path(paths[\"test\"]),\n",
    "        batch_size=batch_size,\n",
    "        encoder=encoder_for_loader,\n",
    "        T=T,\n",
    "        gain=gain,\n",
    "        tfm=tfm,\n",
    "        seed=seed,\n",
    "        # ---- Parche estabilidad WSL ----\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        persistent_workers=pw,\n",
    "        prefetch_factor=pf,\n",
    "        aug_train=AUG_CFG,\n",
    "        balance_train=_balance_flag(paths[\"train\"]),\n",
    "        balance_bins=21,\n",
    "    )\n",
    "\n",
    "print(f\"[Loaders] workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "      f\"pin={PIN_MEMORY} persistent={PERSISTENT} \"\n",
    "      f\"offline_bal={USE_OFFLINE_BALANCED} online_bal={USE_ONLINE_BALANCING}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173dd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.training as training\n",
    "\n",
    "# =============================================================================\n",
    "# Helper de evaluación (permuta a (T,B,C,H,W) y usa copias no bloqueantes)\n",
    "# =============================================================================\n",
    "def eval_loader(loader, model, device):\n",
    "    \"\"\"Calcula MAE/MSE promediados sobre todo el loader.\n",
    "\n",
    "    - El DataLoader produce (B, T, C, H, W)\n",
    "    - El modelo espera      (T, B, C, H, W)\n",
    "    \"\"\"\n",
    "    model.eval()  # modo evaluación: desactiva dropout/batchnorm, etc.\n",
    "    mae_sum = 0.0\n",
    "    mse_sum = 0.0\n",
    "    n = 0\n",
    "\n",
    "    # Un solo no_grad() fuera del bucle para minimizar overhead\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            # (B,T,C,H,W) -> (T,B,C,H,W), y luego a GPU con non_blocking=True\n",
    "            x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            y_hat = model(x)\n",
    "\n",
    "            # Acumula MAE/MSE ponderados por el tamaño real del batch\n",
    "            mae_sum += torch.mean(torch.abs(y_hat - y)).item() * len(y)\n",
    "            mse_sum += torch.mean((y_hat - y) ** 2).item() * len(y)\n",
    "            n += len(y)\n",
    "\n",
    "    return (mae_sum / max(n, 1)), (mse_sum / max(n, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf988a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tareas y su TRAIN CSV:\n",
      " - circuito1: train_balanced.csv\n",
      " - circuito2: train_balanced.csv\n",
      "✔ Verificación OFFLINE balanceado superada (train_balanced.csv por tarea).\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Elegir split: normal (tasks.json) o balanceado offline (tasks_balanced.json)\n",
    "# =============================================================================\n",
    "with open(PROC / (\"tasks_balanced.json\" if USE_OFFLINE_BALANCED else \"tasks.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "# Vista rápida: muestra el CSV de train que se usará por cada tarea\n",
    "print(\"Tareas y su TRAIN CSV:\")\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {Path(t['paths']['train']).name}\")\n",
    "\n",
    "task_list[:2]  # vista rápida\n",
    "\n",
    "# Guardarraíl extra: si has activado el OFFLINE balanceado,\n",
    "# exige que el 'train' sea train_balanced.csv y que exista.\n",
    "if USE_OFFLINE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = Path(t[\"paths\"][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' pero encontré '{train_path.name}'. \"\n",
    "                \"Repite 01A_PREP_BALANCED.ipynb o ajusta USE_OFFLINE_BALANCED=False.\"\n",
    "            )\n",
    "        if not train_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"[{t['name']}] No existe {train_path}. Genera los balanceados con 01A_PREP_BALANCED.ipynb.\"\n",
    "            )\n",
    "    print(\"✔ Verificación OFFLINE balanceado superada (train_balanced.csv por tarea).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63efad39",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/cesar/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cesar/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/cesar/proyectos/TFM_SNN/src/datasets.py\", line 365, in __getitem__\n    X = self._encode(x_img)  # (T, C, H, W) con C=1 o 3\n        ^^^^^^^^^^^^^^^^^^^\n  File \"/home/cesar/proyectos/TFM_SNN/src/datasets.py\", line 297, in _encode\n    raise ValueError(f\"Encoder desconocido: {self.cfg.encoder}\")\nValueError: Encoder desconocido: image\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# --- 1) Loader pequeño con tu helper ---\u001b[39;00m\n\u001b[32m      5\u001b[39m tr, va, te = make_loader_fn(\n\u001b[32m      6\u001b[39m     task=task_list[\u001b[32m0\u001b[39m],\n\u001b[32m      7\u001b[39m     batch_size=\u001b[32m8\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     seed=SEED,\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m xb, yb = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mbatch del loader:\u001b[39m\u001b[33m\"\u001b[39m, xb.shape, yb.shape)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# --- 2) A (T,B,C,H,W) según formato de entrada ---\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#    - Si el dataset ya codifica (5D): solo permutar.\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m#    - Si es 4D (imagen): activamos encode en GPU y usamos el helper runtime.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1465\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1463\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1464\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_info[idx]\n\u001b[32m-> \u001b[39m\u001b[32m1465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/torch/_utils.py:715\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    712\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    714\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mValueError\u001b[39m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/cesar/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cesar/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/cesar/proyectos/TFM_SNN/src/datasets.py\", line 365, in __getitem__\n    X = self._encode(x_img)  # (T, C, H, W) con C=1 o 3\n        ^^^^^^^^^^^^^^^^^^^\n  File \"/home/cesar/proyectos/TFM_SNN/src/datasets.py\", line 297, in _encode\n    raise ValueError(f\"Encoder desconocido: {self.cfg.encoder}\")\nValueError: Encoder desconocido: image\n"
     ]
    }
   ],
   "source": [
    "# === PRUEBA UNIVERSAL: loader -> (T,B,C,H,W) -> forward con fallback AMP ===\n",
    "import torch, src.training as training\n",
    "\n",
    "# --- 1) Loader pequeño con tu helper ---\n",
    "tr, va, te = make_loader_fn(\n",
    "    task=task_list[0],\n",
    "    batch_size=8,\n",
    "    encoder=\"rate\",   # si tu pipeline ya devuelve 4D, lo detectamos abajo\n",
    "    T=10,\n",
    "    gain=0.5,\n",
    "    tfm=tfm,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(tr))\n",
    "print(\"batch del loader:\", xb.shape, yb.shape)\n",
    "\n",
    "# --- 2) A (T,B,C,H,W) según formato de entrada ---\n",
    "#    - Si el dataset ya codifica (5D): solo permutar.\n",
    "#    - Si es 4D (imagen): activamos encode en GPU y usamos el helper runtime.\n",
    "if xb.ndim == 5:  # (B,T,C,H,W)\n",
    "    x5d = xb.permute(1,0,2,3,4).contiguous()\n",
    "    used_runtime_encode = False\n",
    "    print(\"dataset ya codificado; solo permuto a (T,B,C,H,W)\")\n",
    "elif xb.ndim == 4:  # (B,C,H,W)\n",
    "    training.set_runtime_encode(mode=\"rate\", T=10, gain=0.5,\n",
    "                                device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    x5d = training._permute_if_needed(xb)  # aplica encode+permuta -> (T,B,C,H,W)\n",
    "    used_runtime_encode = True\n",
    "    print(\"dataset 4D; uso encode en GPU y permuto a (T,B,C,H,W)\")\n",
    "else:\n",
    "    raise RuntimeError(f\"Forma inesperada del batch: {xb.shape}\")\n",
    "\n",
    "print(\"x5d.device:\", x5d.device, \"| shape:\", tuple(x5d.shape))\n",
    "\n",
    "# --- 3) Modelo y forward con fallback automático AMP ---\n",
    "model = make_snn_model(tfm).to(device).eval()\n",
    "\n",
    "def forward_with_auto_amp(model, x5d, device):\n",
    "    # Intento 1: AMP (solo si hay CUDA)\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            x_amp = x5d.to(device, dtype=torch.float16, non_blocking=True)\n",
    "            with torch.inference_mode(), torch.amp.autocast('cuda', enabled=True):\n",
    "                y = model(x_amp)\n",
    "            print(\"[forward] ejecutado con AMP (fp16)\")\n",
    "            return y\n",
    "        except Exception as e:\n",
    "            print(\"[forward] AMP falló, reintento en FP32. Motivo:\", str(e))\n",
    "\n",
    "    # Intento 2: FP32 (CPU o fallback)\n",
    "    x_fp32 = x5d.to(device, dtype=torch.float32, non_blocking=True)\n",
    "    with torch.inference_mode():\n",
    "        y = model(x_fp32)\n",
    "    print(\"[forward] ejecutado en FP32\")\n",
    "    return y\n",
    "\n",
    "yhat = forward_with_auto_amp(model, x5d, device)\n",
    "print(\"yhat:\", tuple(yhat.shape))\n",
    "\n",
    "# --- 4) Limpieza del runtime encode (si se usó) ---\n",
    "if used_runtime_encode:\n",
    "    training.set_runtime_encode(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== BENCH: toggle y eco de configuración =====================\n",
    "# Usa el RUN_BENCH que ya defines en la Celda 2\n",
    "print(\n",
    "    f\"[Bench RUN_BENCH={RUN_BENCH}] workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "    f\"pin={PIN_MEMORY} persistent={PERSISTENT} \"\n",
    "    f\"| offline_bal={USE_OFFLINE_BALANCED} online_bal={USE_ONLINE_BALANCING}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ENCODE = True  # activa codificación (rate/latency/raw) en GPU\n",
    "RUN_BENCH = False   # pon True para ejecutar\n",
    "\n",
    "# --- SAFE MODE: desactiva todo lo pesado para estabilizar ---\n",
    "SAFE_MODE = False  # o False cuando quieras rendimiento\n",
    "\n",
    "NUM_WORKERS   = 12\n",
    "PREFETCH      = 2\n",
    "PIN_MEMORY    = True\n",
    "PERSISTENT    = True\n",
    "\n",
    "# AUG_CFG = None\n",
    "from src.datasets import AugmentConfig\n",
    "# --- Augment: perfiles ---\n",
    "AUG_CFG_LIGHT = AugmentConfig(prob_hflip=0.5, brightness=None, gamma=None, noise_std=0.0)\n",
    "AUG_CFG_FULL  = AugmentConfig(prob_hflip=0.5, brightness=(0.9, 1.1), gamma=(0.95, 1.05), noise_std=0.005)\n",
    "\n",
    "AUG_CFG = AUG_CFG_LIGHT   # ← usa LIGHT ahora; luego prueba FULL\n",
    "\n",
    "USE_OFFLINE_BALANCED  = True\n",
    "USE_ONLINE_BALANCING  = False\n",
    "\n",
    "if SAFE_MODE:\n",
    "    NUM_WORKERS  = 0\n",
    "    PREFETCH     = None   # ← IMPORTANTÍSIMO con num_workers=0\n",
    "    PIN_MEMORY   = False\n",
    "    PERSISTENT   = False  # ← también obligatorio con num_workers=0\n",
    "    USE_OFFLINE_BALANCED = False\n",
    "    USE_ONLINE_BALANCING = False\n",
    "    AUG_CFG = None\n",
    "\n",
    "print(f\"[SAFE_MODE={SAFE_MODE}] workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "      f\"pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bcff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== run_continual (versión conservadora) ======================\n",
    "from pathlib import Path\n",
    "import json, time, torch\n",
    "from src.utils import load_preset, set_seeds\n",
    "from src.training import TrainConfig, train_supervised\n",
    "from src.models import SNNVisionRegressor\n",
    "from src.methods.ewc import EWC, EWCConfig\n",
    "import src.training as training  # para _permute_if_needed y runtime encode\n",
    "\n",
    "def run_continual(\n",
    "    preset: str,                 # \"fast\" | \"std\" | \"accurate\"\n",
    "    method: str,                 # \"ewc\" | \"naive\"\n",
    "    lam: float | None,           # λ si EWC; None si naive\n",
    "    seed: int,\n",
    "    encoder: str,                # \"rate\" | \"latency\" | \"raw\"\n",
    "    tfm,                         # ImageTransform\n",
    "    fisher_batches_by_preset: dict[str,int] | None = None,\n",
    "    epochs_override: int | None = None,   # override opcional de epochs\n",
    "    verbose: bool = False,                # traza opcional\n",
    "):\n",
    "    cfg    = load_preset(ROOT/\"configs\"/\"presets.yaml\", preset)\n",
    "    T      = int(cfg[\"T\"])\n",
    "    gain   = float(cfg[\"gain\"])\n",
    "    lr     = float(cfg[\"lr\"])\n",
    "    epochs = int(epochs_override if epochs_override is not None else cfg[\"epochs\"])\n",
    "    bs     = int(cfg[\"batch_size\"])\n",
    "    use_amp= bool(cfg[\"amp\"])\n",
    "\n",
    "    fb = 100\n",
    "    if fisher_batches_by_preset and preset in fisher_batches_by_preset:\n",
    "        fb = int(fisher_batches_by_preset[preset])\n",
    "\n",
    "    set_seeds(seed)\n",
    "\n",
    "    model = make_snn_model(tfm)\n",
    "    ewc = None\n",
    "    if method == \"ewc\":\n",
    "        assert lam is not None, \"Para EWC debes pasar λ (lam)\"\n",
    "        ewc = EWC(model, EWCConfig(lambd=float(lam), fisher_batches=fb))\n",
    "\n",
    "    out_tag = f\"continual_{preset}_{method}\" + (f\"_lam_{lam:.0e}\" if method=='ewc' else \"\") + f\"_{encoder}_seed_{seed}\"\n",
    "    out_dir = ROOT/\"outputs\"/out_tag\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    tcfg    = TrainConfig(epochs=epochs, batch_size=bs, lr=lr, amp=use_amp, seed=seed)\n",
    "\n",
    "    results = {}\n",
    "    seen = []\n",
    "\n",
    "    for i, t in enumerate(task_list):\n",
    "        name = t[\"name\"]\n",
    "        if verbose:\n",
    "            print(f\"\\n--- Tarea {i+1}/{len(task_list)}: {name} | preset={preset} | method={method} \"\n",
    "                  f\"| λ={lam if method=='ewc' else '-'} | B={bs} T={T} AMP={use_amp} | enc={encoder} ---\")\n",
    "\n",
    "        # Loaders: si GPU_ENCODE=True la celda 5 ya los crea con encoder=\"image\" (batches 4D)\n",
    "        tr, va, te = make_loader_fn(\n",
    "            task=t, batch_size=bs, encoder=encoder, T=T, gain=gain, tfm=tfm, seed=seed,\n",
    "        )\n",
    "\n",
    "        # Miramos el primer batch para decidir (robusto si algún día cambias el loader)\n",
    "        xb0, yb0 = next(iter(tr))\n",
    "        if verbose:\n",
    "            print(\"  loader batch shape:\", tuple(xb0.shape), \"| y:\", tuple(yb0.shape))\n",
    "\n",
    "        # === EXACTAMENTE EL MISMO COMPORTAMIENTO DE ANTES, PERO MÁS SEGURO ===\n",
    "        # Solo activamos encode en GPU si:\n",
    "        # - tú lo has pedido (GPU_ENCODE=True), y\n",
    "        # - el batch viene 4D (B,C,H,W) y necesita codificación temporal.\n",
    "        used_runtime = False\n",
    "        if 'GPU_ENCODE' in globals() and GPU_ENCODE and xb0.ndim == 4:\n",
    "            training.set_runtime_encode(mode=encoder, T=T, gain=gain, device=device)\n",
    "            used_runtime = True\n",
    "            if verbose: print(\"  runtime encode: ON (GPU)\")\n",
    "\n",
    "        # Entrenamiento normal\n",
    "        _ = train_supervised(\n",
    "            model, tr, va, loss_fn, tcfg,\n",
    "            out_dir/f\"task_{i+1}_{name}\",\n",
    "            method=ewc if method==\"ewc\" else None\n",
    "        )\n",
    "\n",
    "        # EWC: Fisher al final de la tarea\n",
    "        if method==\"ewc\":\n",
    "            print(\"Estimando Fisher…\")\n",
    "            ewc.estimate_fisher(va, loss_fn, device=device)\n",
    "\n",
    "        # evaluación tarea actual\n",
    "        te_mae, te_mse = eval_loader(te, model, device)\n",
    "        results[name] = {\"test_mae\": te_mae, \"test_mse\": te_mse}\n",
    "        seen.append((name, te))\n",
    "\n",
    "        # reevaluación tareas previas (olvido)\n",
    "        for pname, p_loader in seen[:-1]:\n",
    "            p_mae, p_mse = eval_loader(p_loader, model, device)\n",
    "            results[pname][f\"after_{name}_mae\"] = p_mae\n",
    "            results[pname][f\"after_{name}_mse\"] = p_mse\n",
    "\n",
    "        # Apaga el runtime cuando acabes la tarea (igual que antes)\n",
    "        if used_runtime:\n",
    "            training.set_runtime_encode(None)\n",
    "            if verbose: print(\"  runtime encode: OFF\")\n",
    "\n",
    "    (out_dir/\"continual_results.json\").write_text(json.dumps(results, indent=2), encoding=\"utf-8\")\n",
    "    return out_dir, results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Activar métrica de it/s por época (parche temporal) ===\n",
    "import time, json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "import src.training as training\n",
    "from src.utils import set_seeds  # ya lo tienes importado en el notebook\n",
    "\n",
    "# Guarda la referencia al original para poder restaurar luego\n",
    "orig_train_supervised = training.train_supervised\n",
    "\n",
    "def train_supervised_ips(model: nn.Module, train_loader, val_loader, loss_fn: nn.Module,\n",
    "                         cfg, out_dir: Path, method=None):\n",
    "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if cfg.seed is not None:\n",
    "        set_seeds(cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "    use_amp = bool(cfg.amp and torch.cuda.is_available())\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "    t0_total = time.perf_counter()\n",
    "\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        nb = 0\n",
    "        t_epoch0 = time.perf_counter()\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            # encode/permutación runtime y subida a device (usa tu helper actual)\n",
    "            x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast(\"cuda\", enabled=use_amp):\n",
    "                y_hat = model(x)\n",
    "                loss = loss_fn(y_hat, y)\n",
    "                if method is not None:\n",
    "                    loss = loss + method.penalty()\n",
    "\n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(opt); scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "            nb += 1\n",
    "\n",
    "        epoch_time = time.perf_counter() - t_epoch0\n",
    "        ips = nb / epoch_time if epoch_time > 0 else float(\"nan\")\n",
    "        print(f\"[TRAIN it/s] epoch {epoch}/{cfg.epochs}: {ips:.1f} it/s  \"\n",
    "              f\"({nb} iters en {epoch_time:.2f}s)\")\n",
    "\n",
    "        train_loss = running / max(1, nb)\n",
    "\n",
    "        # --- validación ---\n",
    "        model.eval()\n",
    "        v_running = 0.0; nvb = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                with autocast(\"cuda\", enabled=use_amp):\n",
    "                    y_hat = model(x)\n",
    "                    v_loss = loss_fn(y_hat, y)\n",
    "                v_running += v_loss.item(); nvb += 1\n",
    "        val_loss = v_running / max(1, nvb)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "    elapsed = time.perf_counter() - t0_total\n",
    "    manifest = {\n",
    "        \"epochs\": cfg.epochs, \"batch_size\": cfg.batch_size, \"lr\": cfg.lr,\n",
    "        \"amp\": cfg.amp, \"seed\": cfg.seed, \"elapsed_sec\": elapsed,\n",
    "        \"device\": str(device), \"history\": history,\n",
    "    }\n",
    "    (out_dir / \"manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    return history\n",
    "\n",
    "# Activa el parche\n",
    "training.train_supervised = train_supervised_ips\n",
    "print(\"✅ it/s por época ACTIVADO. Para desactivarlo: training.train_supervised = orig_train_supervised\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Demo smoke (naive + ewc, 2 épocas) =====================\n",
    "RUN_DEMO = False\n",
    "if RUN_DEMO:\n",
    "    preset_demo  = \"std\"\n",
    "    seed_demo    = 42\n",
    "    enc_demo     = load_preset(ROOT / \"configs\" / \"presets.yaml\", preset_demo)[\"encoder\"]\n",
    "\n",
    "    print(\"\\n>>> NAIVE (smoke)\")\n",
    "    out_path, res = run_continual(\n",
    "        preset=preset_demo, method=\"naive\", lam=None,\n",
    "        seed=seed_demo, encoder=enc_demo, tfm=tfm,\n",
    "        fisher_batches_by_preset={\"std\": 600},\n",
    "        epochs_override=2,   # smoke rápido\n",
    "        verbose=True\n",
    "    )\n",
    "    print(\"OK:\", out_path)\n",
    "\n",
    "    print(\"\\n>>> EWC (smoke)\")\n",
    "    out_path, res = run_continual(\n",
    "        preset=preset_demo, method=\"ewc\", lam=1e9,\n",
    "        seed=seed_demo, encoder=enc_demo, tfm=tfm,\n",
    "        fisher_batches_by_preset={\"std\": 600},\n",
    "        epochs_override=2,   # smoke rápido\n",
    "        verbose=True\n",
    "    )\n",
    "    print(\"OK:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-sweep de λ en preset std (rápido)\n",
    "# lams = [3e8, 5e8, 7e8]\n",
    "# out_runs = []\n",
    "# for lam in lams:\n",
    "#     print(f\"\\n>>> EWC SMOKE λ={lam:.0e}\")\n",
    "#     out_dir, _ = run_continual(\n",
    "#         preset=\"std\",\n",
    "#         method=\"ewc\",\n",
    "#         lam=lam,\n",
    "#         seed=42,\n",
    "#         encoder=\"rate\",\n",
    "#         tfm=tfm,\n",
    "#         fisher_batches_by_preset={\"std\": 600},\n",
    "#         epochs_override=2,      # smoke rápido\n",
    "#         verbose=True,\n",
    "#     )\n",
    "#     out_runs.append(out_dir)\n",
    "# print(\"\\nHecho:\", out_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d378658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== CONFIG POR DEFECTO PARA LAS COMPARATIVAS ======================\n",
    "# Recomendaciones acordadas:\n",
    "# - fast: EWC λ=1e9 (estable). Extra: λ=1e8 (mejor T2, algo más de olvido)\n",
    "# - std : EWC λ=1e7 (baseline estable). Extra: λ=3e7 (mejor T2, más olvido)\n",
    "\n",
    "# EWC_DEFAULTS = {\n",
    "#     \"fast\":     {\"primary\": [1e9, 3e8],      \"extra\": [3e9]},\n",
    "#     \"std\": {\"primary\": [7e8, 1e9, 1.2e9, 1.5e9], \"extra\": []},\n",
    "#     \"accurate\": {\"primary\": [1e6, 3e6, 1e7], \"extra\": []},  # ← mucho más bajo que 1e9\n",
    "# }\n",
    "\n",
    "EWC_DEFAULTS = {\n",
    "    \"fast\": {\"primary\": [7e8, 1e9, 1.2e9], \"extra\": []},\n",
    "    \"std\":  {\"primary\": [5e8, 7e8, 1e9],   \"extra\": []},\n",
    "    \"accurate\": {\"primary\": [1e6, 3e6, 1e7], \"extra\": []}, \n",
    "    # de momento accurate solo NAIVE; EWC en accurate lo aparcamos\n",
    "    # \"accurate\": {\"primary\": [], \"extra\": []},\n",
    "}\n",
    "\n",
    "INCLUDE_NAIVE    = True          # añade baseline sin EWC\n",
    "INCLUDE_EXTRAS   = False          # activa los λ \"extra\" por preset\n",
    "SEEDS            = [42]  # multisemillas para medias/σ\n",
    "# SEEDS            = [42, 43, 44]  # multisemillas para medias/σ\n",
    "ENCODERS         = [\"rate\"]      # luego podrás añadir \"latency\"\n",
    "# FISHER_BY_PRESET = {\"fast\": 200, \"std\": 600, \"accurate\": 600}  # estabiliza el cálculo de Fisher\n",
    "# FISHER_BY_PRESET = {\"fast\": 800, \"std\": 1000}  # estabiliza el cálculo de Fisher\n",
    "# Endurecemos Fisher para estabilidad; accurate necesita más por ser más largo\n",
    "# FISHER_BY_PRESET = {\"fast\": 800, \"std\": 1200, \"accurate\": 1500}\n",
    "FISHER_BY_PRESET = {\"fast\": 800, \"std\": 1000, \"accurate\": 1500}\n",
    "# Elige qué presets lanzar\n",
    "PRESETS_TO_RUN = [\"fast\", \"std\", \"accurate\"]  # añade \"accurate\" si lo necesitas más adelante\n",
    "# PRESETS_TO_RUN = [\"accurate\"]  # añade \"accurate\" si lo necesitas más adelante\n",
    "\n",
    "# ---- Construcción del plan de ejecuciones ----\n",
    "runs_plan = []\n",
    "for preset_i in PRESETS_TO_RUN:\n",
    "    # EWC primary\n",
    "    for lam in EWC_DEFAULTS[preset_i][\"primary\"]:\n",
    "        runs_plan.append((preset_i, \"ewc\", lam))\n",
    "    # EWC extras (opcionales)\n",
    "    if INCLUDE_EXTRAS:\n",
    "        for lam in EWC_DEFAULTS[preset_i][\"extra\"]:\n",
    "            runs_plan.append((preset_i, \"ewc\", lam))\n",
    "    # Baseline sin EWC\n",
    "    if INCLUDE_NAIVE:\n",
    "        runs_plan.append((preset_i, \"naive\", None))\n",
    "\n",
    "print(\"Plan de runs (preset, método, λ):\")\n",
    "for preset_i, method_i, lam_i in runs_plan:\n",
    "    print(f\"  {preset_i:>7}  {method_i:>5}  λ={lam_i}\")\n",
    "print(\"Semillas:\", SEEDS, \" | Encoders:\", ENCODERS)\n",
    "print(\"Fisher batches por preset:\", FISHER_BY_PRESET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== DRIVER MULTISEMILLAS (usa la CONFIG de arriba) ======================\n",
    "for enc in ENCODERS:\n",
    "    for seed in SEEDS:\n",
    "        for preset_i, method_i, lam_i in runs_plan:\n",
    "            print(f\"\\n=== RUN: preset={preset_i} | method={method_i} | λ={lam_i} | seed={seed} | encoder={enc} ===\")\n",
    "            out_path, _ = run_continual(\n",
    "                preset=preset_i,\n",
    "                method=method_i,\n",
    "                lam=(lam_i if method_i == \"ewc\" else None),\n",
    "                seed=seed,\n",
    "                encoder=enc,\n",
    "                tfm=tfm,  # definido en tu celda de setup\n",
    "                fisher_batches_by_preset=FISHER_BY_PRESET,\n",
    "            )\n",
    "            print(\"OK:\", out_path)\n",
    "print(\"\\n✅ Listo. Ejecuta las celdas de resumen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9835a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Resumen comparativo de todos los continual_* en outputs/\n",
    "# =============================================================================\n",
    "import re, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def parse_exp_name(name: str):\n",
    "    \"\"\"\n",
    "    Extrae preset, método, lambda, encoder y seed del nombre de carpeta:\n",
    "\n",
    "      continual_<preset>_<method>[_lam_<lambda>]_<_encoder>[_seed_<seed>]\n",
    "\n",
    "    Ejemplos:\n",
    "      continual_fast_naive_rate_seed_42\n",
    "      continual_fast_ewc_lam_1e+08_rate_seed_42\n",
    "      continual_std_ewc_lam_3e+07_latency_seed_43\n",
    "    \"\"\"\n",
    "    m = re.match(\n",
    "        r\"continual_(?P<preset>\\w+)_(?P<method>ewc|naive)\"\n",
    "        r\"(?:_lam_(?P<lambda>[^_]+))?_(?P<enc>[^_]+)\"\n",
    "        r\"(?:_seed_(?P<seed>\\d+))?$\",\n",
    "        name\n",
    "    )\n",
    "    meta = {\"preset\": None, \"method\": None, \"lambda\": None, \"encoder\": None, \"seed\": None}\n",
    "    if m:\n",
    "        d = m.groupdict()\n",
    "        meta.update({\n",
    "            \"preset\": d[\"preset\"],\n",
    "            \"method\": d[\"method\"],\n",
    "            \"lambda\": d.get(\"lambda\"),\n",
    "            \"encoder\": d.get(\"enc\"),\n",
    "            \"seed\": d.get(\"seed\"),\n",
    "        })\n",
    "    return meta\n",
    "\n",
    "rows = []\n",
    "root_out = ROOT / \"outputs\"\n",
    "\n",
    "for exp_dir in sorted(root_out.glob(\"continual_*\")):\n",
    "    name = exp_dir.name\n",
    "    meta = parse_exp_name(name)\n",
    "\n",
    "    # Saltar nombres no reconocidos (runs muy antiguos)\n",
    "    if meta[\"preset\"] is None:\n",
    "        continue\n",
    "\n",
    "    results_path = exp_dir / \"continual_results.json\"\n",
    "    if not results_path.exists():\n",
    "        continue\n",
    "\n",
    "    with open(results_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        res = json.load(f)\n",
    "\n",
    "    # Detectar tareas: la \"última\" es la que NO tiene claves 'after_*'\n",
    "    task_names = list(res.keys())\n",
    "    if len(task_names) < 2:\n",
    "        continue\n",
    "\n",
    "    def is_last(d):  # no tiene after_*\n",
    "        return not any(k.startswith(\"after_\") for k in d.keys())\n",
    "\n",
    "    last_task = None\n",
    "    first_task = None\n",
    "    for tn in task_names:\n",
    "        if is_last(res[tn]):\n",
    "            last_task = tn\n",
    "        else:\n",
    "            first_task = tn\n",
    "\n",
    "    # Fallback por si no se identifica bien\n",
    "    if first_task is None or last_task is None:\n",
    "        task_names_sorted = sorted(task_names)\n",
    "        first_task = task_names_sorted[0]\n",
    "        last_task  = task_names_sorted[-1]\n",
    "\n",
    "    c1, c2 = first_task, last_task\n",
    "\n",
    "    c1_test_mae = float(res[c1].get(\"test_mae\", float(\"nan\")))\n",
    "    c2_test_mae = float(res[c2].get(\"test_mae\", float(\"nan\")))\n",
    "    after_key_mae = f\"after_{c2}_mae\"\n",
    "    c1_after_c2_mae = float(res[c1].get(after_key_mae, float(\"nan\")))\n",
    "\n",
    "    forgetting_abs = c1_after_c2_mae - c1_test_mae\n",
    "    forgetting_rel = (forgetting_abs / c1_test_mae * 100.0) if c1_test_mae == c1_test_mae else float(\"nan\")\n",
    "\n",
    "    rows.append({\n",
    "        \"exp\": name,\n",
    "        \"preset\": meta[\"preset\"],\n",
    "        \"method\": meta[\"method\"],\n",
    "        \"lambda\": meta[\"lambda\"] if meta[\"method\"] == \"ewc\" else None,\n",
    "        \"encoder\": meta[\"encoder\"],\n",
    "        \"seed\": int(meta[\"seed\"]) if meta[\"seed\"] is not None else None,\n",
    "        \"c1_name\": c1,\n",
    "        \"c2_name\": c2,\n",
    "        \"c1_mae\": c1_test_mae,\n",
    "        \"c1_after_c2_mae\": c1_after_c2_mae,\n",
    "        \"c1_forgetting_mae_abs\": forgetting_abs,\n",
    "        \"c1_forgetting_mae_rel_%\": forgetting_rel,\n",
    "        \"c2_mae\": c2_test_mae,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Asegura columnas numéricas auxiliares\n",
    "if \"lambda_num\" not in df.columns:\n",
    "    df[\"lambda_num\"] = pd.to_numeric(df[\"lambda\"], errors=\"coerce\")  # '1e+08' -> 1e+08 ; NAIVE -> NaN\n",
    "\n",
    "# Deja 'seed' como entero y elimina 'seed_num' si existe\n",
    "df[\"seed\"] = pd.to_numeric(df[\"seed\"], errors=\"coerce\").astype(\"Int64\")\n",
    "if \"seed_num\" in df.columns:\n",
    "    df = df.drop(columns=[\"seed_num\"])\n",
    "\n",
    "# Ordenar: preset, method, encoder, lambda_num (NaN al final), seed\n",
    "df = df.sort_values(\n",
    "    by=[\"preset\", \"method\", \"encoder\", \"lambda_num\", \"seed\"],\n",
    "    na_position=\"last\",\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Vista agregada (media±std por preset/method/λ/encoder) ======================\n",
    "import pandas as pd\n",
    "\n",
    "# Métricas a agregar\n",
    "cols_metrics = [\"c1_mae\", \"c1_after_c2_mae\", \"c1_forgetting_mae_abs\", \"c1_forgetting_mae_rel_%\", \"c2_mae\"]\n",
    "\n",
    "# Copia y asegura columna numérica auxiliar para ordenar por λ\n",
    "gdf = df.copy()\n",
    "if \"lambda_num\" not in gdf.columns:\n",
    "    gdf[\"lambda_num\"] = pd.to_numeric(gdf[\"lambda\"], errors=\"coerce\")  # NA para NAIVE\n",
    "\n",
    "# Agregación: media, std y número de corridas (semillas) por combinación\n",
    "agg = (\n",
    "    gdf\n",
    "    .groupby([\"preset\", \"method\", \"encoder\", \"lambda\", \"lambda_num\"], dropna=False)[cols_metrics]\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Aplanar nombres de columnas (de MultiIndex a una sola capa)\n",
    "agg.columns = [\n",
    "    \"_\".join(filter(None, map(str, col))).rstrip(\"_\")\n",
    "    for col in agg.columns.to_flat_index()\n",
    "]\n",
    "\n",
    "# Ordena por preset/method/encoder/λ_num (NaN al final ⇒ NAIVE al final de su grupo)\n",
    "agg = agg.sort_values(\n",
    "    by=[\"preset\", \"method\", \"encoder\", \"lambda_num\"],\n",
    "    na_position=\"last\",\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# (Opcional) guardar a CSV\n",
    "summary_dir = ROOT / \"outputs\" / \"summary\"\n",
    "summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "agg.to_csv(summary_dir / \"continual_summary_agg.csv\", index=False)\n",
    "print(\"Guardado:\", summary_dir / \"continual_summary_agg.csv\")\n",
    "\n",
    "agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821024ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Formateo para la memoria (tabla compacta) ======================\n",
    "\n",
    "def fmt(x, prec=4):\n",
    "    # Redondea y gestiona NaN de forma amigable\n",
    "    import pandas as pd\n",
    "    return \"\" if pd.isna(x) else f\"{x:.{prec}f}\"\n",
    "\n",
    "show = agg.copy()\n",
    "\n",
    "# 1) Crea 'count' a partir de cualquiera de las columnas *_count\n",
    "count_cols = [c for c in show.columns if c.endswith(\"_count\")]\n",
    "if count_cols:\n",
    "    show[\"count\"] = show[count_cols[0]].astype(\"Int64\")  # todas deberían coincidir\n",
    "    # (opcional) elimina las columnas *_count individuales\n",
    "    show = show.drop(columns=count_cols)\n",
    "\n",
    "# 2) Redondea columnas de medias/desviaciones\n",
    "for c in [c for c in show.columns if c.endswith(\"_mean\") or c.endswith(\"_std\")]:\n",
    "    show[c] = show[c].map(lambda v: fmt(v, 4))\n",
    "\n",
    "# 3) Selección de columnas clave (ajusta el orden a tu gusto)\n",
    "cols = [\n",
    "    \"preset\", \"method\", \"encoder\", \"lambda\",\n",
    "    \"c1_mae_mean\", \"c1_forgetting_mae_rel_%_mean\", \"c2_mae_mean\",\n",
    "    \"c1_mae_std\",  \"c1_forgetting_mae_rel_%_std\",  \"c2_mae_std\",\n",
    "    \"count\"\n",
    "]\n",
    "\n",
    "# Si alguna columna no existiera (según tus métricas), la ignoramos con aviso\n",
    "missing = [c for c in cols if c not in show.columns]\n",
    "if missing:\n",
    "    print(\"Aviso: faltan columnas en 'show':\", missing)\n",
    "    cols = [c for c in cols if c in show.columns]\n",
    "\n",
    "show = show[cols].rename(columns={\n",
    "    \"preset\": \"preset\",\n",
    "    \"method\": \"método\",\n",
    "    \"encoder\": \"codificador\",\n",
    "    \"lambda\": \"λ\",\n",
    "    \"c1_mae_mean\": \"MAE Tarea1 (media)\",\n",
    "    \"c1_forgetting_mae_rel_%_mean\": \"Olvido T1 (%) (media)\",\n",
    "    \"c2_mae_mean\": \"MAE Tarea2 (media)\",\n",
    "    \"c1_mae_std\": \"MAE Tarea1 (σ)\",\n",
    "    \"c1_forgetting_mae_rel_%_std\": \"Olvido T1 (%) (σ)\",\n",
    "    \"c2_mae_std\": \"MAE Tarea2 (σ)\",\n",
    "    \"count\": \"n (semillas)\"\n",
    "})\n",
    "\n",
    "show\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
