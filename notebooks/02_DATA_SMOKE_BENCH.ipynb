{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e50374",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "# 02 ¬∑ Data Smoke & Bench\n",
    "\n",
    "**Qu√© hace este notebook:**\n",
    "\n",
    "Pruebas r√°pidas para validar **datos/splits**, comprobar el **pipeline de codificaci√≥n temporal** (offline H5 o runtime) y hacer **micro-bench** de *throughput*. Lee la configuraci√≥n desde `configs/presets.yaml` para asegurar coherencia con el cuaderno 03.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Detectar r√°pido problemas en datos/H5\n",
    "- Tener una referencia de it/s y formas de tensores antes de lanzar entrenos largos.\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "\n",
    "- [1) Setup del entorno e imports](#sec-01)\n",
    "- [2) Cargar preset y eco de configuraci√≥n](#sec-02)\n",
    "- [3) Verificaci√≥n de datos y carga de `task_list`](#sec-03)\n",
    "- [4) Factory de DataLoaders (H5 offline o CSV + runtime)](#sec-04)\n",
    "- [5) Smoke universal (loader ‚Üí modelo)](#sec-05)\n",
    "- [6) Forward manual con fallback AMP](#sec-06)\n",
    "- [7) Echo de configuraci√≥n del bench](#sec-07)\n",
    "- [8) Toggle: *it/s* por √©poca](#sec-08)\n",
    "- [9) (Opc.) Micro-bench pipeline *it/s*](#sec-09)\n",
    "- [10) (Opc.) Smokes de m√©todos con `run_continual`](#sec-10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad44dbd",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "## 1) Setup del entorno e imports\n",
    "\n",
    "**Objetivo:** dejar preparado el entorno para realizar *smoke tests* (comprobaciones m√≠nimas de punta a punta) y micro-*benchmarks* de **loader ‚Üí forward** sin entrenar.\n",
    "\n",
    "Esta celda:\n",
    "- Limita hilos BLAS (`OMP`, `MKL`, `OPENBLAS`) para evitar *over-subscription*.\n",
    "- Detecta la ra√≠z del repo (`ROOT`) y la a√±ade a `sys.path`.\n",
    "- Importa utilidades de *bench* y helpers del proyecto:\n",
    "  - **Datos/loader**: `build_make_loader_fn`, `ImageTransform`, `AugmentConfig`.\n",
    "  - **Modelo**: `build_model`.\n",
    "  - **Entrenamiento**: `set_encode_runtime` y utilidades de `training`.\n",
    "  - **Bench**: `universal_smoke_forward`, `enable_epoch_ips`, `disable_epoch_ips`, `print_bench_config`, `pipeline_its`.\n",
    "- Selecciona dispositivo (`cuda` si est√° disponible) y activa optimizaciones razonables:\n",
    "  - `cudnn.benchmark`, TF32 en CUDA y precisi√≥n alta en *matmul*.\n",
    "\n",
    "> **Nota:** Este cuaderno **no entrena**. Su meta es validar que tu configuraci√≥n de datos, *loader* y modelo **encienden** y medir un *throughput* de referencia.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4da4bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup\n",
    "# =============================================================================\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.utils import load_preset, set_seeds, build_make_loader_fn  # ‚Üê nuevo\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import build_model\n",
    "import src.training as training\n",
    "from src.bench import (\n",
    "    universal_smoke_forward,\n",
    "    enable_epoch_ips, disable_epoch_ips,\n",
    "    print_bench_config,\n",
    "    pipeline_its,\n",
    "    to_5d,  # ‚Üê lo usaremos en la celda 6 para evitar duplicar l√≥gica\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e878424",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "## 2) Config desde `presets.yaml` y eco de configuraci√≥n\n",
    "\n",
    "**Objetivo:** usar exactamente la **misma configuraci√≥n** que en entrenamiento (03), leyendo el `PRESET` de `configs/presets.yaml`.\n",
    "\n",
    "Incluye:\n",
    "- **Modelo y *transform*** (tama√±o y escala a gris) v√≠a `ImageTransform`.\n",
    "- **Codificaci√≥n temporal**: `ENCODER` (`rate`/`latency`), `T`, `GAIN` y `SEED`.\n",
    "- **Modo de datos**:\n",
    "  - `use_offline_spikes`: si es `true`, esperamos **H5** pre-generados.\n",
    "  - `encode_runtime`: si es `true`, el *loader* entregar√° im√°genes y se codificar√°n a eventos **en GPU**.\n",
    "- **DataLoader**: `num_workers`, `prefetch_factor`, `pin_memory`, `persistent_workers`.\n",
    "- **Augment** (train) y **balanceo online** (si lo activas).\n",
    "- Define `make_model_fn(tfm)` para instanciar el modelo con la misma *transform*.\n",
    "\n",
    "> **Consejo:** pon todos los cambios (modelo, codificaci√≥n, *augment*, *loader*) en el **YAML**, as√≠ 02/03/04 usan la misma fuente de verdad.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c35de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRESET=fast] model=pilotnet_snn 200x66 gray=True\n",
      "[DATA] encoder=rate T=10 gain=0.5 seed=42\n",
      "[LOADER] workers=8 prefetch=2 pin=True persistent=True\n",
      "[BALANCE] online=False bins=50\n",
      "[RUNTIME_ENCODE] False | [OFFLINE_SPIKES] True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Config: lee presets.yaml\n",
    "# =============================================================================\n",
    "PRESET = \"fast\"  # fast | std | accurate\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# Modelo / tfm\n",
    "MODEL_NAME = CFG[\"model\"][\"name\"]\n",
    "tfm = ImageTransform(\n",
    "    CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"],\n",
    "    to_gray=bool(CFG[\"model\"][\"to_gray\"]), crop_top=None)\n",
    "\n",
    "# Datos / codificaci√≥n temporal\n",
    "ENCODER = CFG[\"data\"][\"encoder\"]\n",
    "T       = int(CFG[\"data\"][\"T\"])\n",
    "GAIN    = float(CFG[\"data\"][\"gain\"])\n",
    "SEED    = int(CFG[\"data\"][\"seed\"])\n",
    "\n",
    "USE_OFFLINE_SPIKES   = bool(CFG[\"data\"].get(\"use_offline_spikes\", False))\n",
    "RUNTIME_ENCODE       = bool(CFG[\"data\"].get(\"encode_runtime\", False))\n",
    "\n",
    "# ---- DataLoader / augment / balanceo ----------------------------------------\n",
    "NUM_WORKERS = int(CFG[\"data\"].get(\"num_workers\") or 0)\n",
    "PREFETCH    = CFG[\"data\"].get(\"prefetch_factor\")\n",
    "PIN_MEMORY  = bool(CFG[\"data\"].get(\"pin_memory\", True))\n",
    "PERSISTENT  = bool(CFG[\"data\"].get(\"persistent_workers\", True))\n",
    "\n",
    "AUG_CFG = AugmentConfig(**(CFG[\"data\"].get(\"aug_train\") or {})) \\\n",
    "          if CFG[\"data\"].get(\"aug_train\") else None\n",
    "\n",
    "USE_ONLINE_BALANCING = bool(CFG[\"data\"].get(\"balance_online\", False))\n",
    "BAL_BINS = int(CFG[\"data\"].get(\"balance_bins\") or 50)\n",
    "BAL_EPS  = float(CFG[\"data\"].get(\"balance_smooth_eps\") or 1e-3)\n",
    "\n",
    "print(f\"[PRESET={PRESET}] model={MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] encoder={ENCODER} T={T} gain={GAIN} seed={SEED}\")\n",
    "print(f\"[LOADER] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "print(f\"[BALANCE] online={USE_ONLINE_BALANCING} bins={BAL_BINS}\")\n",
    "print(f\"[RUNTIME_ENCODE] {RUNTIME_ENCODE} | [OFFLINE_SPIKES] {USE_OFFLINE_SPIKES}\")\n",
    "\n",
    "def make_model_fn(tfm):\n",
    "    # kwargs solo necesarios para pilotnet_snn\n",
    "    return build_model(MODEL_NAME, tfm, beta=0.9, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ffe6a8",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "## 3) Verificaci√≥n de datos y carga de `task_list`\n",
    "\n",
    "Esta celda:\n",
    "1. **Elige el fichero de tareas** en funci√≥n del preset:\n",
    "   - Si `prep.use_balanced_tasks = true` y existe, usa `tasks_balanced.json`.\n",
    "   - En caso contrario, usa `tasks.json`.\n",
    "2. Construye `task_list` con cada *run* y las rutas de `train/val/test`.\n",
    "3. **Guardarra√≠l** (si `use_balanced_tasks = true`): exige que `train` apunte a `train_balanced.csv`.\n",
    "4. Verifica seg√∫n el **modo de datos**:\n",
    "   - **H5 offline** (`use_offline_spikes = true`): comprueba que existen los H5 esperados para cada *split* con el **naming** coherente (`{split}_{encoder}_T{T}_gain{...}_{gray|rgb}_{W}x{H}.h5`).\n",
    "   - **CSV + runtime**: valida que los CSV existen y que las rutas de imagen son reales (muestra m√≠nima). Si esperabas material en `aug/` y no est√°, re-genera con `01A_PREP_BALANCED`.\n",
    "\n",
    "> Si faltan H5 y est√°s en modo offline, **g√©n√©ralos** con `02_ENCODE_OFFLINE.ipynb`.  \n",
    "> Si est√°s en modo runtime, aseg√∫rate de que las rutas de imagen del CSV son absolutas o resolubles desde `ROOT`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3d6f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando tasks: tasks_balanced.json\n",
      " - circuito1: train_balanced.csv\n",
      " - circuito2: train_balanced.csv\n",
      "Verificaci√≥n de tasks balanceadas OK.\n",
      "OK: H5 requeridos encontrados para todos los splits.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Verificaci√≥n de datos + selecci√≥n de tasks seg√∫n el PRESET\n",
    "# =============================================================================\n",
    "from pathlib import Path as _P\n",
    "\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "RAW  = ROOT / \"data\" / \"raw\" / \"udacity\"\n",
    "\n",
    "# --- Elegir tasks seg√∫n el preset ---\n",
    "tb_name = CFG[\"prep\"][\"tasks_balanced_file_name\"]   # p.ej., \"tasks_balanced.json\"\n",
    "t_name  = CFG[\"prep\"][\"tasks_file_name\"]            # p.ej., \"tasks.json\"\n",
    "USE_BALANCED = bool(CFG.get(\"prep\", {}).get(\"use_balanced_tasks\", False))\n",
    "\n",
    "cand_bal = PROC / tb_name\n",
    "cand_std = PROC / t_name\n",
    "\n",
    "if USE_BALANCED and cand_bal.exists():\n",
    "    TASKS_FILE = cand_bal\n",
    "else:\n",
    "    TASKS_FILE = cand_std\n",
    "\n",
    "with open(TASKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "print(\"Usando tasks:\", TASKS_FILE.name)\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {_P(t['paths']['train']).name}\")\n",
    "\n",
    "# --- Guardarra√≠l: si usamos tasks balanceadas, aseguramos train_balanced.csv ---\n",
    "if USE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = _P(t[\"paths\"][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' en tasks balanceadas, \"\n",
    "                f\"pero encontr√© '{train_path.name}'.\"\n",
    "            )\n",
    "    print(\"Verificaci√≥n de tasks balanceadas OK.\")\n",
    "\n",
    "# --- Verificaci√≥n espec√≠fica seg√∫n el modo de datos ---\n",
    "if USE_OFFLINE_SPIKES:\n",
    "    # Comprobamos que existen los H5 requeridos por el preset\n",
    "    mw, mh = CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"]\n",
    "    color = \"gray\" if CFG[\"model\"][\"to_gray\"] else \"rgb\"\n",
    "    gain_tag = (GAIN if ENCODER == \"rate\" else 0)\n",
    "    missing = []\n",
    "\n",
    "    for t in task_list:\n",
    "        run = t[\"name\"]\n",
    "        base = PROC / run\n",
    "        for split in (\"train\", \"val\", \"test\"):\n",
    "            expected = base / f\"{split}_{ENCODER}_T{T}_gain{gain_tag}_{color}_{mw}x{mh}.h5\"\n",
    "            if not expected.exists():\n",
    "                missing.append(str(expected))\n",
    "\n",
    "    if missing:\n",
    "        raise FileNotFoundError(\n",
    "            \"Faltan H5 requeridos por el preset. Genera primero con 02_ENCODE_OFFLINE.ipynb.\\n\"\n",
    "            + \"\\n\".join(\" - \" + m for m in missing)\n",
    "        )\n",
    "    print(\"OK: H5 requeridos encontrados para todos los splits.\")\n",
    "\n",
    "else:\n",
    "    # CSV + encode en runtime: comprobamos que el CSV existe y que hay im√°genes accesibles\n",
    "    import pandas as _pd\n",
    "\n",
    "    for t in task_list:\n",
    "        for split in (\"train\", \"val\", \"test\"):\n",
    "            csv_path = _P(tasks_json[\"splits\"][t[\"name\"]][split])\n",
    "            if not csv_path.is_absolute():\n",
    "                csv_path = ROOT / csv_path\n",
    "            if not csv_path.exists():\n",
    "                raise FileNotFoundError(f\"No existe CSV: {csv_path}\")\n",
    "\n",
    "    # Muestra m√≠nima para detectar rutas rotas (ej. 'aug/' sin materializar)\n",
    "    run0 = task_list[0][\"name\"]\n",
    "    csv0 = _P(tasks_json[\"splits\"][run0][\"train\"])\n",
    "    if not csv0.is_absolute():\n",
    "        csv0 = ROOT / csv0\n",
    "    df0 = _pd.read_csv(csv0, nrows=5)\n",
    "    col_path = \"path\" if \"path\" in df0.columns else None\n",
    "    if col_path is None:\n",
    "        # fallback: si el CSV tiene 'center/left/right', tomamos 'center'\n",
    "        for c in (\"center\", \"image\", \"img\"):\n",
    "            if c in df0.columns:\n",
    "                col_path = c\n",
    "                break\n",
    "    if col_path is None:\n",
    "        raise RuntimeError(\n",
    "            f\"No encuentro columna de ruta en {csv0}. Esperaba 'path' o 'center'.\"\n",
    "        )\n",
    "\n",
    "    missing_imgs = [p for p in df0[col_path].tolist() if not _P(p).exists()]\n",
    "    if missing_imgs:\n",
    "        raise FileNotFoundError(\n",
    "            \"Rutas de imagen no v√°lidas en CSV (ejemplo):\\n\"\n",
    "            f\" - {missing_imgs[0]}\\n\"\n",
    "            \"Si esperabas im√°genes balanceadas en 'aug/', re-ejecuta 01A_PREP_BALANCED.ipynb.\"\n",
    "        )\n",
    "    print(\"OK: CSV y rutas de im√°genes accesibles para encode en runtime.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9bd138",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "## 4) Factory de DataLoaders (H5 offline o CSV + runtime)\n",
    "\n",
    "Crea `make_loader_fn` con los *flags* del preset:\n",
    "- Si `use_offline_spikes = true`, prioriza **H5**.\n",
    "- Si no hay H5 o `use_offline_spikes = false`, usa **CSV + codificaci√≥n en runtime** (en GPU si est√° disponible).\n",
    "- Aplica por defecto los *kwargs* del `DataLoader` (workers, *prefetch*, *pin/persistent*), *augment* de `train` y **balanceo online** si lo activas.\n",
    "\n",
    "`make_loader_fn(...)` permite **sobrescribir** puntualmente *kwargs* (p. ej., bajar `batch_size` para un *smoke*).\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9fdab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_loader_fn listo (H5 si use_offline_spikes=True; fallback CSV+runtime si no).\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Factory de loaders (H5 offline o CSV + runtime encode)\n",
    "#   Igual que en 03_TRAIN_CONTINUAL: elige H5 si use_offline_spikes=True,\n",
    "#   y si no hay H5 cae a CSV + encode en GPU.\n",
    "# =============================================================================\n",
    "_raw_make_loader_fn = build_make_loader_fn(\n",
    "    root=ROOT,\n",
    "    use_offline_spikes=USE_OFFLINE_SPIKES,\n",
    "    encode_runtime=RUNTIME_ENCODE,\n",
    ")\n",
    "\n",
    "# kwargs comunes del DataLoader que queremos aplicar por defecto\n",
    "_DL_KW = dict(\n",
    "    num_workers=NUM_WORKERS,\n",
    "    prefetch_factor=PREFETCH,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers=PERSISTENT,\n",
    "    aug_train=AUG_CFG,\n",
    "    balance_train=USE_ONLINE_BALANCING,\n",
    "    balance_bins=BAL_BINS,\n",
    "    balance_smooth_eps=BAL_EPS,\n",
    ")\n",
    "\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed, **dl_kwargs):\n",
    "    \"\"\"Wrapper pass-through (permite override puntual de kwargs si se pasan).\"\"\"\n",
    "    return _raw_make_loader_fn(\n",
    "        task=task, batch_size=batch_size, encoder=encoder, T=T, gain=gain,\n",
    "        tfm=tfm, seed=seed, **{**_DL_KW, **dl_kwargs}\n",
    "    )\n",
    "\n",
    "print(\"make_loader_fn listo (H5 si use_offline_spikes=True; fallback CSV+runtime si no).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519003dc",
   "metadata": {},
   "source": [
    "<a id=\"sec-05\"></a>\n",
    "## 5) Smoke universal (loader ‚Üí modelo)\n",
    "\n",
    "Lanza un *smoke test* con el **primer `task`**:\n",
    "- Inicializa un *loader* coherente con el preset (H5 o CSV+runtime).\n",
    "- Comprueba que produce *batches* con la forma esperada.\n",
    "- Ejecuta un **forward** del modelo (con AMP en CUDA si procede).\n",
    "- Reporta errores tempranos de forma clara (shapes, *dtype*, dispositivo).\n",
    "\n",
    "> √ötil para detectar r√°pido desajustes entre `ENCODER`/`T`/`GAIN`, la forma del *batch* y lo que espera el modelo.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06a26a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset ya codificado; solo permuto a (T,B,C,H,W)\n",
      "x5d.device: cpu | shape: (10, 8, 1, 66, 200)\n",
      "[forward] ejecutado con AMP\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Smoke universal de loader+modelo (usa variables del preset)\n",
    "# =============================================================================\n",
    "_ = universal_smoke_forward(\n",
    "    make_loader_fn,\n",
    "    task=task_list[0],\n",
    "    encoder=ENCODER, T=T, gain=GAIN,\n",
    "    tfm=tfm, seed=SEED, device=device,\n",
    "    use_encode_runtime=RUNTIME_ENCODE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f83fa",
   "metadata": {},
   "source": [
    "<a id=\"sec-06\"></a>\n",
    "## 6) Forward manual con fallback AMP\n",
    "\n",
    "Ejecuta el camino completo de forma expl√≠cita:\n",
    "- Crea un *loader* peque√±o.\n",
    "- Convierte el *batch* a **(T, B, C, H, W)**:\n",
    "  - Si ya viene 5D (B,T,C,H,W), solo permuta a (T,B,C,H,W).\n",
    "  - Si viene 4D (B,C,H,W), **activa codificaci√≥n en runtime** (`set_encode_runtime`) y obtiene la secuencia temporal.\n",
    "- Ejecuta `forward` con **AMP** en CUDA; si falla, reintenta en **FP32**.\n",
    "- Limpia el modo *runtime encode* al finalizar.\n",
    "\n",
    "> Esta celda te ayuda a aislar problemas de forma/dispositivo y a validar que la **codificaci√≥n temporal** est√° correctamente parametrizada para tu modelo.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15029956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch del loader: torch.Size([8, 10, 1, 66, 200]) torch.Size([8, 1])\n",
      "x5d.device: cpu | shape: (10, 8, 1, 66, 200)\n",
      "[forward] ejecutado con AMP\n",
      "yhat: (8, 1)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Forward manual: loader -> (T,B,C,H,W) con fallback AMP\n",
    "# =============================================================================\n",
    "from contextlib import nullcontext\n",
    "\n",
    "# 1) Loader peque√±o con tu helper\n",
    "tr, va, te = make_loader_fn(\n",
    "    task=task_list[0],\n",
    "    batch_size=8,\n",
    "    encoder=ENCODER,   # <-- preset\n",
    "    T=T,               # <-- preset\n",
    "    gain=GAIN,         # <-- preset\n",
    "    tfm=tfm,\n",
    "    seed=SEED,\n",
    ")\n",
    "xb, yb = next(iter(tr))\n",
    "print(\"batch del loader:\", xb.shape, yb.shape)\n",
    "\n",
    "# 2) A (T,B,C,H,W) con helper (activa runtime encode si hace falta)\n",
    "used_runtime_encode = False\n",
    "try:\n",
    "    x5d, used_runtime_encode = to_5d(xb, ENCODER, T, GAIN, device)\n",
    "    print(\"x5d.device:\", x5d.device, \"| shape:\", tuple(x5d.shape))\n",
    "\n",
    "    # 3) Modelo y forward con fallback AMP\n",
    "    model = make_model_fn(tfm).to(device).eval()\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    ctx = torch.amp.autocast(\"cuda\", enabled=use_cuda) if use_cuda else nullcontext()\n",
    "\n",
    "    try:\n",
    "        with torch.inference_mode(), ctx:\n",
    "            yhat = model(x5d.to(device, non_blocking=True))\n",
    "        print(\"[forward] ejecutado con AMP\" if use_cuda else \"[forward] ejecutado en FP32\")\n",
    "    except Exception as e:\n",
    "        if use_cuda:\n",
    "            print(\"[forward] AMP fall√≥, reintento en FP32. Motivo:\", str(e))\n",
    "        with torch.inference_mode():\n",
    "            yhat = model(x5d.to(device, dtype=torch.float32, non_blocking=True))\n",
    "        print(\"[forward] ejecutado en FP32\")\n",
    "\n",
    "    print(\"yhat:\", tuple(yhat.shape))\n",
    "\n",
    "finally:\n",
    "    # 4) Limpieza del runtime encode (si se us√≥)\n",
    "    if used_runtime_encode:\n",
    "        training.set_encode_runtime(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2600ee",
   "metadata": {},
   "source": [
    "<a id=\"sec-07\"></a>\n",
    "## 7) Echo de configuraci√≥n del bench\n",
    "\n",
    "Imprime los par√°metros efectivos del `DataLoader` y del balanceo **online** activos en este cuaderno.  \n",
    "Sirve para dejar rastro cuando compares *throughput* entre presets o m√°quinas.\n",
    "\n",
    "> Recuerda: el **balanceo offline** (por im√°genes) se decide **antes** en los cuadernos de *prep*; aqu√≠ solo afecta el **balanceo online** en el `DataLoader`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6158c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bench workers=8 prefetch=2 pin=True persistent=True | online_bal=False\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Bench: echo de configuraci√≥n efectiva\n",
    "# =============================================================================\n",
    "print_bench_config(\n",
    "    NUM_WORKERS=NUM_WORKERS, PREFETCH=PREFETCH,\n",
    "    PIN_MEMORY=PIN_MEMORY, PERSISTENT=PERSISTENT,\n",
    "    USE_ONLINE_BALANCING=USE_ONLINE_BALANCING,  # ‚Üê sin USE_OFFLINE_BALANCED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e5c3ae",
   "metadata": {},
   "source": [
    "<a id=\"sec-08\"></a>\n",
    "## 8) Toggle: *it/s* por √©poca\n",
    "\n",
    "Activa un *hook* que imprime **iteraciones/segundo** (*it/s*) por √©poca durante entrenamiento.  \n",
    "Es √∫til cuando luego ejecutes 03 para tener una **lectura r√°pida de rendimiento**.\n",
    "\n",
    "- Llama a `enable_epoch_ips()` para **activar**.\n",
    "- Llama a `disable_epoch_ips()` para **restaurar** el comportamiento normal.\n",
    "\n",
    "> Este *toggle* no cambia la m√©trica ni el *logger*; solo a√±ade un contador de *throughput* por √©poca.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf03722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it/s por √©poca ACTIVADO. Llama a disable_epoch_ips() para restaurar.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Toggle: imprimir it/s por √©poca durante entrenamiento\n",
    "# =============================================================================\n",
    "enable_epoch_ips()\n",
    "print(\"it/s por √©poca ACTIVADO. Llama a disable_epoch_ips() para restaurar.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2877f7",
   "metadata": {},
   "source": [
    "<a id=\"sec-09\"></a>\n",
    "## 9) (Opcional) Micro-bench pipeline *it/s*\n",
    "\n",
    "Mide un **throughput aproximado** de `loader ‚Üí modelo` (con AMP si procede) durante un n√∫mero acotado de iteraciones.\n",
    "\n",
    "Recomendaciones:\n",
    "- Usa un `batch_size` realista para tu preset.\n",
    "- Aseg√∫rate de que el primer *batch* ha calentado cach√©s (la funci√≥n ya hace *warmup* b√°sico).\n",
    "- Interpreta el valor como **tendencia**: variar√° con el estado del sistema, E/S de disco, *workers* y *augment*.\n",
    "\n",
    "> √ösalo para comparar **H5 offline** vs **CSV + runtime** y valorar impacto de `num_workers/prefetch` antes de correr entrenos largos.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e410f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline it/s ‚âà 35.77\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# (Opcional) Micro-bench pipeline: it/s (loader + modelo)\n",
    "# =============================================================================\n",
    "tr, va, te = make_loader_fn(\n",
    "    task=task_list[0],\n",
    "    batch_size=8,\n",
    "    encoder=ENCODER, T=T, gain=GAIN,\n",
    "    tfm=tfm, seed=SEED,\n",
    ")\n",
    "\n",
    "its = pipeline_its(\n",
    "    model=make_model_fn(tfm).to(device).eval(),\n",
    "    loader=tr, device=device,\n",
    "    iters=100, use_amp=True,\n",
    "    encoder=ENCODER, T=T, gain=GAIN,\n",
    ")\n",
    "print(f\"pipeline it/s ‚âà {its:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc0795",
   "metadata": {},
   "source": [
    "<a id=\"sec-10\"></a>\n",
    "## 10) (Opcional) Smokes de m√©todos con `run_continual`\n",
    "\n",
    "Lanza **ejecuciones cortas** (‚Äú*smokes*‚Äù) por m√©todo de aprendizaje continuo usando la **misma configuraci√≥n** del preset, cambiando solo:\n",
    "- `continual.method` (p. ej., `naive`, `ewc`, `rehearsal`, `rehearsal+ewc`, `as-snn`, ‚Ä¶)\n",
    "- `continual.params` (los m√≠nimos para que arranque).\n",
    "\n",
    "¬øQu√© valida?\n",
    "- Integraci√≥n **end-to-end**: *task list* ‚Üí *loader factory* ‚Üí modelo ‚Üí bucle continual.\n",
    "- Que cada m√©todo **enciende** con sus par√°metros b√°sicos.\n",
    "- Que se generan salidas en `outputs/` (manifiestos y m√©tricas m√≠nimas).\n",
    "\n",
    "> Mant√©n estos *smokes* **breves** (pocas √©pocas y/o menos datos) para no sesgar el *bench* ni bloquear la GPU.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8558126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> SMOKE: preset=fast | method=sa-snn | seed=42 | enc=rate | kwargs={'k': 10, 'tau': 10.0, 'th_min': 1.0, 'th_max': 2.0, 'p': 2000000, 'vt_scale': 1.0, 'flatten_spatial': False, 'assume_binary_spikes': False, 'reset_counters_each_task': False}\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=sa-snn_k10_tau10_th1-2_p2000000 | B=128 T=10 AMP=True | enc=rate ---\n",
      "[SA-SNN] attach_to=auto -> hook en primera capa Linear: Linear(in_features=1152, out_features=100, bias=True)\n",
      "[SA-SNN] tracing cada 100 pasos sobre Linear (auto)\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.9082 | score_mean=2.9062 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.8848 | score_mean=2.8828 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.8652 | score_mean=2.8633 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.8008 | score_mean=2.7969 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.8008 | score_mean=2.7969 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.6699 | score_mean=2.6660 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.5391 | score_mean=2.5352 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4746 | score_mean=2.4688 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4746 | score_mean=2.4688 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4746 | score_mean=2.4668 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4746 | score_mean=2.4668 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.4023 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.4004 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.4004 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.4004 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3984 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3984 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3965 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3965 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[TRAIN it/s] epoch 1/2: 6.8 it/s (196 iters en 29.03s)\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3965 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3965 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3945 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3945 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3945 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3926 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3926 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3926 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3906 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.4102 | score_mean=2.3906 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.3438 | score_mean=2.3242 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.3438 | score_mean=2.3242 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.3438 | score_mean=2.3242 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.3438 | score_mean=2.3223 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2793 | score_mean=2.2578 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2793 | score_mean=2.2559 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2793 | score_mean=2.2559 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1895 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1895 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1895 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1875 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1875 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1875 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1855 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[TRAIN it/s] epoch 2/2: 7.8 it/s (196 iters en 25.02s)\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1855 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1855 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1836 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2148 | score_mean=2.1836 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] resumen tarea: neuronas con actividad aceptada = 67/100 (67.0%), mask_avg‚âà10.0%\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2145 | score_mean=2.1839 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2145 | score_mean=2.1833 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2145 | score_mean=2.1826 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.2145 | score_mean=2.1820 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=sa-snn_k10_tau10_th1-2_p2000000 | B=128 T=10 AMP=True | enc=rate ---\n",
      "[SA-SNN] attach_to=auto -> hook en primera capa Linear: Linear(in_features=1152, out_features=100, bias=True)\n",
      "[SA-SNN] tracing cada 100 pasos sobre Linear (auto)\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.1484 | score_mean=2.1152 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=2.0195 | score_mean=1.9844 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.9531 | score_mean=1.9189 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.6934 | score_mean=1.6582 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.6279 | score_mean=1.5918 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.5625 | score_mean=1.5264 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.4980 | score_mean=1.4609 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.4990 | score_mean=1.4619 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3672 | score_mean=1.3291 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[TRAIN it/s] epoch 1/2: 6.4 it/s (85 iters en 13.28s)\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3672 | score_mean=1.3291 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3672 | score_mean=1.3281 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3672 | score_mean=1.3271 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3027 | score_mean=1.2617 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3027 | score_mean=1.2607 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3027 | score_mean=1.2607 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3027 | score_mean=1.2598 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3027 | score_mean=1.2588 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3027 | score_mean=1.2588 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3027 | score_mean=1.2578 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[TRAIN it/s] epoch 2/2: 7.7 it/s (85 iters en 11.01s)\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3027 | score_mean=1.2568 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3027 | score_mean=1.2568 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3026 | score_mean=1.2562 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3026 | score_mean=1.2556 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3026 | score_mean=1.2550 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3026 | score_mean=1.2544 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3026 | score_mean=1.2537 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "[SA-SNN] Linear t=9/9 | trace_mean=1.3026 | score_mean=1.2531 | mask‚âà10.0% (target‚âà10.0%) | k=10 N=100 | tau=10 | vt=1 | th‚àà[1,2]\n",
      "\n",
      "Hecho: ['/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_sa-snn_k10_tau10_th1-2_p2000000_rate_model-PilotNetSNN_66x200_gray_seed_42']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# (Opcional) Smokes de m√©todos con run_continual (cfg del preset)\n",
    "# =============================================================================\n",
    "from copy import deepcopy\n",
    "from src.runner import run_continual\n",
    "\n",
    "DO_RUNS = True  # pon False para saltar\n",
    "\n",
    "if DO_RUNS:\n",
    "    base_cfg = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "    base_cfg = deepcopy(base_cfg)\n",
    "    base_cfg[\"data\"][\"seed\"] = SEED  # fija la semilla si quieres\n",
    "\n",
    "    METHODS = {\n",
    "        \"naive\": {},\n",
    "        \"ewc\": {\"lam\": 1e9, \"fisher_batches\": 200},\n",
    "        \"rehearsal\": {\"buffer_size\": 1000, \"replay_ratio\": 0.2},\n",
    "        \"rehearsal+ewc\": {\"buffer_size\": 1000, \"replay_ratio\": 0.2, \"lam\": 7e8, \"fisher_batches\": 200},\n",
    "        \"as-snn\": {\"gamma_ratio\": 0.3, \"lambda_a\": 1.59168, \"ema\": 0.824},\n",
    "    }\n",
    "\n",
    "    METHODS = {\n",
    "        \"sa-snn\": {\n",
    "            \"k\": 10,\n",
    "            \"tau\": 10.0,\n",
    "            \"th_min\": 1.0,\n",
    "            \"th_max\": 2.0,\n",
    "            \"p\": 2000000,\n",
    "            \"vt_scale\": 1.0,\n",
    "            # \"attach_to\": \"classifier.0\",   # opcional: si sabes la capa densa\n",
    "            \"flatten_spatial\": False,\n",
    "            \"assume_binary_spikes\": False,\n",
    "            \"reset_counters_each_task\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "    out_runs = []\n",
    "    for mname, mparams in METHODS.items():\n",
    "        cfg_i = deepcopy(base_cfg)\n",
    "        cfg_i[\"continual\"][\"method\"] = mname\n",
    "        cfg_i[\"continual\"][\"params\"] = mparams\n",
    "\n",
    "        print(\n",
    "            f\"\\n>>> SMOKE: preset={PRESET} | method={mname} | \"\n",
    "            f\"seed={cfg_i['data']['seed']} | enc={cfg_i['data']['encoder']} | kwargs={mparams}\"\n",
    "        )\n",
    "        out_dir, _ = run_continual(\n",
    "            task_list=task_list,\n",
    "            make_loader_fn=make_loader_fn,  # factory de Celda 4\n",
    "            make_model_fn=make_model_fn,\n",
    "            tfm=tfm,\n",
    "            cfg=cfg_i,               # CONFIG COMPLETA del preset con el m√©todo cambiado\n",
    "            preset_name=PRESET,      # solo naming\n",
    "            out_root=ROOT / \"outputs\",\n",
    "            verbose=True,\n",
    "        )\n",
    "        out_runs.append(out_dir)\n",
    "    print(\"\\nHecho:\", [str(p) for p in out_runs])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
