{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup\n",
    "# =============================================================================\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.utils import set_seeds, load_preset\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import SNNVisionRegressor\n",
    "from src.training import TrainConfig\n",
    "from src.eval import eval_loader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "\n",
    "tfm = ImageTransform(160, 80, True, None)\n",
    "def make_model_fn(tfm):\n",
    "    return SNNVisionRegressor(in_channels=(1 if tfm.to_gray else 3), lif_beta=0.95)\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ENCODE = True\n",
    "\n",
    "SAFE_MODE = False\n",
    "NUM_WORKERS    = 12\n",
    "PREFETCH       = 2\n",
    "PIN_MEMORY     = True\n",
    "PERSISTENT     = True\n",
    "\n",
    "AUG_CFG_LIGHT = AugmentConfig(prob_hflip=0.5, brightness=None, gamma=None, noise_std=0.0)\n",
    "AUG_CFG_FULL  = AugmentConfig(prob_hflip=0.5, brightness=(0.9, 1.1), gamma=(0.95, 1.05), noise_std=0.005)\n",
    "AUG_CFG = AUG_CFG_LIGHT\n",
    "\n",
    "USE_OFFLINE_BALANCED = True\n",
    "USE_ONLINE_BALANCING = False\n",
    "\n",
    "if SAFE_MODE:\n",
    "    NUM_WORKERS = 0\n",
    "    PREFETCH = None\n",
    "    PIN_MEMORY = False\n",
    "    PERSISTENT = False\n",
    "    USE_OFFLINE_BALANCED = False\n",
    "    USE_ONLINE_BALANCING = False\n",
    "    AUG_CFG = None\n",
    "\n",
    "print(f\"[SAFE_MODE={SAFE_MODE}] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Verificación de datos (normal y, si existe, balanceado offline)\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "RAW  = ROOT/\"data\"/\"raw\"/\"udacity\"\n",
    "PROC = ROOT/\"data\"/\"processed\"\n",
    "\n",
    "RUNS = [\"circuito1\",\"circuito2\"]  # ajusta si hace falta\n",
    "\n",
    "missing = []\n",
    "for run in RUNS:\n",
    "    base = PROC / run\n",
    "\n",
    "    # Comprobación obligatoria: splits normales\n",
    "    for part in [\"train\",\"val\",\"test\"]:\n",
    "        p = base / f\"{part}.csv\"\n",
    "        if not p.exists():\n",
    "            missing.append(str(p))\n",
    "\n",
    "    # Comprobación opcional: train_balanced.csv (para modo OFFLINE balanceado)\n",
    "    p_bal = base / \"train_balanced.csv\"\n",
    "    if p_bal.exists():\n",
    "        print(f\"✓ {p_bal} OK\")\n",
    "    else:\n",
    "        print(f\"⚠️  Falta {p_bal}. Si más abajo pones USE_OFFLINE_BALANCED=True, \"\n",
    "              f\"ejecuta 01A_PREP_BALANCED.ipynb o el script tools/make_splits_balanced.py\")\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Faltan CSV obligatorios (ejecuta 01A_PREP_BALANCED.ipynb o tu pipeline de prep):\\n\"\n",
    "        + \"\\n\".join(\" - \" + m for m in missing)\n",
    "    )\n",
    "\n",
    "print(\"OK: splits 'train/val/test' encontrados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9fdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Balanceo: helper =====================\n",
    "print(\n",
    "    \"Modo balanceo:\",\n",
    "    \"OFFLINE (tasks_balanced.json)\" if USE_OFFLINE_BALANCED else \"ORIGINAL (tasks.json)\",\n",
    "    \"| Balanceo ONLINE:\", USE_ONLINE_BALANCING\n",
    ")\n",
    "\n",
    "# Seguridad anti doble balanceo:\n",
    "if USE_OFFLINE_BALANCED and USE_ONLINE_BALANCING:\n",
    "    raise RuntimeError(\"Doble balanceo detectado: OFFLINE y ONLINE a la vez. \"\n",
    "                       \"Pon USE_ONLINE_BALANCING=False cuando uses train_balanced.csv.\")\n",
    "\n",
    "from pathlib import Path  # (omite esta línea si ya importaste Path arriba)\n",
    "\n",
    "def _balance_flag(train_csv_path: str | Path) -> bool:\n",
    "    \"\"\"\n",
    "    Activa balanceo ONLINE solo si:\n",
    "    - USE_ONLINE_BALANCING == True\n",
    "    - Y el CSV de train NO es 'train_balanced.csv'\n",
    "    \"\"\"\n",
    "    is_balanced_csv = Path(train_csv_path).name == \"train_balanced.csv\"\n",
    "    return bool(USE_ONLINE_BALANCING and not is_balanced_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.training as training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15029956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Elegir split: normal (tasks.json) o balanceado offline (tasks_balanced.json)\n",
    "# =============================================================================\n",
    "with open(PROC / (\"tasks_balanced.json\" if USE_OFFLINE_BALANCED else \"tasks.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "# Vista rápida: muestra el CSV de train que se usará por cada tarea\n",
    "print(\"Tareas y su TRAIN CSV:\")\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {Path(t['paths']['train']).name}\")\n",
    "\n",
    "task_list[:2]  # vista rápida\n",
    "\n",
    "# Guardarraíl extra: si has activado el OFFLINE balanceado,\n",
    "# exige que el 'train' sea train_balanced.csv y que exista.\n",
    "if USE_OFFLINE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = Path(t[\"paths\"][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' pero encontré '{train_path.name}'. \"\n",
    "                \"Repite 01A_PREP_BALANCED.ipynb o ajusta USE_OFFLINE_BALANCED=False.\"\n",
    "            )\n",
    "        if not train_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"[{t['name']}] No existe {train_path}. Genera los balanceados con 01A_PREP_BALANCED.ipynb.\"\n",
    "            )\n",
    "    print(\"✔ Verificación OFFLINE balanceado superada (train_balanced.csv por tarea).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6158c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.utils import make_loaders_from_csvs\n",
    "\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed, **dl_kwargs):\n",
    "    RAW = ROOT / \"data\" / \"raw\" / \"udacity\" / task[\"name\"]\n",
    "    paths = task[\"paths\"]\n",
    "\n",
    "    # Si vamos a codificar en GPU, pedimos 4D (image) al loader;\n",
    "    # si no, dejamos el encoder temporal en el propio dataset.\n",
    "    encoder_for_loader = \"image\" if (GPU_ENCODE and encoder in {\"rate\",\"latency\",\"raw\"}) else encoder\n",
    "\n",
    "    return make_loaders_from_csvs(\n",
    "        base_dir=RAW,\n",
    "        train_csv=Path(paths[\"train\"]),\n",
    "        val_csv=Path(paths[\"val\"]),\n",
    "        test_csv=Path(paths[\"test\"]),\n",
    "        batch_size=batch_size,\n",
    "        encoder=encoder_for_loader,\n",
    "        T=T, gain=gain, tfm=tfm, seed=SEED,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        persistent_workers=PERSISTENT,\n",
    "        prefetch_factor=PREFETCH,\n",
    "        # online balancing opcional:\n",
    "        aug_train=AUG_CFG,\n",
    "        balance_train=(USE_ONLINE_BALANCING and Path(paths[\"train\"]).name != \"train_balanced.csv\"),\n",
    "        balance_bins=21,\n",
    "        balance_smooth_eps=1e-3,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf03722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PRUEBA UNIVERSAL: loader -> (T,B,C,H,W) -> forward con fallback AMP ===\n",
    "import torch, src.training as training\n",
    "\n",
    "# --- 1) Loader pequeño con tu helper ---\n",
    "tr, va, te = make_loader_fn(\n",
    "    task=task_list[0],\n",
    "    batch_size=8,\n",
    "    encoder=\"rate\",   # si tu pipeline ya devuelve 4D, lo detectamos abajo\n",
    "    T=10,\n",
    "    gain=0.5,\n",
    "    tfm=tfm,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(tr))\n",
    "print(\"batch del loader:\", xb.shape, yb.shape)\n",
    "\n",
    "# --- 2) A (T,B,C,H,W) según formato de entrada ---\n",
    "#    - Si el dataset ya codifica (5D): solo permutar.\n",
    "#    - Si es 4D (imagen): activamos encode en GPU y usamos el helper runtime.\n",
    "if xb.ndim == 5:  # (B,T,C,H,W)\n",
    "    x5d = xb.permute(1,0,2,3,4).contiguous()\n",
    "    used_runtime_encode = False\n",
    "    print(\"dataset ya codificado; solo permuto a (T,B,C,H,W)\")\n",
    "elif xb.ndim == 4:  # (B,C,H,W)\n",
    "    training.set_runtime_encode(mode=\"rate\", T=10, gain=0.5,\n",
    "                                device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    x5d = training._permute_if_needed(xb)  # aplica encode+permuta -> (T,B,C,H,W)\n",
    "    used_runtime_encode = True\n",
    "    print(\"dataset 4D; uso encode en GPU y permuto a (T,B,C,H,W)\")\n",
    "else:\n",
    "    raise RuntimeError(f\"Forma inesperada del batch: {xb.shape}\")\n",
    "\n",
    "print(\"x5d.device:\", x5d.device, \"| shape:\", tuple(x5d.shape))\n",
    "\n",
    "# --- 3) Modelo y forward con fallback automático AMP ---\n",
    "model = make_model_fn(tfm).to(device).eval()\n",
    "\n",
    "def forward_with_auto_amp(model, x5d, device):\n",
    "    # Intento 1: AMP (solo si hay CUDA)\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            x_amp = x5d.to(device, dtype=torch.float16, non_blocking=True)\n",
    "            with torch.inference_mode(), torch.amp.autocast('cuda', enabled=True):\n",
    "                y = model(x_amp)\n",
    "            print(\"[forward] ejecutado con AMP (fp16)\")\n",
    "            return y\n",
    "        except Exception as e:\n",
    "            print(\"[forward] AMP falló, reintento en FP32. Motivo:\", str(e))\n",
    "\n",
    "    # Intento 2: FP32 (CPU o fallback)\n",
    "    x_fp32 = x5d.to(device, dtype=torch.float32, non_blocking=True)\n",
    "    with torch.inference_mode():\n",
    "        y = model(x_fp32)\n",
    "    print(\"[forward] ejecutado en FP32\")\n",
    "    return y\n",
    "\n",
    "yhat = forward_with_auto_amp(model, x5d, device)\n",
    "print(\"yhat:\", tuple(yhat.shape))\n",
    "\n",
    "# --- 4) Limpieza del runtime encode (si se usó) ---\n",
    "if used_runtime_encode:\n",
    "    training.set_runtime_encode(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== BENCH: toggle y eco de configuración =====================\n",
    "# Usa el RUN_BENCH que ya defines en la Celda 2\n",
    "print(\n",
    "    f\"[Bench workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "    f\"pin={PIN_MEMORY} persistent={PERSISTENT} \"\n",
    "    f\"| offline_bal={USE_OFFLINE_BALANCED} online_bal={USE_ONLINE_BALANCING}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.runner import run_continual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc768f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Activar métrica de it/s por época (parche temporal) ===\n",
    "import time, json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "import src.training as training\n",
    "from src.utils import set_seeds  # ya lo tienes importado en el notebook\n",
    "\n",
    "# Guarda la referencia al original para poder restaurar luego\n",
    "orig_train_supervised = training.train_supervised\n",
    "\n",
    "def train_supervised_ips(model: nn.Module, train_loader, val_loader, loss_fn: nn.Module,\n",
    "                         cfg, out_dir: Path, method=None):\n",
    "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if cfg.seed is not None:\n",
    "        set_seeds(cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "    use_amp = bool(cfg.amp and torch.cuda.is_available())\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "    t0_total = time.perf_counter()\n",
    "\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        nb = 0\n",
    "        t_epoch0 = time.perf_counter()\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            # encode/permutación runtime y subida a device (usa tu helper actual)\n",
    "            x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast(\"cuda\", enabled=use_amp):\n",
    "                y_hat = model(x)\n",
    "                loss = loss_fn(y_hat, y)\n",
    "                if method is not None:\n",
    "                    loss = loss + method.penalty()\n",
    "\n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(opt); scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "            nb += 1\n",
    "\n",
    "        epoch_time = time.perf_counter() - t_epoch0\n",
    "        ips = nb / epoch_time if epoch_time > 0 else float(\"nan\")\n",
    "        print(f\"[TRAIN it/s] epoch {epoch}/{cfg.epochs}: {ips:.1f} it/s  \"\n",
    "              f\"({nb} iters en {epoch_time:.2f}s)\")\n",
    "\n",
    "        train_loss = running / max(1, nb)\n",
    "\n",
    "        # --- validación ---\n",
    "        model.eval()\n",
    "        v_running = 0.0; nvb = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                with autocast(\"cuda\", enabled=use_amp):\n",
    "                    y_hat = model(x)\n",
    "                    v_loss = loss_fn(y_hat, y)\n",
    "                v_running += v_loss.item(); nvb += 1\n",
    "        val_loss = v_running / max(1, nvb)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "    elapsed = time.perf_counter() - t0_total\n",
    "    manifest = {\n",
    "        \"epochs\": cfg.epochs, \"batch_size\": cfg.batch_size, \"lr\": cfg.lr,\n",
    "        \"amp\": cfg.amp, \"seed\": cfg.seed, \"elapsed_sec\": elapsed,\n",
    "        \"device\": str(device), \"history\": history,\n",
    "    }\n",
    "    (out_dir / \"manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    return history\n",
    "\n",
    "# Activa el parche\n",
    "training.train_supervised = train_supervised_ips\n",
    "print(\"✅ it/s por época ACTIVADO. Para desactivarlo: training.train_supervised = orig_train_supervised\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preset_demo = \"std\"\n",
    "seed_demo = 42\n",
    "enc_demo = load_preset(ROOT / \"configs\" / \"presets.yaml\", preset_demo)[\"encoder\"]\n",
    "\n",
    "print(\"\\n>>> NAIVE (smoke)\")\n",
    "out_path, res = run_continual(\n",
    "    task_list=task_list,\n",
    "    make_loader_fn=make_loader_fn,\n",
    "    make_model_fn=make_model_fn,\n",
    "    tfm=tfm,\n",
    "    preset=preset_demo,\n",
    "    method=\"naive\",\n",
    "    lam=None,\n",
    "    seed=seed_demo,\n",
    "    encoder=enc_demo,\n",
    "    fisher_batches_by_preset={\"std\": 600},\n",
    "    epochs_override=2,\n",
    "    runtime_encode=GPU_ENCODE,\n",
    "    out_root=ROOT/\"outputs\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"OK:\", out_path)\n",
    "\n",
    "print(\"\\n>>> EWC (smoke)\")\n",
    "out_path, res = run_continual(\n",
    "    task_list=task_list,\n",
    "    make_loader_fn=make_loader_fn,\n",
    "    make_model_fn=make_model_fn,\n",
    "    tfm=tfm,\n",
    "    preset=preset_demo,\n",
    "    method=\"ewc\",\n",
    "    lam=1e9,\n",
    "    seed=seed_demo,\n",
    "    encoder=enc_demo,\n",
    "    fisher_batches_by_preset={\"std\": 600},\n",
    "    epochs_override=2,\n",
    "    runtime_encode=GPU_ENCODE,\n",
    "    out_root=ROOT/\"outputs\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"OK:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-sweep de λ en preset std (rápido)\n",
    "lams = [3e8, 5e8, 7e8]\n",
    "out_runs = []\n",
    "\n",
    "for lam in lams:\n",
    "    print(f\"\\n>>> EWC SMOKE λ={lam:.0e}\")\n",
    "    out_dir, _ = run_continual(\n",
    "        task_list=task_list,\n",
    "        make_loader_fn=make_loader_fn,\n",
    "        make_model_fn=make_model_fn,\n",
    "        tfm=tfm,\n",
    "        preset=\"std\",\n",
    "        method=\"ewc\",\n",
    "        lam=lam,\n",
    "        seed=42,\n",
    "        encoder=\"rate\",\n",
    "        fisher_batches_by_preset={\"std\": 600},\n",
    "        epochs_override=2,           # smoke rápido\n",
    "        runtime_encode=GPU_ENCODE,   # << importante\n",
    "        out_root=ROOT/\"outputs\",\n",
    "        verbose=True,\n",
    "    )\n",
    "    out_runs.append(out_dir)\n",
    "\n",
    "print(\"\\nHecho:\", out_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efc9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
