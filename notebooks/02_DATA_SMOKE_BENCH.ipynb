{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4da4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup\n",
    "# =============================================================================\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.utils import set_seeds, load_preset\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import build_model, default_tfm_for_model\n",
    "from src.training import TrainConfig\n",
    "from src.eval import eval_loader\n",
    "\n",
    "from src.bench import make_loader_fn_factory, universal_smoke_forward, enable_epoch_ips, disable_epoch_ips, print_bench_config\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "\n",
    "MODEL_NAME = \"pilotnet_snn\"   # \"snn_vision\" | \"pilotnet_ann\" | \"pilotnet_snn\"\n",
    "\n",
    "# tfm por defecto según el modelo:\n",
    "tfm = default_tfm_for_model(MODEL_NAME, to_gray=True)\n",
    "\n",
    "def make_model_fn(tfm):\n",
    "    # kwargs solo necesarios para pilotnet_snn; ignorados por otros\n",
    "    return build_model(MODEL_NAME, tfm, beta=0.9, threshold=0.5)\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c35de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAFE_MODE=False] workers=12 prefetch=2 pin=True persistent=True\n"
     ]
    }
   ],
   "source": [
    "GPU_ENCODE = True\n",
    "SAFE_MODE = False\n",
    "NUM_WORKERS = 12\n",
    "PREFETCH    = 2\n",
    "PIN_MEMORY  = True\n",
    "PERSISTENT  = True\n",
    "\n",
    "AUG_CFG_LIGHT = AugmentConfig(prob_hflip=0.5, brightness=None, gamma=None, noise_std=0.0)\n",
    "AUG_CFG_FULL  = AugmentConfig(prob_hflip=0.5, brightness=(0.9, 1.1), gamma=(0.95, 1.05), noise_std=0.005)\n",
    "AUG_CFG = AUG_CFG_LIGHT\n",
    "\n",
    "USE_OFFLINE_BALANCED = True\n",
    "USE_ONLINE_BALANCING = False\n",
    "\n",
    "if SAFE_MODE:\n",
    "    NUM_WORKERS = 0; PREFETCH = None; PIN_MEMORY = False; PERSISTENT = False\n",
    "    USE_OFFLINE_BALANCED = False; USE_ONLINE_BALANCING = False; AUG_CFG = None\n",
    "\n",
    "print(f\"[SAFE_MODE={SAFE_MODE}] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3d6f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ /home/cesar/proyectos/TFM_SNN/data/processed/circuito1/train_balanced.csv OK\n",
      "✓ /home/cesar/proyectos/TFM_SNN/data/processed/circuito2/train_balanced.csv OK\n",
      "OK: splits 'train/val/test' encontrados.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Verificación de datos (normal y, si existe, balanceado offline)\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "RAW  = ROOT / \"data\" / \"raw\" / \"udacity\"\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# Ajusta si usas otros recorridos\n",
    "# RUNS = [\"circuito1\", \"circuito2\"]\n",
    "RUNS = [d.name for d in PROC.iterdir() if d.is_dir()]\n",
    "\n",
    "missing = []\n",
    "for run in RUNS:\n",
    "    base = PROC / run\n",
    "\n",
    "    # Comprobación obligatoria: splits normales\n",
    "    for part in [\"train\", \"val\", \"test\"]:\n",
    "        p = base / f\"{part}.csv\"\n",
    "        if not p.exists():\n",
    "            missing.append(str(p))\n",
    "\n",
    "    # Comprobación opcional: train_balanced.csv (para modo OFFLINE balanceado)\n",
    "    p_bal = base / \"train_balanced.csv\"\n",
    "    if p_bal.exists():\n",
    "        print(f\"✓ {p_bal} OK\")\n",
    "    else:\n",
    "        print(f\"  Falta {p_bal}. Si más abajo pones USE_OFFLINE_BALANCED=True, \"\n",
    "              f\"ejecuta 01A_PREP_BALANCED.ipynb o tools/make_splits_balanced.py\")\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Faltan CSV obligatorios (ejecuta 01A_PREP_BALANCED.ipynb o tu pipeline de prep):\\n\"\n",
    "        + \"\\n\".join(\" - \" + m for m in missing)\n",
    "    )\n",
    "\n",
    "print(\"OK: splits 'train/val/test' encontrados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9fdab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tareas y su TRAIN CSV:\n",
      " - circuito1: train_balanced.csv\n",
      " - circuito2: train_balanced.csv\n",
      " Verificación OFFLINE balanceado superada.\n"
     ]
    }
   ],
   "source": [
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "with open(PROC / (\"tasks_balanced.json\" if USE_OFFLINE_BALANCED else \"tasks.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "print(\"Tareas y su TRAIN CSV:\")\n",
    "for t in task_list:\n",
    "    from pathlib import Path as _P\n",
    "    print(f\" - {t['name']}: {_P(t['paths']['train']).name}\")\n",
    "\n",
    "# Guardarraíl si activas OFFLINE balanceado:\n",
    "if USE_OFFLINE_BALANCED:\n",
    "    from pathlib import Path as _P\n",
    "    for t in task_list:\n",
    "        train_path = _P(t[\"paths\"][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(f\"[{t['name']}] Esperaba 'train_balanced.csv' pero encontré '{train_path.name}'.\")\n",
    "        if not train_path.exists():\n",
    "            raise FileNotFoundError(f\"[{t['name']}] No existe {train_path}.\")\n",
    "    print(\" Verificación OFFLINE balanceado superada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06a26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_loader_fn = make_loader_fn_factory(\n",
    "    ROOT,\n",
    "    GPU_ENCODE=GPU_ENCODE,\n",
    "    SEED=SEED,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    prefetch_factor=PREFETCH,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers=PERSISTENT,\n",
    "    aug_train=AUG_CFG,\n",
    "    use_online_balancing=USE_ONLINE_BALANCING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15029956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 4D; uso encode en GPU y permuto a (T,B,C,H,W)\n",
      "x5d.device: cuda:0 | shape: (10, 8, 1, 66, 200)\n",
      "[forward] ejecutado con AMP\n"
     ]
    }
   ],
   "source": [
    "_ = universal_smoke_forward(\n",
    "    make_loader_fn,\n",
    "    task=task_list[0],\n",
    "    encoder=\"rate\", T=10, gain=0.5,\n",
    "    tfm=tfm, seed=SEED, device=device,\n",
    "    use_runtime_encode=GPU_ENCODE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6158c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bench workers=12 prefetch=2 pin=True persistent=True | offline_bal=True online_bal=False\n"
     ]
    }
   ],
   "source": [
    "print_bench_config(\n",
    "    NUM_WORKERS=NUM_WORKERS, PREFETCH=PREFETCH,\n",
    "    PIN_MEMORY=PIN_MEMORY, PERSISTENT=PERSISTENT,\n",
    "    USE_OFFLINE_BALANCED=USE_OFFLINE_BALANCED, USE_ONLINE_BALANCING=USE_ONLINE_BALANCING\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf03722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch del loader: torch.Size([8, 1, 66, 200]) torch.Size([8, 1])\n",
      "dataset 4D; uso encode en GPU y permuto a (T,B,C,H,W)\n",
      "x5d.device: cuda:0 | shape: (10, 8, 1, 66, 200)\n",
      "[forward] ejecutado con AMP (fp16)\n",
      "yhat: (8, 1)\n"
     ]
    }
   ],
   "source": [
    "# === PRUEBA UNIVERSAL: loader -> (T,B,C,H,W) -> forward con fallback AMP ===\n",
    "import torch, src.training as training\n",
    "\n",
    "# --- 1) Loader pequeño con tu helper ---\n",
    "tr, va, te = make_loader_fn(\n",
    "    task=task_list[0],\n",
    "    batch_size=8,\n",
    "    encoder=\"rate\",   # si tu pipeline ya devuelve 4D, lo detectamos abajo\n",
    "    T=10,\n",
    "    gain=0.5,\n",
    "    tfm=tfm,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(tr))\n",
    "print(\"batch del loader:\", xb.shape, yb.shape)\n",
    "\n",
    "# --- 2) A (T,B,C,H,W) según formato de entrada ---\n",
    "#    - Si el dataset ya codifica (5D): solo permutar.\n",
    "#    - Si es 4D (imagen): activamos encode en GPU y usamos el helper runtime.\n",
    "if xb.ndim == 5:  # (B,T,C,H,W)\n",
    "    x5d = xb.permute(1,0,2,3,4).contiguous()\n",
    "    used_runtime_encode = False\n",
    "    print(\"dataset ya codificado; solo permuto a (T,B,C,H,W)\")\n",
    "elif xb.ndim == 4:  # (B,C,H,W)\n",
    "    training.set_runtime_encode(mode=\"rate\", T=10, gain=0.5,\n",
    "                                device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    x5d = training._permute_if_needed(xb)  # aplica encode+permuta -> (T,B,C,H,W)\n",
    "    used_runtime_encode = True\n",
    "    print(\"dataset 4D; uso encode en GPU y permuto a (T,B,C,H,W)\")\n",
    "else:\n",
    "    raise RuntimeError(f\"Forma inesperada del batch: {xb.shape}\")\n",
    "\n",
    "print(\"x5d.device:\", x5d.device, \"| shape:\", tuple(x5d.shape))\n",
    "\n",
    "# --- 3) Modelo y forward con fallback automático AMP ---\n",
    "model = make_model_fn(tfm).to(device).eval()\n",
    "\n",
    "def forward_with_auto_amp(model, x5d, device):\n",
    "    # Intento 1: AMP (solo si hay CUDA)\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            x_amp = x5d.to(device, dtype=torch.float16, non_blocking=True)\n",
    "            with torch.inference_mode(), torch.amp.autocast('cuda', enabled=True):\n",
    "                y = model(x_amp)\n",
    "            print(\"[forward] ejecutado con AMP (fp16)\")\n",
    "            return y\n",
    "        except Exception as e:\n",
    "            print(\"[forward] AMP falló, reintento en FP32. Motivo:\", str(e))\n",
    "\n",
    "    # Intento 2: FP32 (CPU o fallback)\n",
    "    x_fp32 = x5d.to(device, dtype=torch.float32, non_blocking=True)\n",
    "    with torch.inference_mode():\n",
    "        y = model(x_fp32)\n",
    "    print(\"[forward] ejecutado en FP32\")\n",
    "    return y\n",
    "\n",
    "yhat = forward_with_auto_amp(model, x5d, device)\n",
    "print(\"yhat:\", tuple(yhat.shape))\n",
    "\n",
    "# --- 4) Limpieza del runtime encode (si se usó) ---\n",
    "if used_runtime_encode:\n",
    "    training.set_runtime_encode(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e410f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bench workers=12 prefetch=2 pin=True persistent=True | offline_bal=True online_bal=False\n"
     ]
    }
   ],
   "source": [
    "# ===================== BENCH: toggle y eco de configuración =====================\n",
    "# Usa el RUN_BENCH que ya defines en la Celda 2\n",
    "print(\n",
    "    f\"[Bench workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "    f\"pin={PIN_MEMORY} persistent={PERSISTENT} \"\n",
    "    f\"| offline_bal={USE_OFFLINE_BALANCED} online_bal={USE_ONLINE_BALANCING}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8558126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it/s por época ACTIVADO. Llama a disable_epoch_ips() para restaurar.\n"
     ]
    }
   ],
   "source": [
    "enable_epoch_ips()\n",
    "print(\"it/s por época ACTIVADO. Llama a disable_epoch_ips() para restaurar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> REHEARSAL+EWC (smoke)\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=rehearsal_buf_5000_rr_20+ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 17.0 it/s (909 iters en 53.51s)\n"
     ]
    }
   ],
   "source": [
    "from src.runner import run_continual\n",
    "\n",
    "preset_demo = \"fast\"\n",
    "seed_demo   = 42\n",
    "enc_demo    = load_preset(ROOT / \"configs\" / \"presets.yaml\", preset_demo)[\"encoder\"]\n",
    "\n",
    "print(\"\\n>>> REHEARSAL+EWC (smoke)\")\n",
    "_ = run_continual(\n",
    "    task_list=task_list,\n",
    "    make_loader_fn=make_loader_fn,\n",
    "    make_model_fn=make_model_fn,\n",
    "    tfm=tfm,\n",
    "    preset=preset_demo,\n",
    "    method=\"rehearsal+ewc\",\n",
    "    seed=seed_demo,\n",
    "    encoder=enc_demo,\n",
    "    epochs_override=2,\n",
    "    runtime_encode=GPU_ENCODE,\n",
    "    out_root=ROOT / \"outputs\",\n",
    "    verbose=True,\n",
    "    method_kwargs={\"buffer_size\": 5000, \"replay_ratio\": 0.2, \"lam\": 7e8, \"fisher_batches\": 1000},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc768f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> NAIVE (smoke)\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=naive | B=64 T=10 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 16.9 it/s (909 iters en 53.64s)\n",
      "[TRAIN it/s] epoch 2/2: 15.3 it/s (909 iters en 59.52s)\n",
      "  runtime encode: OFF\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=naive | B=64 T=10 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 13.2 it/s (202 iters en 15.33s)\n",
      "[TRAIN it/s] epoch 2/2: 12.7 it/s (202 iters en 15.95s)\n",
      "  runtime encode: OFF\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_naive_rate_model-PilotNetSNN_66x200_gray_seed_42\n",
      "\n",
      ">>> EWC (smoke)\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_1e+09 | B=64 T=10 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 11.3 it/s (909 iters en 80.41s)\n",
      "[TRAIN it/s] epoch 2/2: 11.1 it/s (909 iters en 81.79s)\n",
      "  runtime encode: OFF\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_1e+09 | B=64 T=10 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 11.3 it/s (202 iters en 17.92s)\n",
      "[TRAIN it/s] epoch 2/2: 11.5 it/s (202 iters en 17.61s)\n",
      "  runtime encode: OFF\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_1e+09_lam_1e+09_rate_model-PilotNetSNN_66x200_gray_seed_42\n",
      "\n",
      ">>> REHEARSAL (smoke)\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=rehearsal_buf_5000_rr_20 | B=64 T=10 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 11.7 it/s (909 iters en 77.75s)\n",
      "[TRAIN it/s] epoch 2/2: 11.8 it/s (909 iters en 77.18s)\n",
      "  runtime encode: OFF\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=rehearsal_buf_5000_rr_20 | B=64 T=10 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 10.7 it/s (202 iters en 18.94s)\n",
      "[TRAIN it/s] epoch 2/2: 10.7 it/s (202 iters en 18.80s)\n",
      "  runtime encode: OFF\n",
      "\n",
      ">>> REHEARSAL+EWC (smoke)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Composite +EWC requiere 'ewc_lam' en method_kwargs",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     49\u001b[39m _ = run_continual(\n\u001b[32m     50\u001b[39m     task_list=task_list,\n\u001b[32m     51\u001b[39m     make_loader_fn=make_loader_fn,\n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m     method_kwargs={\u001b[33m\"\u001b[39m\u001b[33mbuffer_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5000\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mreplay_ratio\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.2\u001b[39m},\n\u001b[32m     64\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m>>> REHEARSAL+EWC (smoke)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m _ = \u001b[43mrun_continual\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmake_loader_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_loader_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmake_model_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_model_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtfm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtfm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreset_demo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrehearsal+ewc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed_demo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m=\u001b[49m\u001b[43menc_demo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfisher_batches_by_preset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFBS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs_override\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruntime_encode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGPU_ENCODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_root\u001b[49m\u001b[43m=\u001b[49m\u001b[43mROOT\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlam\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m7e8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbuffer_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreplay_ratio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/TFM_SNN/src/runner.py:57\u001b[39m, in \u001b[36mrun_continual\u001b[39m\u001b[34m(task_list, make_loader_fn, make_model_fn, tfm, preset, method, seed, encoder, fisher_batches_by_preset, epochs_override, runtime_encode, out_root, verbose, method_kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m method_kwargs = (method_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}).copy()\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Construcción unificada (el builder resuelve composites tipo \"rehearsal+ewc\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m method_obj = \u001b[43mbuild_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod_l\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfisher_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# <- TODOS los hiperparámetros del método van aquí\u001b[39;49;00m\n\u001b[32m     64\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Nombre del experimento: usa .name y añade sufijo de λ si aplica\u001b[39;00m\n\u001b[32m     67\u001b[39m tag = method_obj.name  \u001b[38;5;66;03m# p.ej., \"naive\", \"ewc\", \"rehearsal\", \"rehearsal+ewc\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/TFM_SNN/src/methods/registry.py:53\u001b[39m, in \u001b[36mbuild_method\u001b[39m\u001b[34m(name, model, loss_fn, device, fisher_batches, **method_kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m loss_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mComposite +EWC requiere \u001b[39m\u001b[33m'\u001b[39m\u001b[33mloss_fn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     52\u001b[39m ewc_lam = method_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mewc_lam\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m ewc_lam \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mComposite +EWC requiere \u001b[39m\u001b[33m'\u001b[39m\u001b[33mewc_lam\u001b[39m\u001b[33m'\u001b[39m\u001b[33m en method_kwargs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m ewc = EWCMethod(model, \u001b[38;5;28mfloat\u001b[39m(ewc_lam), \u001b[38;5;28mint\u001b[39m(fisher_batches), loss_fn, device)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompositeMethod([base, ewc])\n",
      "\u001b[31mAssertionError\u001b[39m: Composite +EWC requiere 'ewc_lam' en method_kwargs"
     ]
    }
   ],
   "source": [
    "from src.runner import run_continual\n",
    "\n",
    "preset_demo = \"fast\"\n",
    "seed_demo   = 42\n",
    "enc_demo    = load_preset(ROOT / \"configs\" / \"presets.yaml\", preset_demo)[\"encoder\"]\n",
    "\n",
    "print(\"\\n>>> NAIVE (smoke)\")\n",
    "out_path, res = run_continual(\n",
    "    task_list=task_list,\n",
    "    make_loader_fn=make_loader_fn,\n",
    "    make_model_fn=make_model_fn,\n",
    "    tfm=tfm,\n",
    "    preset=preset_demo,\n",
    "    method=\"naive\",\n",
    "    seed=seed_demo,\n",
    "    encoder=enc_demo,\n",
    "    epochs_override=2,\n",
    "    runtime_encode=GPU_ENCODE,\n",
    "    out_root=ROOT / \"outputs\",\n",
    "    verbose=True,\n",
    "    method_kwargs={},  # sin hiperparámetros\n",
    ")\n",
    "print(\"OK:\", out_path)\n",
    "\n",
    "print(\"\\n>>> EWC (smoke)\")\n",
    "out_path, res = run_continual(\n",
    "    task_list=task_list,\n",
    "    make_loader_fn=make_loader_fn,\n",
    "    make_model_fn=make_model_fn,\n",
    "    tfm=tfm,\n",
    "    preset=preset_demo,\n",
    "    method=\"ewc\",\n",
    "    seed=seed_demo,\n",
    "    encoder=enc_demo,\n",
    "    epochs_override=2,\n",
    "    runtime_encode=GPU_ENCODE,\n",
    "    out_root=ROOT / \"outputs\",\n",
    "    verbose=True,\n",
    "    method_kwargs={\"lam\": 1e9},  # <- λ por method_kwargs\n",
    ")\n",
    "print(\"OK:\", out_path)\n",
    "\n",
    "# (Opcional) extra de bench:\n",
    "print(\"\\n>>> REHEARSAL (smoke)\")\n",
    "_ = run_continual(\n",
    "    task_list=task_list,\n",
    "    make_loader_fn=make_loader_fn,\n",
    "    make_model_fn=make_model_fn,\n",
    "    tfm=tfm,\n",
    "    preset=preset_demo,\n",
    "    method=\"rehearsal\",\n",
    "    seed=seed_demo,\n",
    "    encoder=enc_demo,\n",
    "    epochs_override=2,\n",
    "    runtime_encode=GPU_ENCODE,\n",
    "    out_root=ROOT / \"outputs\",\n",
    "    verbose=True,\n",
    "    method_kwargs={\"buffer_size\": 5000, \"replay_ratio\": 0.2},\n",
    ")\n",
    "\n",
    "print(\"\\n>>> REHEARSAL+EWC (smoke)\")\n",
    "_ = run_continual(\n",
    "    task_list=task_list,\n",
    "    make_loader_fn=make_loader_fn,\n",
    "    make_model_fn=make_model_fn,\n",
    "    tfm=tfm,\n",
    "    preset=preset_demo,\n",
    "    method=\"rehearsal+ewc\",\n",
    "    seed=seed_demo,\n",
    "    encoder=enc_demo,\n",
    "    epochs_override=2,\n",
    "    runtime_encode=GPU_ENCODE,\n",
    "    out_root=ROOT / \"outputs\",\n",
    "    verbose=True,\n",
    "    method_kwargs={\"buffer_size\": 5000, \"replay_ratio\": 0.2, \"lam\": 7e8, \"fisher_batches\": 1000},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c545f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> EWC SMOKE λ=3e+08\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=std | method=ewc_lam_3e+08 | B=56 T=16 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 7.5 it/s (1038 iters en 137.76s)\n",
      "[TRAIN it/s] epoch 2/2: 7.6 it/s (1038 iters en 136.47s)\n",
      "  runtime encode: OFF\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=std | method=ewc_lam_3e+08 | B=56 T=16 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 7.0 it/s (230 iters en 32.87s)\n",
      "[TRAIN it/s] epoch 2/2: 7.3 it/s (230 iters en 31.38s)\n",
      "  runtime encode: OFF\n",
      "\n",
      ">>> EWC SMOKE λ=5e+08\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=std | method=ewc_lam_5e+08 | B=56 T=16 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 7.5 it/s (1038 iters en 137.62s)\n",
      "[TRAIN it/s] epoch 2/2: 7.7 it/s (1038 iters en 134.44s)\n",
      "  runtime encode: OFF\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=std | method=ewc_lam_5e+08 | B=56 T=16 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 7.4 it/s (230 iters en 31.21s)\n",
      "[TRAIN it/s] epoch 2/2: 7.2 it/s (230 iters en 31.85s)\n",
      "  runtime encode: OFF\n",
      "\n",
      ">>> EWC SMOKE λ=7e+08\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=std | method=ewc_lam_7e+08 | B=56 T=16 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 7.7 it/s (1038 iters en 134.86s)\n",
      "[TRAIN it/s] epoch 2/2: 7.6 it/s (1038 iters en 135.69s)\n",
      "  runtime encode: OFF\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=std | method=ewc_lam_7e+08 | B=56 T=16 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 7.4 it/s (230 iters en 31.13s)\n",
      "[TRAIN it/s] epoch 2/2: 7.2 it/s (230 iters en 31.92s)\n",
      "  runtime encode: OFF\n",
      "\n",
      "Hecho: [PosixPath('/home/cesar/proyectos/TFM_SNN/outputs/continual_std_ewc_lam_3e+08_lam_3e+08_rate_seed_42'), PosixPath('/home/cesar/proyectos/TFM_SNN/outputs/continual_std_ewc_lam_5e+08_lam_5e+08_rate_seed_42'), PosixPath('/home/cesar/proyectos/TFM_SNN/outputs/continual_std_ewc_lam_7e+08_lam_7e+08_rate_seed_42')]\n"
     ]
    }
   ],
   "source": [
    "# Mini-sweep de λ en preset std (rápido)\n",
    "lams = [3e8, 5e8, 7e8]\n",
    "out_runs = []\n",
    "\n",
    "FISHER_BY_PRESET = {\"fast\": 200, \"std\": 600, \"accurate\": 800}\n",
    "\n",
    "for lam in lams:\n",
    "    print(f\"\\n>>> EWC SMOKE λ={lam:.0e}\")\n",
    "    out_dir, _ = run_continual(\n",
    "        task_list=task_list,\n",
    "        make_loader_fn=make_loader_fn,\n",
    "        make_model_fn=make_model_fn,\n",
    "        tfm=tfm,\n",
    "        preset=\"std\",\n",
    "        method=\"ewc\",\n",
    "        seed=42,\n",
    "        encoder=\"rate\",\n",
    "        epochs_override=2,          # smoke rápido\n",
    "        runtime_encode=GPU_ENCODE,  # importante\n",
    "        out_root=ROOT/\"outputs\",\n",
    "        verbose=True,\n",
    "        method_kwargs={\"lam\": lam, \"fisher_batches\": 1000},\n",
    "    )\n",
    "    out_runs.append(out_dir)\n",
    "\n",
    "print(\"\\nHecho:\", out_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efc9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> REHEARSAL+EWC SMOKE λ=7e+08\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=rehearsal_buf_5000_rr_20+ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 12.1 it/s (909 iters en 75.42s)\n",
      "[TRAIN it/s] epoch 2/2: 11.8 it/s (909 iters en 76.81s)\n",
      "  runtime encode: OFF\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=rehearsal_buf_5000_rr_20+ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 8.7 it/s (202 iters en 23.10s)\n",
      "[TRAIN it/s] epoch 2/2: 10.3 it/s (202 iters en 19.53s)\n",
      "  runtime encode: OFF\n",
      "\n",
      ">>> REHEARSAL+EWC SMOKE λ=1e+09\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=rehearsal_buf_5000_rr_20+ewc_lam_1e+09 | B=64 T=10 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 11.6 it/s (909 iters en 78.08s)\n",
      "[TRAIN it/s] epoch 2/2: 11.9 it/s (909 iters en 76.23s)\n",
      "  runtime encode: OFF\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=rehearsal_buf_5000_rr_20+ewc_lam_1e+09 | B=64 T=10 AMP=True | enc=rate ---\n",
      "  runtime encode: ON (GPU)\n",
      "[TRAIN it/s] epoch 1/2: 10.5 it/s (202 iters en 19.26s)\n",
      "[TRAIN it/s] epoch 2/2: 10.3 it/s (202 iters en 19.60s)\n",
      "  runtime encode: OFF\n",
      "\n",
      "Hecho: [PosixPath('/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_rehearsal_buf_5000_rr_20+ewc_lam_7e+08_lam_7e+08_rate_seed_42'), PosixPath('/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_rehearsal_buf_5000_rr_20+ewc_lam_1e+09_lam_1e+09_rate_seed_42')]\n"
     ]
    }
   ],
   "source": [
    "# Sweep composite: rehearsal+ewc\n",
    "lams = [7e8, 1e9]\n",
    "out_runs = []\n",
    "\n",
    "FISHER_BY_PRESET = {\"fast\": 200, \"std\": 600, \"accurate\": 800}\n",
    "\n",
    "for lam in lams:\n",
    "    print(f\"\\n>>> REHEARSAL+EWC SMOKE λ={lam:.0e}\")\n",
    "    out_dir, _ = run_continual(\n",
    "        task_list=task_list,\n",
    "        make_loader_fn=make_loader_fn,\n",
    "        make_model_fn=make_model_fn,\n",
    "        tfm=tfm,\n",
    "        preset=\"fast\",\n",
    "        method=\"rehearsal+ewc\",\n",
    "        seed=42,\n",
    "        encoder=\"rate\",\n",
    "        epochs_override=2,\n",
    "        runtime_encode=GPU_ENCODE,\n",
    "        out_root=ROOT/\"outputs\",\n",
    "        verbose=True,\n",
    "       method_kwargs={\"buffer_size\": 5000, \"replay_ratio\": 0.2, \"lam\": 7e8, \"fisher_batches\": 1000},\n",
    "    )\n",
    "    out_runs.append(out_dir)\n",
    "\n",
    "print(\"\\nHecho:\", out_runs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
