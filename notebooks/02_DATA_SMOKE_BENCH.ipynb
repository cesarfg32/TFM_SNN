{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup\n",
    "# =============================================================================\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "# Detecta la raíz del repo (si estás dentro de notebooks/, sube un nivel)\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Utilidades y módulos del proyecto\n",
    "from src.datasets import AugmentConfig\n",
    "from src.utils import set_seeds, load_preset, make_loaders_from_csvs\n",
    "from src.datasets import ImageTransform\n",
    "from src.models import SNNVisionRegressor\n",
    "from src.training import TrainConfig, train_supervised, _permute_if_needed\n",
    "from src.methods.ewc import EWC, EWCConfig\n",
    "\n",
    "# Dispositivo (CUDA si disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ROOT, device\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Transformación de imagen\n",
    "# IMPORTANTE: usa argumentos **posicionales** (w, h, to_gray, crop_top)\n",
    "# Evita keywords tipo target_w/target_h porque la clase no los define.\n",
    "tfm = ImageTransform(160, 80, True, None)\n",
    "\n",
    "def make_snn_model(tfm):\n",
    "    # C = 1 si gris, 3 si color\n",
    "    return SNNVisionRegressor(in_channels=(1 if tfm.to_gray else 3), lif_beta=0.95)\n",
    "\n",
    "torch.set_num_threads(4)               # evita sobre-contención de CPU al decodificar\n",
    "torch.backends.cudnn.benchmark = True  # selecciona la mejor impl. de convs para tamaño fijo\n",
    "\n",
    "# Permite TF32 (barato y suele acelerar matmul/convs en Ampere+ sin tocar precisión de FP16)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "# Precisión alta para kernels FP32 cuando no uses AMP\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "\n",
    "GPU_ENCODE = True  # activa codificación (rate/latency/raw) en GPU\n",
    "RUN_BENCH = True   # pon True para ejecutar\n",
    "\n",
    "# --- SAFE MODE: desactiva todo lo pesado para estabilizar ---\n",
    "SAFE_MODE = False  # o False cuando quieras rendimiento\n",
    "\n",
    "NUM_WORKERS   = 12\n",
    "PREFETCH      = 2\n",
    "PIN_MEMORY    = True\n",
    "PERSISTENT    = True\n",
    "\n",
    "# AUG_CFG = None\n",
    "from src.datasets import AugmentConfig\n",
    "# --- Augment: perfiles ---\n",
    "AUG_CFG_LIGHT = AugmentConfig(prob_hflip=0.5, brightness=None, gamma=None, noise_std=0.0)\n",
    "AUG_CFG_FULL  = AugmentConfig(prob_hflip=0.5, brightness=(0.9, 1.1), gamma=(0.95, 1.05), noise_std=0.005)\n",
    "\n",
    "AUG_CFG = AUG_CFG_LIGHT   # ← usa LIGHT ahora; luego prueba FULL\n",
    "\n",
    "USE_OFFLINE_BALANCED  = True\n",
    "USE_ONLINE_BALANCING  = False\n",
    "\n",
    "if SAFE_MODE:\n",
    "    NUM_WORKERS  = 0\n",
    "    PREFETCH     = None   # ← IMPORTANTÍSIMO con num_workers=0\n",
    "    PIN_MEMORY   = False\n",
    "    PERSISTENT   = False  # ← también obligatorio con num_workers=0\n",
    "    USE_OFFLINE_BALANCED = False\n",
    "    USE_ONLINE_BALANCING = False\n",
    "    AUG_CFG = None\n",
    "\n",
    "print(f\"[SAFE_MODE={SAFE_MODE}] workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "      f\"pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Verificación de datos (normal y, si existe, balanceado offline)\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "RAW  = ROOT/\"data\"/\"raw\"/\"udacity\"\n",
    "PROC = ROOT/\"data\"/\"processed\"\n",
    "\n",
    "RUNS = [\"circuito1\",\"circuito2\"]  # ajusta si hace falta\n",
    "\n",
    "missing = []\n",
    "for run in RUNS:\n",
    "    base = PROC / run\n",
    "\n",
    "    # Comprobación obligatoria: splits normales\n",
    "    for part in [\"train\",\"val\",\"test\"]:\n",
    "        p = base / f\"{part}.csv\"\n",
    "        if not p.exists():\n",
    "            missing.append(str(p))\n",
    "\n",
    "    # Comprobación opcional: train_balanced.csv (para modo OFFLINE balanceado)\n",
    "    p_bal = base / \"train_balanced.csv\"\n",
    "    if p_bal.exists():\n",
    "        print(f\"✓ {p_bal} OK\")\n",
    "    else:\n",
    "        print(f\"⚠️  Falta {p_bal}. Si más abajo pones USE_OFFLINE_BALANCED=True, \"\n",
    "              f\"ejecuta 01A_PREP_BALANCED.ipynb o el script tools/make_splits_balanced.py\")\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Faltan CSV obligatorios (ejecuta 01A_PREP_BALANCED.ipynb o tu pipeline de prep):\\n\"\n",
    "        + \"\\n\".join(\" - \" + m for m in missing)\n",
    "    )\n",
    "\n",
    "print(\"OK: splits 'train/val/test' encontrados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import make_loaders_from_csvs\n",
    "# =============================================================================\n",
    "# Función para crear loaders de una tarea dada (respeta cfg del preset)\n",
    "# =============================================================================\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed,\n",
    "                   num_workers=NUM_WORKERS, prefetch_factor=PREFETCH,\n",
    "                   pin_memory=PIN_MEMORY, persistent_workers=PERSISTENT):\n",
    "    from pathlib import Path\n",
    "    name  = task[\"name\"]\n",
    "    paths = task[\"paths\"]\n",
    "\n",
    "    pw = persistent_workers and (num_workers > 0)\n",
    "    pf = prefetch_factor if (num_workers > 0) else None\n",
    "\n",
    "    # CLAVE: si vamos a codificar en GPU, el loader debe dar (B,C,H,W):\n",
    "    encoder_for_loader = \"image\" if GPU_ENCODE else encoder\n",
    "\n",
    "    return make_loaders_from_csvs(\n",
    "        base_dir=RAW/name,\n",
    "        train_csv=Path(paths[\"train\"]),\n",
    "        val_csv=Path(paths[\"val\"]),\n",
    "        test_csv=Path(paths[\"test\"]),\n",
    "        batch_size=batch_size,\n",
    "        encoder=encoder_for_loader,\n",
    "        T=T,\n",
    "        gain=gain,\n",
    "        tfm=tfm,\n",
    "        seed=seed,\n",
    "        # ---- Parche estabilidad WSL ----\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        persistent_workers=pw,\n",
    "        prefetch_factor=pf,\n",
    "        aug_train=AUG_CFG,\n",
    "        balance_train=_balance_flag(paths[\"train\"]),\n",
    "        balance_bins=21,\n",
    "    )\n",
    "\n",
    "print(f\"[Loaders] workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "      f\"pin={PIN_MEMORY} persistent={PERSISTENT} \"\n",
    "      f\"offline_bal={USE_OFFLINE_BALANCED} online_bal={USE_ONLINE_BALANCING}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9fdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PRUEBA UNIVERSAL: loader -> (T,B,C,H,W) -> forward con fallback AMP ===\n",
    "import torch, src.training as training\n",
    "\n",
    "# --- 1) Loader pequeño con tu helper ---\n",
    "tr, va, te = make_loader_fn(\n",
    "    task=task_list[0],\n",
    "    batch_size=8,\n",
    "    encoder=\"rate\",   # si tu pipeline ya devuelve 4D, lo detectamos abajo\n",
    "    T=10,\n",
    "    gain=0.5,\n",
    "    tfm=tfm,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(tr))\n",
    "print(\"batch del loader:\", xb.shape, yb.shape)\n",
    "\n",
    "# --- 2) A (T,B,C,H,W) según formato de entrada ---\n",
    "#    - Si el dataset ya codifica (5D): solo permutar.\n",
    "#    - Si es 4D (imagen): activamos encode en GPU y usamos el helper runtime.\n",
    "if xb.ndim == 5:  # (B,T,C,H,W)\n",
    "    x5d = xb.permute(1,0,2,3,4).contiguous()\n",
    "    used_runtime_encode = False\n",
    "    print(\"dataset ya codificado; solo permuto a (T,B,C,H,W)\")\n",
    "elif xb.ndim == 4:  # (B,C,H,W)\n",
    "    training.set_runtime_encode(mode=\"rate\", T=10, gain=0.5,\n",
    "                                device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    x5d = training._permute_if_needed(xb)  # aplica encode+permuta -> (T,B,C,H,W)\n",
    "    used_runtime_encode = True\n",
    "    print(\"dataset 4D; uso encode en GPU y permuto a (T,B,C,H,W)\")\n",
    "else:\n",
    "    raise RuntimeError(f\"Forma inesperada del batch: {xb.shape}\")\n",
    "\n",
    "print(\"x5d.device:\", x5d.device, \"| shape:\", tuple(x5d.shape))\n",
    "\n",
    "# --- 3) Modelo y forward con fallback automático AMP ---\n",
    "model = make_snn_model(tfm).to(device).eval()\n",
    "\n",
    "def forward_with_auto_amp(model, x5d, device):\n",
    "    # Intento 1: AMP (solo si hay CUDA)\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            x_amp = x5d.to(device, dtype=torch.float16, non_blocking=True)\n",
    "            with torch.inference_mode(), torch.amp.autocast('cuda', enabled=True):\n",
    "                y = model(x_amp)\n",
    "            print(\"[forward] ejecutado con AMP (fp16)\")\n",
    "            return y\n",
    "        except Exception as e:\n",
    "            print(\"[forward] AMP falló, reintento en FP32. Motivo:\", str(e))\n",
    "\n",
    "    # Intento 2: FP32 (CPU o fallback)\n",
    "    x_fp32 = x5d.to(device, dtype=torch.float32, non_blocking=True)\n",
    "    with torch.inference_mode():\n",
    "        y = model(x_fp32)\n",
    "    print(\"[forward] ejecutado en FP32\")\n",
    "    return y\n",
    "\n",
    "yhat = forward_with_auto_amp(model, x5d, device)\n",
    "print(\"yhat:\", tuple(yhat.shape))\n",
    "\n",
    "# --- 4) Limpieza del runtime encode (si se usó) ---\n",
    "if used_runtime_encode:\n",
    "    training.set_runtime_encode(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a26a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
