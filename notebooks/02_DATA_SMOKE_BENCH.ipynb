{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e50374",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "# 02 ¬∑ Data Smoke & Bench\n",
    "\n",
    "Pruebas r√°pidas para validar **datos/splits**, comprobar el **pipeline de codificaci√≥n temporal** (offline H5 o runtime) y hacer **micro-bench** de *throughput*. Lee la configuraci√≥n desde `configs/presets.yaml` para asegurar coherencia con el cuaderno 03.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Detectar r√°pido problemas en datos/H5\n",
    "- Tener una referencia de it/s y formas de tensores antes de lanzar entrenos largos.\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "\n",
    "- [1) Setup del entorno e imports](#sec-01)\n",
    "- [2) Cargar preset y eco de configuraci√≥n](#sec-02)\n",
    "- [3) Verificaci√≥n de datos y carga de `task_list`](#sec-03)\n",
    "- [4) Factory de DataLoaders (H5 offline o CSV + runtime)](#sec-04)\n",
    "- [5) Smoke universal (loader ‚Üí modelo)](#sec-05)\n",
    "- [6) Forward manual con fallback AMP](#sec-06)\n",
    "- [7) Echo de configuraci√≥n del bench](#sec-07)\n",
    "- [8) Toggle: *it/s* por √©poca](#sec-08)\n",
    "- [9) (Opc.) Micro-bench pipeline *it/s*](#sec-09)\n",
    "- [10) (Opc.) Smokes de m√©todos con `run_continual`](#sec-10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad44dbd",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "\n",
    "## 1) Setup del entorno e imports\n",
    "\n",
    "**Objetivo:** preparar el entorno para micro-benchmarks y *smoke tests* de los loaders/modelo.\n",
    "\n",
    "- Configura hilos BLAS (evita over-subscription).\n",
    "- Detecta `ROOT` y a√±ade el repo al `sys.path`.\n",
    "- Importa utilidades de *bench*: `make_loader_fn_factory`, `universal_smoke_forward`, etc.\n",
    "- Selecciona dispositivo (`cuda` si est√°) y activa optimizaciones (TF32, cuDNN benchmark).\n",
    "\n",
    "> Este notebook **no entrena**; su objetivo es validar *data ‚Üí loader ‚Üí forward* y medir throughput base.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4da4bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup\n",
    "# =============================================================================\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.utils import load_preset, set_seeds\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import build_model, default_tfm_for_model\n",
    "from src.training import TrainConfig\n",
    "from src.eval import eval_loader\n",
    "from src.bench import (\n",
    "    make_loader_fn_factory,\n",
    "    universal_smoke_forward,\n",
    "    enable_epoch_ips, disable_epoch_ips,\n",
    "    print_bench_config,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e878424",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "\n",
    "## 2) Config desde `presets.yaml` y eco de configuraci√≥n\n",
    "\n",
    "**Objetivo:** usar el mismo preset del proyecto para alinear el bench con entrenamiento.\n",
    "\n",
    "Incluye:\n",
    "- Lectura de `PRESET` y extracci√≥n de:\n",
    "  - Modelo + `ImageTransform`.\n",
    "  - Par√°metros de codificaci√≥n temporal (`ENCODER`, `T`, `GAIN`, `SEED`).\n",
    "  - Par√°metros de DataLoader (workers, prefetch, pin/persistent).\n",
    "  - *Augment* (`AUG_CFG`) y balanceo online (si aplica).\n",
    "- Define `make_model_fn(tfm)` para instanciar el modelo con los mismos hiperpar√°metros neuronales.\n",
    "\n",
    "> As√≠, cualquier *smoke/bench* que hagas aqu√≠ usa exactamente la misma configuraci√≥n que 03_TRAIN_CONTINUAL.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c35de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRESET=fast] model=pilotnet_snn 200x66 gray=True\n",
      "[DATA] encoder=rate T=10 gain=0.5 seed=42\n",
      "[LOADER] workers=8 prefetch=2 pin=True persistent=True\n",
      "[BALANCE] offline=False online=False bins=21\n",
      "[RUNTIME_ENCODE] False | [OFFLINE_SPIKES] True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Config: lee presets.yaml\n",
    "# =============================================================================\n",
    "PRESET = \"fast\"  # fast | std | accurate\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# Modelo / tfm\n",
    "MODEL_NAME = CFG[\"model\"][\"name\"]\n",
    "tfm = ImageTransform(\n",
    "    CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"],\n",
    "    to_gray=bool(CFG[\"model\"][\"to_gray\"]), crop_top=None\n",
    ")\n",
    "\n",
    "# Datos / codificaci√≥n temporal\n",
    "ENCODER = CFG[\"data\"][\"encoder\"]\n",
    "T       = int(CFG[\"data\"][\"T\"])\n",
    "GAIN    = float(CFG[\"data\"][\"gain\"])\n",
    "SEED    = int(CFG[\"data\"][\"seed\"])\n",
    "\n",
    "USE_OFFLINE_SPIKES   = bool(CFG[\"data\"][\"use_offline_spikes\"])\n",
    "USE_OFFLINE_BALANCED = bool(CFG[\"data\"][\"use_offline_balanced\"])\n",
    "RUNTIME_ENCODE       = bool(CFG[\"data\"][\"encode_runtime\"])\n",
    "\n",
    "# DataLoader / augment / balance\n",
    "NUM_WORKERS  = int(CFG[\"data\"][\"num_workers\"])\n",
    "PREFETCH     = CFG[\"data\"][\"prefetch_factor\"]\n",
    "PIN_MEMORY   = bool(CFG[\"data\"][\"pin_memory\"])\n",
    "PERSISTENT   = bool(CFG[\"data\"][\"persistent_workers\"])\n",
    "\n",
    "AUG_CFG = AugmentConfig(**CFG[\"data\"][\"aug_train\"]) if CFG[\"data\"][\"aug_train\"] else None\n",
    "\n",
    "USE_ONLINE_BALANCING = bool(CFG[\"data\"][\"balance_online\"])\n",
    "BAL_BINS = int(CFG[\"data\"][\"balance_bins\"])\n",
    "BAL_EPS  = float(CFG[\"data\"][\"balance_smooth_eps\"])\n",
    "\n",
    "print(f\"[PRESET={PRESET}] model={MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] encoder={ENCODER} T={T} gain={GAIN} seed={SEED}\")\n",
    "print(f\"[LOADER] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "print(f\"[BALANCE] offline={USE_OFFLINE_BALANCED} online={USE_ONLINE_BALANCING} bins={BAL_BINS}\")\n",
    "print(f\"[RUNTIME_ENCODE] {RUNTIME_ENCODE} | [OFFLINE_SPIKES] {USE_OFFLINE_SPIKES}\")\n",
    "\n",
    "def make_model_fn(tfm):\n",
    "    # kwargs solo necesarios para pilotnet_snn\n",
    "    return build_model(MODEL_NAME, tfm, beta=0.9, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ffe6a8",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "\n",
    "## 3) Verificaci√≥n de datos y carga de `task_list`\n",
    "\n",
    "Comprueba `train/val/test.csv` por recorrido y el `train_balanced.csv` si activas modo offline balanceado. Construye `task_list` desde `tasks.json`/`tasks_balanced.json`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3d6f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì /home/cesar/proyectos/TFM_SNN/data/processed/circuito1/train_balanced.csv OK\n",
      "‚úì /home/cesar/proyectos/TFM_SNN/data/processed/circuito2/train_balanced.csv OK\n",
      "OK: splits 'train/val/test' encontrados.\n",
      "Tareas y su TRAIN CSV:\n",
      " - circuito1: train.csv\n",
      " - circuito2: train.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Verificaci√≥n de datos (normal y, si existe, balanceado offline) + tasks list\n",
    "# =============================================================================\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "RAW  = ROOT / \"data\" / \"raw\" / \"udacity\"\n",
    "\n",
    "# 1) Comprobaci√≥n de splits presentes\n",
    "RUNS = [d.name for d in PROC.iterdir() if d.is_dir()]\n",
    "missing = []\n",
    "for run in RUNS:\n",
    "    base = PROC / run\n",
    "    for part in [\"train\", \"val\", \"test\"]:\n",
    "        p = base / f\"{part}.csv\"\n",
    "        if not p.exists():\n",
    "            missing.append(str(p))\n",
    "    p_bal = base / \"train_balanced.csv\"\n",
    "    if p_bal.exists():\n",
    "        print(f\"‚úì {p_bal} OK\")\n",
    "    else:\n",
    "        print(f\"  Falta {p_bal}. Si vas a usar USE_OFFLINE_BALANCED=True,\"\n",
    "              f\" ejecuta 01A_PREP_BALANCED.ipynb o tools/make_splits_balanced.py\")\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Faltan CSV obligatorios:\\n\" + \"\\n\".join(\" - \" + m for m in missing)\n",
    "    )\n",
    "print(\"OK: splits 'train/val/test' encontrados.\")\n",
    "\n",
    "# 2) Cargar tasks.json | tasks_balanced.json\n",
    "TASKS_FILE = PROC / (\"tasks_balanced.json\" if USE_OFFLINE_BALANCED else \"tasks.json\")\n",
    "with open(TASKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "print(\"Tareas y su TRAIN CSV:\")\n",
    "for t in task_list:\n",
    "    from pathlib import Path as _P\n",
    "    print(f\" - {t['name']}: {_P(t['paths']['train']).name}\")\n",
    "\n",
    "# Guardarra√≠l si activas OFFLINE balanceado:\n",
    "if USE_OFFLINE_BALANCED:\n",
    "    from pathlib import Path as _P\n",
    "    for t in task_list:\n",
    "        train_path = _P(t[\"paths\"][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(f\"[{t['name']}] Esperaba 'train_balanced.csv' pero encontr√© '{train_path.name}'.\")\n",
    "        if not train_path.exists():\n",
    "            raise FileNotFoundError(f\"[{t['name']}] No existe {train_path}.\")\n",
    "    print(\"Verificaci√≥n OFFLINE balanceado superada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9bd138",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "\n",
    "## 4) Factory de DataLoaders (H5 offline o CSV + runtime)\n",
    "\n",
    "Crea `make_loader_fn` con los flags del preset (workers, prefetch, pin, persistent, augment, balanceo online). No pases `SEED` aqu√≠.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9fdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Factory de loaders (H5 offline o CSV + runtime encode)\n",
    "# =============================================================================\n",
    "make_loader_fn = make_loader_fn_factory(\n",
    "    ROOT,\n",
    "    RUNTIME_ENCODE=RUNTIME_ENCODE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    prefetch_factor=PREFETCH,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers=PERSISTENT,\n",
    "    aug_train=AUG_CFG,\n",
    "    # balanceo online\n",
    "    balance_train=USE_ONLINE_BALANCING,\n",
    "    balance_bins=BAL_BINS,\n",
    "    balance_smooth_eps=BAL_EPS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519003dc",
   "metadata": {},
   "source": [
    "<a id=\"sec-05\"></a>\n",
    "\n",
    "## 5) Smoke universal (loader ‚Üí modelo)\n",
    "\n",
    "Verifica que el primer `task` produce batches v√°lidos y que el modelo hace *forward* sin errores (AMP si hay CUDA). Usa `ENCODER`, `T`, `GAIN` del preset.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06a26a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset ya codificado; solo permuto a (T,B,C,H,W)\n",
      "x5d.device: cpu | shape: (10, 8, 1, 66, 200)\n",
      "[forward] ejecutado con AMP\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Smoke universal de loader+modelo (usa variables del preset)\n",
    "# =============================================================================\n",
    "_ = universal_smoke_forward(\n",
    "    make_loader_fn,\n",
    "    task=task_list[0],\n",
    "    encoder=ENCODER, T=T, gain=GAIN,\n",
    "    tfm=tfm, seed=SEED, device=device,\n",
    "    use_runtime_encode=RUNTIME_ENCODE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f83fa",
   "metadata": {},
   "source": [
    "<a id=\"sec-06\"></a>\n",
    "\n",
    "## 6) Forward manual con fallback AMP\n",
    "\n",
    "Ejecuta el camino completo manual: loader ‚Üí (T,B,C,H,W) ‚Üí modelo, con AMP si est√° disponible y limpieza del runtime-encode.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15029956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch del loader: torch.Size([8, 10, 1, 66, 200]) torch.Size([8, 1])\n",
      "dataset ya codificado; solo permuto a (T,B,C,H,W)\n",
      "x5d.device: cpu | shape: (10, 8, 1, 66, 200)\n",
      "[forward] ejecutado con AMP (fp16)\n",
      "yhat: (8, 1)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Forward manual: loader -> (T,B,C,H,W) con fallback AMP\n",
    "# =============================================================================\n",
    "import torch, src.training as training\n",
    "\n",
    "# 1) Loader peque√±o con tu helper\n",
    "tr, va, te = make_loader_fn(\n",
    "    task=task_list[0],\n",
    "    batch_size=8,\n",
    "    encoder=ENCODER,   # <-- preset\n",
    "    T=T,               # <-- preset\n",
    "    gain=GAIN,         # <-- preset\n",
    "    tfm=tfm,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(tr))\n",
    "print(\"batch del loader:\", xb.shape, yb.shape)\n",
    "\n",
    "# 2) A (T,B,C,H,W) seg√∫n formato de entrada\n",
    "if xb.ndim == 5:  # (B,T,C,H,W)\n",
    "    x5d = xb.permute(1,0,2,3,4).contiguous()\n",
    "    used_runtime_encode = False\n",
    "    print(\"dataset ya codificado; solo permuto a (T,B,C,H,W)\")\n",
    "elif xb.ndim == 4:  # (B,C,H,W)\n",
    "    training.set_runtime_encode(\n",
    "        mode=ENCODER, T=T, gain=GAIN,\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    )\n",
    "    x5d = training._permute_if_needed(xb)  # encode+permuta -> (T,B,C,H,W)\n",
    "    used_runtime_encode = True\n",
    "    print(\"dataset 4D; uso encode en GPU y permuto a (T,B,C,H,W)\")\n",
    "else:\n",
    "    raise RuntimeError(f\"Forma inesperada del batch: {xb.shape}\")\n",
    "\n",
    "print(\"x5d.device:\", x5d.device, \"| shape:\", tuple(x5d.shape))\n",
    "\n",
    "# 3) Modelo y forward con fallback AMP\n",
    "model = make_model_fn(tfm).to(device).eval()\n",
    "\n",
    "def forward_with_auto_amp(model, x5d, device):\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            x_amp = x5d.to(device, dtype=torch.float16, non_blocking=True)\n",
    "            with torch.inference_mode(), torch.amp.autocast('cuda', enabled=True):\n",
    "                y = model(x_amp)\n",
    "            print(\"[forward] ejecutado con AMP (fp16)\")\n",
    "            return y\n",
    "        except Exception as e:\n",
    "            print(\"[forward] AMP fall√≥, reintento en FP32. Motivo:\", str(e))\n",
    "\n",
    "    x_fp32 = x5d.to(device, dtype=torch.float32, non_blocking=True)\n",
    "    with torch.inference_mode():\n",
    "        y = model(x_fp32)\n",
    "    print(\"[forward] ejecutado en FP32\")\n",
    "    return y\n",
    "\n",
    "yhat = forward_with_auto_amp(model, x5d, device)\n",
    "print(\"yhat:\", tuple(yhat.shape))\n",
    "\n",
    "# 4) Limpieza del runtime encode (si se us√≥)\n",
    "if used_runtime_encode:\n",
    "    training.set_runtime_encode(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2600ee",
   "metadata": {},
   "source": [
    "<a id=\"sec-07\"></a>\n",
    "\n",
    "## 7) Echo de configuraci√≥n del bench\n",
    "\n",
    "Imprime los par√°metros efectivos de DataLoader y balanceo. √ötil para rastrear cambios de preset.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6158c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bench workers=8 prefetch=2 pin=True persistent=True | offline_bal=False online_bal=False\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Bench: echo de configuraci√≥n efectiva\n",
    "# =============================================================================\n",
    "print_bench_config(\n",
    "    NUM_WORKERS=NUM_WORKERS, PREFETCH=PREFETCH,\n",
    "    PIN_MEMORY=PIN_MEMORY, PERSISTENT=PERSISTENT,\n",
    "    USE_OFFLINE_BALANCED=USE_OFFLINE_BALANCED, USE_ONLINE_BALANCING=USE_ONLINE_BALANCING\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e5c3ae",
   "metadata": {},
   "source": [
    "<a id=\"sec-08\"></a>\n",
    "\n",
    "## 8) Toggle: *it/s* por √©poca\n",
    "\n",
    "Activa un parche temporal que imprime *iterations/second* por √©poca durante entrenamiento. Llama a `disable_epoch_ips()` para restaurar.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf03722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it/s por √©poca ACTIVADO. Llama a disable_epoch_ips() para restaurar.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Toggle: imprimir it/s por √©poca durante entrenamiento\n",
    "# =============================================================================\n",
    "enable_epoch_ips()\n",
    "print(\"it/s por √©poca ACTIVADO. Llama a disable_epoch_ips() para restaurar.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2877f7",
   "metadata": {},
   "source": [
    "<a id=\"sec-09\"></a>\n",
    "\n",
    "## 9) (Opcional) Micro-bench pipeline *it/s*\n",
    "\n",
    "Mide *throughput* aproximado iterando `loader ‚Üí modelo` varias veces, con AMP si procede.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e410f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline it/s ‚âà 29.19\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# (Opcional) Micro-bench pipeline: it/s (loader + modelo)\n",
    "# =============================================================================\n",
    "from src.bench import pipeline_its\n",
    "\n",
    "# peque√±o loader\n",
    "tr, va, te = make_loader_fn(\n",
    "    task=task_list[0],\n",
    "    batch_size=8,\n",
    "    encoder=ENCODER, T=T, gain=GAIN,\n",
    "    tfm=tfm, seed=SEED,\n",
    ")\n",
    "\n",
    "# preparar un batch inicial\n",
    "xb0, _ = next(iter(tr))\n",
    "if xb0.ndim == 4:\n",
    "    import src.training as training\n",
    "    training.set_runtime_encode(mode=ENCODER, T=T, gain=GAIN, device=device)\n",
    "\n",
    "its = pipeline_its(\n",
    "    model=make_model_fn(tfm).to(device).eval(),\n",
    "    loader=tr, device=device,\n",
    "    iters=100, use_amp=True,\n",
    "    encoder=ENCODER, T=T, gain=GAIN,\n",
    ")\n",
    "print(f\"pipeline it/s ‚âà {its:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc0795",
   "metadata": {},
   "source": [
    "<a id=\"sec-10\"></a>\n",
    "\n",
    "## 10) (Opcional) Smokes de m√©todos con `run_continual`\n",
    "\n",
    "Lanza runs cortos por m√©todo (`naive`, `ewc`, `rehearsal`, `rehearsal+ewc`) usando la **misma** `CFG` del preset para asegurar coherencia con el 03.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8558126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> SMOKE: preset=fast | method=naive | seed=42 | enc=rate | kwargs={}\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=naive | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 8.4 it/s (164 iters en 19.64s)\n",
      "[TRAIN it/s] epoch 2/2: 10.5 it/s (164 iters en 15.56s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=naive | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 7.0 it/s (49 iters en 7.04s)\n",
      "[TRAIN it/s] epoch 2/2: 8.5 it/s (49 iters en 5.77s)\n",
      "\n",
      ">>> SMOKE: preset=fast | method=ewc | seed=42 | enc=rate | kwargs={'lam': 1000000000.0, 'fisher_batches': 200}\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_1e+09 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 10.1 it/s (164 iters en 16.18s)\n",
      "[TRAIN it/s] epoch 2/2: 9.3 it/s (164 iters en 17.58s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_1e+09 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 8.4 it/s (49 iters en 5.84s)\n",
      "[TRAIN it/s] epoch 2/2: 7.8 it/s (49 iters en 6.32s)\n",
      "\n",
      ">>> SMOKE: preset=fast | method=rehearsal | seed=42 | enc=rate | kwargs={'buffer_size': 5000, 'replay_ratio': 0.2}\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=rehearsal_buf_5000_rr_20 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 8.4 it/s (164 iters en 19.61s)\n",
      "[TRAIN it/s] epoch 2/2: 8.2 it/s (164 iters en 20.08s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=rehearsal_buf_5000_rr_20 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 4.3 it/s (49 iters en 11.35s)\n",
      "[TRAIN it/s] epoch 2/2: 6.9 it/s (49 iters en 7.14s)\n",
      "\n",
      ">>> SMOKE: preset=fast | method=rehearsal+ewc | seed=42 | enc=rate | kwargs={'buffer_size': 5000, 'replay_ratio': 0.2, 'lam': 700000000.0, 'fisher_batches': 200}\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=rehearsal_buf_5000_rr_20+ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 8.4 it/s (164 iters en 19.42s)\n",
      "[TRAIN it/s] epoch 2/2: 8.6 it/s (164 iters en 19.09s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=rehearsal_buf_5000_rr_20+ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 7.6 it/s (49 iters en 6.46s)\n",
      "[TRAIN it/s] epoch 2/2: 8.4 it/s (49 iters en 5.83s)\n",
      "\n",
      "Hecho: ['/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_naive_rate_model-PilotNetSNN_66x200_gray_seed_42', '/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_1e+09_lam_1e+09_rate_model-PilotNetSNN_66x200_gray_seed_42', '/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_rehearsal_buf_5000_rr_20_rate_model-PilotNetSNN_66x200_gray_seed_42', '/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_rehearsal_buf_5000_rr_20+ewc_lam_7e+08_lam_7e+08_rate_model-PilotNetSNN_66x200_gray_seed_42']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# (Opcional) Smokes de m√©todos con run_continual (cfg del preset)\n",
    "# =============================================================================\n",
    "from copy import deepcopy\n",
    "from src.runner import run_continual\n",
    "\n",
    "DO_RUNS = True  # pon False para saltar\n",
    "\n",
    "if DO_RUNS:\n",
    "    base_cfg = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "    base_cfg = deepcopy(base_cfg)\n",
    "    base_cfg[\"data\"][\"seed\"] = SEED  # fija la semilla si quieres\n",
    "\n",
    "    METHODS = {\n",
    "        \"naive\": {},\n",
    "        \"ewc\": {\"lam\": 1e9, \"fisher_batches\": 200},\n",
    "        \"rehearsal\": {\"buffer_size\": 5000, \"replay_ratio\": 0.2},\n",
    "        \"rehearsal+ewc\": {\"buffer_size\": 5000, \"replay_ratio\": 0.2, \"lam\": 7e8, \"fisher_batches\": 200},\n",
    "    }\n",
    "\n",
    "    out_runs = []\n",
    "    for mname, mparams in METHODS.items():\n",
    "        cfg_i = deepcopy(base_cfg)\n",
    "        cfg_i[\"continual\"][\"method\"] = mname\n",
    "        cfg_i[\"continual\"][\"params\"] = mparams\n",
    "\n",
    "        print(\n",
    "            f\"\\n>>> SMOKE: preset={PRESET} | method={mname} | \"\n",
    "            f\"seed={cfg_i['data']['seed']} | enc={cfg_i['data']['encoder']} | kwargs={mparams}\"\n",
    "        )\n",
    "        out_dir, _ = run_continual(\n",
    "            task_list=task_list,\n",
    "            make_loader_fn=make_loader_fn,  # factory de Celda 4\n",
    "            make_model_fn=make_model_fn,\n",
    "            tfm=tfm,\n",
    "            cfg=cfg_i,               # CONFIG COMPLETA del preset con el m√©todo cambiado\n",
    "            preset_name=PRESET,      # solo naming\n",
    "            out_root=ROOT / \"outputs\",\n",
    "            verbose=True,\n",
    "        )\n",
    "        out_runs.append(out_dir)\n",
    "    print(\"\\nHecho:\", [str(p) for p in out_runs])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
