{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c448d5",
   "metadata": {},
   "source": [
    "# 03_TRAIN_CONTINUAL ‚Äî Entrenamiento Continual con *presets*\n",
    "\n",
    "**Qu√© hace este notebook:**\n",
    "\n",
    "Este notebook entrena y eval√∫a modelos en **aprendizaje continual** usando una configuraci√≥n unificada desde `configs/presets.yaml`.  \n",
    "Permite: (1) lanzar un *run* base, (2) comparar m√©todos continual con id√©ntica configuraci√≥n de datos/modelo, y (3) generar un **resumen** y **agregados** de resultados.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Centralizar la configuraci√≥n (modelo, datos, optimizador, continual) v√≠a `presets.yaml`.\n",
    "- Entrenar con **H5 offline** o **CSV+runtime encode** (auto-detectado).\n",
    "- Comparar m√©todos (`naive`, `ewc`, `rehearsal`, `rehearsal+ewc`) de forma reproducible.\n",
    "- Exportar res√∫menes a `outputs/summary/continual_summary_agg.csv`.\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "- `data/processed/tasks.json` o `data/processed/tasks_balanced.json` generados.\n",
    "- Si usas **offline** (H5), haberlos creado con `tools/encode_tasks.py`.\n",
    "- Revisar `configs/presets.yaml` (secciones: `model`, `data`, `optim`, `continual`).\n",
    "\n",
    "## ‚ö†Ô∏è Notas importantes\n",
    "- No combines `use_offline_spikes=True` con `encode_runtime=True`.\n",
    "- La **semilla** del experimento viene de `CFG[\"data\"][\"seed\"]` (reproducibilidad).\n",
    "- El nombre de la carpeta de salida codifica preset, m√©todo y meta (ver `src/runner.py`).\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "\n",
    "- [1) Setup del entorno y paths](#sec-01)\n",
    "- [2) Carga del preset unificado (`configs/presets.yaml`)](#sec-02)\n",
    "- [3) Verificaci√≥n de datos y selecci√≥n de `tasks.json`](#sec-03)\n",
    "- [4) Factories DataLoaders + Modelo (+ tasks)](#sec-04)\n",
    "- [5) (Opcional) Parche: imprimir *it/s* por √©poca](#sec-06)\n",
    "- [6) Ejecuci√≥n base con el preset (eco de config + run)](#sec-07)\n",
    "- [7) Comparativa de m√©todos (mismo preset/semilla/datos)](#sec-08)\n",
    "- [8) Barrido de combinaciones (opcional)](#sec-09)\n",
    "- [9) Resumen completo: inventario ‚Üí parseo ‚Üí agregados ‚Üí tabla](#sec-10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668cb21",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "\n",
    "## 1) Setup del entorno y paths\n",
    "\n",
    "**Objetivo:** preparar el entorno de ejecuci√≥n con granularidad de hilos, selecci√≥n de dispositivo y rutas del proyecto.\n",
    "\n",
    "- Fija variables de entorno para limitar hilos BLAS (reproducibilidad y evitar oversubscription).\n",
    "- Detecta `ROOT` (ra√≠z del repo) y lo a√±ade a `sys.path`.\n",
    "- Importa utilidades del proyecto (datasets, modelos, presets).\n",
    "- Selecciona dispositivo (`cuda` si est√° disponible).\n",
    "- Activa optimizaciones de PyTorch (TF32/cuDNN) para acelerar entrenamiento en GPU.\n",
    "\n",
    "> **Nota:** No se leen presets aqu√≠ todav√≠a; √∫nicamente se configura el runtime global.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9084ebfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup de entorno (threads, paths, dispositivo)\n",
    "# =============================================================================\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "# Ra√≠z del repo y sys.path\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Librer√≠as del proyecto\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import build_model\n",
    "from src.utils import load_preset\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Ajustes de rendimiento (opcional)\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851cb55",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "\n",
    "## 2) Carga del preset unificado (`configs/presets.yaml`)\n",
    "\n",
    "**Objetivo:** cargar un *preset* y derivar toda la configuraci√≥n de trabajo.\n",
    "\n",
    "Contenido:\n",
    "- Lee el preset (`PRESET = \"fast\" | \"std\" | \"accurate\"`).\n",
    "- Construye el `ImageTransform` seg√∫n el modelo del preset.\n",
    "- Extrae par√°metros de **datos/codificaci√≥n temporal** (`ENCODER`, `T`, `GAIN`, `SEED`).\n",
    "- Extrae configuraci√≥n del **DataLoader** (workers, prefetch, pin/persistent).\n",
    "- Prepara *augment* opcional (`AUG_CFG`) y **balanceo online** (si procede).\n",
    "- Guardarra√≠l: proh√≠be usar a la vez `use_offline_spikes=True` y `encode_runtime=True`.\n",
    "\n",
    "> **Consejo:** cambia el valor de `PRESET` aqu√≠ para barrer configuraciones sin tocar c√≥digo en m√°s sitios.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232708c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRESET=fast] model=pilotnet_snn 200x66 gray=True\n",
      "[DATA] encoder=rate T=10 gain=0.5 seed=42\n",
      "[LOADER] workers=8 prefetch=2 pin=True persistent=True\n",
      "[BALANCE] online=False bins=50\n",
      "[RUNTIME_ENCODE] False | [OFFLINE_SPIKES] True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Config global: presets.yaml\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.utils import load_preset\n",
    "\n",
    "PRESET = \"std\"  # fast | std | accurate\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# ---- Modelo / Transform ------------------------------------------------------\n",
    "MODEL_NAME = CFG[\"model\"][\"name\"]\n",
    "tfm = ImageTransform(\n",
    "    CFG[\"model\"][\"img_w\"],\n",
    "    CFG[\"model\"][\"img_h\"],\n",
    "    to_gray=bool(CFG[\"model\"][\"to_gray\"]),\n",
    "    crop_top=None\n",
    ")\n",
    "\n",
    "# ---- Datos / codificaci√≥n temporal ------------------------------------------\n",
    "ENCODER = CFG[\"data\"][\"encoder\"]\n",
    "T       = int(CFG[\"data\"][\"T\"])\n",
    "GAIN    = float(CFG[\"data\"][\"gain\"])\n",
    "SEED    = int(CFG[\"data\"][\"seed\"])\n",
    "\n",
    "USE_OFFLINE_SPIKES = bool(CFG[\"data\"].get(\"use_offline_spikes\", False))\n",
    "RUNTIME_ENCODE     = bool(CFG[\"data\"].get(\"encode_runtime\", False))\n",
    "\n",
    "# ---- DataLoader / augment / balanceo ----------------------------------------\n",
    "NUM_WORKERS = int(CFG[\"data\"].get(\"num_workers\") or 0)           # robusto ante None\n",
    "PREFETCH    = int(CFG[\"data\"].get(\"prefetch_factor\") or 2)       # <- casteo robusto\n",
    "PIN_MEMORY  = bool(CFG[\"data\"].get(\"pin_memory\", True))\n",
    "PERSISTENT  = bool(CFG[\"data\"].get(\"persistent_workers\", True))\n",
    "\n",
    "AUG_CFG = AugmentConfig(**(CFG[\"data\"].get(\"aug_train\") or {})) \\\n",
    "          if CFG[\"data\"].get(\"aug_train\") else None\n",
    "\n",
    "USE_ONLINE_BALANCING = bool(CFG[\"data\"].get(\"balance_online\", False))\n",
    "BAL_BINS = int(CFG[\"data\"].get(\"balance_bins\") or 50)\n",
    "BAL_EPS  = float(CFG[\"data\"].get(\"balance_smooth_eps\") or 1e-3)\n",
    "\n",
    "# Guardarra√≠les\n",
    "if USE_OFFLINE_SPIKES and RUNTIME_ENCODE:\n",
    "    raise RuntimeError(\"Config inv√°lida: use_offline_spikes=True y encode_runtime=True a la vez.\")\n",
    "\n",
    "print(f\"[PRESET={PRESET}] model={MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] encoder={ENCODER} T={T} gain={GAIN} seed={SEED}\")\n",
    "print(f\"[LOADER] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "print(f\"[BALANCE] online={USE_ONLINE_BALANCING} bins={BAL_BINS}\")\n",
    "print(f\"[RUNTIME_ENCODE] {RUNTIME_ENCODE} | [OFFLINE_SPIKES] {USE_OFFLINE_SPIKES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5de0d",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "\n",
    "## 3) Verificaci√≥n de datasets y selecci√≥n de `tasks.json`\n",
    "\n",
    "Comprueba que existen los CSV de `train/val/test` por tarea, y (si corresponde)\n",
    "que `train_balanced.csv` est√° disponible para el modo **offline balanceado**.\n",
    "\n",
    "- Lee `tasks_balanced.json` si `USE_OFFLINE_BALANCED=True`; si faltan, cae a `tasks.json`.\n",
    "- Construye `task_list` con rutas por split.\n",
    "\n",
    "> *Salida esperada:* listado de tareas y su CSV de `train`. Mensaje de OK/aviso.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c673a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando: tasks_balanced.json\n",
      " - circuito1: train_balanced.csv\n",
      " - circuito2: train_balanced.csv\n",
      "OK: verificaci√≥n de splits.\n",
      "Preset en uso: fast\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Verificaci√≥n de datos (splits y, si procede, H5)\n",
    "# =============================================================================\n",
    "from pathlib import Path as _P\n",
    "import json\n",
    "\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# --- Elegir tasks seg√∫n el preset ---\n",
    "USE_BALANCED = bool(CFG.get(\"prep\", {}).get(\"use_balanced_tasks\", False))\n",
    "tb_name = (CFG.get(\"prep\", {}).get(\"tasks_balanced_file_name\") or \"tasks_balanced.json\")\n",
    "t_name  = (CFG.get(\"prep\", {}).get(\"tasks_file_name\")           or \"tasks.json\")\n",
    "\n",
    "cand_bal = PROC / tb_name\n",
    "cand_std = PROC / t_name\n",
    "TASKS_FILE = cand_bal if (USE_BALANCED and cand_bal.exists()) else cand_std\n",
    "\n",
    "with open(TASKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "print(\"Usando:\", TASKS_FILE.name)\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {_P(t['paths']['train']).name}\")\n",
    "\n",
    "# Guardarra√≠l: si se pidi√≥ balanced, exigir train_balanced.csv\n",
    "if USE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = _P(tasks_json[\"splits\"][t[\"name\"]][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' en modo balanced, pero encontr√© '{train_path.name}'.\"\n",
    "            )\n",
    "\n",
    "# Si entrenas con H5 offline, comprueba que existan\n",
    "if USE_OFFLINE_SPIKES:\n",
    "    mw, mh = CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"]\n",
    "    color = \"gray\" if CFG[\"model\"][\"to_gray\"] else \"rgb\"\n",
    "    gain_tag = (GAIN if ENCODER == \"rate\" else 0)\n",
    "    missing = []\n",
    "    for t in task_list:\n",
    "        run = t[\"name\"]\n",
    "        base = PROC / run\n",
    "        for split in (\"train\", \"val\", \"test\"):\n",
    "            expected = base / f\"{split}_{ENCODER}_T{T}_gain{gain_tag}_{color}_{mw}x{mh}.h5\"\n",
    "            if not expected.exists():\n",
    "                missing.append(str(expected))\n",
    "    if missing:\n",
    "        print(\"[WARN] Faltan H5 compatibles con el preset.\")\n",
    "        print(\"       Genera primero con 02_ENCODE_OFFLINE.ipynb (o tools/encode_tasks.py).\")\n",
    "\n",
    "print(\"OK: verificaci√≥n de splits.\")\n",
    "print(f\"Preset en uso: {PRESET}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926bb4b",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "\n",
    "## 4) Factories unificados: DataLoaders + Modelo (+ tasks)\n",
    "\n",
    "Construye en **una sola pasada** todos los componentes a partir del `CFG`:\n",
    "\n",
    "- `build_components_for(CFG, ROOT)` ‚Üí `tfm`, `make_loader_fn`, `make_model_fn`  \n",
    "  - El **loader** respeta autom√°ticamente los flags del preset (H5 offline vs. CSV+encode runtime, workers, prefetch, pin_memory, persistent, augmentaci√≥n y balanceo online).\n",
    "  - El **modelo** se crea seg√∫n `model.name` y aplica, cuando procede, hiperpar√°metros de neurona.\n",
    "- `build_task_list_for(CFG, ROOT)` ‚Üí `task_list`, `tasks_file`  \n",
    "  - Selecciona `tasks_balanced.json` si el preset lo pide y existe; en caso contrario usa `tasks.json`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a172cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks file: tasks_balanced.json\n",
      "make_loader_fn listo (H5 si use_offline_spikes=True; fallback CSV+runtime si no).\n"
     ]
    }
   ],
   "source": [
    "# === Factories y task list coherentes con el PRESET cargado ===\n",
    "from src.utils import build_task_list_for, build_components_for\n",
    "\n",
    "# Construye tfm, make_loader_fn y make_model_fn leyendo TODO de CFG (igual que hac√≠as a mano):\n",
    "tfm, make_loader_fn, make_model_fn = build_components_for(CFG, ROOT)\n",
    "\n",
    "# Elige autom√°ticamente tasks_balanced.json si el preset lo pide y existe; si no, tasks.json\n",
    "task_list, tasks_file = build_task_list_for(CFG, ROOT)\n",
    "\n",
    "print(\"Tasks file:\", tasks_file.name)\n",
    "print(\"make_loader_fn listo (H5 si use_offline_spikes=True; fallback CSV+runtime si no).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a07afb",
   "metadata": {},
   "source": [
    "<a id=\"sec-05\"></a>\n",
    "\n",
    "## 5) (Opcional) Parche: imprimir iteraciones/segundo por √©poca\n",
    "\n",
    "Sobrescribe temporalmente `training.train_supervised` para:\n",
    "\n",
    "- Medir **it/s** por √©poca (√∫til para benchmarks de rendimiento).\n",
    "- Mantener el resto del entrenamiento sin cambios funcionales.\n",
    "\n",
    "> Para restaurar el comportamiento original: `training.train_supervised = orig_train_supervised`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7ecabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parche it/s + EarlyStopping ACTIVADO. Para desactivarlo: training.train_supervised = orig_train_supervised\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# (Opcional) Parche: it/s + Early Stopping (controlado por preset)\n",
    "# =============================================================================\n",
    "import time, json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "import src.training as training\n",
    "from src.utils import set_seeds\n",
    "\n",
    "orig_train_supervised = training.train_supervised  # backup\n",
    "\n",
    "def train_supervised_ips_es(model: nn.Module, train_loader, val_loader, loss_fn: nn.Module,\n",
    "                            cfg, out_dir: Path, method=None):\n",
    "    \"\"\"\n",
    "    it/s + Early Stopping:\n",
    "      - Activo si cfg.es_patience y cfg.es_min_delta no son None.\n",
    "      - Criterio: min val_loss con tolerancia es_min_delta.\n",
    "    Escribe manifest.json con 'history' y 'early_stop_epoch' (si aplica).\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if cfg.seed is not None:\n",
    "        set_seeds(cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "    use_amp = bool(cfg.amp and torch.cuda.is_available())\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "    # ES params (le√≠dos del preset)\n",
    "    patience = getattr(cfg, \"es_patience\", None)\n",
    "    min_delta = getattr(cfg, \"es_min_delta\", None)\n",
    "    use_es = (patience is not None) and (min_delta is not None)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    wait = 0\n",
    "    early_stop_epoch = None\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        # -------- train --------\n",
    "        model.train()\n",
    "        running = 0.0; nb = 0\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast(\"cuda\", enabled=use_amp):\n",
    "                y_hat = model(x)\n",
    "                loss = loss_fn(y_hat, y)\n",
    "                if method is not None:\n",
    "                    loss = loss + method.penalty()\n",
    "\n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(opt); scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                opt.step()\n",
    "\n",
    "            running += loss.item(); nb += 1\n",
    "\n",
    "        dt = time.perf_counter() - t0\n",
    "        ips = nb / dt if dt > 0 else float(\"nan\")\n",
    "        print(f\"[TRAIN it/s] epoch {epoch}/{cfg.epochs}: {ips:.1f} it/s  ({nb} iters en {dt:.2f}s)\")\n",
    "        train_loss = running / max(1, nb)\n",
    "\n",
    "        # -------- val --------\n",
    "        model.eval()\n",
    "        v_running = 0.0; nvb = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                with autocast(\"cuda\", enabled=use_amp):\n",
    "                    y_hat = model(x)\n",
    "                    v_loss = loss_fn(y_hat, y)\n",
    "                v_running += v_loss.item(); nvb += 1\n",
    "        val_loss = v_running / max(1, nvb)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        # -------- Early Stopping check --------\n",
    "        if use_es:\n",
    "            improved = (best_val - val_loss) > float(min_delta)\n",
    "            if improved:\n",
    "                best_val = val_loss\n",
    "                wait = 0\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= int(patience):\n",
    "                    early_stop_epoch = epoch\n",
    "                    print(f\"[EarlyStopping] Stop en epoch={epoch} (best_val={best_val:.6f})\")\n",
    "                    break\n",
    "\n",
    "    manifest = {\n",
    "        \"epochs\": cfg.epochs, \"batch_size\": cfg.batch_size, \"lr\": cfg.lr,\n",
    "        \"amp\": cfg.amp, \"seed\": cfg.seed, \"history\": history,\n",
    "        \"early_stop_epoch\": early_stop_epoch,\n",
    "    }\n",
    "    (out_dir / \"manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    return history\n",
    "\n",
    "training.train_supervised = train_supervised_ips_es\n",
    "print(\"Parche it/s + EarlyStopping ACTIVADO. Para desactivarlo: training.train_supervised = orig_train_supervised\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bdd076",
   "metadata": {},
   "source": [
    "<a id=\"sec-06\"></a>\n",
    "\n",
    "## 6) Ejecuci√≥n base con el preset (eco de config + run)\n",
    "\n",
    "Lanza **un experimento** con el m√©todo y par√°metros definidos en el preset (`CFG[\"continual\"]`).  \n",
    "Se imprimen los campos m√°s relevantes (modelo, datos, loader) y se guarda la salida en `outputs/continual_*`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ff246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] preset=fast | method=ewc | seed=42 | enc=rate | kwargs={'lam': '1.0e9', 'fisher_batches': 1000}\n",
      "[MODEL] pilotnet_snn 200x66 gray=True\n",
      "[DATA] T=10 gain=0.5 | offline_spikes=True | runtime_encode=False\n",
      "[LOADER] workers=8 prefetch=2 pin=True persistent=True | aug=True | balance_online=False\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_1e+09 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 12.6 it/s  (391 iters en 30.96s)\n",
      "[TRAIN it/s] epoch 2/2: 13.2 it/s  (391 iters en 29.62s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_1e+09 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 10.1 it/s  (170 iters en 16.75s)\n",
      "[TRAIN it/s] epoch 2/2: 10.4 it/s  (170 iters en 16.32s)\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_1e+09_lam_1e+09_rate_model-PilotNetSNN_66x200_gray_seed_42\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ejecuci√≥n base con el preset (eco de config + run)\n",
    "# =============================================================================\n",
    "from src.runner import run_continual\n",
    "\n",
    "# Echo de configuraci√≥n ‚Äúresumido‚Äù (lo esencial para el run)\n",
    "print(f\"[RUN] preset={PRESET} | method={CFG['continual']['method']} \"\n",
    "      f\"| seed={CFG['data']['seed']} | enc={CFG['data']['encoder']} \"\n",
    "      f\"| kwargs={CFG['continual'].get('params', {})}\")\n",
    "print(f\"[MODEL] {MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] T={CFG['data']['T']} gain={CFG['data']['gain']} \"\n",
    "      f\"| offline_spikes={CFG['data']['use_offline_spikes']} \"\n",
    "      f\"| runtime_encode={CFG['data']['encode_runtime']}\")\n",
    "print(f\"[LOADER] workers={CFG['data']['num_workers']} \"\n",
    "      f\"prefetch={CFG['data']['prefetch_factor']} pin={CFG['data']['pin_memory']} \"\n",
    "      f\"persistent={CFG['data']['persistent_workers']} \"\n",
    "      f\"| aug={bool(CFG['data']['aug_train'])} \"\n",
    "      f\"| balance_online={CFG['data']['balance_online']}\")\n",
    "\n",
    "out_path, _ = run_continual(\n",
    "    task_list=task_list,\n",
    "    make_loader_fn=make_loader_fn,   # wrapper (Celda 4)\n",
    "    make_model_fn=make_model_fn,     # factory (Celda 5)\n",
    "    tfm=tfm,\n",
    "    cfg=CFG,                         # preset completo\n",
    "    preset_name=PRESET,              # solo naming\n",
    "    out_root=ROOT / \"outputs\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"OK:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f15dc1",
   "metadata": {},
   "source": [
    "<a id=\"sec-07\"></a>\n",
    "\n",
    "## 7) Comparativa de m√©todos (mismo preset / misma semilla / mismos datos)\n",
    "\n",
    "Esta celda ejecuta varias corridas cambiando **√∫nicamente** el m√©todo de aprendizaje\n",
    "continual, manteniendo fijos el `preset` cargado en la Celda 2 (modelo, loader, AMP,\n",
    "LR, epochs, T, gain, tama√±o de imagen, etc.).\n",
    "\n",
    "- Usa `CFG` tal cual (ya trae `continual.method`/`params`, `data.encoder`, `data.seed`, etc.).\n",
    "- Para cada m√©todo, se clona `CFG` y se sobreescriben **solo** `continual.method` y `continual.params`.\n",
    "- Los resultados se escriben en `outputs/continual_<preset>_<tag>_<encoder>_model-..._seed_<seed>/continual_results.json`.\n",
    "- Despu√©s, usa las Celdas 10‚Äì13 para generar el resumen y el CSV de agregados.\n",
    "\n",
    "**Requisitos**:\n",
    "- Si usas *offline spikes*, aseg√∫rate de que existen H5 compatibles con el preset:\n",
    "  encoder/T/gain/size/to_gray. Si no, el loader emitir√° un `FileNotFoundError`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f64d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN: preset=fast | method=naive | seed=42 | enc=rate | kwargs={} ===\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=naive | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 9.8 it/s  (391 iters en 40.03s)\n",
      "[TRAIN it/s] epoch 2/2: 10.3 it/s  (391 iters en 37.93s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=naive | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 10.0 it/s  (170 iters en 16.97s)\n",
      "[TRAIN it/s] epoch 2/2: 10.4 it/s  (170 iters en 16.30s)\n",
      "\n",
      "=== RUN: preset=fast | method=ewc | seed=42 | enc=rate | kwargs={'lam': 700000000.0, 'fisher_batches': 800} ===\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 10.6 it/s  (391 iters en 36.72s)\n",
      "[TRAIN it/s] epoch 2/2: 11.0 it/s  (391 iters en 35.40s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 9.7 it/s  (170 iters en 17.47s)\n",
      "[TRAIN it/s] epoch 2/2: 10.3 it/s  (170 iters en 16.58s)\n",
      "\n",
      "=== RUN: preset=fast | method=rehearsal | seed=42 | enc=rate | kwargs={'buffer_size': 3000, 'replay_ratio': 0.1} ===\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=rehearsal_buf_3000_rr_10 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 10.8 it/s  (391 iters en 36.31s)\n",
      "[TRAIN it/s] epoch 2/2: 10.9 it/s  (391 iters en 35.99s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=rehearsal_buf_3000_rr_10 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 8.2 it/s  (170 iters en 20.65s)\n",
      "[TRAIN it/s] epoch 2/2: 10.1 it/s  (170 iters en 16.80s)\n",
      "\n",
      "=== RUN: preset=fast | method=rehearsal+ewc | seed=42 | enc=rate | kwargs={'buffer_size': 3000, 'replay_ratio': 0.1, 'lam': 700000000.0, 'fisher_batches': 800} ===\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=rehearsal_buf_3000_rr_10+ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 11.5 it/s  (391 iters en 33.90s)\n",
      "[TRAIN it/s] epoch 2/2: 11.8 it/s  (391 iters en 33.05s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=rehearsal_buf_3000_rr_10+ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 9.0 it/s  (170 iters en 18.83s)\n",
      "[TRAIN it/s] epoch 2/2: 9.6 it/s  (170 iters en 17.80s)\n",
      "\n",
      "=== RUN: preset=fast | method=as-snn | seed=42 | enc=rate | kwargs={'gamma_ratio': 0.3, 'lambda_a': 1.59168, 'ema': 0.824} ===\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=as-snn_gr_0.3_lam_1.59168 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 11.6 it/s  (391 iters en 33.80s)\n",
      "[TRAIN it/s] epoch 2/2: 12.1 it/s  (391 iters en 32.22s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=as-snn_gr_0.3_lam_1.59168 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 11.5 it/s  (170 iters en 14.74s)\n",
      "[TRAIN it/s] epoch 2/2: 12.0 it/s  (170 iters en 14.21s)\n",
      "\n",
      "Hecho: ['/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_naive_rate_model-PilotNetSNN_66x200_gray_seed_42', '/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_7e+08_lam_7e+08_rate_model-PilotNetSNN_66x200_gray_seed_42', '/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_rehearsal_buf_3000_rr_10_rate_model-PilotNetSNN_66x200_gray_seed_42', '/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_rehearsal_buf_3000_rr_10+ewc_lam_7e+08_lam_7e+08_rate_model-PilotNetSNN_66x200_gray_seed_42', '/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_as-snn_gr_0.3_lam_1.59168_rate_model-PilotNetSNN_66x200_gray_seed_42']\n"
     ]
    }
   ],
   "source": [
    "# === COMPARATIVA DE M√âTODOS: mismo preset, misma semilla, mismos datos ===\n",
    "from copy import deepcopy\n",
    "from src.runner import run_continual\n",
    "from src.utils import build_task_list_for, build_components_for\n",
    "\n",
    "CFG_BASE = deepcopy(CFG)\n",
    "METHODS = {\n",
    "    \"naive\": {},\n",
    "    \"ewc\": {\"lam\": 7e8, \"fisher_batches\": 800},\n",
    "    \"rehearsal\": {\"buffer_size\": 3000, \"replay_ratio\": 0.1},\n",
    "    \"rehearsal+ewc\": {\"buffer_size\": 3000, \"replay_ratio\": 0.1, \"lam\": 7e8, \"fisher_batches\": 800},\n",
    "    \"as-snn\": {\"gamma_ratio\": 0.3, \"lambda_a\": 1.59168, \"ema\": 0.824},\n",
    "}\n",
    "\n",
    "runs_out = []\n",
    "for method_name, method_params in METHODS.items():\n",
    "    cfg_i = deepcopy(CFG_BASE)\n",
    "    cfg_i[\"continual\"][\"method\"] = method_name\n",
    "    cfg_i[\"continual\"][\"params\"] = method_params\n",
    "    if \"rehearsal\" in method_name:\n",
    "        cfg_i[\"data\"][\"persistent_workers\"] = False\n",
    "\n",
    "    # (Re)construye factories por si el cfg cambia\n",
    "    tfm_i, make_loader_fn_i, make_model_fn_i = build_components_for(cfg_i, ROOT)\n",
    "    task_list_i, tasks_file_i = build_task_list_for(cfg_i, ROOT)\n",
    "\n",
    "    print(f\"\\n=== RUN: preset={PRESET} | method={method_name} | seed={cfg_i['data']['seed']} \"\n",
    "          f\"| enc={cfg_i['data']['encoder']} | kwargs={method_params} ===\")\n",
    "    out_dir, _ = run_continual(\n",
    "        task_list=task_list_i,\n",
    "        make_loader_fn=make_loader_fn_i,\n",
    "        make_model_fn=make_model_fn_i,\n",
    "        tfm=tfm_i,\n",
    "        cfg=cfg_i,\n",
    "        preset_name=PRESET,\n",
    "        out_root=ROOT / \"outputs\",\n",
    "        verbose=True,\n",
    "    )\n",
    "    runs_out.append(out_dir)\n",
    "\n",
    "print(\"\\nHecho:\", [str(p) for p in runs_out])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e604e8",
   "metadata": {},
   "source": [
    "<a id=\"sec-08\"></a>\n",
    "\n",
    "## 8) Barrido de combinaciones (opcional)\n",
    "\n",
    "Driver gen√©rico para explorar:\n",
    "\n",
    "- `presets √ó seeds √ó encoders √ó m√©todos`.\n",
    "\n",
    "√ötil para estudios m√°s amplios (coste alto).  \n",
    "Asegura H5 compatibles si usas modo offline; controla carga (workers/prefetch) si la GPU va justa.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08f824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN: preset=fast | method=as-snn | seed=42 | enc=rate | kwargs={'gamma_ratio': 0.3, 'lambda_a': 1.59168, 'ema': 0.824} ===\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=as-snn_gr_0.3_lam_1.59168 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 11.5 it/s  (391 iters en 33.89s)\n",
      "[TRAIN it/s] epoch 2/2: 11.7 it/s  (391 iters en 33.53s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=as-snn_gr_0.3_lam_1.59168 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 11.5 it/s  (170 iters en 14.73s)\n",
      "[TRAIN it/s] epoch 2/2: 11.7 it/s  (170 iters en 14.52s)\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_as-snn_gr_0.3_lam_1.59168_rate_model-PilotNetSNN_66x200_gray_seed_42\n",
      "\n",
      "=== RUN: preset=fast | method=as-snn | seed=43 | enc=rate | kwargs={'gamma_ratio': 0.3, 'lambda_a': 1.59168, 'ema': 0.824} ===\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=as-snn_gr_0.3_lam_1.59168 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 11.3 it/s  (391 iters en 34.66s)\n",
      "[TRAIN it/s] epoch 2/2: 12.2 it/s  (391 iters en 32.06s)\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=as-snn_gr_0.3_lam_1.59168 | B=64 T=10 AMP=True | enc=rate ---\n",
      "[TRAIN it/s] epoch 1/2: 12.4 it/s  (170 iters en 13.75s)\n",
      "[TRAIN it/s] epoch 2/2: 12.4 it/s  (170 iters en 13.68s)\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_as-snn_gr_0.3_lam_1.59168_rate_model-PilotNetSNN_66x200_gray_seed_43\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Driver de ejecuci√≥n: barrido de combinaciones (opcional)\n",
    "# =============================================================================\n",
    "from copy import deepcopy\n",
    "from src.runner import run_continual\n",
    "from src.utils import load_preset, build_task_list_for, build_components_for\n",
    "\n",
    "PRESETS   = [PRESET]  # a√±ade \"std\", \"accurate\" si quieres\n",
    "SEEDS     = [CFG[\"data\"][\"seed\"], 43]\n",
    "ENCODERS  = [CFG[\"data\"][\"encoder\"]]\n",
    "METHODS   = [\n",
    "    # (\"naive\", {}),\n",
    "    # (\"ewc\", {\"lam\": 1e9, \"fisher_batches\": 600}),\n",
    "    # (\"rehearsal\", {\"buffer_size\": 5000, \"replay_ratio\": 0.2}),\n",
    "    # (\"rehearsal+ewc\", {\"buffer_size\": 5000, \"replay_ratio\": 0.2, \"lam\": 7e8, \"fisher_batches\": 600}),\n",
    "    (\"as-snn\", {\"gamma_ratio\": 0.3, \"lambda_a\": 1.59168, \"ema\": 0.824}),\n",
    "]\n",
    "\n",
    "for preset_i in PRESETS:\n",
    "    CFG_i = load_preset(ROOT / \"configs\" / \"presets.yaml\", preset_i)\n",
    "    for seed_i in SEEDS:\n",
    "        for enc_i in ENCODERS:\n",
    "            for method_name, method_params in METHODS:\n",
    "                cfg_i2 = deepcopy(CFG_i)\n",
    "                cfg_i2[\"data\"][\"seed\"] = seed_i\n",
    "                cfg_i2[\"data\"][\"encoder\"] = enc_i\n",
    "                cfg_i2[\"continual\"][\"method\"] = method_name\n",
    "                cfg_i2[\"continual\"][\"params\"] = method_params\n",
    "                if \"rehearsal\" in method_name:\n",
    "                    cfg_i2[\"data\"][\"persistent_workers\"] = False\n",
    "\n",
    "                tfm_i, make_loader_fn_i, make_model_fn_i = build_components_for(cfg_i2, ROOT)\n",
    "                task_list_i, tasks_file_i = build_task_list_for(cfg_i2, ROOT)\n",
    "\n",
    "                print(f\"\\n=== RUN: preset={preset_i} | method={method_name} | seed={seed_i} \"\n",
    "                      f\"| enc={enc_i} | kwargs={method_params} ===\")\n",
    "                out_path, _ = run_continual(\n",
    "                    task_list=task_list_i,\n",
    "                    make_loader_fn=make_loader_fn_i,\n",
    "                    make_model_fn=make_model_fn_i,\n",
    "                    tfm=tfm_i,\n",
    "                    cfg=cfg_i2,\n",
    "                    preset_name=preset_i,\n",
    "                    out_root=ROOT / \"outputs\",\n",
    "                    verbose=True,\n",
    "                )\n",
    "                print(\"OK:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0650365",
   "metadata": {},
   "source": [
    "<a id=\"sec-09\"></a>\n",
    "\n",
    "## 9) Resumen completo: inventario ‚Üí parseo ‚Üí agregados ‚Üí tabla\n",
    "\n",
    "- **Inventario** de runs en `outputs/continual_*`.  \n",
    "- **Parseo** del nombre de las carpetas para extraer `preset`, `m√©todo`, `Œª`, `encoder`, `seed`, `modelo`.  \n",
    "- **C√°lculo de olvido**: diferencia absoluta y relativa de T1 tras T2.  \n",
    "- **Agregados** por grupo (media/œÉ/n) y export a `outputs/summary/continual_summary_agg.csv`.  \n",
    "- **Tabla formateada** con m√©tricas clave y desviaciones.\n",
    "\n",
    "> Si no aparece nada, revisa que existan `continual_results.json` en las carpetas de salida.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dae41ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventario de runs en: /home/cesar/proyectos/TFM_SNN/outputs\n",
      " - continual_fast_as-snn_gr_0.3_lam_1.59168_rate_model-PilotNetSNN_66x200_gray_seed_42 | results.json: True\n",
      " - continual_fast_as-snn_gr_0.3_lam_1.59168_rate_model-PilotNetSNN_66x200_gray_seed_43 | results.json: True\n",
      " - continual_fast_ewc_lam_1e+09_lam_1e+09_rate_model-PilotNetSNN_66x200_gray_seed_42 | results.json: True\n",
      " - continual_fast_ewc_lam_7e+08_lam_7e+08_rate_model-PilotNetSNN_66x200_gray_seed_42 | results.json: True\n",
      " - continual_fast_naive_rate_model-PilotNetSNN_66x200_gray_seed_42 | results.json: True\n",
      " - continual_fast_rehearsal_buf_3000_rr_10+ewc_lam_7e+08_lam_7e+08_rate_model-PilotNetSNN_66x200_gray_seed_42 | results.json: True\n",
      " - continual_fast_rehearsal_buf_3000_rr_10_rate_model-PilotNetSNN_66x200_gray_seed_42 | results.json: True\n",
      "runs en resumen: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>preset</th>\n",
       "      <th>method</th>\n",
       "      <th>lambda</th>\n",
       "      <th>encoder</th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>c1_name</th>\n",
       "      <th>c2_name</th>\n",
       "      <th>c1_mae</th>\n",
       "      <th>c1_after_c2_mae</th>\n",
       "      <th>c1_forgetting_mae_abs</th>\n",
       "      <th>c1_forgetting_mae_rel_%</th>\n",
       "      <th>c2_mae</th>\n",
       "      <th>lambda_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continual_fast_as-snn_gr_0.3_lam_1.59168_rate_...</td>\n",
       "      <td>fast</td>\n",
       "      <td>as-snn_gr_0.3</td>\n",
       "      <td>1.59168</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.171290</td>\n",
       "      <td>0.172986</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.990284</td>\n",
       "      <td>0.224034</td>\n",
       "      <td>1.591680e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continual_fast_as-snn_gr_0.3_lam_1.59168_rate_...</td>\n",
       "      <td>fast</td>\n",
       "      <td>as-snn_gr_0.3</td>\n",
       "      <td>1.59168</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>43</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.172936</td>\n",
       "      <td>0.172952</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.009722</td>\n",
       "      <td>0.224013</td>\n",
       "      <td>1.591680e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continual_fast_ewc_lam_7e+08_lam_7e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.171290</td>\n",
       "      <td>0.171568</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.162523</td>\n",
       "      <td>0.223178</td>\n",
       "      <td>7.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.171993</td>\n",
       "      <td>0.172596</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.350517</td>\n",
       "      <td>0.223798</td>\n",
       "      <td>1.000000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>continual_fast_naive_rate_model-PilotNetSNN_66...</td>\n",
       "      <td>fast</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.171290</td>\n",
       "      <td>0.172986</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.990284</td>\n",
       "      <td>0.224034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>continual_fast_rehearsal_buf_3000_rr_10_rate_m...</td>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_3000_rr_10</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.175333</td>\n",
       "      <td>0.174515</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.466733</td>\n",
       "      <td>0.224983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>continual_fast_rehearsal_buf_3000_rr_10+ewc_la...</td>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_3000_rr_10+ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>circuito1</td>\n",
       "      <td>circuito2</td>\n",
       "      <td>0.174054</td>\n",
       "      <td>0.173953</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.058274</td>\n",
       "      <td>0.224627</td>\n",
       "      <td>7.000000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 exp preset  \\\n",
       "0  continual_fast_as-snn_gr_0.3_lam_1.59168_rate_...   fast   \n",
       "1  continual_fast_as-snn_gr_0.3_lam_1.59168_rate_...   fast   \n",
       "2  continual_fast_ewc_lam_7e+08_lam_7e+08_rate_mo...   fast   \n",
       "3  continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...   fast   \n",
       "4  continual_fast_naive_rate_model-PilotNetSNN_66...   fast   \n",
       "5  continual_fast_rehearsal_buf_3000_rr_10_rate_m...   fast   \n",
       "6  continual_fast_rehearsal_buf_3000_rr_10+ewc_la...   fast   \n",
       "\n",
       "                         method   lambda encoder                    model  \\\n",
       "0                 as-snn_gr_0.3  1.59168    rate  PilotNetSNN_66x200_gray   \n",
       "1                 as-snn_gr_0.3  1.59168    rate  PilotNetSNN_66x200_gray   \n",
       "2                           ewc    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "3                           ewc    1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "4                         naive     None    rate  PilotNetSNN_66x200_gray   \n",
       "5      rehearsal_buf_3000_rr_10     None    rate  PilotNetSNN_66x200_gray   \n",
       "6  rehearsal_buf_3000_rr_10+ewc    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "\n",
       "   seed    c1_name    c2_name    c1_mae  c1_after_c2_mae  \\\n",
       "0    42  circuito1  circuito2  0.171290         0.172986   \n",
       "1    43  circuito1  circuito2  0.172936         0.172952   \n",
       "2    42  circuito1  circuito2  0.171290         0.171568   \n",
       "3    42  circuito1  circuito2  0.171993         0.172596   \n",
       "4    42  circuito1  circuito2  0.171290         0.172986   \n",
       "5    42  circuito1  circuito2  0.175333         0.174515   \n",
       "6    42  circuito1  circuito2  0.174054         0.173953   \n",
       "\n",
       "   c1_forgetting_mae_abs  c1_forgetting_mae_rel_%    c2_mae    lambda_num  \n",
       "0               0.001696                 0.990284  0.224034  1.591680e+00  \n",
       "1               0.000017                 0.009722  0.224013  1.591680e+00  \n",
       "2               0.000278                 0.162523  0.223178  7.000000e+08  \n",
       "3               0.000603                 0.350517  0.223798  1.000000e+09  \n",
       "4               0.001696                 0.990284  0.224034           NaN  \n",
       "5              -0.000818                -0.466733  0.224983           NaN  \n",
       "6              -0.000101                -0.058274  0.224627  7.000000e+08  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: /home/cesar/proyectos/TFM_SNN/outputs/summary/continual_summary_agg.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preset</th>\n",
       "      <th>m√©todo</th>\n",
       "      <th>codificador</th>\n",
       "      <th>Œª</th>\n",
       "      <th>MAE Tarea1 (media)</th>\n",
       "      <th>Olvido T1 (%) (media)</th>\n",
       "      <th>MAE Tarea2 (media)</th>\n",
       "      <th>MAE Tarea1 (œÉ)</th>\n",
       "      <th>Olvido T1 (%) (œÉ)</th>\n",
       "      <th>MAE Tarea2 (œÉ)</th>\n",
       "      <th>n (semillas)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fast</td>\n",
       "      <td>as-snn_gr_0.3</td>\n",
       "      <td>rate</td>\n",
       "      <td>1.59168</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.6934</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>rate</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2232</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>rate</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.2238</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fast</td>\n",
       "      <td>naive</td>\n",
       "      <td>rate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.2240</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_3000_rr_10</td>\n",
       "      <td>rate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1753</td>\n",
       "      <td>-0.4667</td>\n",
       "      <td>0.2250</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_3000_rr_10+ewc</td>\n",
       "      <td>rate</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>-0.0583</td>\n",
       "      <td>0.2246</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preset                        m√©todo codificador        Œª  \\\n",
       "0   fast                 as-snn_gr_0.3        rate  1.59168   \n",
       "1   fast                           ewc        rate    7e+08   \n",
       "2   fast                           ewc        rate    1e+09   \n",
       "3   fast                         naive        rate      NaN   \n",
       "4   fast      rehearsal_buf_3000_rr_10        rate      NaN   \n",
       "5   fast  rehearsal_buf_3000_rr_10+ewc        rate    7e+08   \n",
       "\n",
       "  MAE Tarea1 (media) Olvido T1 (%) (media) MAE Tarea2 (media) MAE Tarea1 (œÉ)  \\\n",
       "0             0.1721                0.5000             0.2240         0.0012   \n",
       "1             0.1713                0.1625             0.2232                  \n",
       "2             0.1720                0.3505             0.2238                  \n",
       "3             0.1713                0.9903             0.2240                  \n",
       "4             0.1753               -0.4667             0.2250                  \n",
       "5             0.1741               -0.0583             0.2246                  \n",
       "\n",
       "  Olvido T1 (%) (œÉ) MAE Tarea2 (œÉ)  n (semillas)  \n",
       "0            0.6934         0.0000             2  \n",
       "1                                              1  \n",
       "2                                              1  \n",
       "3                                              1  \n",
       "4                                              1  \n",
       "5                                              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Resumen de runs (usa utilidades comunes) ===\n",
    "from pathlib import Path\n",
    "from src.utils_exp import build_runs_df, aggregate_and_show\n",
    "\n",
    "outputs_root = ROOT / \"outputs\"\n",
    "\n",
    "# (Opcional) inventario r√°pido en disco\n",
    "print(\"Inventario de runs en:\", outputs_root)\n",
    "for p in sorted(outputs_root.glob(\"continual_*\")):\n",
    "    print(\" -\", p.name, \"| results.json:\", (p / \"continual_results.json\").exists())\n",
    "\n",
    "df = build_runs_df(outputs_root)\n",
    "print(f\"runs en resumen: {len(df)}\")\n",
    "_ = aggregate_and_show(df, outputs_root)  # tambi√©n guarda CSV en outputs/summary/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
