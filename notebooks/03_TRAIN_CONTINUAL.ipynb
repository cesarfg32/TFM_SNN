{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c448d5",
   "metadata": {},
   "source": [
    "# 03_TRAIN_CONTINUAL ‚Äî Entrenamiento Continual con *presets*\n",
    "\n",
    "**Qu√© hace este notebook:**\n",
    "\n",
    "Este notebook entrena y eval√∫a modelos en **aprendizaje continual** usando una configuraci√≥n unificada desde `configs/presets.yaml`.  \n",
    "Permite: (1) lanzar un *run* base, (2) comparar m√©todos continual con id√©ntica configuraci√≥n de datos/modelo, y (3) generar un **resumen** y **agregados** de resultados.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Centralizar la configuraci√≥n (modelo, datos, optimizador, continual) v√≠a `presets.yaml`.\n",
    "- Entrenar con **H5 offline** o **CSV+runtime encode** (auto-detectado).\n",
    "- Comparar m√©todos (`naive`, `ewc`, `rehearsal`, `rehearsal+ewc`) de forma reproducible.\n",
    "- Exportar res√∫menes a `outputs/summary/continual_summary_agg.csv`.\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "- `data/processed/tasks.json` o `data/processed/tasks_balanced.json` generados.\n",
    "- Si usas **offline** (H5), haberlos creado con `tools/encode_tasks.py`.\n",
    "- Revisar `configs/presets.yaml` (secciones: `model`, `data`, `optim`, `continual`).\n",
    "\n",
    "## ‚ö†Ô∏è Notas importantes\n",
    "- No combines `use_offline_spikes=True` con `encode_runtime=True`.\n",
    "- La **semilla** del experimento viene de `CFG[\"data\"][\"seed\"]` (reproducibilidad).\n",
    "- El nombre de la carpeta de salida codifica preset, m√©todo y meta (ver `src/runner.py`).\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "\n",
    "- [1) Setup del entorno y paths](#sec-01)\n",
    "- [2) Carga del preset unificado (`configs/presets.yaml`)](#sec-02)\n",
    "- [3) Verificaci√≥n de datos y selecci√≥n de `tasks.json`](#sec-03)\n",
    "- [4) Factory de DataLoaders (H5 offline o CSV + runtime encode)](#sec-04)\n",
    "- [5) Factory del modelo](#sec-05)\n",
    "- [6) (Opcional) Parche: imprimir *it/s* por √©poca](#sec-06)\n",
    "- [7) Ejecuci√≥n base con el preset (eco de config + run)](#sec-07)\n",
    "- [8) Comparativa de m√©todos (mismo preset/semilla/datos)](#sec-08)\n",
    "- [9) Barrido de combinaciones (opcional)](#sec-09)\n",
    "- [10) Resumen completo: inventario ‚Üí parseo ‚Üí agregados ‚Üí tabla](#sec-10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668cb21",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "\n",
    "## 1) Setup del entorno y paths\n",
    "\n",
    "**Objetivo:** preparar el entorno de ejecuci√≥n con granularidad de hilos, selecci√≥n de dispositivo y rutas del proyecto.\n",
    "\n",
    "- Fija variables de entorno para limitar hilos BLAS (reproducibilidad y evitar oversubscription).\n",
    "- Detecta `ROOT` (ra√≠z del repo) y lo a√±ade a `sys.path`.\n",
    "- Importa utilidades del proyecto (datasets, modelos, presets).\n",
    "- Selecciona dispositivo (`cuda` si est√° disponible).\n",
    "- Activa optimizaciones de PyTorch (TF32/cuDNN) para acelerar entrenamiento en GPU.\n",
    "\n",
    "> **Nota:** No se leen presets aqu√≠ todav√≠a; √∫nicamente se configura el runtime global.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup de entorno (threads, paths, dispositivo)\n",
    "# =============================================================================\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "# Ra√≠z del repo y sys.path\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Librer√≠as del proyecto\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import build_model, default_tfm_for_model\n",
    "from src.utils import load_preset\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Ajustes de rendimiento (opcional)\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851cb55",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "\n",
    "## 2) Carga del preset unificado (`configs/presets.yaml`)\n",
    "\n",
    "**Objetivo:** cargar un *preset* y derivar toda la configuraci√≥n de trabajo.\n",
    "\n",
    "Contenido:\n",
    "- Lee el preset (`PRESET = \"fast\" | \"std\" | \"accurate\"`).\n",
    "- Construye el `ImageTransform` seg√∫n el modelo del preset.\n",
    "- Extrae par√°metros de **datos/codificaci√≥n temporal** (`ENCODER`, `T`, `GAIN`, `SEED`).\n",
    "- Extrae configuraci√≥n del **DataLoader** (workers, prefetch, pin/persistent).\n",
    "- Prepara *augment* opcional (`AUG_CFG`) y **balanceo online** (si procede).\n",
    "- Guardarra√≠l: proh√≠be usar a la vez `use_offline_spikes=True` y `encode_runtime=True`.\n",
    "\n",
    "> **Consejo:** cambia el valor de `PRESET` aqu√≠ para barrer configuraciones sin tocar c√≥digo en m√°s sitios.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232708c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Config global: presets.yaml\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.utils import load_preset\n",
    "\n",
    "PRESET = \"fast\"  # cambia aqu√≠ el preset a usar: fast | std | accurate\n",
    "\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# ---- Modelo / Transform ------------------------------------------------------\n",
    "MODEL_NAME = CFG[\"model\"][\"name\"]\n",
    "tfm = ImageTransform(\n",
    "    CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"],\n",
    "    to_gray=bool(CFG[\"model\"][\"to_gray\"]),\n",
    "    crop_top=None\n",
    ")\n",
    "\n",
    "# ---- Datos / codificaci√≥n temporal ------------------------------------------\n",
    "ENCODER  = CFG[\"data\"][\"encoder\"]\n",
    "T        = int(CFG[\"data\"][\"T\"])\n",
    "GAIN     = float(CFG[\"data\"][\"gain\"])\n",
    "SEED     = int(CFG[\"data\"][\"seed\"])\n",
    "\n",
    "USE_OFFLINE_SPIKES   = bool(CFG[\"data\"][\"use_offline_spikes\"])\n",
    "USE_OFFLINE_BALANCED = bool(CFG[\"data\"][\"use_offline_balanced\"])\n",
    "RUNTIME_ENCODE       = bool(CFG[\"data\"][\"encode_runtime\"])   # == runtime_encode\n",
    "\n",
    "# ---- DataLoader / augment / balanceo ----------------------------------------\n",
    "NUM_WORKERS = int(CFG[\"data\"][\"num_workers\"])\n",
    "PREFETCH    = CFG[\"data\"][\"prefetch_factor\"]\n",
    "PIN_MEMORY  = bool(CFG[\"data\"][\"pin_memory\"])\n",
    "PERSISTENT  = bool(CFG[\"data\"][\"persistent_workers\"])\n",
    "\n",
    "AUG_CFG = AugmentConfig(**CFG[\"data\"][\"aug_train\"]) if CFG[\"data\"][\"aug_train\"] else None\n",
    "\n",
    "USE_ONLINE_BALANCING = bool(CFG[\"data\"][\"balance_online\"])\n",
    "BAL_BINS             = int(CFG[\"data\"][\"balance_bins\"])\n",
    "BAL_EPS              = float(CFG[\"data\"][\"balance_smooth_eps\"])\n",
    "\n",
    "# Guardarra√≠les\n",
    "if USE_OFFLINE_SPIKES and RUNTIME_ENCODE:\n",
    "    raise RuntimeError(\"Config inv√°lida: use_offline_spikes=True y encode_runtime=True a la vez.\")\n",
    "\n",
    "print(f\"[PRESET={PRESET}] model={MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] encoder={ENCODER} T={T} gain={GAIN} seed={SEED}\")\n",
    "print(f\"[LOADER] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "print(f\"[BALANCE] offline={USE_OFFLINE_BALANCED} online={USE_ONLINE_BALANCING} bins={BAL_BINS}\")\n",
    "print(f\"[RUNTIME_ENCODE] {RUNTIME_ENCODE} | [OFFLINE_SPIKES] {USE_OFFLINE_SPIKES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5de0d",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "\n",
    "## 3) Verificaci√≥n de datasets y selecci√≥n de `tasks.json`\n",
    "\n",
    "Comprueba que existen los CSV de `train/val/test` por tarea, y (si corresponde)\n",
    "que `train_balanced.csv` est√° disponible para el modo **offline balanceado**.\n",
    "\n",
    "- Lee `tasks_balanced.json` si `USE_OFFLINE_BALANCED=True`; si faltan, cae a `tasks.json`.\n",
    "- Construye `task_list` con rutas por split.\n",
    "\n",
    "> *Salida esperada:* listado de tareas y su CSV de `train`. Mensaje de OK/aviso.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c673a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Verificaci√≥n de datos (splits y, si procede, H5)\n",
    "# =============================================================================\n",
    "PROC = ROOT/\"data\"/\"processed\"\n",
    "TASKS_FILE = PROC / (\"tasks_balanced.json\" if USE_OFFLINE_BALANCED else \"tasks.json\")\n",
    "with open(TASKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "print(\"Tareas y TRAIN CSV a usar:\")\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {Path(t['paths']['train']).name}\")\n",
    "\n",
    "if USE_OFFLINE_BALANCED:\n",
    "    missing = []\n",
    "    for t in task_list:\n",
    "        p = Path(t[\"paths\"][\"train\"])\n",
    "        if p.name != \"train_balanced.csv\" or not p.exists():\n",
    "            missing.append(str(p))\n",
    "    if missing:\n",
    "        print(\"[WARN] Faltan balanceados:\", missing, \" ‚Üí usando tasks.json (no balanceado).\")\n",
    "        USE_OFFLINE_BALANCED = False\n",
    "        with open(PROC/\"tasks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            tasks_json = json.load(f)\n",
    "        task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "print(\"OK: verificaci√≥n de splits.\")\n",
    "\n",
    "print(f\"Preset en uso: {PRESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926bb4b",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "\n",
    "## 4) Factory de DataLoaders (offline H5 o CSV + encode en runtime)\n",
    "\n",
    "Construye un **builder** unificado de loaders:\n",
    "\n",
    "- `_raw_make_loader_fn` decide entre H5 offline o CSV seg√∫n flags.\n",
    "- `make_loader_fn(...)` es un **wrapper pass-through**: recibe par√°metros del runner y\n",
    "  **propaga** kwargs de DataLoader (workers, prefetch, pin_memory, persistent, augment, balanceo).\n",
    "\n",
    "> Usa este `make_loader_fn` en el runner para no duplicar l√≥gica en el notebook.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Factory de loaders (elige H5 offline o CSV + runtime encode) + pass-through de kwargs\n",
    "# =============================================================================\n",
    "from src.utils import build_make_loader_fn\n",
    "\n",
    "_raw_make_loader_fn = build_make_loader_fn(\n",
    "    root=ROOT,\n",
    "    use_offline_spikes=USE_OFFLINE_SPIKES,\n",
    "    runtime_encode=RUNTIME_ENCODE,\n",
    ")\n",
    "\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed, **dl_kwargs):\n",
    "    \"\"\"Wrapper que solo pasa los kwargs al factory real (runner le a√±ade dl_kwargs).\"\"\"\n",
    "    return _raw_make_loader_fn(\n",
    "        task=task, batch_size=batch_size, encoder=encoder, T=T, gain=gain, tfm=tfm, seed=seed,\n",
    "        **dl_kwargs\n",
    "    )\n",
    "\n",
    "print(\"make_loader_fn listo (pass-through de kwargs del runner).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68671c4d",
   "metadata": {},
   "source": [
    "<a id=\"sec-05\"></a>\n",
    "\n",
    "## 5) Factory del modelo\n",
    "\n",
    "Devuelve el modelo seg√∫n el nombre del preset (`MODEL_NAME`).\n",
    "\n",
    "- Si es `pilotnet_snn`, aplica hiperpar√°metros de neurona (`beta`, `threshold`).\n",
    "- Para otros modelos, estos kwargs se ignoran.\n",
    "\n",
    "> *Salida esperada:* impresi√≥n del nombre del modelo elegido.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efae5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Construcci√≥n del modelo (factory)\n",
    "# =============================================================================\n",
    "def make_model_fn(tfm):\n",
    "    \"\"\"\n",
    "    Devuelve el modelo con los hyperpar√°metros de neuronas (beta/threshold).\n",
    "    Para 'pilotnet_snn' estos kwargs aplican; para otros modelos se ignoran.\n",
    "    \"\"\"\n",
    "    return build_model(MODEL_NAME, tfm, beta=0.9, threshold=0.5)\n",
    "\n",
    "print(\"Modelo:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a07afb",
   "metadata": {},
   "source": [
    "<a id=\"sec-06\"></a>\n",
    "\n",
    "## 6) (Opcional) Parche: imprimir iteraciones/segundo por √©poca\n",
    "\n",
    "Sobrescribe temporalmente `training.train_supervised` para:\n",
    "\n",
    "- Medir **it/s** por √©poca (√∫til para benchmarks de rendimiento).\n",
    "- Mantener el resto del entrenamiento sin cambios funcionales.\n",
    "\n",
    "> Para restaurar el comportamiento original: `training.train_supervised = orig_train_supervised`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ecabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# (Opcional) Parche: it/s + Early Stopping (controlado por preset)\n",
    "# =============================================================================\n",
    "import time, json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "import src.training as training\n",
    "from src.utils import set_seeds\n",
    "\n",
    "orig_train_supervised = training.train_supervised  # backup\n",
    "\n",
    "def train_supervised_ips_es(model: nn.Module, train_loader, val_loader, loss_fn: nn.Module,\n",
    "                            cfg, out_dir: Path, method=None):\n",
    "    \"\"\"\n",
    "    it/s + Early Stopping:\n",
    "      - Activo si cfg.es_patience y cfg.es_min_delta no son None.\n",
    "      - Criterio: min val_loss con tolerancia es_min_delta.\n",
    "    Escribe manifest.json con 'history' y 'early_stop_epoch' (si aplica).\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if cfg.seed is not None:\n",
    "        set_seeds(cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "    use_amp = bool(cfg.amp and torch.cuda.is_available())\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "    # ES params (le√≠dos del preset)\n",
    "    patience = getattr(cfg, \"es_patience\", None)\n",
    "    min_delta = getattr(cfg, \"es_min_delta\", None)\n",
    "    use_es = (patience is not None) and (min_delta is not None)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    wait = 0\n",
    "    early_stop_epoch = None\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        # -------- train --------\n",
    "        model.train()\n",
    "        running = 0.0; nb = 0\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast(\"cuda\", enabled=use_amp):\n",
    "                y_hat = model(x)\n",
    "                loss = loss_fn(y_hat, y)\n",
    "                if method is not None:\n",
    "                    loss = loss + method.penalty()\n",
    "\n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(opt); scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                opt.step()\n",
    "\n",
    "            running += loss.item(); nb += 1\n",
    "\n",
    "        dt = time.perf_counter() - t0\n",
    "        ips = nb / dt if dt > 0 else float(\"nan\")\n",
    "        print(f\"[TRAIN it/s] epoch {epoch}/{cfg.epochs}: {ips:.1f} it/s  ({nb} iters en {dt:.2f}s)\")\n",
    "        train_loss = running / max(1, nb)\n",
    "\n",
    "        # -------- val --------\n",
    "        model.eval()\n",
    "        v_running = 0.0; nvb = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x = training._permute_if_needed(x).to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                with autocast(\"cuda\", enabled=use_amp):\n",
    "                    y_hat = model(x)\n",
    "                    v_loss = loss_fn(y_hat, y)\n",
    "                v_running += v_loss.item(); nvb += 1\n",
    "        val_loss = v_running / max(1, nvb)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        # -------- Early Stopping check --------\n",
    "        if use_es:\n",
    "            improved = (best_val - val_loss) > float(min_delta)\n",
    "            if improved:\n",
    "                best_val = val_loss\n",
    "                wait = 0\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= int(patience):\n",
    "                    early_stop_epoch = epoch\n",
    "                    print(f\"[EarlyStopping] Stop en epoch={epoch} (best_val={best_val:.6f})\")\n",
    "                    break\n",
    "\n",
    "    manifest = {\n",
    "        \"epochs\": cfg.epochs, \"batch_size\": cfg.batch_size, \"lr\": cfg.lr,\n",
    "        \"amp\": cfg.amp, \"seed\": cfg.seed, \"history\": history,\n",
    "        \"early_stop_epoch\": early_stop_epoch,\n",
    "    }\n",
    "    (out_dir / \"manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    return history\n",
    "\n",
    "training.train_supervised = train_supervised_ips_es\n",
    "print(\"Parche it/s + EarlyStopping ACTIVADO. Para desactivarlo: training.train_supervised = orig_train_supervised\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bdd076",
   "metadata": {},
   "source": [
    "<a id=\"sec-07\"></a>\n",
    "\n",
    "## 7) Ejecuci√≥n base con el preset (eco de config + run)\n",
    "\n",
    "Lanza **un experimento** con el m√©todo y par√°metros definidos en el preset (`CFG[\"continual\"]`).  \n",
    "Se imprimen los campos m√°s relevantes (modelo, datos, loader) y se guarda la salida en `outputs/continual_*`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Ejecuci√≥n base con el preset (eco de config + run)\n",
    "# =============================================================================\n",
    "from src.runner import run_continual\n",
    "\n",
    "# Echo de configuraci√≥n ‚Äúresumido‚Äù (lo esencial para el run)\n",
    "print(f\"[RUN] preset={PRESET} | method={CFG['continual']['method']} \"\n",
    "      f\"| seed={CFG['data']['seed']} | enc={CFG['data']['encoder']} \"\n",
    "      f\"| kwargs={CFG['continual'].get('params', {})}\")\n",
    "print(f\"[MODEL] {MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] T={CFG['data']['T']} gain={CFG['data']['gain']} \"\n",
    "      f\"| offline_spikes={CFG['data']['use_offline_spikes']} \"\n",
    "      f\"| runtime_encode={CFG['data']['encode_runtime']}\")\n",
    "print(f\"[LOADER] workers={CFG['data']['num_workers']} \"\n",
    "      f\"prefetch={CFG['data']['prefetch_factor']} pin={CFG['data']['pin_memory']} \"\n",
    "      f\"persistent={CFG['data']['persistent_workers']} \"\n",
    "      f\"| aug={bool(CFG['data']['aug_train'])} \"\n",
    "      f\"| balance_online={CFG['data']['balance_online']}\")\n",
    "\n",
    "out_path, _ = run_continual(\n",
    "    task_list=task_list,\n",
    "    make_loader_fn=make_loader_fn,   # wrapper (Celda 4)\n",
    "    make_model_fn=make_model_fn,     # factory (Celda 5)\n",
    "    tfm=tfm,\n",
    "    cfg=CFG,                         # preset completo\n",
    "    preset_name=PRESET,              # solo naming\n",
    "    out_root=ROOT / \"outputs\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"OK:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f15dc1",
   "metadata": {},
   "source": [
    "<a id=\"sec-08\"></a>\n",
    "\n",
    "## 8) Comparativa de m√©todos (mismo preset / misma semilla / mismos datos)\n",
    "\n",
    "Esta celda ejecuta varias corridas cambiando **√∫nicamente** el m√©todo de aprendizaje\n",
    "continual, manteniendo fijos el `preset` cargado en la Celda 2 (modelo, loader, AMP,\n",
    "LR, epochs, T, gain, tama√±o de imagen, etc.).\n",
    "\n",
    "- Usa `CFG` tal cual (ya trae `continual.method`/`params`, `data.encoder`, `data.seed`, etc.).\n",
    "- Para cada m√©todo, se clona `CFG` y se sobreescriben **solo** `continual.method` y `continual.params`.\n",
    "- Los resultados se escriben en `outputs/continual_<preset>_<tag>_<encoder>_model-..._seed_<seed>/continual_results.json`.\n",
    "- Despu√©s, usa las Celdas 10‚Äì13 para generar el resumen y el CSV de agregados.\n",
    "\n",
    "**Requisitos**:\n",
    "- Si usas *offline spikes*, aseg√∫rate de que existen H5 compatibles con el preset:\n",
    "  encoder/T/gain/size/to_gray. Si no, el loader emitir√° un `FileNotFoundError`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f64d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === COMPARATIVA DE M√âTODOS: mismo preset, misma semilla, mismos datos ===\n",
    "from copy import deepcopy\n",
    "from src.runner import run_continual\n",
    "\n",
    "# 1) Base de configuraci√≥n: la CFG ya cargada en Celda 2\n",
    "CFG_BASE = deepcopy(CFG)  # opcionalmente, fija aqu√≠ la semilla com√∫n\n",
    "# CFG_BASE[\"data\"][\"seed\"] = 42\n",
    "\n",
    "# 2) Define los m√©todos a comparar (ajusta hiperpar√°metros a tu gusto)\n",
    "METHODS = {\n",
    "    \"naive\": {},\n",
    "    \"ewc\": {\"lam\": 7e8, \"fisher_batches\": 800},\n",
    "    \"rehearsal\": {\"buffer_size\": 5000, \"replay_ratio\": 0.2},\n",
    "    \"rehearsal+ewc\": {\"buffer_size\": 5000, \"replay_ratio\": 0.2, \"lam\": 7e8, \"fisher_batches\": 800},\n",
    "}\n",
    "\n",
    "runs_out = []\n",
    "for method_name, method_params in METHODS.items():\n",
    "    cfg_i = deepcopy(CFG_BASE)\n",
    "    cfg_i[\"continual\"][\"method\"] = method_name\n",
    "    cfg_i[\"continual\"][\"params\"] = method_params\n",
    "\n",
    "    print(\n",
    "        f\"\\n=== RUN: preset={PRESET} | method={method_name} | \"\n",
    "        f\"seed={cfg_i['data']['seed']} | enc={cfg_i['data']['encoder']} | kwargs={method_params} ===\"\n",
    "    )\n",
    "\n",
    "    out_dir, _ = run_continual(\n",
    "        task_list=task_list,\n",
    "        make_loader_fn=make_loader_fn,  # wrapper pass-through definido en Celda 4\n",
    "        make_model_fn=make_model_fn,\n",
    "        tfm=tfm,\n",
    "        cfg=cfg_i,                      # configuraci√≥n completa del preset con el m√©todo cambiado\n",
    "        preset_name=PRESET,             # solo para naming de la carpeta de salida\n",
    "        out_root=ROOT / \"outputs\",\n",
    "        verbose=True,\n",
    "    )\n",
    "    runs_out.append(out_dir)\n",
    "\n",
    "print(\"\\nHecho:\", [str(p) for p in runs_out])\n",
    "print(\"Ahora ejecuta las Celdas 10‚Äì13 para ver el resumen y comparativas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e604e8",
   "metadata": {},
   "source": [
    "<a id=\"sec-09\"></a>\n",
    "\n",
    "## 9) Barrido de combinaciones (opcional)\n",
    "\n",
    "Driver gen√©rico para explorar:\n",
    "\n",
    "- `presets √ó seeds √ó encoders √ó m√©todos`.\n",
    "\n",
    "√ötil para estudios m√°s amplios (coste alto).  \n",
    "Asegura H5 compatibles si usas modo offline; controla carga (workers/prefetch) si la GPU va justa.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Driver de ejecuci√≥n: barrido de combinaciones (opcional)\n",
    "# =============================================================================\n",
    "from copy import deepcopy\n",
    "from src.runner import run_continual\n",
    "\n",
    "PRESETS   = [PRESET]  # puedes a√±adir \"std\", \"accurate\", etc.\n",
    "SEEDS     = [CFG[\"data\"][\"seed\"], 43]\n",
    "ENCODERS  = [CFG[\"data\"][\"encoder\"]]  # ej. [\"rate\", \"latency\"]\n",
    "METHODS   = [\n",
    "    (\"naive\", {}),\n",
    "    (\"ewc\", {\"lam\": 1e9, \"fisher_batches\": 600}),\n",
    "    # (\"rehearsal\", {\"buffer_size\": 5000, \"replay_ratio\": 0.2}),\n",
    "    # (\"rehearsal+ewc\", {\"buffer_size\": 5000, \"replay_ratio\": 0.2, \"lam\": 7e8, \"fisher_batches\": 600}),\n",
    "]\n",
    "\n",
    "for preset_i in PRESETS:\n",
    "    for seed_i in SEEDS:\n",
    "        for enc_i in ENCODERS:\n",
    "            for method_name, method_params in METHODS:\n",
    "                cfg_i = deepcopy(CFG)\n",
    "                cfg_i[\"data\"][\"seed\"] = seed_i\n",
    "                cfg_i[\"data\"][\"encoder\"] = enc_i\n",
    "                cfg_i[\"continual\"][\"method\"] = method_name\n",
    "                cfg_i[\"continual\"][\"params\"] = method_params\n",
    "\n",
    "                print(\n",
    "                    f\"\\n=== RUN: preset={preset_i} | method={method_name} \"\n",
    "                    f\"| seed={seed_i} | enc={enc_i} | kwargs={method_params} ===\"\n",
    "                )\n",
    "                out_path, _ = run_continual(\n",
    "                    task_list=task_list,\n",
    "                    make_loader_fn=make_loader_fn,   # mismo factory si no cambias offline/runtime\n",
    "                    make_model_fn=make_model_fn,\n",
    "                    tfm=tfm,\n",
    "                    cfg=cfg_i,\n",
    "                    preset_name=preset_i,\n",
    "                    out_root=ROOT / \"outputs\",\n",
    "                    verbose=True,\n",
    "                )\n",
    "                print(\"OK:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0650365",
   "metadata": {},
   "source": [
    "<a id=\"sec-10\"></a>\n",
    "\n",
    "## 10) Resumen completo: inventario ‚Üí parseo ‚Üí agregados ‚Üí tabla\n",
    "\n",
    "- **Inventario** de runs en `outputs/continual_*`.  \n",
    "- **Parseo** del nombre de las carpetas para extraer `preset`, `m√©todo`, `Œª`, `encoder`, `seed`, `modelo`.  \n",
    "- **C√°lculo de olvido**: diferencia absoluta y relativa de T1 tras T2.  \n",
    "- **Agregados** por grupo (media/œÉ/n) y export a `outputs/summary/continual_summary_agg.csv`.  \n",
    "- **Tabla formateada** con m√©tricas clave y desviaciones.\n",
    "\n",
    "> Si no aparece nada, revisa que existan `continual_results.json` en las carpetas de salida.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## === 10) Resumen completo: inventario ‚Üí parseo ‚Üí agregados ‚Üí tabla ===\n",
    "import re, json, pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "ALLOWED_ENC = r\"(rate|latency|raw|image)\"\n",
    "\n",
    "def parse_exp_name(name: str):\n",
    "    \"\"\"continual_<preset>_<tag>_<encoder>[_model-<model>]?_seed_<seed>?\"\"\"\n",
    "    pat = re.compile(\n",
    "        rf\"^continual_(?P<preset>[^_]+)_(?P<tag>.+)_(?P<enc>{ALLOWED_ENC})\"\n",
    "        rf\"(?:_model\\-(?P<model>.+?))?(?:_seed_(?P<seed>\\d+))?$\"\n",
    "    )\n",
    "    m = pat.match(name)\n",
    "    meta = {\"preset\": None, \"method\": None, \"lambda\": None, \"encoder\": None, \"seed\": None, \"model\": None}\n",
    "    if not m:\n",
    "        return meta\n",
    "    preset = m.group(\"preset\"); tag = m.group(\"tag\"); enc = m.group(\"enc\")\n",
    "    seed = m.group(\"seed\"); model = m.group(\"model\")\n",
    "    lam = None; mlam = re.search(r\"_lam_([^_]+)\", tag)\n",
    "    if mlam:\n",
    "        lam = mlam.group(1)\n",
    "        method = tag.replace(f\"_lam_{lam}\", \"\")\n",
    "    else:\n",
    "        method = tag\n",
    "    meta.update({\"preset\": preset, \"method\": method, \"lambda\": lam, \"encoder\": enc,\n",
    "                 \"seed\": int(seed) if seed is not None else None, \"model\": model})\n",
    "    return meta\n",
    "\n",
    "def build_runs_df(outputs_root: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for exp_dir in sorted((outputs_root).glob(\"continual_*\")):\n",
    "        name = exp_dir.name\n",
    "        meta = parse_exp_name(name)\n",
    "        if meta[\"preset\"] is None:\n",
    "            continue\n",
    "        results_path = exp_dir / \"continual_results.json\"\n",
    "        if not results_path.exists():\n",
    "            continue\n",
    "        with open(results_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            res = json.load(f)\n",
    "\n",
    "        task_names = list(res.keys())\n",
    "        if len(task_names) < 2:\n",
    "            continue  # con 1 tarea no hay after_*\n",
    "\n",
    "        def is_last(d: dict) -> bool:\n",
    "            return not any(k.startswith(\"after_\") for k in d.keys())\n",
    "\n",
    "        last_task = None; first_task = None\n",
    "        for tn in task_names:\n",
    "            if is_last(res[tn]): last_task = tn\n",
    "            else: first_task = tn\n",
    "        if first_task is None or last_task is None:\n",
    "            task_names_sorted = sorted(task_names)\n",
    "            first_task = task_names_sorted[0]; last_task = task_names_sorted[-1]\n",
    "\n",
    "        c1, c2 = first_task, last_task\n",
    "        c1_test_mae = float(res[c1].get(\"test_mae\", float(\"nan\")))\n",
    "        c2_test_mae = float(res[c2].get(\"test_mae\", float(\"nan\")))\n",
    "        after_key_mae = f\"after_{c2}_mae\"\n",
    "        c1_after_c2_mae = float(res[c1].get(after_key_mae, float(\"nan\")))\n",
    "        forgetting_abs = c1_after_c2_mae - c1_test_mae\n",
    "        forgetting_rel = (forgetting_abs / c1_test_mae * 100.0) if c1_test_mae == c1_test_mae else float(\"nan\")\n",
    "\n",
    "        rows.append({\n",
    "            \"exp\": name, \"preset\": meta[\"preset\"], \"method\": meta[\"method\"], \"lambda\": meta[\"lambda\"],\n",
    "            \"encoder\": meta[\"encoder\"], \"model\": meta[\"model\"], \"seed\": meta[\"seed\"],\n",
    "            \"c1_name\": c1, \"c2_name\": c2,\n",
    "            \"c1_mae\": c1_test_mae, \"c1_after_c2_mae\": c1_after_c2_mae,\n",
    "            \"c1_forgetting_mae_abs\": forgetting_abs, \"c1_forgetting_mae_rel_%\": forgetting_rel,\n",
    "            \"c2_mae\": c2_test_mae,\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df[\"lambda_num\"] = pd.to_numeric(df[\"lambda\"], errors=\"coerce\")\n",
    "    df[\"seed\"] = pd.to_numeric(df[\"seed\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df = df.sort_values(by=[\"preset\", \"method\", \"encoder\", \"model\", \"lambda_num\", \"seed\"],\n",
    "                        na_position=\"last\", ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def aggregate_and_show(df: pd.DataFrame, outputs_root: Path):\n",
    "    if df.empty:\n",
    "        print(\"No hay filas (¬øno existen JSONs o solo hubo 1 tarea por run?).\")\n",
    "        return\n",
    "    # Vista detalle\n",
    "    display(df[[\n",
    "        \"exp\",\"preset\",\"method\",\"lambda\",\"encoder\",\"model\",\"seed\",\n",
    "        \"c1_name\",\"c2_name\",\"c1_mae\",\"c1_after_c2_mae\",\n",
    "        \"c1_forgetting_mae_abs\",\"c1_forgetting_mae_rel_%\",\"c2_mae\",\"lambda_num\"\n",
    "    ]])\n",
    "\n",
    "    # Agregados\n",
    "    cols_metrics = [\"c1_mae\", \"c1_after_c2_mae\", \"c1_forgetting_mae_abs\", \"c1_forgetting_mae_rel_%\", \"c2_mae\"]\n",
    "    gdf = df.copy()\n",
    "    if \"lambda_num\" not in gdf.columns:\n",
    "        gdf[\"lambda_num\"] = pd.to_numeric(gdf[\"lambda\"], errors=\"coerce\")\n",
    "    agg = (gdf\n",
    "           .groupby([\"preset\", \"method\", \"encoder\", \"lambda\", \"lambda_num\"], dropna=False)[cols_metrics]\n",
    "           .agg([\"mean\", \"std\", \"count\"])\n",
    "           .reset_index())\n",
    "    agg.columns = [\"_\".join(filter(None, map(str, col))).rstrip(\"_\") for col in agg.columns.to_flat_index()]\n",
    "    agg = agg.sort_values(by=[\"preset\", \"method\", \"encoder\", \"lambda_num\"], na_position=\"last\", ignore_index=True)\n",
    "\n",
    "    # Persistencia y vista bonita\n",
    "    summary_dir = outputs_root / \"summary\"\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_csv = summary_dir / \"continual_summary_agg.csv\"\n",
    "    agg.to_csv(out_csv, index=False)\n",
    "    print(\"Guardado:\", out_csv)\n",
    "\n",
    "    def fmt(x, prec=4):\n",
    "        return \"\" if pd.isna(x) else f\"{x:.{prec}f}\"\n",
    "\n",
    "    show = agg.copy()\n",
    "    count_cols = [c for c in show.columns if c.endswith(\"_count\")]\n",
    "    if count_cols:\n",
    "        show[\"count\"] = show[count_cols[0]].astype(\"Int64\")\n",
    "        show = show.drop(columns=count_cols)\n",
    "    for c in [c for c in show.columns if c.endswith(\"_mean\") or c.endswith(\"_std\")]:\n",
    "        show[c] = show[c].map(lambda v: fmt(v, 4))\n",
    "    cols = [\n",
    "        \"preset\", \"method\", \"encoder\", \"lambda\",\n",
    "        \"c1_mae_mean\", \"c1_forgetting_mae_rel_%_mean\", \"c2_mae_mean\",\n",
    "        \"c1_mae_std\",  \"c1_forgetting_mae_rel_%_std\",  \"c2_mae_std\",\n",
    "        \"count\"\n",
    "    ]\n",
    "    cols = [c for c in cols if c in show.columns]\n",
    "    show = show[cols].rename(columns={\n",
    "        \"preset\": \"preset\", \"method\": \"m√©todo\", \"encoder\": \"codificador\", \"lambda\": \"Œª\",\n",
    "        \"c1_mae_mean\": \"MAE Tarea1 (media)\",\n",
    "        \"c1_forgetting_mae_rel_%_mean\": \"Olvido T1 (%) (media)\",\n",
    "        \"c2_mae_mean\": \"MAE Tarea2 (media)\",\n",
    "        \"c1_mae_std\": \"MAE Tarea1 (œÉ)\",\n",
    "        \"c1_forgetting_mae_rel_%_std\": \"Olvido T1 (%) (œÉ)\",\n",
    "        \"c2_mae_std\": \"MAE Tarea2 (œÉ)\",\n",
    "        \"count\": \"n (semillas)\"\n",
    "    })\n",
    "    display(show)\n",
    "\n",
    "# Ejecuta el resumen\n",
    "outputs_root = ROOT / \"outputs\"\n",
    "print(\"Inventario de runs en:\", outputs_root)\n",
    "for p in sorted(outputs_root.glob(\"continual_*\")):\n",
    "    print(\" -\", p.name, \"| results.json:\", (p / \"continual_results.json\").exists())\n",
    "\n",
    "df = build_runs_df(outputs_root)\n",
    "print(f\"runs en resumen: {len(df)}\")\n",
    "aggregate_and_show(df, outputs_root)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
