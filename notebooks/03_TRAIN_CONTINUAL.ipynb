{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c448d5",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# 03_TRAIN_CONTINUAL ‚Äî Entrenamiento Continual con **presets**\n",
    "\n",
    "**Qu√© hace este notebook:**\n",
    "- Lanza un **run base** con el m√©todo del preset (`configs/presets.yaml`).\n",
    "- Ejecuta **lotes comparativos** (misma semilla/datos/modelo; cambia solo el m√©todo y sus `params`).\n",
    "- Ofrece un **barrido param√©trico opcional** (grid/variantes).\n",
    "- **Reeval√∫a** runs existentes cuando falta/est√° incompleta `eval_matrix.json`.\n",
    "- Genera **res√∫menes y gr√°ficas** en `outputs/summary/` usando `src/plots.py`.\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "1. Haber generado `data/processed/tasks.json` (y opcional `tasks_balanced.json`) con `01_DATA_QC_PREP` o `01A_PREP_BALANCED`.\n",
    "2. Si el preset usa **offline** (`use_offline_spikes: true`), haber creado los **H5 v2** con `02_ENCODE_OFFLINE` para el mismo `encoder/T/gain/size/to_gray`.\n",
    "\n",
    "## ‚ö†Ô∏è Notas\n",
    "- No mezcles `use_offline_spikes: true` **y** `encode_runtime: true`. El cuaderno aborta si detecta conflicto.\n",
    "- La carpeta de salida codifica `preset`, `m√©todo`, `encoder`, `modelo`, `seed`, etc. (trazabilidad).\n",
    "- Para gr√°ficas y tablas, se utilizan utilidades centralizadas de `src/plots.py`.\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "## üß≠ √çndice\n",
    "1. [Setup del entorno y paths](#sec-01) \n",
    "2. [Carga del preset y guardarra√≠l datos](#sec-02) \n",
    "3. [Selecci√≥n de *tasks* y verificaci√≥n de datos/H5](#sec-03) \n",
    "4. [Factories unificadas: DataLoaders + Modelo + *task_list*](#sec-04)\n",
    "5. [Ejecuci√≥n base con el preset](#sec-05)\n",
    "6. [Comparativa de m√©todos (lista cerrada)](#sec-06)\n",
    "7. [Barrido param√©trico (opcional)](#sec-07)\n",
    "8. [Reevaluaci√≥n de runs (eval_matrix) ‚Äî **firma nueva**](#sec-08)\n",
    "9. [Resumen + gr√°ficas (tablas, leaderboards, plots)](#sec-09)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668cb21",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "## 1) Setup del entorno y paths\n",
    "\n",
    "**Objetivo:** preparar entorno (ROOT, `sys.path`, device), fijar *hints* de rendimiento e inicializar carpeta de salidas `outputs/`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1) Setup del entorno y paths\n",
    "# =============================================================================\n",
    "import os, sys, torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Consejos de estabilidad (WSL/HDF5/CUDA)\n",
    "os.environ.setdefault(\"HDF5_USE_FILE_LOCKING\", \"FALSE\")\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True,max_split_size_mb:64\")\n",
    "os.environ[\"TRAIN_LOG_ITPS\"] = os.environ.get(\"TRAIN_LOG_ITPS\", \"1\")\n",
    "\n",
    "try:\n",
    "    import torch.multiprocessing as mp\n",
    "    mp.set_sharing_strategy(\"file_system\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "OUT = ROOT / \"outputs\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"OUT :\", OUT)\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851cb55",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "## 2) Carga del preset y guardarra√≠l datos\n",
    "\n",
    "**Objetivo:** cargar `PRESET` desde `configs/presets.yaml` y derivar:\n",
    "- Modelo/transform (`img_w/img_h`, `to_gray`).\n",
    "- Datos/codificaci√≥n (`encoder`, `T`, `gain`, `seed`).\n",
    "- Loader (`num_workers`, `prefetch_factor`, `pin_memory`, `persistent_workers`).\n",
    "- *Augment* y balanceo **online** si procede.\n",
    "- **Guardarra√≠l**: aborta si `use_offline_spikes` y `encode_runtime` est√°n ambos a `true`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232708c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2) Carga del preset (configs/presets.yaml)\n",
    "# =============================================================================\n",
    "from src.config import load_preset\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "\n",
    "PRESET = \"fast\"  # \"fast\" para pruebas, \"std\" estable, \"accurate\" para resultados\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# ---- Modelo / Transform ----\n",
    "MODEL_NAME = CFG[\"model\"][\"name\"]\n",
    "tfm = ImageTransform(\n",
    "    CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"],\n",
    "    to_gray=bool(CFG[\"model\"][\"to_gray\"]),\n",
    "    crop_top=None,\n",
    ")\n",
    "\n",
    "# ---- Datos / Codificaci√≥n ----\n",
    "ENCODER = CFG[\"data\"][\"encoder\"]\n",
    "T       = int(CFG[\"data\"][\"T\"])\n",
    "GAIN    = float(CFG[\"data\"][\"gain\"])\n",
    "SEED    = int(CFG[\"data\"][\"seed\"])\n",
    "USE_OFFLINE_SPIKES = bool(CFG[\"data\"].get(\"use_offline_spikes\", False))\n",
    "RUNTIME_ENCODE     = bool(CFG[\"data\"].get(\"encode_runtime\", False))\n",
    "\n",
    "# ---- Loader / Augment / Balanceo online ----\n",
    "NUM_WORKERS = int(CFG[\"data\"].get(\"num_workers\") or 0)\n",
    "PREFETCH    = int(CFG[\"data\"].get(\"prefetch_factor\") or 2)\n",
    "PIN_MEMORY  = bool(CFG[\"data\"].get(\"pin_memory\", True))\n",
    "PERSISTENT  = bool(CFG[\"data\"].get(\"persistent_workers\", True))\n",
    "\n",
    "AUG_CFG = AugmentConfig(**(CFG[\"data\"].get(\"aug_train\") or {})) \\\n",
    "    if CFG[\"data\"].get(\"aug_train\") else None\n",
    "\n",
    "USE_ONLINE_BALANCING = bool(CFG[\"data\"].get(\"balance_online\", False))\n",
    "BAL_BINS = int(CFG[\"data\"].get(\"balance_bins\") or CFG.get(\"prep\", {}).get(\"bins\", 50) or 50)\n",
    "BAL_EPS  = float(CFG[\"data\"].get(\"balance_smooth_eps\") or 1e-3)\n",
    "\n",
    "# Guardarra√≠l de coherencia\n",
    "if USE_OFFLINE_SPIKES and RUNTIME_ENCODE:\n",
    "    raise RuntimeError(\"Config inv√°lida: use_offline_spikes=True y encode_runtime=True simult√°neamente.\")\n",
    "\n",
    "print(f\"[PRESET={PRESET}] model={MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] encoder={ENCODER} T={T} gain={GAIN} seed={SEED}\")\n",
    "print(f\"[LOADER] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "print(f\"[BALANCE] online={USE_ONLINE_BALANCING} bins={BAL_BINS} eps={BAL_EPS}\")\n",
    "print(f\"[RUNTIME_ENCODE] {RUNTIME_ENCODE} | [OFFLINE_SPIKES] {USE_OFFLINE_SPIKES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5de0d",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "## 3) Selecci√≥n de *tasks* y verificaci√≥n de datos/H5\n",
    "\n",
    "**Objetivo:** elegir el fichero de tareas adecuado y comprobar:\n",
    "- Existencia de `train/val/test.csv` por *run*.\n",
    "- Si es **offline**, existencia de H5 v2 compatibles con el preset (`encoder/T/gain/size/to_gray`).\n",
    "\n",
    "Preferencia: `prep.use_balanced_tasks: true` ‚Üí usa `tasks_balanced.json` si existe; si no, `tasks.json`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c673a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3) Verificaci√≥n de datos (splits y, si procede, H5)\n",
    "# =============================================================================\n",
    "import json\n",
    "from pathlib import Path as _P\n",
    "\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "USE_BALANCED = bool(CFG.get(\"prep\", {}).get(\"use_balanced_tasks\", False))\n",
    "tb_name = (CFG.get(\"prep\", {}).get(\"tasks_balanced_file_name\") or \"tasks_balanced.json\")\n",
    "t_name  = (CFG.get(\"prep\", {}).get(\"tasks_file_name\") or \"tasks.json\")\n",
    "\n",
    "cand_bal = PROC / tb_name\n",
    "cand_std = PROC / t_name\n",
    "TASKS_FILE = cand_bal if (USE_BALANCED and cand_bal.exists()) else cand_std\n",
    "\n",
    "tasks_json = json.loads(TASKS_FILE.read_text(encoding=\"utf-8\"))\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "print(\"Usando tasks:\", TASKS_FILE.name)\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {_P(t['paths']['train']).name}\")\n",
    "\n",
    "# Chequeo coherencia balanced\n",
    "if USE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = _P(tasks_json[\"splits\"][t[\"name\"]][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' en modo balanced y encontr√© '{train_path.name}'.\"\n",
    "            )\n",
    "\n",
    "# Chequeo H5 si offline\n",
    "if USE_OFFLINE_SPIKES:\n",
    "    mw, mh = CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"]\n",
    "    color  = \"gray\" if CFG[\"model\"][\"to_gray\"] else \"rgb\"\n",
    "    gain_tag = (GAIN if ENCODER == \"rate\" else 0)\n",
    "    missing = []\n",
    "    for t in task_list:\n",
    "        base = PROC / t[\"name\"]\n",
    "        for split in (\"train\", \"val\", \"test\"):\n",
    "            expected = base / f\"{split}_{ENCODER}_T{T}_gain{gain_tag}_{color}_{mw}x{mh}.h5\"\n",
    "            if not expected.exists():\n",
    "                missing.append(str(expected))\n",
    "    if missing:\n",
    "        print(\"[WARN] Faltan H5 compatibles con el preset. Genera primero con 02_ENCODE_OFFLINE.\")\n",
    "else:\n",
    "    print(\"Modo CSV + codificaci√≥n en runtime (si RUNTIME_ENCODE=True).\")\n",
    "\n",
    "print(\"OK: verificaci√≥n de splits/H5.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926bb4b",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "## 4) Factories unificadas: DataLoaders + Modelo + *task_list*\n",
    "\n",
    "**Objetivo:** construir en **una sola llamada** los componentes coherentes con un `cfg`:\n",
    "- `build_components_for(cfg, ROOT)` ‚Üí `tfm, make_loader_fn, make_model_fn`.\n",
    "- `build_task_list_for(cfg, ROOT)` ‚Üí `task_list` + `tasks_file`.\n",
    "\n",
    "Estas *factories* abstraen si trabajas con **H5 offline** o **CSV+runtime**, as√≠ como *workers/prefetch/pin/persistent*, *augment*, balanceo online, etc.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4) Factories: DataLoaders + Modelo + task_list\n",
    "# =============================================================================\n",
    "from src.utils import build_task_list_for, build_components_for\n",
    "\n",
    "tfm_fac, make_loader_fn, make_model_fn = build_components_for(CFG, ROOT)\n",
    "task_list_fac, tasks_file_used = build_task_list_for(CFG, ROOT)\n",
    "\n",
    "print(\"Tasks file efectivo:\", tasks_file_used.name)\n",
    "print(\"Factories OK (offline/CSV se resuelve internamente).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bdd076",
   "metadata": {},
   "source": [
    "<a id=\"sec-05\"></a>\n",
    "## 5) Ejecuci√≥n base con el preset\n",
    "\n",
    "**Objetivo:** ejecutar **un** experimento con el m√©todo del preset (`CFG[\"continual\"]`).\n",
    "\n",
    "Salida en `outputs/continual_*` con:\n",
    "- `continual_results.json`, `eval_matrix.(json|csv)`, `forgetting_*.json`,\n",
    "- `per_task_perf.(json|csv|v2.csv)`,\n",
    "- `efficiency_summary.json`, `run_row.*`, `method_params.json`‚Ä¶\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5) Ejecuci√≥n base con el preset\n",
    "# =============================================================================\n",
    "from src.runner import run_continual\n",
    "\n",
    "print(\n",
    "    f\"[RUN] preset={PRESET} | method={CFG['continual']['method']} \"\n",
    "    f\"| seed={CFG['data']['seed']} | enc={CFG['data']['encoder']} \"\n",
    "    f\"| kwargs={CFG['continual'].get('params', {})}\"\n",
    ")\n",
    "print(f\"[MODEL] {MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(\n",
    "    f\"[DATA] T={CFG['data']['T']} gain={CFG['data']['gain']} \"\n",
    "    f\"| offline_spikes={CFG['data']['use_offline_spikes']} \"\n",
    "    f\"| runtime_encode={CFG['data']['encode_runtime']}\"\n",
    ")\n",
    "print(\n",
    "    f\"[LOADER] workers={CFG['data']['num_workers']} prefetch={CFG['data']['prefetch_factor']} \"\n",
    "    f\"pin={CFG['data']['pin_memory']} persistent={CFG['data']['persistent_workers']} \"\n",
    "    f\"| aug={bool(CFG['data']['aug_train'])} | balance_online={CFG['data']['balance_online']}\"\n",
    ")\n",
    "\n",
    "out_path_base, _ = run_continual(\n",
    "    task_list=task_list_fac,\n",
    "    make_loader_fn=make_loader_fn,\n",
    "    make_model_fn=make_model_fn,\n",
    "    tfm=tfm_fac,\n",
    "    cfg=CFG,\n",
    "    preset_name=PRESET,\n",
    "    out_root=OUT,\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"OK:\", out_path_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f15dc1",
   "metadata": {},
   "source": [
    "<a id=\"sec-06\"></a>\n",
    "## 6) Comparativa de m√©todos (lista cerrada)\n",
    "\n",
    "**Objetivo:** lanzar **varios m√©todos** cambiando solo `continual.method` y sus `params`, manteniendo fijos datos/modelo/semilla.\n",
    "\n",
    "- Se clona `CFG` por entrada.\n",
    "- **Etiqueta** cada run con `cfg_i[\"naming\"][\"tag\"]` para identificar la variante.\n",
    "- Ajuste de robustez: para `rehearsal`, se fuerza `persistent_workers=False`.\n",
    "\n",
    "> La forma de **pasar combinaciones** ha cambiado respecto a versiones antiguas: usa una **lista de dicts `EXPS`** con `method`, `params`, `tag`. El bucle se encarga del resto (no repitas l√≥gica del runner).\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f64d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6) Comparativa de m√©todos / variantes\n",
    "# =============================================================================\n",
    "from copy import deepcopy\n",
    "import gc, time\n",
    "from src.runner import run_continual\n",
    "from src.utils import build_task_list_for, build_components_for\n",
    "\n",
    "EXPS = [\n",
    "    # Baseline\n",
    "    dict(method=\"naive\", params={}, tag=\"cmp_naive\"),\n",
    "\n",
    "    # EWC\n",
    "    dict(method=\"ewc\", params={\"lam\": 7e8, \"fisher_batches\": 1000}, tag=\"cmp_ewc_lam7e8_fb1000\"),\n",
    "\n",
    "    # Rehearsal\n",
    "    dict(method=\"rehearsal\", params={\"buffer_size\": 3000, \"replay_ratio\": 0.10}, tag=\"cmp_reh_rr10\"),\n",
    "    dict(method=\"rehearsal\", params={\"buffer_size\": 3000, \"replay_ratio\": 0.20}, tag=\"cmp_reh_rr20\"),\n",
    "\n",
    "    # SA-SNN\n",
    "    dict(method=\"sa-snn\", params={\"attach_to\":\"f6\",\"k\":8,\"tau\":28,\"th_min\":1.0,\"th_max\":2.0,\"p\":2_000_000,\n",
    "                                  \"vt_scale\":1.0,\"flatten_spatial\":False,\n",
    "                                  \"assume_binary_spikes\":False,\"reset_counters_each_task\":False},\n",
    "         tag=\"cmp_sa_k8_tau28_p2m\"),\n",
    "\n",
    "    # AS-SNN\n",
    "    dict(method=\"as-snn\", params={\"gamma_ratio\":0.25,\"lambda_a\":1.20,\"ema\":0.90,\n",
    "                                  \"attach_to\":\"f6\",\"measure_at\":\"modules\",\"penalty_mode\":\"l1\",\n",
    "                                  \"do_synaptic_scaling\":False},\n",
    "         tag=\"cmp_as_soft\"),\n",
    "    dict(method=\"as-snn\", params={\"gamma_ratio\":0.35,\"lambda_a\":1.80,\"ema\":0.95,\n",
    "                                  \"attach_to\":\"f6\",\"measure_at\":\"modules\",\"penalty_mode\":\"l1\",\n",
    "                                  \"do_synaptic_scaling\":True,\"scale_clip\":(0.5,2.0),\"scale_bias\":False},\n",
    "         tag=\"cmp_as_scaling\"),\n",
    "\n",
    "    # SCA-SNN\n",
    "    dict(method=\"sca-snn\", params={\"attach_to\":\"f6\",\"flatten_spatial\":False,\"num_bins\":50,\n",
    "                                   \"anchor_batches\":16,\"beta\":0.60,\"bias\":0.05,\"soft_mask_temp\":0.50,\n",
    "                                   \"verbose\":False,\"log_every\":65536},\n",
    "         tag=\"cmp_sca_b060_bias005_t050_ab16\"),\n",
    "]\n",
    "\n",
    "SAFE_DATALOADER_FOR_ALL = False   # Si True, fuerza num_workers=0 para todo\n",
    "SLEEP_BETWEEN_RUNS_SEC = 1.0\n",
    "\n",
    "runs_out = []\n",
    "for idx, exp in enumerate(EXPS, start=1):\n",
    "    cfg_i = deepcopy(CFG)\n",
    "    cfg_i[\"continual\"][\"method\"] = exp[\"method\"]\n",
    "    cfg_i[\"continual\"][\"params\"] = exp[\"params\"]\n",
    "    cfg_i.setdefault(\"naming\", {})\n",
    "    cfg_i[\"naming\"][\"tag\"] = exp[\"tag\"]\n",
    "\n",
    "    # Seguridad dataloader\n",
    "    if SAFE_DATALOADER_FOR_ALL or (\"rehearsal\" in exp[\"method\"].lower()):\n",
    "        cfg_i[\"data\"][\"persistent_workers\"] = False\n",
    "    if SAFE_DATALOADER_FOR_ALL:\n",
    "        cfg_i[\"data\"][\"num_workers\"] = 0\n",
    "\n",
    "    # Factories y tasks coherentes con ESTE cfg_i\n",
    "    tfm_i, make_loader_fn_i, make_model_fn_i = build_components_for(cfg_i, ROOT)\n",
    "    task_list_i, tasks_file_i = build_task_list_for(cfg_i, ROOT)\n",
    "\n",
    "    print(\n",
    "        f\"\\n=== RUN {idx}/{len(EXPS)} preset={PRESET} | method={exp['method']} \"\n",
    "        f\"| enc={cfg_i['data']['encoder']} | tag={exp['tag']} ===\"\n",
    "    )\n",
    "    try:\n",
    "        out_dir, _ = run_continual(\n",
    "            task_list=task_list_i,\n",
    "            make_loader_fn=make_loader_fn_i,\n",
    "            make_model_fn=make_model_fn_i,\n",
    "            tfm=tfm_i,\n",
    "            cfg=cfg_i,\n",
    "            preset_name=PRESET,\n",
    "            out_root=OUT,\n",
    "            verbose=True,\n",
    "        )\n",
    "        runs_out.append(out_dir)\n",
    "        print(\"[OK]\", out_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Fall√≥ method={exp['method']} tag={exp['tag']}: {type(e).__name__}: {e}\")\n",
    "\n",
    "    # Limpieza entre runs\n",
    "    try:\n",
    "        del tfm_i, make_loader_fn_i, make_model_fn_i, task_list_i\n",
    "    except Exception:\n",
    "        pass\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    time.sleep(SLEEP_BETWEEN_RUNS_SEC)\n",
    "\n",
    "print(\"\\nHecho:\", [str(p) for p in runs_out])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d01912a",
   "metadata": {},
   "source": [
    "<a id=\"sec-07\"></a>\n",
    "## 7) Barrido param√©trico (opcional)\n",
    "\n",
    "**Objetivo:** patr√≥n compacto para probar **variantes de un mismo m√©todo** (p.ej., *SCA-SNN* variando `beta` y `bias`).\n",
    "- Define una **funci√≥n generadora** de `params` a partir de rejillas.\n",
    "- Reutiliza el mismo bucle del punto 6 (cambia solo la fuente `EXPS_GRID`).\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fe026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7) Barrido param√©trico ‚Äî ejemplo SCA-SNN\n",
    "# =============================================================================\n",
    "from itertools import product\n",
    "from copy import deepcopy\n",
    "import gc, time\n",
    "from src.runner import run_continual\n",
    "from src.utils import build_task_list_for, build_components_for\n",
    "\n",
    "def sca_params_grid(betas=(0.55, 0.60, 0.65), biases=(0.00, 0.05, 0.10), bins=(50,), anchors=(16,)):\n",
    "    for beta, bias, nb, ab in product(betas, biases, bins, anchors):\n",
    "        yield dict(\n",
    "            method=\"sca-snn\",\n",
    "            params={\"attach_to\":\"f6\",\"flatten_spatial\":False,\"num_bins\":nb,\n",
    "                    \"anchor_batches\":ab,\"beta\":beta,\"bias\":bias,\"soft_mask_temp\":0.50,\n",
    "                    \"verbose\":False,\"log_every\":65536},\n",
    "            tag=f\"grid_sca_b{beta:.2f}_bias{bias:.2f}_bins{nb}_ab{ab}\"\n",
    "        )\n",
    "\n",
    "# Activa para lanzar el grid:\n",
    "DO_GRID = False\n",
    "\n",
    "if DO_GRID:\n",
    "    EXPS_GRID = list(sca_params_grid())\n",
    "    runs_out_grid = []\n",
    "    for idx, exp in enumerate(EXPS_GRID, start=1):\n",
    "        cfg_i = deepcopy(CFG)\n",
    "        cfg_i[\"continual\"][\"method\"] = exp[\"method\"]\n",
    "        cfg_i[\"continual\"][\"params\"] = exp[\"params\"]\n",
    "        cfg_i.setdefault(\"naming\", {})\n",
    "        cfg_i[\"naming\"][\"tag\"] = exp[\"tag\"]\n",
    "        cfg_i[\"data\"][\"persistent_workers\"] = False  # robustez en grids\n",
    "\n",
    "        tfm_i, make_loader_fn_i, make_model_fn_i = build_components_for(cfg_i, ROOT)\n",
    "        task_list_i, tasks_file_i = build_task_list_for(cfg_i, ROOT)\n",
    "\n",
    "        print(f\"\\n=== GRID {idx}/{len(EXPS_GRID)} {exp['tag']} ===\")\n",
    "        try:\n",
    "            out_dir, _ = run_continual(\n",
    "                task_list=task_list_i,\n",
    "                make_loader_fn=make_loader_fn_i,\n",
    "                make_model_fn=make_model_fn_i,\n",
    "                tfm=tfm_i,\n",
    "                cfg=cfg_i,\n",
    "                preset_name=PRESET,\n",
    "                out_root=OUT,\n",
    "                verbose=True,\n",
    "            )\n",
    "            runs_out_grid.append(out_dir)\n",
    "            print(\"[OK]\", out_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {exp['tag']}: {type(e).__name__}: {e}\")\n",
    "\n",
    "        try:\n",
    "            del tfm_i, make_loader_fn_i, make_model_fn_i, task_list_i\n",
    "        except Exception:\n",
    "            pass\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    print(\"\\nGrid hecho:\", [str(p) for p in runs_out_grid])\n",
    "else:\n",
    "    print(\"Grid desactivado (DO_GRID=False).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447789bc",
   "metadata": {},
   "source": [
    "<a id=\"sec-08\"></a>\n",
    "## 8) Reevaluaci√≥n de runs (eval_matrix) ‚Äî **firma nueva**\n",
    "\n",
    "**Objetivo:** reconstruir `eval_matrix.json`/`forgetting.*` cuando:\n",
    "- Falta el fichero, o\n",
    "- Tiene forma vac√≠a/incompleta (p. ej., columnas finales `NaN`).\n",
    "\n",
    "> **Importante:** `reevaluate_only(...)` ahora **requiere** los *factories* y `task_list` adem√°s de `out_dir`, pues necesita reconstruir los *loaders* coherentes con el `cfg`. Este cuaderno ya prepara todo correctamente.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f721bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8) Reevaluaci√≥n de runs (corrige firma y detecci√≥n)\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import json, numpy as np\n",
    "from src.runner import reevaluate_only\n",
    "\n",
    "def _needs_reeval(run_dir: Path) -> bool:\n",
    "    jf = run_dir / \"eval_matrix.json\"\n",
    "    if not jf.exists():\n",
    "        return True\n",
    "    try:\n",
    "        j = json.loads(jf.read_text(encoding=\"utf-8\"))\n",
    "        tasks = j.get(\"tasks\") or []\n",
    "        M = j.get(\"mae_matrix\") or []\n",
    "        A = np.array(M, dtype=float)\n",
    "        if A.ndim != 2 or A.shape[0] != len(tasks) or A.shape[1] == 0:\n",
    "            return True\n",
    "        last_col = A[:, -1]\n",
    "        return not np.isfinite(last_col).any()\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "# Factories y tasks de referencia (usamos el preset actual)\n",
    "tfm_r, make_loader_fn_r, make_model_fn_r = build_components_for(CFG, ROOT)\n",
    "task_list_r, _ = build_task_list_for(CFG, ROOT)\n",
    "\n",
    "targets = []\n",
    "for p in sorted(OUT.glob(\"continual_*\")):\n",
    "    if p.is_dir() and _needs_reeval(p):\n",
    "        targets.append(p)\n",
    "\n",
    "print(f\"[INFO] Runs a reevaluar: {len(targets)}\")\n",
    "for rd in targets:\n",
    "    print(\" -\", rd.name)\n",
    "    reevaluate_only(\n",
    "        out_dir=rd,\n",
    "        task_list=task_list_r,\n",
    "        make_loader_fn=make_loader_fn_r,\n",
    "        make_model_fn=make_model_fn_r,\n",
    "        tfm=tfm_r,\n",
    "        cfg=CFG,\n",
    "        preset_name=PRESET,\n",
    "        verbose=True,\n",
    "    )\n",
    "print(\"[OK] Reevaluaci√≥n terminada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a6206",
   "metadata": {},
   "source": [
    "<a id=\"sec-09\"></a>\n",
    "## 9) Resumen + gr√°ficas (tablas, leaderboards, plots)\n",
    "\n",
    "**Objetivo:** centralizar reporting usando `src/plots.py`:\n",
    "- Tabla consolidada `results_table.csv` a partir de `outputs/`.\n",
    "- *Leaderboards* y agregados por m√©todo: `export_leaderboards(...)`.\n",
    "- Gr√°ficas globales: `plot_across_runs(...)`.\n",
    "- Historias por run/tarea: `plot_loss_curves_all_runs(...)` (opcional).\n",
    "- Heatmap `eval_matrix` y reparto de **emisiones por tarea** (si hay telemetr√≠a).\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 9) Resumen y gr√°ficas\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src.results_io import build_results_table\n",
    "from src.plots import (\n",
    "    export_leaderboards, plot_across_runs, plot_loss_curves_all_runs,\n",
    "    plot_mae_curves_for_run, plot_eval_matrix_heatmap, plot_energy_by_task\n",
    ")\n",
    "\n",
    "summary_dir = OUT / \"summary\"\n",
    "summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 9.1 Tabla consolidada (desde outputs/*)\n",
    "df = build_results_table(OUT)\n",
    "display(df.head(10))\n",
    "tbl_path = summary_dir / \"results_table.csv\"\n",
    "df.to_csv(tbl_path, index=False)\n",
    "print(\"[OK] Tabla consolidada:\", tbl_path)\n",
    "\n",
    "# 9.2 Leaderboards y agregados (preset actual por defecto)\n",
    "ld_paths = export_leaderboards(df, summary_dir / \"leaderboards\", preset=PRESET, topN=6)\n",
    "print(\"[OK] Leaderboards/agregados:\", ld_paths)\n",
    "\n",
    "# 9.3 Gr√°ficas globales (MAE final por tarea, olvido, emisiones, trade-off)\n",
    "plots_dir = plot_across_runs(df, summary_dir / \"plots_global\")\n",
    "print(\"[OK] Gr√°ficas globales:\", plots_dir)\n",
    "\n",
    "# 9.4 Curvas de validaci√≥n por run/tarea (opcional)\n",
    "DO_CURVES_ALL = False\n",
    "if DO_CURVES_ALL:\n",
    "    curves_dir = plot_loss_curves_all_runs(OUT, summary_dir, smooth_window=3)\n",
    "    print(\"[OK] Curvas por run:\", curves_dir)\n",
    "\n",
    "# 9.5 Para el √∫ltimo run por fecha: heatmap eval_matrix + energ√≠a por tarea (si hay)\n",
    "runs_sorted = sorted(OUT.glob(\"continual_*\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if runs_sorted:\n",
    "    last_run = runs_sorted[0]\n",
    "    print(\"√öltimo run:\", last_run.name)\n",
    "    try:\n",
    "        plot_eval_matrix_heatmap(last_run, summary_dir / \"by_run\")\n",
    "        plot_energy_by_task(last_run, summary_dir / \"by_run\")\n",
    "        plot_mae_curves_for_run(last_run, summary_dir / \"by_run\", smooth_window=3)\n",
    "        print(\"[OK] Plots por run:\", summary_dir / \"by_run\" / last_run.name)\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] No se pudieron generar algunos plots por run:\", e)\n",
    "else:\n",
    "    print(\"[INFO] No hay carpetas 'continual_*' en outputs/ todav√≠a.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
