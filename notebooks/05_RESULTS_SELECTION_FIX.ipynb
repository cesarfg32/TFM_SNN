{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8647b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 0 ‚Äî Config\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, math, re, os, json\n",
    "\n",
    "# Ra√≠z de outputs del proyecto\n",
    "OUT = Path(\"/home/cesar/proyectos/TFM_SNN/outputs\")\n",
    "\n",
    "# Carpeta donde guardaremos los artefactos de este informe\n",
    "SUMMARY = OUT / \"summary\" / \"paper_set_accurate_2025-11-06\"\n",
    "SUMMARY.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------- Filtros \"paper set\" --------\n",
    "PRESET_KEEP       = {\"std_16\"}     # None para no filtrar por preset\n",
    "ENCODER_KEEP      = {\"rate\"}         # None para no filtrar por encoder\n",
    "SEED_KEEP         = None             # None para no filtrar por semilla {42}\n",
    "\n",
    "# üëâ No filtrar por m√©todos (incluye composites sin tocarlos)\n",
    "METHODS_KEEP      = None\n",
    "\n",
    "ONLY_NEW_RUNNER   = True             # Solo runs con run_row.json (o run_row.csv)\n",
    "MTIME_FROM        = pd.Timestamp(\"2025-11-11\")  # fecha corte (incluido)\n",
    "\n",
    "# -------- Comparabilidad \"dura\" --------\n",
    "STRICT_CFG        = True             # mismo modelo/T/AMP/batch_size\n",
    "\n",
    "# -------- M√©trica compuesta --------\n",
    "ALPHA_COMPOSITE   = 0.5              # peso de MAE vs olvido\n",
    "\n",
    "# -------- Opciones de informe / narrativa --------\n",
    "IGNORE_NAIVE_IN_REPORTS = False      # True para ocultar naive en tablas/gr√°ficos finales\n",
    "GROUP_BY_FULL_METHOD    = False      # False ‚Üí agrupa por 'method_base'; True ‚Üí por 'method' (separa composites)\n",
    "RELATIVE_BASELINE       = \"naive\"    # \"naive\", \"ewc\" o None. Calcula deltas vs este baseline\n",
    "BASELINE_MATCH_STRICT   = True       # emparejar baseline por (preset,encoder,model,T,amp,batch,seed)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd90cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1 ‚Äî Utils\n",
    "\n",
    "def _safe_float(x, default=np.nan):\n",
    "    try:\n",
    "        if x is None: return default\n",
    "        if isinstance(x, (int, float)): return float(x)\n",
    "        s = str(x).strip()\n",
    "        if s.lower() in {\"nan\",\"none\",\"null\",\"\"}: return default\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def _read_json(p: Path):\n",
    "    try:\n",
    "        if p.exists():\n",
    "            return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def _read_csv_df(p: Path):\n",
    "    try:\n",
    "        if p.exists():\n",
    "            return pd.read_csv(p)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def _abs_run_dir(rel: str|Path) -> Path:\n",
    "    rel = str(rel)\n",
    "    return (OUT / rel) if not rel.startswith(str(OUT)) else Path(rel)\n",
    "\n",
    "def run_mtime(rel: str|Path) -> float:\n",
    "    rd = _abs_run_dir(rel)\n",
    "    mt = 0.0\n",
    "    for root, _, files in os.walk(rd):\n",
    "        for f in files:\n",
    "            try:\n",
    "                mt = max(mt, (Path(root)/f).stat().st_mtime)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return mt\n",
    "\n",
    "def canonical_method(m: str) -> str:\n",
    "    if not m: return \"none\"\n",
    "    m = m.lower()\n",
    "    if m.startswith(\"ewc\"):        return \"ewc\"\n",
    "    if m.startswith(\"as-snn\"):     return \"as-snn\"\n",
    "    if m.startswith(\"sa-snn\"):     return \"sa-snn\"\n",
    "    if m.startswith(\"sca-snn\"):    return \"sca-snn\"\n",
    "    if m.startswith(\"rehearsal\"):  return \"rehearsal\"\n",
    "    if m.startswith(\"naive\"):      return \"naive\"\n",
    "    return m\n",
    "\n",
    "def _read_forgetting(run_dir: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Lee primero forgetting_summary.json (preferente).\n",
    "    Si no existe, lee forgetting.json (anidado por tareas) y calcula la media.\n",
    "    Devuelve claves normalizadas: circuito1_forget_abs/rel, circuito2_forget_abs/rel, avg_forget_rel.\n",
    "    \"\"\"\n",
    "    def _nanmean2(a, b):\n",
    "        vals = [x for x in [a, b] if x is not None and not math.isnan(_safe_float(x))]\n",
    "        return float(np.mean([_safe_float(x) for x in vals])) if vals else np.nan\n",
    "\n",
    "    # 1) summary (preferido)\n",
    "    summ = _read_json(run_dir / \"forgetting_summary.json\")\n",
    "    if isinstance(summ, dict):\n",
    "        c1_abs = _safe_float(summ.get(\"circuito1_forget_abs\", summ.get(\"task_1_forget_abs\")))\n",
    "        c1_rel = _safe_float(summ.get(\"circuito1_forget_rel\", summ.get(\"task_1_forget_rel\")))\n",
    "        c2_abs = _safe_float(summ.get(\"circuito2_forget_abs\", summ.get(\"task_2_forget_abs\")))\n",
    "        c2_rel = _safe_float(summ.get(\"circuito2_forget_rel\", summ.get(\"task_2_forget_rel\")))\n",
    "        avg_rel = _safe_float(summ.get(\"avg_forget_rel\", summ.get(\"avg_forgetting_rel\")))\n",
    "        if math.isnan(avg_rel):\n",
    "            avg_rel = _nanmean2(c1_rel, c2_rel)\n",
    "        return {\n",
    "            \"circuito1_forget_abs\": c1_abs,\n",
    "            \"circuito1_forget_rel\": c1_rel,\n",
    "            \"circuito2_forget_abs\": c2_abs,\n",
    "            \"circuito2_forget_rel\": c2_rel,\n",
    "            \"avg_forget_rel\":       avg_rel,\n",
    "        }\n",
    "\n",
    "    # 2) forgetting.json (anidado por tareas) o plano\n",
    "    js = _read_json(run_dir / \"forgetting.json\") or {}\n",
    "    if not isinstance(js, dict):\n",
    "        return {}\n",
    "\n",
    "    def pick(d, *keys):\n",
    "        for k in keys:\n",
    "            if k in d: return d[k]\n",
    "        return None\n",
    "\n",
    "    c1_abs = _safe_float(pick(js, \"circuito1_forget_abs\",\"task_1_circuito1_forget_abs\",\"c1_forget_abs\",\"task_1_forget_abs\"))\n",
    "    c1_rel = _safe_float(pick(js, \"circuito1_forget_rel\",\"task_1_circuito1_forget_rel\",\"c1_forget_rel\",\"task_1_forget_rel\"))\n",
    "    c2_abs = _safe_float(pick(js, \"circuito2_forget_abs\",\"task_2_circuito2_forget_abs\",\"c2_forget_abs\",\"task_2_forget_abs\"))\n",
    "    c2_rel = _safe_float(pick(js, \"circuito2_forget_rel\",\"task_2_circuito2_forget_rel\",\"c2_forget_rel\",\"task_2_forget_rel\"))\n",
    "    avg_rel = _safe_float(pick(js, \"avg_forget_rel\",\"avg_forgetting_rel\",\"mean_forget_rel\",\"forget_rel_avg\"))\n",
    "\n",
    "    # Si sigue faltando, leer anidado por tarea\n",
    "    if (\"circuito1\" in js) and isinstance(js[\"circuito1\"], dict):\n",
    "        if math.isnan(c1_abs): c1_abs = _safe_float(js[\"circuito1\"].get(\"forget_abs\"))\n",
    "        if math.isnan(c1_rel): c1_rel = _safe_float(js[\"circuito1\"].get(\"forget_rel\"))\n",
    "    if (\"circuito2\" in js) and isinstance(js[\"circuito2\"], dict):\n",
    "        if math.isnan(c2_abs): c2_abs = _safe_float(js[\"circuito2\"].get(\"forget_abs\"))\n",
    "        if math.isnan(c2_rel): c2_rel = _safe_float(js[\"circuito2\"].get(\"forget_rel\"))\n",
    "\n",
    "    if math.isnan(avg_rel):\n",
    "        avg_rel = _nanmean2(c1_rel, c2_rel)\n",
    "\n",
    "    return {\n",
    "        \"circuito1_forget_abs\": c1_abs,\n",
    "        \"circuito1_forget_rel\": c1_rel,\n",
    "        \"circuito2_forget_abs\": c2_abs,\n",
    "        \"circuito2_forget_rel\": c2_rel,\n",
    "        \"avg_forget_rel\":       avg_rel,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1102c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2 ‚Äî Reconstrucci√≥n 100% desde ficheros (robusta a formatos)\n",
    "\n",
    "import os, re, json, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ‚Äî‚Äî‚Äî Fallback por si _read_forgetting no qued√≥ definido en la Celda 1 ‚Äî‚Äî‚Äî\n",
    "try:\n",
    "    _read_forgetting\n",
    "except NameError:\n",
    "    def _read_forgetting(run_dir: Path):\n",
    "        def _nanmean2(a, b):\n",
    "            vals = [x for x in [a, b] if x is not None and not math.isnan(_safe_float(x))]\n",
    "            return (float(np.mean([_safe_float(x) for x in vals])) if vals else np.nan)\n",
    "        summ = _read_json(run_dir / \"forgetting_summary.json\")\n",
    "        if isinstance(summ, dict):\n",
    "            c1_abs = _safe_float(summ.get(\"circuito1_forget_abs\", summ.get(\"task_1_forget_abs\")))\n",
    "            c1_rel = _safe_float(summ.get(\"circuito1_forget_rel\", summ.get(\"task_1_forget_rel\")))\n",
    "            c2_abs = _safe_float(summ.get(\"circuito2_forget_abs\", summ.get(\"task_2_forget_abs\")))\n",
    "            c2_rel = _safe_float(summ.get(\"circuito2_forget_rel\", summ.get(\"task_2_forget_rel\")))\n",
    "            avg_rel = _safe_float(summ.get(\"avg_forget_rel\", summ.get(\"avg_forgetting_rel\")))\n",
    "            if math.isnan(avg_rel): avg_rel = _nanmean2(c1_rel, c2_rel)\n",
    "            return {\n",
    "                \"circuito1_forget_abs\": c1_abs, \"circuito1_forget_rel\": c1_rel,\n",
    "                \"circuito2_forget_abs\": c2_abs, \"circuito2_forget_rel\": c2_rel,\n",
    "                \"avg_forget_rel\": avg_rel,\n",
    "            }\n",
    "        js = _read_json(run_dir / \"forgetting.json\") or {}\n",
    "        if not isinstance(js, dict): return {}\n",
    "        def pick(d, *keys):\n",
    "            for k in keys:\n",
    "                if k in d: return d[k]\n",
    "            return None\n",
    "        c1_abs = _safe_float(pick(js, \"circuito1_forget_abs\",\"task_1_circuito1_forget_abs\",\"c1_forget_abs\",\"task_1_forget_abs\"))\n",
    "        c1_rel = _safe_float(pick(js, \"circuito1_forget_rel\",\"task_1_circuito1_forget_rel\",\"c1_forget_rel\",\"task_1_forget_rel\"))\n",
    "        c2_abs = _safe_float(pick(js, \"circuito2_forget_abs\",\"task_2_circuito2_forget_abs\",\"c2_forget_abs\",\"task_2_forget_abs\"))\n",
    "        c2_rel = _safe_float(pick(js, \"circuito2_forget_rel\",\"task_2_circuito2_forget_rel\",\"c2_forget_rel\",\"task_2_forget_rel\"))\n",
    "        avg_rel = _safe_float(pick(js, \"avg_forget_rel\",\"avg_forgetting_rel\",\"mean_forget_rel\",\"forget_rel_avg\"))\n",
    "        if (\"circuito1\" in js) and isinstance(js[\"circuito1\"], dict):\n",
    "            if math.isnan(c1_abs): c1_abs = _safe_float(js[\"circuito1\"].get(\"forget_abs\"))\n",
    "            if math.isnan(c1_rel): c1_rel = _safe_float(js[\"circuito1\"].get(\"forget_rel\"))\n",
    "        if (\"circuito2\" in js) and isinstance(js[\"circuito2\"], dict):\n",
    "            if math.isnan(c2_abs): c2_abs = _safe_float(js[\"circuito2\"].get(\"forget_abs\"))\n",
    "            if math.isnan(c2_rel): c2_rel = _safe_float(js[\"circuito2\"].get(\"forget_rel\"))\n",
    "        if math.isnan(avg_rel):\n",
    "            vals = [x for x in [c1_rel, c2_rel] if not math.isnan(_safe_float(x))]\n",
    "            avg_rel = float(np.mean([_safe_float(x) for x in vals])) if vals else np.nan\n",
    "        return {\n",
    "            \"circuito1_forget_abs\": c1_abs, \"circuito1_forget_rel\": c1_rel,\n",
    "            \"circuito2_forget_abs\": c2_abs, \"circuito2_forget_rel\": c2_rel,\n",
    "            \"avg_forget_rel\": avg_rel,\n",
    "        }\n",
    "\n",
    "# ‚Äî‚Äî‚Äî Helpers internos ‚Äî‚Äî‚Äî\n",
    "\n",
    "def _parse_basic_meta(run_dir: Path) -> dict:\n",
    "    \"\"\"Extrae preset, method, encoder, model, seed, T, amp, batch_size desde los artefactos.\n",
    "       Prioridad: run_row.json ‚Üí manifest de tarea ‚Üí heur√≠stica de nombre de carpeta.\n",
    "    \"\"\"\n",
    "    jrow = _read_json(run_dir / \"run_row.json\") or {}\n",
    "\n",
    "    def gj(*ks, default=None):\n",
    "        obj = jrow\n",
    "        for k in ks:\n",
    "            if not isinstance(obj, dict) or (k not in obj):\n",
    "                return default\n",
    "            obj = obj[k]\n",
    "        return obj\n",
    "\n",
    "    # Campos directos de run_row.json (top-level o dentro de meta/data/training)\n",
    "    preset   = jrow.get(\"preset\") or gj(\"meta\",\"preset\")\n",
    "    method   = jrow.get(\"method\") or gj(\"meta\",\"method\")\n",
    "    encoder  = jrow.get(\"encoder\") or gj(\"meta\",\"encoder\")\n",
    "    model    = jrow.get(\"model\")   or jrow.get(\"model_name\") or gj(\"meta\",\"model\") or gj(\"meta\",\"model_name\")\n",
    "    seed     = jrow.get(\"seed\")    or gj(\"meta\",\"seed\")\n",
    "    T        = jrow.get(\"T\")       or gj(\"data\",\"T\") or gj(\"meta\",\"data\",\"T\") or gj(\"meta\",\"T\")\n",
    "    amp      = jrow.get(\"amp\")     or gj(\"training\",\"amp\") or gj(\"meta\",\"amp\")\n",
    "    batch_sz = jrow.get(\"batch_size\") or gj(\"meta\",\"batch_size\")\n",
    "\n",
    "    # Manifest de la primera tarea (por si faltan cosas)\n",
    "    man1 = _read_json(run_dir / \"task_1_circuito1\" / \"manifest.json\")\n",
    "    if isinstance(man1, dict):\n",
    "        meta1 = man1.get(\"meta\", {}) if isinstance(man1.get(\"meta\", {}), dict) else {}\n",
    "        if not model:        model     = meta1.get(\"model\") or man1.get(\"model\") or man1.get(\"model_name\")\n",
    "        if batch_sz is None: batch_sz  = meta1.get(\"batch_size\", batch_sz)\n",
    "        # Claves t√≠picas en tu formato:\n",
    "        if T is None:        T         = meta1.get(\"T\", T)        # T vive en meta\n",
    "        if amp is None:      amp       = meta1.get(\"amp\", amp)    # amp vive en meta\n",
    "        if not encoder:      encoder   = meta1.get(\"encoder\", encoder)\n",
    "        if not preset:       preset    = meta1.get(\"preset\", preset)\n",
    "        if not method:       method    = meta1.get(\"method\", method)\n",
    "\n",
    "    # Heur√≠stica de nombre de carpeta si faltan preset/method/encoder\n",
    "    if not preset or not method or not encoder:\n",
    "        name = run_dir.name\n",
    "        m = re.match(r\"continual_([^_]+)_([^_].*?)_(rate|latency|raw|image).*\", name)\n",
    "        if m:\n",
    "            preset  = preset  or m.group(1)\n",
    "            method  = method  or m.group(2)\n",
    "            encoder = encoder or m.group(3)\n",
    "\n",
    "    # Tipados/normalizaciones\n",
    "    seed    = _safe_float(seed)\n",
    "    T       = _safe_float(T)\n",
    "    if isinstance(amp, str):\n",
    "        amp = amp.strip().lower() in {\"true\",\"1\",\"yes\",\"y\"}\n",
    "    elif isinstance(amp, (int, float)):\n",
    "        amp = bool(amp)\n",
    "    elif amp is not None and not isinstance(amp, bool):\n",
    "        amp = None\n",
    "    batch_sz = _safe_float(batch_sz)\n",
    "\n",
    "    return dict(\n",
    "        preset=preset, method=method, encoder=encoder, model=model,\n",
    "        seed=seed, T=T, amp=amp, batch_size=batch_sz\n",
    "    )\n",
    "\n",
    "def _read_per_task_perf(run_dir: Path) -> dict:\n",
    "    \"\"\"Devuelve dict por tarea con {'best_mae','final_mae'} normalizadas.\n",
    "       Soporta per_task_perf.json (lista/dict) y per_task_perf.csv.\n",
    "       Normaliza nombres de tarea (lower) y fusiona JSON+CSV para rellenar huecos.\n",
    "    \"\"\"\n",
    "    def _norm_row_dictlike(d):\n",
    "        tname = (str(d.get(\"task_name\") or d.get(\"task\") or d.get(\"name\") or \"\")).strip().lower()\n",
    "        # a√±adimos 'test_mae' como candidato de 'best'\n",
    "        best_candidates  = [\"best_mae\",\"val_best_mae\",\"best\",\"mae_best\",\"min_mae\",\"test_mae\"]\n",
    "        final_candidates = [\"final_mae\",\"val_final_mae\",\"val_last_mae\",\"last_mae\",\"mae_last\",\"mae_final\"]\n",
    "        best  = next((d.get(k) for k in best_candidates  if k in d), None)\n",
    "        final = next((d.get(k) for k in final_candidates if k in d), None)\n",
    "        return tname, {\"best_mae\": _safe_float(best), \"final_mae\": _safe_float(final)}\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    # 1) JSON\n",
    "    js = _read_json(run_dir / \"per_task_perf.json\")\n",
    "    if js is not None:\n",
    "        if isinstance(js, list):\n",
    "            for row in js:\n",
    "                if isinstance(row, dict):\n",
    "                    t, val = _norm_row_dictlike(row)\n",
    "                    if t:\n",
    "                        out[t] = val\n",
    "        elif isinstance(js, dict):\n",
    "            if all(isinstance(v, dict) for v in js.values()):\n",
    "                for k, v in js.items():\n",
    "                    t, val = _norm_row_dictlike({\"task_name\": k, **v})\n",
    "                    if t:\n",
    "                        out[t] = val\n",
    "            else:\n",
    "                try:\n",
    "                    df = pd.DataFrame(js)\n",
    "                    for _, row in df.iterrows():\n",
    "                        t, val = _norm_row_dictlike(row.to_dict())\n",
    "                        if t:\n",
    "                            out[t] = val\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    # 2) CSV (fusiona y rellena NaNs si los hay)\n",
    "    df = _read_csv_df(run_dir / \"per_task_perf.csv\")\n",
    "    if df is not None and not df.empty:\n",
    "        for _, row in df.iterrows():\n",
    "            tn = (str(row.get(\"task_name\") or row.get(\"task\") or row.get(\"name\") or \"\")).strip().lower()\n",
    "            if not tn:\n",
    "                continue\n",
    "            cur = out.get(tn, {\"best_mae\": np.nan, \"final_mae\": np.nan})\n",
    "            if math.isnan(_safe_float(cur.get(\"best_mae\"))):\n",
    "                cur[\"best_mae\"] = _safe_float(row.get(\"val_best_mae\", row.get(\"best_mae\", row.get(\"test_mae\"))))\n",
    "            if math.isnan(_safe_float(cur.get(\"final_mae\"))):\n",
    "                cur[\"final_mae\"] = _safe_float(row.get(\"val_last_mae\", row.get(\"val_final_mae\", row.get(\"final_mae\"))))\n",
    "            out[tn] = cur\n",
    "\n",
    "    return out\n",
    "\n",
    "def _read_efficiency(run_dir: Path):\n",
    "    \"\"\"Lee emisiones/tiempo desde efficiency_summary.json; si falta, intenta emissions.csv y run_row.json.\"\"\"\n",
    "    j = _read_json(run_dir / \"efficiency_summary.json\") or {}\n",
    "    emissions = _safe_float(j.get(\"emissions_kg\"), default=np.nan)\n",
    "    elapsed   = _safe_float(j.get(\"elapsed_sec\"),   default=np.nan)\n",
    "\n",
    "    if math.isnan(emissions):\n",
    "        df = _read_csv_df(run_dir / \"emissions.csv\")\n",
    "        if df is not None:\n",
    "            col = \"co2e_kg\" if \"co2e_kg\" in df.columns else (\"emissions_kg\" if \"emissions_kg\" in df.columns else None)\n",
    "            if col:\n",
    "                emissions = float(df[col].sum())\n",
    "\n",
    "    if math.isnan(elapsed) or math.isnan(emissions):\n",
    "        rj = _read_json(run_dir / \"run_row.json\") or {}\n",
    "        if math.isnan(elapsed):\n",
    "            elapsed = _safe_float(rj.get(\"elapsed_sec\"), default=elapsed)\n",
    "        if math.isnan(emissions):\n",
    "            emissions = _safe_float(rj.get(\"emissions_kg\"), default=emissions)\n",
    "\n",
    "    return emissions, elapsed\n",
    "\n",
    "def _read_eval_matrix(run_dir: Path) -> pd.DataFrame | None:\n",
    "    \"\"\"Carga eval_matrix (csv preferente) o reconstruye desde json {'tasks':[], 'mae_matrix':[[]]}.\"\"\"\n",
    "    p_csv = run_dir / \"eval_matrix.csv\"\n",
    "    if p_csv.exists():\n",
    "        try:\n",
    "            return pd.read_csv(p_csv)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    js = _read_json(run_dir / \"eval_matrix.json\")\n",
    "    if isinstance(js, dict) and (\"tasks\" in js) and (\"mae_matrix\" in js):\n",
    "        tasks = list(js.get(\"tasks\") or [])\n",
    "        mat   = js.get(\"mae_matrix\") or []\n",
    "        # Intentamos formato de columnas como en CSV: 'task', 'after_circuito1', 'after_circuito2',...\n",
    "        try:\n",
    "            mat = np.array(mat, dtype=float)\n",
    "            cols = [\"task\"] + [f\"after_{t}\" for t in tasks]\n",
    "            data = {\"task\": tasks}\n",
    "            for j, cname in enumerate(cols[1:]):\n",
    "                colvals = [row[j] if j < len(row) else np.nan for row in mat]\n",
    "                data[cname] = colvals\n",
    "            return pd.DataFrame(data)\n",
    "        except Exception:\n",
    "            # fallback gen√©rico\n",
    "            try:\n",
    "                return pd.DataFrame(js)\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "def _compute_best_final_from_eval(eval_df: pd.DataFrame, task_token: str):\n",
    "    \"\"\"Obtiene BEST/FINAL mirando primero por FILAS (col 'task') y,\n",
    "    si no existe, hace fallback a columnas que contengan el token.\"\"\"\n",
    "    if eval_df is None or eval_df.empty:\n",
    "        return (np.nan, np.nan)\n",
    "\n",
    "    # 1) Preferir formato fila: 'task' == task_token\n",
    "    tcol = None\n",
    "    for c in eval_df.columns:\n",
    "        if str(c).strip().lower() == \"task\":\n",
    "            tcol = c\n",
    "            break\n",
    "    if tcol is not None:\n",
    "        mask = eval_df[tcol].astype(str).str.lower() == str(task_token).lower()\n",
    "        if mask.any():\n",
    "            row = eval_df.loc[mask].iloc[0]\n",
    "            data_cols = [c for c in eval_df.columns if c != tcol]\n",
    "\n",
    "            vals = pd.to_numeric(row[data_cols], errors=\"coerce\").values.astype(float)\n",
    "            finite = np.isfinite(vals)\n",
    "            best = float(np.nanmin(vals)) if finite.any() else np.nan\n",
    "\n",
    "            # FINAL = valor en la √∫ltima columna temporal (p.ej., after_√∫ltima_tarea)\n",
    "            final = _safe_float(row[data_cols[-1]])\n",
    "            return (best, final)\n",
    "\n",
    "    # 2) Fallback: columnas que contengan el token (formatos antiguos)\n",
    "    cols = [c for c in eval_df.columns if str(task_token).lower() in str(c).lower()]\n",
    "    if cols:\n",
    "        dfc = eval_df[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        vals = dfc.values.astype(float)\n",
    "        finite = np.isfinite(vals)\n",
    "        best = float(np.nanmin(vals)) if finite.any() else np.nan\n",
    "        final = _safe_float(dfc.iloc[-1, -1])\n",
    "        return (best, final)\n",
    "\n",
    "    return (np.nan, np.nan)\n",
    "\n",
    "\n",
    "def _compute_forgetting_from_eval_matrix(eval_df: pd.DataFrame, per_task: dict):\n",
    "    \"\"\"Olvido para c1 tras aprender c2. C2 no olvida (0).\"\"\"\n",
    "    out = {}\n",
    "    t1_keys = [k for k in (per_task or {}).keys() if \"circuito1\" in str(k).lower()]\n",
    "    best_t1 = None\n",
    "    if t1_keys:\n",
    "        best_t1 = _safe_float((per_task.get(t1_keys[0]) or {}).get(\"best_mae\"))\n",
    "    if best_t1 is None or math.isnan(best_t1):\n",
    "        best_t1, _ = _compute_best_final_from_eval(eval_df, \"circuito1\")\n",
    "\n",
    "    _, final_t1_after_last = _compute_best_final_from_eval(eval_df, \"circuito1\")\n",
    "    if best_t1 is None or math.isnan(best_t1) or final_t1_after_last is None or math.isnan(final_t1_after_last):\n",
    "        return out\n",
    "\n",
    "    forget_abs = max(0.0, final_t1_after_last - best_t1)\n",
    "    forget_rel = forget_abs / max(1e-9, best_t1)\n",
    "    out[\"circuito1_forget_abs\"] = forget_abs\n",
    "    out[\"circuito1_forget_rel\"] = forget_rel\n",
    "    out[\"circuito2_forget_abs\"] = 0.0\n",
    "    out[\"circuito2_forget_rel\"] = 0.0\n",
    "    out[\"avg_forget_rel\"] = forget_rel\n",
    "    return out\n",
    "\n",
    "def _read_continual_results(run_dir: Path) -> dict:\n",
    "    \"\"\"Fallback final para MAEs desde continual_results.json.\"\"\"\n",
    "    j = _read_json(run_dir / \"continual_results.json\")\n",
    "    if not isinstance(j, dict):\n",
    "        return {}\n",
    "    c1 = j.get(\"circuito1\", {}) or {}\n",
    "    c2 = j.get(\"circuito2\", {}) or {}\n",
    "    return {\n",
    "        \"c1_best\":  _safe_float(c1.get(\"test_mae\")),\n",
    "        \"c1_final\": _safe_float(c1.get(\"after_circuito2_mae\")),\n",
    "        \"c2_best\":  _safe_float(c2.get(\"test_mae\")),\n",
    "        \"c2_final\": _safe_float(c2.get(\"test_mae\")),\n",
    "    }\n",
    "\n",
    "def build_results_table_from_disk(base_out: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    run_dirs = [p for p in base_out.glob(\"continual_*\") if p.is_dir()]\n",
    "    print(f\"[INFO] Escaneando {len(run_dirs)} runs en {base_out}\")\n",
    "\n",
    "    for rd in run_dirs:\n",
    "        meta      = _parse_basic_meta(rd)\n",
    "        per_task  = _read_per_task_perf(rd)\n",
    "        eff_kg, elapsed = _read_efficiency(rd)\n",
    "        forget_js = _read_forgetting(rd) or {}\n",
    "        eval_df   = _read_eval_matrix(rd)\n",
    "\n",
    "        # MAEs por tarea con fallback a eval_matrix y, si hace falta, continual_results.json\n",
    "        c1_best = c1_final = c2_best = c2_final = np.nan\n",
    "\n",
    "        t1_keys = [k for k in per_task.keys() if \"circuito1\" in str(k).lower()]\n",
    "        if t1_keys:\n",
    "            c1_best  = _safe_float(per_task[t1_keys[0]].get(\"best_mae\"),  default=np.nan)\n",
    "            c1_final = _safe_float(per_task[t1_keys[0]].get(\"final_mae\"), default=np.nan)\n",
    "        if math.isnan(c1_best) or math.isnan(c1_final):\n",
    "            b, f = _compute_best_final_from_eval(eval_df, \"circuito1\")\n",
    "            if math.isnan(c1_best):  c1_best  = b\n",
    "            if math.isnan(c1_final): c1_final = f\n",
    "\n",
    "        t2_keys = [k for k in per_task.keys() if \"circuito2\" in str(k).lower()]\n",
    "        if t2_keys:\n",
    "            c2_best  = _safe_float(per_task[t2_keys[0]].get(\"best_mae\"),  default=np.nan)\n",
    "            c2_final = _safe_float(per_task[t2_keys[0]].get(\"final_mae\"), default=np.nan)\n",
    "        if math.isnan(c2_best) or math.isnan(c2_final):\n",
    "            b, f = _compute_best_final_from_eval(eval_df, \"circuito2\")\n",
    "            if math.isnan(c2_best):  c2_best  = b\n",
    "            if math.isnan(c2_final): c2_final = f\n",
    "\n",
    "        # Fallback definitivo: continual_results.json\n",
    "        if any(math.isnan(x) for x in [c1_best, c1_final, c2_best, c2_final]):\n",
    "            cr = _read_continual_results(rd)\n",
    "            if math.isnan(c1_best):  c1_best  = _safe_float(cr.get(\"c1_best\"),  default=c1_best)\n",
    "            if math.isnan(c1_final): c1_final = _safe_float(cr.get(\"c1_final\"), default=c1_final)\n",
    "            if math.isnan(c2_best):  c2_best  = _safe_float(cr.get(\"c2_best\"),  default=c2_best)\n",
    "            if math.isnan(c2_final): c2_final = _safe_float(cr.get(\"c2_final\"), default=c2_final)\n",
    "\n",
    "        # Olvido (summary/json) o c√°lculo desde eval_matrix\n",
    "        f_c1_abs = _safe_float(forget_js.get(\"circuito1_forget_abs\"))\n",
    "        f_c1_rel = _safe_float(forget_js.get(\"circuito1_forget_rel\"))\n",
    "        f_c2_abs = _safe_float(forget_js.get(\"circuito2_forget_abs\"))\n",
    "        f_c2_rel = _safe_float(forget_js.get(\"circuito2_forget_rel\"))\n",
    "        avg_f_rel = _safe_float(forget_js.get(\"avg_forget_rel\"))\n",
    "        if all(math.isnan(x) for x in [f_c1_abs, f_c1_rel, f_c2_abs, f_c2_rel, avg_f_rel]):\n",
    "            comp = _compute_forgetting_from_eval_matrix(eval_df, per_task)\n",
    "            if comp:\n",
    "                f_c1_abs = comp.get(\"circuito1_forget_abs\", f_c1_abs)\n",
    "                f_c1_rel = comp.get(\"circuito1_forget_rel\", f_c1_rel)\n",
    "                f_c2_abs = comp.get(\"circuito2_forget_abs\", f_c2_abs)\n",
    "                f_c2_rel = comp.get(\"circuito2_forget_rel\", f_c2_rel)\n",
    "                avg_f_rel = comp.get(\"avg_forget_rel\", avg_f_rel)\n",
    "\n",
    "        row = dict(\n",
    "            run_dir=str(rd.relative_to(base_out)),\n",
    "            preset=meta[\"preset\"],\n",
    "            method=meta[\"method\"],\n",
    "            encoder=meta[\"encoder\"],\n",
    "            model=meta[\"model\"],\n",
    "            seed=meta[\"seed\"],\n",
    "            T=meta[\"T\"],\n",
    "            batch_size=meta[\"batch_size\"],\n",
    "            amp=meta[\"amp\"],\n",
    "            emissions_kg=eff_kg,\n",
    "            elapsed_sec=elapsed,\n",
    "            circuito1_best_mae=c1_best,\n",
    "            circuito1_final_mae=c1_final,\n",
    "            circuito2_best_mae=c2_best,\n",
    "            circuito2_final_mae=c2_final,\n",
    "            circuito1_forget_abs=f_c1_abs,\n",
    "            circuito1_forget_rel=f_c1_rel,\n",
    "            circuito2_forget_abs=f_c2_abs,\n",
    "            circuito2_forget_rel=f_c2_rel,\n",
    "            avg_forget_rel=avg_f_rel,\n",
    "        )\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Flags extra\n",
    "    df[\"is_new_runner\"] = df[\"run_dir\"].apply(lambda rd: (_abs_run_dir(rd) / \"run_row.json\").exists() or (_abs_run_dir(rd) / \"run_row.csv\").exists())\n",
    "    df[\"mtime\"] = df[\"run_dir\"].apply(run_mtime)\n",
    "    df[\"mtime_dt\"] = pd.to_datetime(df[\"mtime\"], unit=\"s\")\n",
    "    df[\"method_base\"] = df[\"method\"].astype(str).apply(canonical_method)\n",
    "\n",
    "    # Tipado num√©rico: EXCLUYE 'amp' (lo normalizamos como boolean m√°s abajo)\n",
    "    numeric_cols = [\n",
    "        \"seed\",\"T\",\"batch_size\",\"emissions_kg\",\"elapsed_sec\",\n",
    "        \"circuito1_best_mae\",\"circuito1_final_mae\",\"circuito2_best_mae\",\"circuito2_final_mae\",\n",
    "        \"circuito1_forget_abs\",\"circuito1_forget_rel\",\"circuito2_forget_abs\",\"circuito2_forget_rel\",\"avg_forget_rel\"\n",
    "    ]\n",
    "    for c in numeric_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # 'amp' como boolean (permite NA)\n",
    "    if \"amp\" in df.columns:\n",
    "        if df[\"amp\"].dtype == bool:\n",
    "            df[\"amp\"] = df[\"amp\"].astype(\"boolean\")\n",
    "        else:\n",
    "            df[\"amp\"] = df[\"amp\"].map(\n",
    "                lambda v: bool(v) if isinstance(v, (bool,int,float))\n",
    "                else (str(v).strip().lower() in {\"true\",\"1\",\"yes\",\"y\"} if isinstance(v, str) else pd.NA)\n",
    "            ).astype(\"boolean\")\n",
    "\n",
    "    out_csv = SUMMARY / \"results_table_fromdisk.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"[OK] results_table_fromdisk ‚Üí {out_csv} | filas:\", len(df))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eed5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Escaneando 144 runs en /home/cesar/proyectos/TFM_SNN/outputs\n",
      "[OK] results_table_fromdisk ‚Üí /home/cesar/proyectos/TFM_SNN/outputs/summary/paper_set_accurate_2025-11-06/results_table_fromdisk.csv | filas: 144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_dir</th>\n",
       "      <th>preset</th>\n",
       "      <th>method</th>\n",
       "      <th>encoder</th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>T</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>amp</th>\n",
       "      <th>emissions_kg</th>\n",
       "      <th>elapsed_sec</th>\n",
       "      <th>circuito1_best_mae</th>\n",
       "      <th>circuito1_final_mae</th>\n",
       "      <th>circuito2_best_mae</th>\n",
       "      <th>circuito2_final_mae</th>\n",
       "      <th>circuito1_forget_abs</th>\n",
       "      <th>circuito1_forget_rel</th>\n",
       "      <th>circuito2_forget_abs</th>\n",
       "      <th>circuito2_forget_rel</th>\n",
       "      <th>avg_forget_rel</th>\n",
       "      <th>is_new_runner</th>\n",
       "      <th>mtime</th>\n",
       "      <th>mtime_dt</th>\n",
       "      <th>method_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continual_fast_ewc_lam_5e+07_fast_ewc_l5e7_fb3...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_lam_5e+07</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>1921.457078</td>\n",
       "      <td>0.140196</td>\n",
       "      <td>0.231559</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>0.199714</td>\n",
       "      <td>0.091363</td>\n",
       "      <td>0.651682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325841</td>\n",
       "      <td>True</td>\n",
       "      <td>1.762962e+09</td>\n",
       "      <td>2025-11-12 15:38:42.516785860</td>\n",
       "      <td>ewc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continual_std_t16_sca-snn_bins50_beta0.5_bias0...</td>\n",
       "      <td>std_t16</td>\n",
       "      <td>sca-snn_bins50_beta0.5_bias0_temp0.3_ab16_flat0</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.019857</td>\n",
       "      <td>3250.495111</td>\n",
       "      <td>0.133684</td>\n",
       "      <td>0.171054</td>\n",
       "      <td>0.148702</td>\n",
       "      <td>0.148702</td>\n",
       "      <td>0.037370</td>\n",
       "      <td>0.279540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139770</td>\n",
       "      <td>True</td>\n",
       "      <td>1.762912e+09</td>\n",
       "      <td>2025-11-12 01:48:09.105263710</td>\n",
       "      <td>sca-snn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continual_accurate_as-snn_gr_0.35_lam_1+ewc_la...</td>\n",
       "      <td>accurate</td>\n",
       "      <td>as-snn_gr_0.35_lam_1+ewc_lam_3e+06</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.104576</td>\n",
       "      <td>17134.081986</td>\n",
       "      <td>0.114577</td>\n",
       "      <td>0.168029</td>\n",
       "      <td>0.134993</td>\n",
       "      <td>0.134993</td>\n",
       "      <td>0.053453</td>\n",
       "      <td>0.466526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233263</td>\n",
       "      <td>True</td>\n",
       "      <td>1.762663e+09</td>\n",
       "      <td>2025-11-09 04:32:20.479027271</td>\n",
       "      <td>as-snn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             run_dir    preset                                           method encoder                    model  seed     T  batch_size   amp  \\\n",
       "0  continual_fast_ewc_lam_5e+07_fast_ewc_l5e7_fb3...      fast                                    ewc_lam_5e+07    rate  PilotNetSNN_66x200_gray  42.0  12.0       320.0  True   \n",
       "1  continual_std_t16_sca-snn_bins50_beta0.5_bias0...   std_t16  sca-snn_bins50_beta0.5_bias0_temp0.3_ab16_flat0    rate  PilotNetSNN_66x200_gray  42.0  16.0       240.0  True   \n",
       "2  continual_accurate_as-snn_gr_0.35_lam_1+ewc_la...  accurate               as-snn_gr_0.35_lam_1+ewc_lam_3e+06    rate  PilotNetSNN_66x200_gray  42.0  30.0       160.0  True   \n",
       "\n",
       "   emissions_kg   elapsed_sec  circuito1_best_mae  circuito1_final_mae  circuito2_best_mae  circuito2_final_mae  circuito1_forget_abs  circuito1_forget_rel  circuito2_forget_abs  \\\n",
       "0      0.008511   1921.457078            0.140196             0.231559            0.199714             0.199714              0.091363              0.651682                   0.0   \n",
       "1      0.019857   3250.495111            0.133684             0.171054            0.148702             0.148702              0.037370              0.279540                   0.0   \n",
       "2      0.104576  17134.081986            0.114577             0.168029            0.134993             0.134993              0.053453              0.466526                   0.0   \n",
       "\n",
       "   circuito2_forget_rel  avg_forget_rel  is_new_runner         mtime                      mtime_dt method_base  \n",
       "0                   0.0        0.325841           True  1.762962e+09 2025-11-12 15:38:42.516785860         ewc  \n",
       "1                   0.0        0.139770           True  1.762912e+09 2025-11-12 01:48:09.105263710     sca-snn  \n",
       "2                   0.0        0.233263           True  1.762663e+09 2025-11-09 04:32:20.479027271      as-snn  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] NaNs globales: {'circuito1_best_mae': 6, 'circuito1_final_mae': 6, 'circuito2_best_mae': 6, 'circuito2_final_mae': 6, 'avg_forget_rel': 6}\n"
     ]
    }
   ],
   "source": [
    "# Celda 3 ‚Äî Construcci√≥n + diagn√≥stico NaNs\n",
    "\n",
    "df_all = build_results_table_from_disk(OUT)\n",
    "display(df_all.head(3))\n",
    "\n",
    "nan_cols = [\"circuito1_best_mae\",\"circuito1_final_mae\",\"circuito2_best_mae\",\"circuito2_final_mae\",\"avg_forget_rel\"]\n",
    "print(\"[DEBUG] NaNs globales:\", {c:int(df_all[c].isna().sum()) for c in nan_cols if c in df_all.columns})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735adae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] filtros duros ‚Üí inicio ‚Üí 144 runs | post ‚Üí 2 runs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_dir</th>\n",
       "      <th>preset</th>\n",
       "      <th>method</th>\n",
       "      <th>encoder</th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>T</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>amp</th>\n",
       "      <th>emissions_kg</th>\n",
       "      <th>elapsed_sec</th>\n",
       "      <th>circuito1_best_mae</th>\n",
       "      <th>circuito1_final_mae</th>\n",
       "      <th>circuito2_best_mae</th>\n",
       "      <th>circuito2_final_mae</th>\n",
       "      <th>circuito1_forget_abs</th>\n",
       "      <th>circuito1_forget_rel</th>\n",
       "      <th>circuito2_forget_abs</th>\n",
       "      <th>circuito2_forget_rel</th>\n",
       "      <th>avg_forget_rel</th>\n",
       "      <th>is_new_runner</th>\n",
       "      <th>mtime</th>\n",
       "      <th>mtime_dt</th>\n",
       "      <th>method_base</th>\n",
       "      <th>batch_size_filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>continual_std_sca-snn_bins50_beta0.5_bias0_tem...</td>\n",
       "      <td>std</td>\n",
       "      <td>sca-snn_bins50_beta0.5_bias0_temp0.5_ab24_flat0</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.05135</td>\n",
       "      <td>8414.727933</td>\n",
       "      <td>0.126052</td>\n",
       "      <td>0.149560</td>\n",
       "      <td>0.15464</td>\n",
       "      <td>0.15464</td>\n",
       "      <td>0.023509</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093250</td>\n",
       "      <td>True</td>\n",
       "      <td>1.762980e+09</td>\n",
       "      <td>2025-11-12 20:32:52.055903673</td>\n",
       "      <td>sca-snn</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>continual_std_sca-snn_bins50_beta0.45_bias-0.0...</td>\n",
       "      <td>std</td>\n",
       "      <td>sca-snn_bins50_beta0.45_bias-0.05_temp0.45_ab2...</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.05175</td>\n",
       "      <td>8417.328931</td>\n",
       "      <td>0.124160</td>\n",
       "      <td>0.170118</td>\n",
       "      <td>0.15719</td>\n",
       "      <td>0.15719</td>\n",
       "      <td>0.045958</td>\n",
       "      <td>0.370149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185075</td>\n",
       "      <td>True</td>\n",
       "      <td>1.762988e+09</td>\n",
       "      <td>2025-11-12 22:53:15.614697695</td>\n",
       "      <td>sca-snn</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               run_dir preset                                             method encoder                    model  seed     T  batch_size   amp  \\\n",
       "59   continual_std_sca-snn_bins50_beta0.5_bias0_tem...    std    sca-snn_bins50_beta0.5_bias0_temp0.5_ab24_flat0    rate  PilotNetSNN_66x200_gray  42.0  18.0       256.0  True   \n",
       "118  continual_std_sca-snn_bins50_beta0.45_bias-0.0...    std  sca-snn_bins50_beta0.45_bias-0.05_temp0.45_ab2...    rate  PilotNetSNN_66x200_gray  42.0  18.0       256.0  True   \n",
       "\n",
       "     emissions_kg  elapsed_sec  circuito1_best_mae  circuito1_final_mae  circuito2_best_mae  circuito2_final_mae  circuito1_forget_abs  circuito1_forget_rel  \\\n",
       "59        0.05135  8414.727933            0.126052             0.149560             0.15464              0.15464              0.023509              0.186500   \n",
       "118       0.05175  8417.328931            0.124160             0.170118             0.15719              0.15719              0.045958              0.370149   \n",
       "\n",
       "     circuito2_forget_abs  circuito2_forget_rel  avg_forget_rel  is_new_runner         mtime                      mtime_dt method_base  batch_size_filled  \n",
       "59                    0.0                   0.0        0.093250           True  1.762980e+09 2025-11-12 20:32:52.055903673     sca-snn              256.0  \n",
       "118                   0.0                   0.0        0.185075           True  1.762988e+09 2025-11-12 22:53:15.614697695     sca-snn              256.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Selecci√≥n final: 2 runs | estrategia: {'estrategia': 'strict:model+T(+amp+batch)', 'kept': 2, 'dropped': 0}\n",
      "[OK] Selecci√≥n ‚Üí /home/cesar/proyectos/TFM_SNN/outputs/summary/paper_set_accurate_2025-11-06/selection_table.csv\n"
     ]
    }
   ],
   "source": [
    "# Celda 4 ‚Äî Selecci√≥n y comparabilidad\n",
    "\n",
    "def _filter_paperset(df: pd.DataFrame, require_both_tasks: bool = True) -> pd.DataFrame:\n",
    "    m = df.copy()\n",
    "    if PRESET_KEEP:\n",
    "        m = m[m[\"preset\"].isin(PRESET_KEEP)]\n",
    "    if ENCODER_KEEP:\n",
    "        m = m[m[\"encoder\"].isin(ENCODER_KEEP)]\n",
    "    if SEED_KEEP:\n",
    "        m = m[m[\"seed\"].isin(SEED_KEEP)]\n",
    "    if METHODS_KEEP:\n",
    "        m = m[m[\"method_base\"].isin(METHODS_KEEP)]\n",
    "    if ONLY_NEW_RUNNER:\n",
    "        m = m[m[\"is_new_runner\"] == True]\n",
    "    if MTIME_FROM is not None:\n",
    "        m = m[m[\"mtime_dt\"] >= MTIME_FROM]\n",
    "\n",
    "    # Runs con ambas tareas evaluadas (mejor y final). Evita arrastrar runs truncados.\n",
    "    if require_both_tasks:\n",
    "        must_cols = [\"circuito1_best_mae\",\"circuito1_final_mae\",\"circuito2_best_mae\",\"circuito2_final_mae\"]\n",
    "        for c in must_cols:\n",
    "            if c in m.columns:\n",
    "                m = m[~m[c].isna()]\n",
    "\n",
    "    print(f\"[DEBUG] filtros duros ‚Üí inicio ‚Üí {len(df)} runs | post ‚Üí {len(m)} runs\")\n",
    "    return m\n",
    "\n",
    "def _comparability_slice(df: pd.DataFrame, strict: bool = True):\n",
    "    if df.empty:\n",
    "        return df, {\"estrategia\":\"empty\", \"kept\":0, \"dropped\":0}\n",
    "    # Siempre mismo modelo y mismo T\n",
    "    modes_model = df[\"model\"].dropna().unique().tolist()\n",
    "    modes_T     = df[\"T\"].dropna().unique().tolist()\n",
    "    if len(modes_model) > 1:\n",
    "        top_model = df[\"model\"].value_counts().idxmax()\n",
    "        df = df[df[\"model\"] == top_model]\n",
    "    if len(modes_T) > 1:\n",
    "        top_T = df[\"T\"].value_counts().idxmax()\n",
    "        df = df[df[\"T\"] == top_T]\n",
    "\n",
    "    kept_before = len(df)\n",
    "    if strict:\n",
    "        # AMP mayoritario (si hay), manteniendo NaN\n",
    "        if df[\"amp\"].notna().any():\n",
    "            top_amp = df[\"amp\"].value_counts(dropna=True).idxmax()\n",
    "            df = df[(df[\"amp\"].isna()) | (df[\"amp\"] == top_amp)]\n",
    "        # batch_size mayoritario (si hay), manteniendo NaN\n",
    "        if df[\"batch_size\"].notna().any():\n",
    "            top_bs = df[\"batch_size\"].value_counts(dropna=True).idxmax()\n",
    "            df = df[(df[\"batch_size\"].isna()) | (df[\"batch_size\"] == top_bs)]\n",
    "        strategy = \"strict:model+T(+amp+batch)\"\n",
    "    else:\n",
    "        strategy = \"relaxed:model+T\"\n",
    "\n",
    "    kept_after = len(df)\n",
    "    return df, {\"estrategia\": strategy, \"kept\": kept_after, \"dropped\": kept_before - kept_after}\n",
    "\n",
    "df_sel0 = _filter_paperset(df_all, require_both_tasks=True)\n",
    "df_sel, stats = _comparability_slice(df_sel0, strict=STRICT_CFG)\n",
    "if df_sel.empty and STRICT_CFG:\n",
    "    print(\"[WARN] Comparabilidad dej√≥ 0 runs. Relajando AMP y batch_size‚Ä¶\")\n",
    "    df_sel, stats = _comparability_slice(df_sel0, strict=False)\n",
    "\n",
    "# Copia para informes (se puede filtrar naive aqu√≠ si se desea solo de cara a tablas/plots)\n",
    "df_sel[\"batch_size_filled\"] = df_sel[\"batch_size\"].copy()\n",
    "df_report = df_sel.copy()\n",
    "if IGNORE_NAIVE_IN_REPORTS and \"method_base\" in df_report.columns:\n",
    "    df_report = df_report[df_report[\"method_base\"] != \"naive\"]\n",
    "\n",
    "display(df_sel.head(10))\n",
    "print(f\"[OK] Selecci√≥n final: {len(df_sel)} runs | estrategia: {stats}\")\n",
    "out_csv = SUMMARY / \"selection_table.csv\"\n",
    "df_sel.to_csv(out_csv, index=False)\n",
    "print(\"[OK] Selecci√≥n ‚Üí\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c8b134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Winners ‚Üí /home/cesar/proyectos/TFM_SNN/outputs/summary/paper_set_accurate_2025-11-06/winners_per_methodbase.csv | candidatos=2 | grupos=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_dir</th>\n",
       "      <th>method_base</th>\n",
       "      <th>seed</th>\n",
       "      <th>circuito2_final_mae</th>\n",
       "      <th>avg_forget_rel</th>\n",
       "      <th>emissions_kg</th>\n",
       "      <th>score_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>continual_std_sca-snn_bins50_beta0.5_bias0_tem...</td>\n",
       "      <td>sca-snn</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.15464</td>\n",
       "      <td>0.09325</td>\n",
       "      <td>0.05135</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              run_dir method_base  seed  circuito2_final_mae  avg_forget_rel  emissions_kg  score_eff\n",
       "59  continual_std_sca-snn_bins50_beta0.5_bias0_tem...     sca-snn  42.0              0.15464         0.09325       0.05135        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 5 ‚Äî Ranking compuesto + winners por m√©todo (versi√≥n robusta)\n",
    "\n",
    "def _ensure_mae_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Crea alias entre c2_final_mae y circuito2_final_mae si falta alguno.\"\"\"\n",
    "    df = df.copy()\n",
    "    has_c2    = \"c2_final_mae\" in df.columns\n",
    "    has_circ2 = \"circuito2_final_mae\" in df.columns\n",
    "    if has_c2 and not has_circ2:\n",
    "        df[\"circuito2_final_mae\"] = df[\"c2_final_mae\"]\n",
    "    elif has_circ2 and not has_c2:\n",
    "        df[\"c2_final_mae\"] = df[\"circuito2_final_mae\"]\n",
    "    return df\n",
    "\n",
    "def _minmax_norm(s: pd.Series) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    if s.size == 0:\n",
    "        return s\n",
    "    vals = s.values.astype(float)\n",
    "    finite = np.isfinite(vals)\n",
    "    if finite.sum() == 0:\n",
    "        return pd.Series(np.full(len(s), np.nan), index=s.index)\n",
    "    lo, hi = float(np.nanmin(vals)), float(np.nanmax(vals))\n",
    "    if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:\n",
    "        out = np.zeros(len(s), dtype=float)\n",
    "        out[~finite] = np.nan\n",
    "        return pd.Series(out, index=s.index)\n",
    "    return (s - lo) / (hi - lo)\n",
    "\n",
    "# 1) Copia y compatibilidad de columnas\n",
    "df_rank = _ensure_mae_columns(df_report)\n",
    "\n",
    "# Columnas clave\n",
    "MAE_COL  = \"circuito2_final_mae\"\n",
    "FORG_COL = \"avg_forget_rel\"\n",
    "\n",
    "# 2) Si est√° vac√≠o, escribe CSV vac√≠o y sal con aviso\n",
    "if df_rank.empty:\n",
    "    winners = df_rank.copy()\n",
    "    out_csv = SUMMARY / \"winners_per_method.csv\"\n",
    "    winners.to_csv(out_csv, index=False)\n",
    "    print(\"[WARN] df_rank est√° vac√≠o tras filtros. Winners vac√≠o ‚Üí\", out_csv)\n",
    "    display(winners)  # DF vac√≠o\n",
    "else:\n",
    "    mae_norm  = _minmax_norm(df_rank[MAE_COL]  if MAE_COL  in df_rank.columns else pd.Series([], dtype=float))\n",
    "    forg_norm = _minmax_norm(df_rank[FORG_COL] if FORG_COL in df_rank.columns else pd.Series([], dtype=float))\n",
    "\n",
    "    score_comp = ALPHA_COMPOSITE * mae_norm + (1 - ALPHA_COMPOSITE) * forg_norm\n",
    "    score_eff  = score_comp.copy()\n",
    "    if len(score_eff) != 0:\n",
    "        score_eff[forg_norm.isna()] = mae_norm[forg_norm.isna()]  # fallback\n",
    "\n",
    "    df_rank[\"score_comp\"] = score_comp\n",
    "    df_rank[\"score_eff\"]  = score_eff\n",
    "\n",
    "    # Agrupaci√≥n: por m√©todo base o por m√©todo completo (separa composites)\n",
    "    group_col = \"method\" if GROUP_BY_FULL_METHOD else \"method_base\"\n",
    "    if group_col not in df_rank.columns:\n",
    "        df_rank[group_col] = df_rank[\"method\"] if \"method\" in df_rank.columns else \"unknown\"\n",
    "\n",
    "    # Winners\n",
    "    if df_rank[\"score_eff\"].notna().any():\n",
    "        winners = (\n",
    "            df_rank\n",
    "            .sort_values([group_col, \"score_eff\", MAE_COL], ascending=[True, True, True])\n",
    "            .groupby(group_col, as_index=False)\n",
    "            .head(1)\n",
    "            .sort_values(\"score_eff\", ascending=True)\n",
    "        )\n",
    "    else:\n",
    "        winners = (\n",
    "            df_rank\n",
    "            .sort_values([group_col, MAE_COL], ascending=[True, True])\n",
    "            .groupby(group_col, as_index=False)\n",
    "            .head(1)\n",
    "        )\n",
    "\n",
    "    # Export\n",
    "    out_csv = SUMMARY / f\"winners_per_{'fullmethod' if GROUP_BY_FULL_METHOD else 'methodbase'}.csv\"\n",
    "    winners.to_csv(out_csv, index=False)\n",
    "\n",
    "    n_rows = len(df_rank)\n",
    "    n_groups = df_rank[group_col].nunique()\n",
    "    print(f\"[OK] Winners ‚Üí {out_csv} | candidatos={n_rows} | grupos={n_groups}\")\n",
    "    cols_show = [c for c in [\"run_dir\", group_col, \"seed\", MAE_COL, FORG_COL, \"emissions_kg\", \"score_eff\"] if c in winners.columns]\n",
    "    display(winners[cols_show] if cols_show else winners)\n",
    "\n",
    "# Mant√©n \"winners\" en el entorno por si otras celdas lo usan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d914cd31",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__key__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_103166/1894149474.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m     36\u001b[39m \n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RELATIVE_BASELINE:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     df_rel = compute_relative_to_baseline(df_sel, baseline=RELATIVE_BASELINE, strict=BASELINE_MATCH_STRICT)\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m df_rel \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     41\u001b[39m         out_csv = SUMMARY / f\"relative_to_{RELATIVE_BASELINE}.csv\"\n\u001b[32m     42\u001b[39m         df_rel.to_csv(out_csv, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m/tmp/ipykernel_103166/1894149474.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df_in, baseline, strict)\u001b[39m\n\u001b[32m     28\u001b[39m             \u001b[33m\"baseline_forget\"\u001b[39m: float(row[\u001b[33m\"avg_forget_rel\"\u001b[39m])\n\u001b[32m     29\u001b[39m         })\n\u001b[32m     30\u001b[39m     base_tbl = pd.DataFrame(base_rows)\n\u001b[32m     31\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     out = dfb.merge(base_tbl, on=\u001b[33m\"__key__\"\u001b[39m, how=\u001b[33m\"left\"\u001b[39m)\n\u001b[32m     33\u001b[39m     out[\u001b[33m\"delta_mae_vs_base\"\u001b[39m]    = out[\u001b[33m\"circuito2_final_mae\"\u001b[39m] - out[\u001b[33m\"baseline_mae\"\u001b[39m]\n\u001b[32m     34\u001b[39m     out[\u001b[33m\"delta_forget_vs_base\"\u001b[39m] = out[\u001b[33m\"avg_forget_rel\"\u001b[39m]      - out[\u001b[33m\"baseline_forget\"\u001b[39m]\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[32m~/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10835\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10836\u001b[39m     ) -> DataFrame:\n\u001b[32m  10837\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10838\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10839\u001b[39m         return merge(\n\u001b[32m  10840\u001b[39m             self,\n\u001b[32m  10841\u001b[39m             right,\n\u001b[32m  10842\u001b[39m             how=how,\n",
      "\u001b[32m~/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32m~/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32m~/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1296\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1297\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1299\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1300\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1301\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32m~/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: '__key__'"
     ]
    }
   ],
   "source": [
    "# Celda 5.1 ‚Äî Deltas relativos vs baseline (para narrativa TFM)\n",
    "\n",
    "def _row_key_for_match(r):\n",
    "    \"\"\"Clave de emparejamiento para baseline estricto.\"\"\"\n",
    "    return (\n",
    "        r.get(\"preset\"), r.get(\"encoder\"), r.get(\"model\"), r.get(\"T\"),\n",
    "        r.get(\"amp\"), r.get(\"batch_size\"), r.get(\"seed\")\n",
    "    )\n",
    "\n",
    "def compute_relative_to_baseline(df_in: pd.DataFrame, baseline=\"naive\", strict=True):\n",
    "    if not baseline:\n",
    "        return None\n",
    "    dfb = df_in.copy()\n",
    "    dfb[\"__key__\"] = dfb.apply(\n",
    "        lambda r: (r.get(\"preset\"), r.get(\"encoder\"), r.get(\"model\"), r.get(\"T\"),\n",
    "                   r.get(\"amp\"), r.get(\"batch_size\"), r.get(\"seed\")), axis=1)\n",
    "\n",
    "    # Para cada clave, escoge el run baseline con menor MAE y usa sus dos m√©tricas\n",
    "    base_rows = []\n",
    "    for key, g in dfb[dfb[\"method_base\"].astype(str).str.lower() == baseline.lower()].groupby(\"__key__\"):\n",
    "        if g.empty: \n",
    "            continue\n",
    "        idx = g[\"circuito2_final_mae\"].astype(float).idxmin()\n",
    "        row = g.loc[idx]\n",
    "        base_rows.append({\n",
    "            \"__key__\": key,\n",
    "            \"baseline_mae\": float(row[\"circuito2_final_mae\"]),\n",
    "            \"baseline_forget\": float(row[\"avg_forget_rel\"])\n",
    "        })\n",
    "    base_tbl = pd.DataFrame(base_rows)\n",
    "\n",
    "    out = dfb.merge(base_tbl, on=\"__key__\", how=\"left\")\n",
    "    out[\"delta_mae_vs_base\"]    = out[\"circuito2_final_mae\"] - out[\"baseline_mae\"]\n",
    "    out[\"delta_forget_vs_base\"] = out[\"avg_forget_rel\"]      - out[\"baseline_forget\"]\n",
    "    return out\n",
    "\n",
    "\n",
    "if RELATIVE_BASELINE:\n",
    "    df_rel = compute_relative_to_baseline(df_sel, baseline=RELATIVE_BASELINE, strict=BASELINE_MATCH_STRICT)\n",
    "    if df_rel is not None:\n",
    "        out_csv = SUMMARY / f\"relative_to_{RELATIVE_BASELINE}.csv\"\n",
    "        df_rel.to_csv(out_csv, index=False)\n",
    "        print(f\"[OK] Relative-to-baseline ‚Üí {out_csv}\")\n",
    "        # Top-10 mejoras vs baseline (orden: delta_mae luego delta_forget)\n",
    "        mask_has_base = (~df_rel[\"baseline_mae\"].isna()) & (~df_rel[\"baseline_forget\"].isna())\n",
    "        top_improve = (df_rel[mask_has_base]\n",
    "                       .sort_values([\"delta_mae_vs_base\",\"delta_forget_vs_base\"], ascending=[True, True])\n",
    "                       .head(10))\n",
    "        cols_show = [\"run_dir\",\"method\",\"method_base\",\"circuito2_final_mae\",\"avg_forget_rel\",\n",
    "                     \"baseline_mae\",\"baseline_forget\",\"delta_mae_vs_base\",\"delta_forget_vs_base\"]\n",
    "        display(top_improve[cols_show])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6 ‚Äî Top-N global y Pareto (versi√≥n robusta)\n",
    "\n",
    "# helpers (por si no vienes de la Celda 5)\n",
    "try:\n",
    "    _ = _ensure_mae_columns\n",
    "except NameError:\n",
    "    def _ensure_mae_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        has_c2 = \"c2_final_mae\" in df.columns\n",
    "        has_circ2 = \"circuito2_final_mae\" in df.columns\n",
    "        if has_c2 and not has_circ2:\n",
    "            df[\"circuito2_final_mae\"] = df[\"c2_final_mae\"]\n",
    "        elif has_circ2 and not has_c2:\n",
    "            df[\"c2_final_mae\"] = df[\"circuito2_final_mae\"]\n",
    "        return df\n",
    "\n",
    "df_rank = _ensure_mae_columns(df_report if \"df_report\" in globals() else df_sel.copy())\n",
    "if \"score_eff\" not in df_rank.columns:\n",
    "    df_rank = df_rank.copy()\n",
    "    df_rank[\"score_eff\"] = np.nan\n",
    "if \"method_base\" not in df_rank.columns:\n",
    "    df_rank[\"method_base\"] = df_rank[\"method\"] if \"method\" in df_rank.columns else \"unknown\"\n",
    "\n",
    "MAE_COL = \"circuito2_final_mae\" if \"circuito2_final_mae\" in df_rank.columns else (\"c2_final_mae\" if \"c2_final_mae\" in df_rank.columns else \"circuito2_final_mae\")\n",
    "\n",
    "# Top-N compuesto\n",
    "TOPN = 6\n",
    "if df_rank.empty:\n",
    "    topn = df_rank.copy()\n",
    "    print(\"[WARN] df_rank est√° vac√≠o; Top-N vac√≠o.\")\n",
    "else:\n",
    "    cols_sort = [c for c in [\"score_eff\", MAE_COL] if c in df_rank.columns]\n",
    "    if not cols_sort:\n",
    "        topn = df_rank.head(TOPN)\n",
    "    else:\n",
    "        topn = df_rank.sort_values(cols_sort, ascending=[True] * len(cols_sort)).head(TOPN)\n",
    "out_csv = SUMMARY / \"top6_composite.csv\"\n",
    "topn.to_csv(out_csv, index=False)\n",
    "print(\"[OK] Top-6 ‚Üí\", out_csv)\n",
    "cols_show = [c for c in [\"run_dir\",\"method_base\",\"seed\",MAE_COL,\"avg_forget_rel\",\"emissions_kg\",\"score_eff\"] if c in topn.columns]\n",
    "display(topn[cols_show] if cols_show else topn)\n",
    "\n",
    "# Pareto (minimiza MAE y olvido); NaN -> +inf para no dominar\n",
    "tmp = _ensure_mae_columns(df_report.copy())\n",
    "if \"method_base\" not in tmp.columns:\n",
    "    tmp[\"method_base\"] = tmp[\"method\"] if \"method\" in tmp.columns else \"unknown\"\n",
    "if MAE_COL not in tmp.columns:\n",
    "    tmp[MAE_COL] = np.nan\n",
    "\n",
    "tmp[\"_olvido_for_pareto\"] = pd.to_numeric(tmp.get(\"avg_forget_rel\", np.nan), errors=\"coerce\")\n",
    "tmp.loc[tmp[\"_olvido_for_pareto\"].isna(), \"_olvido_for_pareto\"] = np.inf\n",
    "tmp[\"_mae_for_pareto\"] = pd.to_numeric(tmp.get(MAE_COL, np.nan), errors=\"coerce\")\n",
    "tmp.loc[tmp[\"_mae_for_pareto\"].isna(), \"_mae_for_pareto\"] = np.inf\n",
    "\n",
    "pareto_idx = []\n",
    "vals = tmp[[\"_mae_for_pareto\", \"_olvido_for_pareto\"]].values\n",
    "for i in range(len(tmp)):\n",
    "    mae_i, forg_i = vals[i]\n",
    "    dominated = False\n",
    "    for j in range(len(tmp)):\n",
    "        if j == i: continue\n",
    "        mae_j, forg_j = vals[j]\n",
    "        if (mae_j <= mae_i) and (forg_j <= forg_i) and ((mae_j < mae_i) or (forg_j < forg_i)):\n",
    "            dominated = True\n",
    "            break\n",
    "    if not dominated:\n",
    "        pareto_idx.append(i)\n",
    "\n",
    "df_pareto = tmp.iloc[pareto_idx].drop(columns=[\"_olvido_for_pareto\", \"_mae_for_pareto\"])\n",
    "out_csv = SUMMARY / \"pareto.csv\"\n",
    "df_pareto.to_csv(out_csv, index=False)\n",
    "print(\"[OK] Pareto ‚Üí\", out_csv)\n",
    "cols_show = [c for c in [\"run_dir\",\"method_base\",MAE_COL,\"avg_forget_rel\"] if c in df_pareto.columns]\n",
    "display(df_pareto[cols_show] if cols_show else df_pareto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7 ‚Äî Scatter MAE vs Olvido\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _scatter(df, title, out_png: Path):\n",
    "    x = pd.to_numeric(df[\"avg_forget_rel\"], errors=\"coerce\")\n",
    "    y = pd.to_numeric(df[\"circuito2_final_mae\"], errors=\"coerce\")\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.scatter(x, y)  # sin estilos ni colores espec√≠ficos\n",
    "    plt.xlabel(\"avg_forget_rel (‚Üì mejor)\")\n",
    "    plt.ylabel(\"circuito2_final_mae (‚Üì mejor)\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "_scatter(df_sel, \"Todos\", SUMMARY / \"scatter_all.png\")\n",
    "_scatter(winners if \"winners\" in globals() else df_sel.head(0), \"Winners por m√©todo\", SUMMARY / \"scatter_winners.png\")\n",
    "print(\"[OK] Scatter ‚Üí\", SUMMARY / \"scatter_all.png\")\n",
    "print(\"[OK] Scatter ‚Üí\", SUMMARY / \"scatter_winners.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8 ‚Äî Trazabilidad por run\n",
    "\n",
    "def explain_sources(run_row):\n",
    "    rd = _abs_run_dir(run_row[\"run_dir\"])\n",
    "    exists = {\n",
    "        \"per_task_perf.json\": (rd / \"per_task_perf.json\").exists(),\n",
    "        \"per_task_perf.csv\":  (rd / \"per_task_perf.csv\").exists(),\n",
    "        \"forgetting.json\":    (rd / \"forgetting.json\").exists(),\n",
    "        \"eval_matrix.csv\":    (rd / \"eval_matrix.csv\").exists(),\n",
    "        \"eval_matrix.json\":   (rd / \"eval_matrix.json\").exists(),\n",
    "        \"efficiency_summary.json\": (rd / \"efficiency_summary.json\").exists(),\n",
    "        \"emissions.csv\":      (rd / \"emissions.csv\").exists(),\n",
    "        \"run_row.json\":       (rd / \"run_row.json\").exists(),\n",
    "        \"task_1_circuito1/manifest.json\": (rd / \"task_1_circuito1/manifest.json\").exists(),\n",
    "    }\n",
    "    return exists\n",
    "\n",
    "print(\"## NaN en selecci√≥n ##\")\n",
    "cols_check = [\"circuito1_best_mae\",\"circuito1_final_mae\",\"circuito2_final_mae\",\"avg_forget_rel\"]\n",
    "mask_nans = df_sel[cols_check].isna().any(axis=1)\n",
    "df_nans = df_sel[mask_nans].copy()\n",
    "print(f\"[INFO] {len(df_nans)} runs con NaN en {cols_check}:\")\n",
    "display(df_nans[[\"run_dir\",\"method_base\",\"preset\",\"encoder\",\"seed\",\"T\",\"amp\",\"batch_size\"] + cols_check] if len(df_nans) else df_nans)\n",
    "\n",
    "for _, r in df_sel.iterrows():\n",
    "    ex = explain_sources(r)\n",
    "    ok_flags = \" | \".join([f\"{k} ‚Üí {'OK' if v else 'NO'}\" for k,v in ex.items()])\n",
    "    print(f\"‚Äî {r['run_dir']}\\n    {ok_flags}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 9 ‚Äî Sanidad naive vs CL\n",
    "\n",
    "DF = df_sel.copy()\n",
    "agg = (\n",
    "    DF.groupby(\"method_base\", dropna=False)\n",
    "      .agg(forget_median=(\"avg_forget_rel\",\"median\"),\n",
    "           forget_mean=(\"avg_forget_rel\",\"mean\"),\n",
    "           mae_mean=(\"circuito2_final_mae\",\"mean\"),\n",
    "           runs=(\"run_dir\",\"count\"))\n",
    "      .reset_index()\n",
    ")\n",
    "display(agg)\n",
    "\n",
    "naive_med = agg.loc[agg[\"method_base\"]==\"naive\",\"forget_median\"].values\n",
    "cl_med    = agg.loc[agg[\"method_base\"]!=\"naive\",\"forget_median\"].median()\n",
    "print(f\"[CHECK] naive_median_forget={naive_med[0] if len(naive_med) else np.nan} vs CL_median={cl_med}\")\n",
    "if len(naive_med) and (np.isnan(naive_med[0]) or (not np.isnan(cl_med) and naive_med[0] <= cl_med)):\n",
    "    print(\"[WARN] Naive NO olvida m√°s que CL. Revisa eval_matrix/forgetting.json o implementaci√≥n.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 9b ‚Äî Sanity-check EWC (parse logs en carpetas de run)\n",
    "\n",
    "import glob\n",
    "\n",
    "def _find_log_files(run_dir: Path):\n",
    "    pats = [\"*.log\", \"stdout*.txt\", \"train*.log\"]\n",
    "    files = []\n",
    "    for p in pats:\n",
    "        files += list(run_dir.glob(p))\n",
    "        files += list((run_dir / \"task_1_circuito1\").glob(p))\n",
    "        files += list((run_dir / \"task_2_circuito2\").glob(p))\n",
    "    return files\n",
    "\n",
    "def _parse_ewc_lines(text: str):\n",
    "    # Busca l√≠neas del estilo: [EWC] base=... | pen=... | pen/base=...\n",
    "    bases, pens, ratios = [], [], []\n",
    "    for line in text.splitlines():\n",
    "        if \"[EWC]\" in line:\n",
    "            # intenta extraer n√∫meros\n",
    "            try:\n",
    "                # formato flexible\n",
    "                # ej: [EWC] base=0.007436 | pen=0 | pen/base=0.000\n",
    "                m_base = re.search(r\"base\\s*=\\s*([0-9.eE+-]+)\", line)\n",
    "                m_pen  = re.search(r\"pen\\s*=\\s*([0-9.eE+-]+)\", line)\n",
    "                m_rat  = re.search(r\"pen/base\\s*=\\s*([0-9.eE+-]+)\", line)\n",
    "                if m_base: bases.append(float(m_base.group(1)))\n",
    "                if m_pen:  pens.append(float(m_pen.group(1)))\n",
    "                if m_rat:  ratios.append(float(m_rat.group(1)))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return bases, pens, ratios\n",
    "\n",
    "rows = []\n",
    "for _, r in df_sel.iterrows():\n",
    "    if not str(r.get(\"method\",\"\")).lower().startswith(\"ewc\") and \"ewc\" not in str(r.get(\"method\",\"\")).lower():\n",
    "        continue\n",
    "    rd = _abs_run_dir(r[\"run_dir\"])\n",
    "    logs = _find_log_files(rd)\n",
    "    all_bases, all_pens, all_ratios = [], [], []\n",
    "    for lf in logs:\n",
    "        try:\n",
    "            txt = lf.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "            b, p, q = _parse_ewc_lines(txt)\n",
    "            all_bases += b; all_pens += p; all_ratios += q\n",
    "        except Exception:\n",
    "            pass\n",
    "    rows.append({\n",
    "        \"run_dir\": r[\"run_dir\"],\n",
    "        \"has_logs\": len(logs) > 0,\n",
    "        \"pen_gt0_count\": int(sum(1 for x in all_pens if (isinstance(x,float) and x > 0))),\n",
    "        \"pen_entries\": len(all_pens),\n",
    "        \"ratio_gt0_count\": int(sum(1 for x in all_ratios if (isinstance(x,float) and x > 0))),\n",
    "        \"ratio_entries\": len(all_ratios),\n",
    "    })\n",
    "\n",
    "df_ewc_sanity = pd.DataFrame(rows)\n",
    "out_csv = SUMMARY / \"ewc_sanity.csv\"\n",
    "df_ewc_sanity.to_csv(out_csv, index=False)\n",
    "print(\"[OK] EWC sanity ‚Üí\", out_csv)\n",
    "display(df_ewc_sanity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c61ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 10 ‚Äî Export final\n",
    "print(\"[OK] Artifacts en:\", SUMMARY)\n",
    "for p in sorted(SUMMARY.glob(\"*.csv\")) + sorted(SUMMARY.glob(\"*.png\")):\n",
    "    print(\" -\", p.name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
