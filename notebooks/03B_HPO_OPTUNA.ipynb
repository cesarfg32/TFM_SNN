{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9f0dc7",
   "metadata": {},
   "source": [
    "# 03B ‚Äî B√∫squeda de hiperpar√°metros con Optuna (Continual Learning)\n",
    "\n",
    "Este cuaderno automatiza la **optimizaci√≥n de hiperpar√°metros (HPO)** para m√©todos de aprendizaje continuo:\n",
    "- **naive** (baseline, sin HPs),\n",
    "- **ewc** (Elastic Weight Consolidation),\n",
    "- **rehearsal** (rejuego con buffer),\n",
    "- **rehearsal+ewc** (combinaci√≥n).\n",
    "\n",
    "Se apoya en:\n",
    "- `configs/presets.yaml` (misma configuraci√≥n que el resto de notebooks),\n",
    "- `build_make_loader_fn` (carga CSV+runtime o H5 offline),\n",
    "- `run_continual` (entrena & eval√∫a y guarda m√©tricas).\n",
    "\n",
    "---\n",
    "\n",
    "### M√©trica objetivo (minimizar)\n",
    "\n",
    "$$\n",
    "\\textbf{Objetivo}\n",
    "= \\mathrm{MAE}_{\\text{tarea final}}\n",
    "+ \\alpha \\cdot \\max\\!\\bigl(0,\\, \\text{OlvidoRelativo}\\,\\%\\bigr)\n",
    "$$\n",
    "\n",
    "\n",
    "- **MAE_tarea final**: error en la **√∫ltima** tarea (queremos aprender bien lo nuevo).\n",
    "- **OlvidoRelativo %**: cu√°nto **empeora** la primera tarea tras aprender la segunda.\n",
    "- **Œ±**: peso del olvido (por defecto 0.5). Sube Œ± si quieres penalizar m√°s el olvido.\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "- `pip install optuna`\n",
    "- Datos preparados (`tasks.json` o `tasks_balanced.json`).\n",
    "- Idealmente H5 offline si `use_offline_spikes: true` en el preset.\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "- [1) Imports y setup](#sec-01)\n",
    "- [2) Carga de preset y construcci√≥n de modelo/transform](#sec-02)\n",
    "- [3) Tareas y factory de loaders](#sec-03)\n",
    "- [4) M√©tricas y objetivo para Optuna](#sec-04)\n",
    "- [5) Espacios de b√∫squeda (por m√©todo)](#sec-05)\n",
    "- [6) Estudio Optuna ‚Äî un m√©todo concreto](#sec-06)\n",
    "- [7) Estudio Optuna conjunto (elige m√©todo + HPs)](#sec-07)\n",
    "- [8) Re-entrena con los mejores hiperpar√°metros](#sec-08)\n",
    "- [9) Resumen r√°pido de runs (tabla)](#sec-09)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> **Consejo**: empieza con el preset `fast` y `N_TRIALS` peque√±o; si todo va bien, sube `N_TRIALS` y/o las `epochs`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5bd35d",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "\n",
    "## 1) Imports y setup de entorno\n",
    "\n",
    "- Limitamos hilos BLAS (`OMP`, `MKL`, `OPENBLAS`) para evitar sobrecarga de CPU.\n",
    "- Configuramos **CUDA/TF32** para acelerar en GPUs NVIDIA.\n",
    "- Insertamos la **ra√≠z del repo** en `sys.path` para importar m√≥dulos locales.\n",
    "- Comprobamos el **dispositivo** (`cuda`/`cpu`).\n",
    "\n",
    "> Si notas que el equipo va justo de CPU, baja `torch.set_num_threads(4)` a `2`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbd7d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Limitar threads BLAS (opcional)\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, copy, time\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "# Ra√≠z del repo y sys.path\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Proyecto\n",
    "from src.utils import load_preset, build_make_loader_fn\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import build_model\n",
    "from src.runner import run_continual\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14b25c",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "\n",
    "## 2) Carga de preset y construcci√≥n de modelo/transform\n",
    "\n",
    "- `PRESET` se carga desde `configs/presets.yaml`.\n",
    "- Extraemos:\n",
    "  - **Modelo** y el **transform** de imagen (`ImageTransform`) acorde a `img_w`, `img_h`, `to_gray`.\n",
    "  - Par√°metros de **codificaci√≥n temporal** (`encoder`, `T`, `gain`) y **semilla**.\n",
    "  - Flags de **carga de datos**: `use_offline_spikes` (H5), `encode_runtime` (codifica en GPU), `use_offline_balanced`.\n",
    "  - Par√°metros del **DataLoader** (workers, prefetch, pin_memory, etc.) y **balanceo online**.\n",
    "\n",
    "- `make_model_fn(tfm)` devuelve el modelo (por ejemplo, `pilotnet_snn` con `beta/threshold`).\n",
    "\n",
    "> Mantener aqu√≠ la **fuente de la verdad** del experimento (preset) ahorra inconsistencias respecto a otros notebooks.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61aef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRESET=fast] model=pilotnet_snn 200x66 gray=True\n",
      "[DATA] encoder=rate T=10 gain=0.5 seed=42\n",
      "[LOADER] workers=8 prefetch=2 pin=True persistent=True\n",
      "[BALANCE] offline=False online=False bins=50\n",
      "[RUNTIME_ENCODE] False | [OFFLINE_SPIKES] True\n"
     ]
    }
   ],
   "source": [
    "PRESET = \"fast\"  # fast | std | accurate\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# Modelo / tfm\n",
    "MODEL_NAME = CFG[\"model\"][\"name\"]\n",
    "tfm = ImageTransform(\n",
    "    CFG[\"model\"][\"img_w\"],\n",
    "    CFG[\"model\"][\"img_h\"],\n",
    "    to_gray=bool(CFG[\"model\"][\"to_gray\"]),\n",
    "    crop_top=None\n",
    ")\n",
    "\n",
    "# Datos / codificaci√≥n temporal\n",
    "ENCODER = CFG[\"data\"][\"encoder\"]\n",
    "T       = int(CFG[\"data\"][\"T\"])\n",
    "GAIN    = float(CFG[\"data\"][\"gain\"])\n",
    "SEED    = int(CFG[\"data\"][\"seed\"])\n",
    "\n",
    "# Flags & loader\n",
    "USE_OFFLINE_SPIKES = bool(CFG[\"data\"].get(\"use_offline_spikes\", False))\n",
    "RUNTIME_ENCODE     = bool(CFG[\"data\"].get(\"encode_runtime\", False))\n",
    "\n",
    "NUM_WORKERS = int(CFG[\"data\"].get(\"num_workers\") or 0)      # robusto\n",
    "PREFETCH    = int(CFG[\"data\"].get(\"prefetch_factor\") or 2)  # <- casteo robusto\n",
    "PIN_MEMORY  = bool(CFG[\"data\"].get(\"pin_memory\", True))\n",
    "PERSISTENT  = bool(CFG[\"data\"].get(\"persistent_workers\", True))\n",
    "\n",
    "AUG_CFG = AugmentConfig(**(CFG[\"data\"].get(\"aug_train\") or {})) \\\n",
    "          if CFG[\"data\"].get(\"aug_train\") else None\n",
    "\n",
    "USE_ONLINE_BAL = bool(CFG[\"data\"].get(\"balance_online\", False))\n",
    "BAL_BINS = int(CFG[\"data\"].get(\"balance_bins\") or 21)\n",
    "BAL_EPS  = float(CFG[\"data\"].get(\"balance_smooth_eps\") or 1e-3)\n",
    "\n",
    "print(f\"[PRESET={PRESET}] model={MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] encoder={ENCODER} T={T} gain={GAIN} seed={SEED}\")\n",
    "print(f\"[LOADER] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "print(f\"[BALANCE] online={USE_ONLINE_BAL} bins={BAL_BINS}\")\n",
    "print(f\"[RUNTIME_ENCODE] {RUNTIME_ENCODE} | [OFFLINE_SPIKES] {USE_OFFLINE_SPIKES}\")\n",
    "\n",
    "def make_model_fn(tfm):\n",
    "    # kwargs espec√≠ficos de pilotnet_snn; ignorados para otros\n",
    "    return build_model(MODEL_NAME, tfm, beta=0.9, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b9209",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "\n",
    "## 3) Tareas y factory de loaders\n",
    "\n",
    "- Leemos `tasks.json` o `tasks_balanced.json` desde `data/processed/`.\n",
    "- Cada tarea apunta a CSV/H5 de `train/val/test`.\n",
    "- Si `use_offline_spikes: true`, `build_make_loader_fn` **elige H5**; si no, usa **CSV + runtime encode** en GPU.\n",
    "\n",
    "El **wrapper** `make_loader_fn(...)` simplemente pasa argumentos al factory real; as√≠ el `runner` puede inyectar kwargs (augment, balanceo online, etc.) sin reescribir nada aqu√≠.\n",
    "\n",
    "> Si activas **offline balanceado**, el **train** deber√≠a ser `train_balanced.csv` o el H5 derivado. El notebook advierte si no coincide.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ce050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tareas y TRAIN CSV/H5 a usar:\n",
      " - circuito1: train_balanced.csv\n",
      " - circuito2: train_balanced.csv\n",
      "make_loader_fn listo.\n"
     ]
    }
   ],
   "source": [
    "# Leer tasks.json / tasks_balanced.json (elige balanced si existe)\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "TB = PROC / \"tasks_balanced.json\"\n",
    "TASKS_FILE = TB if TB.exists() else (PROC / \"tasks.json\")\n",
    "\n",
    "with open(TASKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "print(\"Tareas y TRAIN CSV/H5 a usar:\")\n",
    "for t in task_list:\n",
    "    from pathlib import Path as _P\n",
    "    print(f\" - {t['name']}: {_P(t['paths']['train']).name}\")\n",
    "\n",
    "# Si usas H5 offline, chequear que existan\n",
    "if USE_OFFLINE_SPIKES:\n",
    "    mw, mh = CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"]\n",
    "    color = \"gray\" if CFG[\"model\"][\"to_gray\"] else \"rgb\"\n",
    "    gain_tag = (GAIN if ENCODER == \"rate\" else 0)\n",
    "    missing = []\n",
    "    for t in task_list:\n",
    "        base = PROC / t[\"name\"]\n",
    "        for split in (\"train\", \"val\", \"test\"):\n",
    "            p = base / f\"{split}_{ENCODER}_T{T}_gain{gain_tag}_{color}_{mw}x{mh}.h5\"\n",
    "            if not p.exists():\n",
    "                missing.append(str(p))\n",
    "    if missing:\n",
    "        print(\"[WARN] Faltan H5. Genera primero con tools/encode_tasks.py o prep_offline.py --encode\")\n",
    "\n",
    "# Factory de loaders\n",
    "_raw_make_loader_fn = build_make_loader_fn(\n",
    "    root=ROOT, use_offline_spikes=USE_OFFLINE_SPIKES, encode_runtime=RUNTIME_ENCODE,\n",
    ")\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed, **dl_kwargs):\n",
    "    \"\"\"Wrapper pass-through: el runner a√±ade dl_kwargs; aqu√≠ solo los propagamos.\"\"\"\n",
    "    return _raw_make_loader_fn(\n",
    "        task=task, batch_size=batch_size, encoder=encoder, T=T, gain=gain, tfm=tfm, seed=seed, **dl_kwargs\n",
    "    )\n",
    "print(\"make_loader_fn listo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7c6f6",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "\n",
    "## 4) M√©tricas y objetivo para Optuna\n",
    "\n",
    "**C√≥mo se calcula:**\n",
    "1. Cargamos `continual_results.json` del run.\n",
    "2. Detectamos **primera** y **√∫ltima** tarea (heur√≠stica simple: la √∫ltima no tiene claves `after_*`).\n",
    "3. Extraemos:\n",
    "   - `c1_mae`: MAE en la **primera** tarea en su propio test.\n",
    "   - `c1_after_c2_mae`: MAE de la **primera** *despu√©s* de aprender la segunda (olvido).\n",
    "   - `c2_mae`: MAE de la **√∫ltima** tarea.\n",
    "4. **Olvido relativo %** = \\((c1\\_after\\_c2 - c1\\_mae) / c1\\_mae \\times 100\\).\n",
    "\n",
    "**Objetivo** = `c2_mae + ALPHA_FORGET * max(0, olvido_relativo_%)`  \n",
    "- **Minimizar** este valor favorece: buen rendimiento en la **tarea final** y **poco olvido** de la primera.\n",
    "- Ajusta `ALPHA_FORGET` si quieres **penalizar m√°s** el olvido (sube Œ±) o **priorizar** la tarea nueva (baja Œ±).\n",
    "\n",
    "> Si el JSON no existe o faltan m√©tricas, devolvemos `inf` para que ese trial no gane.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f05f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "ALPHA_FORGET = 0.5   # peso del olvido relativo (%) en la m√©trica objetivo\n",
    "\n",
    "def _load_results(out_dir: Path) -> dict:\n",
    "    p = Path(out_dir) / \"continual_results.json\"\n",
    "    if not p.exists():\n",
    "        return {}\n",
    "    return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def _pick_first_last_task(results: dict):\n",
    "    # heur√≠stica: primera = la que tenga claves 'after_*' (porque fue evaluada despu√©s),\n",
    "    # √∫ltima = la que NO tenga 'after_*'\n",
    "    if not results:\n",
    "        return None, None\n",
    "    task_names = list(results.keys())\n",
    "    def is_last(d: dict) -> bool:\n",
    "        return not any(k.startswith(\"after_\") for k in d.keys())\n",
    "\n",
    "    first_task = None\n",
    "    last_task = None\n",
    "    for tn in task_names:\n",
    "        if is_last(results[tn]):\n",
    "            last_task = tn\n",
    "        else:\n",
    "            first_task = tn\n",
    "\n",
    "    if first_task is None or last_task is None:\n",
    "        # fallback: orden alfab√©tico\n",
    "        task_names_sorted = sorted(task_names)\n",
    "        first_task = task_names_sorted[0]\n",
    "        last_task  = task_names_sorted[-1]\n",
    "    return first_task, last_task\n",
    "\n",
    "def extract_metrics(results: dict):\n",
    "    \"\"\"Devuelve dict con:\n",
    "       - c1_mae, c1_after_c2_mae, forget_rel_%\n",
    "       - c2_mae\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        return {\"c1_mae\": math.nan, \"c1_after_c2_mae\": math.nan, \"forget_rel_%\": math.nan, \"c2_mae\": math.nan}\n",
    "\n",
    "    c1, c2 = _pick_first_last_task(results)\n",
    "    if c1 is None or c2 is None:\n",
    "        return {\"c1_mae\": math.nan, \"c1_after_c2_mae\": math.nan, \"forget_rel_%\": math.nan, \"c2_mae\": math.nan}\n",
    "\n",
    "    c1_test_mae = float(results[c1].get(\"test_mae\", math.nan))\n",
    "    c2_test_mae = float(results[c2].get(\"test_mae\", math.nan))\n",
    "    c1_after_c2 = float(results[c1].get(f\"after_{c2}_mae\", math.nan))\n",
    "\n",
    "    forgetting_abs = c1_after_c2 - c1_test_mae\n",
    "    forgetting_rel = (forgetting_abs / c1_test_mae * 100.0) if (c1_test_mae == c1_test_mae and c1_test_mae != 0.0) else math.nan\n",
    "\n",
    "    return {\n",
    "        \"c1_mae\": c1_test_mae,\n",
    "        \"c1_after_c2_mae\": c1_after_c2,\n",
    "        \"forget_rel_%\": forgetting_rel,\n",
    "        \"c2_mae\": c2_test_mae,\n",
    "    }\n",
    "\n",
    "def objective_value(metrics: dict, alpha: float = ALPHA_FORGET) -> float:\n",
    "    \"\"\"Menor es mejor. Combina rendimiento en la √∫ltima tarea y olvido relativo en la primera.\"\"\"\n",
    "    m2 = metrics.get(\"c2_mae\", math.nan)\n",
    "    f  = metrics.get(\"forget_rel_%\", math.nan)\n",
    "    if math.isnan(m2) or math.isnan(f):\n",
    "        return float(\"inf\")\n",
    "    return float(m2 + alpha * max(0.0, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e35e7",
   "metadata": {},
   "source": [
    "<a id=\"sec-05\"></a>\n",
    "\n",
    "## 5) Espacios de b√∫squeda (por m√©todo)\n",
    "\n",
    "Definimos qu√© hiperpar√°metros explora **Optuna** en cada m√©todo:\n",
    "\n",
    "- **ewc**:\n",
    "  - `lam` (*lambda*): [3e8, 2e9] (log-uniform). Penalizaci√≥n de estabilidad (evita olvidar).\n",
    "  - `fisher_batches`: [200, 1200]. Cu√°nta info de Fisher acumulamos (coste ‚Üë).\n",
    "\n",
    "- **rehearsal**:\n",
    "  - `buffer_size`: [1000, 8000]. Tama√±o de memoria de rejuego.\n",
    "  - `replay_ratio`: [0.05, 0.4]. Fracci√≥n de muestras de memoria por minibatch.\n",
    "\n",
    "- **rehearsal+ewc**: combina ambos sets.\n",
    "\n",
    "- **naive**: sin hiperpar√°metros (sirve como l√≠nea base).\n",
    "\n",
    "> Rango amplio = m√°s tiempo pero m√°s opciones. Ajusta rangos cuando tengas intuici√≥n.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e2b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_params_for_method(trial: optuna.Trial, method: str) -> dict:\n",
    "    method = method.lower()\n",
    "    if method == \"ewc\":\n",
    "        lam = trial.suggest_float(\"lam\", 3e8, 2e9, log=True)\n",
    "        fisher_batches = trial.suggest_int(\"fisher_batches\", 200, 1200, step=100)\n",
    "        return {\"lam\": lam, \"fisher_batches\": fisher_batches}\n",
    "    elif method == \"rehearsal\":\n",
    "        buffer_size  = trial.suggest_int(\"buffer_size\", 1000, 8000, step=1000)\n",
    "        replay_ratio = trial.suggest_float(\"replay_ratio\", 0.05, 0.4, step=0.05)\n",
    "        return {\"buffer_size\": buffer_size, \"replay_ratio\": replay_ratio}\n",
    "    elif method == \"rehearsal+ewc\":\n",
    "        buffer_size  = trial.suggest_int(\"buffer_size\", 1000, 8000, step=1000)\n",
    "        replay_ratio = trial.suggest_float(\"replay_ratio\", 0.05, 0.4, step=0.05)\n",
    "        lam = trial.suggest_float(\"lam\", 3e8, 2e9, log=True)\n",
    "        fisher_batches = trial.suggest_int(\"fisher_batches\", 200, 1200, step=100)\n",
    "        return {\"buffer_size\": buffer_size, \"replay_ratio\": replay_ratio, \"lam\": lam, \"fisher_batches\": fisher_batches}\n",
    "    else:  # naive (sin HPs)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841fd521",
   "metadata": {},
   "source": [
    "<a id=\"sec-06\"></a>\n",
    "\n",
    "## 6) Estudio Optuna ‚Äî un m√©todo concreto\n",
    "\n",
    "- **Study**: contenedor de la b√∫squeda.\n",
    "- **Trial**: una configuraci√≥n (punto) en el espacio de HPs.\n",
    "- **Objective**: funci√≥n que entrena/eval√∫a y devuelve un **valor a minimizar**.\n",
    "\n",
    "Par√°metros clave:\n",
    "- `METHOD_TO_OPTIMIZE`: `\"ewc\"`, `\"rehearsal\"`, `\"rehearsal+ewc\"` o `\"naive\"`.\n",
    "- `N_TRIALS`: n¬∫ de configuraciones a probar.\n",
    "- `HPO_EPOCHS`: si no es `None`, **sobrescribe** las `epochs` del preset **solo durante HPO** (acelera la b√∫squeda). Luego reentrenas a tope en la Secci√≥n 8.\n",
    "\n",
    "**Qu√© hace cada trial:**\n",
    "1. Sugerir HPs (`suggest_*`).\n",
    "2. Construir `cfg` con esos HPs (y `epochs` reducidas si `HPO_EPOCHS`).\n",
    "3. Ejecutar `run_continual(...)`.\n",
    "4. Leer `continual_results.json`, calcular m√©trica objetivo y devolv√©rsela a Optuna.\n",
    "\n",
    "**Salida:**\n",
    "- `study.best_params`: mejores HPs.\n",
    "- `study.best_value`: valor objetivo m√≠nimo.\n",
    "- `study.best_trial.user_attrs`: metadatos (ruta del experimento, m√©tricas) que guardamos nosotros.\n",
    "\n",
    "> **Tip:** Para runs largos a√±ade *pruning* o una base de datos (`optuna.create_study(storage=...)`) si quieres **reanudar** b√∫squedas en varias sesiones.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f92711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-27 21:40:52,685] A new study created in memory with name: HPO_ewc\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_2e+09 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_2e+09 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 4.03627:  12%|‚ñà‚ñé        | 1/8 [04:34<31:58, 274.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-27 21:45:26,705] Trial 0 finished with value: 4.0362714074998225 and parameters: {'lam': 1895163480.3073468, 'fisher_batches': 1200}. Best is trial 0 with value: 4.0362714074998225.\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_4e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_4e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 4.03627:  25%|‚ñà‚ñà‚ñå       | 2/8 [09:18<28:01, 280.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-27 21:50:11,327] Trial 1 finished with value: 6.144042103380284 and parameters: {'lam': 361518805.8734032, 'fisher_batches': 1200}. Best is trial 0 with value: 4.0362714074998225.\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_6e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_6e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.246354:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [14:24<24:20, 292.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-27 21:55:17,587] Trial 2 finished with value: 0.2463536065026938 and parameters: {'lam': 620739673.9712622, 'fisher_batches': 1200}. Best is trial 2 with value: 0.2463536065026938.\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_4e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_4e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.246354:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [18:58<19:00, 285.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-27 21:59:51,681] Trial 3 finished with value: 3.4402625588852564 and parameters: {'lam': 429096856.35070777, 'fisher_batches': 900}. Best is trial 2 with value: 0.2463536065026938.\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_4e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_4e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.246354:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [23:12<13:40, 273.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-27 22:04:04,784] Trial 4 finished with value: 2.9787792418409706 and parameters: {'lam': 389390625.2339849, 'fisher_batches': 1000}. Best is trial 2 with value: 0.2463536065026938.\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_4e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_4e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.246354:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [27:12<08:44, 262.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-27 22:08:05,159] Trial 5 finished with value: 1.8104800566911723 and parameters: {'lam': 369005287.8593578, 'fisher_batches': 1200}. Best is trial 2 with value: 0.2463536065026938.\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_4e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_4e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.246354:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [31:01<04:11, 251.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-27 22:11:53,726] Trial 6 finished with value: 6.261268331904161 and parameters: {'lam': 407876991.3119429, 'fisher_batches': 1100}. Best is trial 2 with value: 0.2463536065026938.\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_2e+09 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_2e+09 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.246354: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [34:48<00:00, 261.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-27 22:15:41,498] Trial 7 finished with value: 0.26502074714166574 and parameters: {'lam': 1851251881.6092882, 'fisher_batches': 900}. Best is trial 2 with value: 0.2463536065026938.\n",
      "Best value: 0.2463536065026938\n",
      "Best params: {'lam': 620739673.9712622, 'fisher_batches': 1200}\n",
      "Best attrs: {'out_dir': '/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_6e+08_lam_6e+08_rate_model-PilotNetSNN_66x200_gray_seed_42', 'metrics': {'c1_mae': 0.1695060603377118, 'c1_after_c2_mae': 0.16681019685886525, 'forget_rel_%': -1.5904230642110921, 'c2_mae': 0.2463536065026938}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n del estudio\n",
    "METHOD_TO_OPTIMIZE = \"ewc\"   # \"naive\" | \"ewc\" | \"rehearsal\" | \"rehearsal+ewc\"\n",
    "N_TRIALS = 8                 # s√∫belo cuando est√©s satisfecho con tiempos/estabilidad\n",
    "HPO_EPOCHS = None            # None -> usar epochs del preset; o pon un int (ej. 3) para acelerar\n",
    "\n",
    "def build_cfg_with_method(base_cfg: dict, method_name: str, params: dict, hpo_epochs: int|None):\n",
    "    cfg = copy.deepcopy(base_cfg)\n",
    "    cfg[\"continual\"][\"method\"] = method_name\n",
    "    cfg[\"continual\"][\"params\"] = params or {}\n",
    "\n",
    "    if hpo_epochs is not None:\n",
    "        cfg[\"optim\"][\"epochs\"] = int(hpo_epochs)\n",
    "    return cfg\n",
    "\n",
    "def run_one_cfg(cfg: dict) -> tuple[Path, dict, dict]:\n",
    "    out_dir, res = run_continual(\n",
    "        task_list=task_list,\n",
    "        make_loader_fn=make_loader_fn,\n",
    "        make_model_fn=make_model_fn,\n",
    "        tfm=tfm,\n",
    "        cfg=cfg,\n",
    "        preset_name=PRESET,\n",
    "        out_root=ROOT / \"outputs\",\n",
    "        verbose=True,\n",
    "    )\n",
    "    # Nota: algunos runners devuelven res; aun as√≠, leemos del JSON para robustez\n",
    "    results = _load_results(out_dir) or (res if isinstance(res, dict) else {})\n",
    "    return out_dir, res, results\n",
    "\n",
    "def optuna_objective(trial: optuna.Trial):\n",
    "    params = suggest_params_for_method(trial, METHOD_TO_OPTIMIZE)\n",
    "    cfg_i  = build_cfg_with_method(CFG, METHOD_TO_OPTIMIZE, params, HPO_EPOCHS)\n",
    "    out_dir, _, results = run_one_cfg(cfg_i)\n",
    "    metrics = extract_metrics(results)\n",
    "    val = objective_value(metrics, ALPHA_FORGET)\n",
    "    trial.set_user_attr(\"out_dir\", str(out_dir))\n",
    "    trial.set_user_attr(\"metrics\", metrics)\n",
    "    return val\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=f\"HPO_{METHOD_TO_OPTIMIZE}\")\n",
    "study.optimize(optuna_objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best attrs:\", study.best_trial.user_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48b08b",
   "metadata": {},
   "source": [
    "<a id=\"sec-07\"></a>\n",
    "\n",
    "## 7) Estudio Optuna conjunto (elige m√©todo + HPs)\n",
    "\n",
    "Si `RUN_JOINT=True`, el **trial** tambi√©n elige el **m√©todo**:\n",
    "- `method ‚àà {naive, ewc, rehearsal, rehearsal+ewc}`\n",
    "- Y luego sus HPs correspondientes.\n",
    "\n",
    "√ötil cuando:\n",
    "- No sabes qu√© m√©todo es mejor en tu dataset.\n",
    "- Quieres una **comparativa autom√°tica** con el mismo presupuesto de c√≥mputo.\n",
    "\n",
    "> Empieza con `RUN_JOINT=False` para validar el flujo con un √∫nico m√©todo. Luego enci√©ndelo y sube `N_TRIALS_JOINT`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e7f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_JOINT=False ‚Äî omitido.\n"
     ]
    }
   ],
   "source": [
    "RUN_JOINT = False   # Pon True si quieres lanzar el estudio conjunto\n",
    "N_TRIALS_JOINT = 10\n",
    "\n",
    "def optuna_objective_joint(trial: optuna.Trial):\n",
    "    method = trial.suggest_categorical(\"method\", [\"naive\",\"ewc\",\"rehearsal\",\"rehearsal+ewc\"])\n",
    "    params = suggest_params_for_method(trial, method)\n",
    "    cfg_i  = build_cfg_with_method(CFG, method, params, HPO_EPOCHS)\n",
    "    out_dir, _, results = run_one_cfg(cfg_i)\n",
    "    metrics = extract_metrics(results)\n",
    "    val = objective_value(metrics, ALPHA_FORGET)\n",
    "    trial.set_user_attr(\"out_dir\", str(out_dir))\n",
    "    trial.set_user_attr(\"metrics\", metrics)\n",
    "    trial.set_user_attr(\"method\", method)\n",
    "    return val\n",
    "\n",
    "if RUN_JOINT:\n",
    "    study_joint = optuna.create_study(direction=\"minimize\", study_name=\"HPO_joint\")\n",
    "    study_joint.optimize(optuna_objective_joint, n_trials=N_TRIALS_JOINT, show_progress_bar=True)\n",
    "    print(\"Best value:\", study_joint.best_value)\n",
    "    print(\"Best params:\", study_joint.best_params)\n",
    "    print(\"Best attrs:\", study_joint.best_trial.user_attrs)\n",
    "else:\n",
    "    print(\"RUN_JOINT=False ‚Äî omitido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cdc9f",
   "metadata": {},
   "source": [
    "<a id=\"sec-08\"></a>\n",
    "\n",
    "## 8) Re-entrena con los mejores hiperpar√°metros\n",
    "\n",
    "- Coge `study.best_params` y `METHOD_TO_OPTIMIZE`.\n",
    "- Reconstruye `cfg_best` con el **m√©todo ganador + HPs**.\n",
    "- (Opcional) Restablece `epochs` del preset si usaste `HPO_EPOCHS` para acelerar.\n",
    "- Lanza `run_continual(...)` **a pleno rendimiento**.\n",
    "- Muestra m√©tricas finales y la **carpeta de salida**.\n",
    "\n",
    "> As√≠ separas la **b√∫squeda r√°pida** (pocas epochs) del **entrenamiento serio** (epochs del preset).\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40464ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor m√©todo: ewc\n",
      "Mejores HPs: {'lam': 620739673.9712622, 'fisher_batches': 1200}\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_6e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_6e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados finales (re-train): {'c1_mae': 0.1695060603377118, 'c1_after_c2_mae': 0.17353918157694118, 'forget_rel_%': 2.379337488697504, 'c2_mae': 0.25451793584478904}\n",
      "Guardado en: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_6e+08_lam_6e+08_rate_model-PilotNetSNN_66x200_gray_seed_42\n"
     ]
    }
   ],
   "source": [
    "# Usa el mejor del estudio por m√©todo (arriba)\n",
    "BEST_PARAMS = study.best_params\n",
    "BEST_METHOD = METHOD_TO_OPTIMIZE\n",
    "\n",
    "print(\"Mejor m√©todo:\", BEST_METHOD)\n",
    "print(\"Mejores HPs:\", BEST_PARAMS)\n",
    "\n",
    "cfg_best = copy.deepcopy(CFG)\n",
    "cfg_best[\"continual\"][\"method\"] = BEST_METHOD\n",
    "cfg_best[\"continual\"][\"params\"] = BEST_PARAMS\n",
    "\n",
    "# (Opcional) restablecer epochs al valor del preset si redujiste para HPO\n",
    "# cfg_best[\"optim\"][\"epochs\"] = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)[\"optim\"][\"epochs\"]\n",
    "\n",
    "out_dir, _, results = run_one_cfg(cfg_best)\n",
    "metrics = extract_metrics(results)\n",
    "print(\"Resultados finales (re-train):\", metrics)\n",
    "print(\"Guardado en:\", out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99cf26e",
   "metadata": {},
   "source": [
    "<a id=\"sec-09\"></a>\n",
    "\n",
    "## 9) Resumen r√°pido de runs (tabla)\n",
    "\n",
    "- Recorremos `outputs/continual_*` y leemos `continual_results.json`.\n",
    "- Extraemos y tabulamos:\n",
    "  - `preset`, `method`, `encoder`, `seed`, (y `lambda` si aplica),\n",
    "  - `c1_mae`, `c1_after_c2_mae`, `forget_rel_%`, `c2_mae`.\n",
    "\n",
    "**C√≥mo leerla:**\n",
    "- **`c2_mae`** bajo ‚Üí aprende bien la √∫ltima tarea.\n",
    "- **`forget_rel_%`** bajo ‚Üí **poco olvido** de la primera.\n",
    "- Filtra por preset/m√©todo para comparar **manzanas con manzanas**.\n",
    "\n",
    "> Consejo: Exporta a CSV/Parquet si quieres hacer gr√°ficas comparativas a posteriori.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34ca61bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs en resumen: 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>preset</th>\n",
       "      <th>method</th>\n",
       "      <th>lambda</th>\n",
       "      <th>encoder</th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>c1_mae</th>\n",
       "      <th>c1_after_c2_mae</th>\n",
       "      <th>forget_rel_%</th>\n",
       "      <th>c2_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.154083</td>\n",
       "      <td>0.177469</td>\n",
       "      <td>15.177439</td>\n",
       "      <td>0.248496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>43</td>\n",
       "      <td>0.156092</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>-2.221175</td>\n",
       "      <td>0.266815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continual_fast_ewc_lam_2e+09_lam_2e+09_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>2e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.169506</td>\n",
       "      <td>0.160106</td>\n",
       "      <td>-5.545270</td>\n",
       "      <td>0.265021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>continual_fast_ewc_lam_3e+08_lam_3e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>3e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.170740</td>\n",
       "      <td>0.170762</td>\n",
       "      <td>0.012979</td>\n",
       "      <td>0.231721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>continual_fast_ewc_lam_4e+08_lam_4e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>4e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.169506</td>\n",
       "      <td>0.189876</td>\n",
       "      <td>12.017457</td>\n",
       "      <td>0.252540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>continual_fast_ewc_lam_6e+08_lam_6e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>6e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.169506</td>\n",
       "      <td>0.173539</td>\n",
       "      <td>2.379337</td>\n",
       "      <td>0.254518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>continual_fast_ewc_lam_7e+08_lam_7e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.154083</td>\n",
       "      <td>0.177091</td>\n",
       "      <td>14.932352</td>\n",
       "      <td>0.223910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>continual_fast_ewc_lam_8e+08_lam_8e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>8e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.170740</td>\n",
       "      <td>0.170724</td>\n",
       "      <td>-0.009259</td>\n",
       "      <td>0.231704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>continual_fast_naive_rate_model-PilotNetSNN_66...</td>\n",
       "      <td>fast</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.165901</td>\n",
       "      <td>0.237017</td>\n",
       "      <td>42.866588</td>\n",
       "      <td>0.205451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>continual_fast_naive_rate_model-PilotNetSNN_66...</td>\n",
       "      <td>fast</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>43</td>\n",
       "      <td>0.152754</td>\n",
       "      <td>0.284062</td>\n",
       "      <td>85.959872</td>\n",
       "      <td>0.198193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>continual_fast_naive_rate_model-SNNVisionRegre...</td>\n",
       "      <td>fast</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>SNNVisionRegressor_80x160_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.177120</td>\n",
       "      <td>0.221733</td>\n",
       "      <td>25.188146</td>\n",
       "      <td>0.177002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>continual_fast_rehearsal_buf_5000_rr_20_rate_m...</td>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_5000_rr_20</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.154083</td>\n",
       "      <td>0.183188</td>\n",
       "      <td>18.889148</td>\n",
       "      <td>0.195154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>continual_fast_rehearsal_buf_5000_rr_20+ewc_la...</td>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_5000_rr_20+ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.169112</td>\n",
       "      <td>0.169201</td>\n",
       "      <td>0.052627</td>\n",
       "      <td>0.231057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>continual_fast_rehearsal_buf_5000_rr_20+ewc_la...</td>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_5000_rr_20+ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.165901</td>\n",
       "      <td>0.167233</td>\n",
       "      <td>0.802680</td>\n",
       "      <td>0.257600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  exp preset  \\\n",
       "0   continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...   fast   \n",
       "1   continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...   fast   \n",
       "2   continual_fast_ewc_lam_2e+09_lam_2e+09_rate_mo...   fast   \n",
       "3   continual_fast_ewc_lam_3e+08_lam_3e+08_rate_mo...   fast   \n",
       "4   continual_fast_ewc_lam_4e+08_lam_4e+08_rate_mo...   fast   \n",
       "5   continual_fast_ewc_lam_6e+08_lam_6e+08_rate_mo...   fast   \n",
       "6   continual_fast_ewc_lam_7e+08_lam_7e+08_rate_mo...   fast   \n",
       "7   continual_fast_ewc_lam_8e+08_lam_8e+08_rate_mo...   fast   \n",
       "8   continual_fast_naive_rate_model-PilotNetSNN_66...   fast   \n",
       "9   continual_fast_naive_rate_model-PilotNetSNN_66...   fast   \n",
       "10  continual_fast_naive_rate_model-SNNVisionRegre...   fast   \n",
       "11  continual_fast_rehearsal_buf_5000_rr_20_rate_m...   fast   \n",
       "12  continual_fast_rehearsal_buf_5000_rr_20+ewc_la...   fast   \n",
       "13  continual_fast_rehearsal_buf_5000_rr_20+ewc_la...   fast   \n",
       "\n",
       "                          method lambda encoder  \\\n",
       "0                            ewc  1e+09    rate   \n",
       "1                            ewc  1e+09    rate   \n",
       "2                            ewc  2e+09    rate   \n",
       "3                            ewc  3e+08    rate   \n",
       "4                            ewc  4e+08    rate   \n",
       "5                            ewc  6e+08    rate   \n",
       "6                            ewc  7e+08    rate   \n",
       "7                            ewc  8e+08    rate   \n",
       "8                          naive   None    rate   \n",
       "9                          naive   None    rate   \n",
       "10                         naive   None    rate   \n",
       "11      rehearsal_buf_5000_rr_20   None    rate   \n",
       "12  rehearsal_buf_5000_rr_20+ewc  1e+09    rate   \n",
       "13  rehearsal_buf_5000_rr_20+ewc  7e+08    rate   \n",
       "\n",
       "                             model  seed    c1_mae  c1_after_c2_mae  \\\n",
       "0          PilotNetSNN_66x200_gray    42  0.154083         0.177469   \n",
       "1          PilotNetSNN_66x200_gray    43  0.156092         0.152625   \n",
       "2          PilotNetSNN_66x200_gray    42  0.169506         0.160106   \n",
       "3          PilotNetSNN_66x200_gray    42  0.170740         0.170762   \n",
       "4          PilotNetSNN_66x200_gray    42  0.169506         0.189876   \n",
       "5          PilotNetSNN_66x200_gray    42  0.169506         0.173539   \n",
       "6          PilotNetSNN_66x200_gray    42  0.154083         0.177091   \n",
       "7          PilotNetSNN_66x200_gray    42  0.170740         0.170724   \n",
       "8          PilotNetSNN_66x200_gray    42  0.165901         0.237017   \n",
       "9          PilotNetSNN_66x200_gray    43  0.152754         0.284062   \n",
       "10  SNNVisionRegressor_80x160_gray    42  0.177120         0.221733   \n",
       "11         PilotNetSNN_66x200_gray    42  0.154083         0.183188   \n",
       "12         PilotNetSNN_66x200_gray    42  0.169112         0.169201   \n",
       "13         PilotNetSNN_66x200_gray    42  0.165901         0.167233   \n",
       "\n",
       "    forget_rel_%    c2_mae  \n",
       "0      15.177439  0.248496  \n",
       "1      -2.221175  0.266815  \n",
       "2      -5.545270  0.265021  \n",
       "3       0.012979  0.231721  \n",
       "4      12.017457  0.252540  \n",
       "5       2.379337  0.254518  \n",
       "6      14.932352  0.223910  \n",
       "7      -0.009259  0.231704  \n",
       "8      42.866588  0.205451  \n",
       "9      85.959872  0.198193  \n",
       "10     25.188146  0.177002  \n",
       "11     18.889148  0.195154  \n",
       "12      0.052627  0.231057  \n",
       "13      0.802680  0.257600  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re, pandas as pd\n",
    "\n",
    "ALLOWED_ENC = r\"(rate|latency|raw|image)\"\n",
    "\n",
    "def parse_exp_name(name: str):\n",
    "    pat = re.compile(rf\"^continual_(?P<preset>[^_]+)_(?P<tag>.+)_(?P<enc>{ALLOWED_ENC})(?:_model\\-(?P<model>.+?))?(?:_seed_(?P<seed>\\d+))?$\")\n",
    "    m = pat.match(name)\n",
    "    meta = {\"preset\": None, \"method\": None, \"lambda\": None, \"encoder\": None, \"seed\": None, \"model\": None}\n",
    "    if not m:\n",
    "        return meta\n",
    "    preset = m.group(\"preset\"); tag = m.group(\"tag\"); enc = m.group(\"enc\")\n",
    "    seed = m.group(\"seed\"); model = m.group(\"model\")\n",
    "    lam = None; mlam = re.search(r\"_lam_([^_]+)\", tag)\n",
    "    if mlam:\n",
    "        lam = mlam.group(1)\n",
    "        method = tag.replace(f\"_lam_{lam}\", \"\")\n",
    "    else:\n",
    "        method = tag\n",
    "    return {\"preset\": preset, \"method\": method, \"lambda\": lam, \"encoder\": enc,\n",
    "            \"seed\": int(seed) if seed is not None else None, \"model\": model}\n",
    "\n",
    "rows = []\n",
    "root_out = ROOT / \"outputs\"\n",
    "for exp_dir in sorted(root_out.glob(\"continual_*\")):\n",
    "    name = exp_dir.name\n",
    "    meta = parse_exp_name(name)\n",
    "    if meta[\"preset\"] is None:\n",
    "        continue\n",
    "    results_path = exp_dir / \"continual_results.json\"\n",
    "    if not results_path.exists():\n",
    "        continue\n",
    "    with open(results_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        res = json.load(f)\n",
    "\n",
    "    # m√©trica m√≠nima para la tabla\n",
    "    m = extract_metrics(res)\n",
    "    rows.append({\n",
    "        \"exp\": name,\n",
    "        \"preset\": meta[\"preset\"],\n",
    "        \"method\": meta[\"method\"],\n",
    "        \"lambda\": meta[\"lambda\"],\n",
    "        \"encoder\": meta[\"encoder\"],\n",
    "        \"model\": meta[\"model\"],\n",
    "        \"seed\": meta[\"seed\"],\n",
    "        \"c1_mae\": m[\"c1_mae\"],\n",
    "        \"c1_after_c2_mae\": m[\"c1_after_c2_mae\"],\n",
    "        \"forget_rel_%\": m[\"forget_rel_%\"],\n",
    "        \"c2_mae\": m[\"c2_mae\"],\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"runs en resumen: {len(df)}\")\n",
    "if not df.empty:\n",
    "    display(df.sort_values([\"preset\",\"method\",\"encoder\",\"lambda\"], na_position=\"last\", ignore_index=True))\n",
    "else:\n",
    "    print(\"No hay filas (¬øno existen JSONs o solo hubo 1 tarea por run?).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716c060",
   "metadata": {},
   "source": [
    "## Ap√©ndice ‚Äî Optuna en 90 segundos\n",
    "\n",
    "- **Study**: el proyecto de HPO (contiene todos los trials).\n",
    "- **Trial**: una evaluaci√≥n con un conjunto de HPs (`suggest_int`, `suggest_float`, etc.).\n",
    "- **Sampler**: estrategia para elegir el siguiente punto (por defecto, TPE).\n",
    "- **Pruner**: **corta** trials que pintan mal (acelera b√∫squedas largas).\n",
    "- **Storage**: base de datos (SQLite, PostgreSQL) para **reanudar** y/o **paralelizar**.\n",
    "\n",
    "### Reanudar b√∫squedas\n",
    "Puedes crear el estudio con almacenamiento:\n",
    "```python\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"HPO_ewc\",\n",
    "    storage=f\"sqlite:///{ROOT/'outputs'/'optuna_ewc.sqlite'}\",\n",
    "    load_if_exists=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
