{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9f0dc7",
   "metadata": {},
   "source": [
    "# 03B ‚Äî B√∫squeda de hiperpar√°metros con Optuna (Continual Learning)\n",
    "\n",
    "Este cuaderno automatiza la **optimizaci√≥n de hiperpar√°metros (HPO)** para m√©todos de aprendizaje continuo:\n",
    "- **naive** (baseline, sin HPs),\n",
    "- **ewc** (Elastic Weight Consolidation),\n",
    "- **rehearsal** (rejuego con buffer),\n",
    "- **rehearsal+ewc** (combinaci√≥n).\n",
    "\n",
    "Se apoya en:\n",
    "- `configs/presets.yaml` (misma configuraci√≥n que el resto de notebooks),\n",
    "- `build_make_loader_fn` (carga CSV+runtime o H5 offline),\n",
    "- `run_continual` (entrena & eval√∫a y guarda m√©tricas).\n",
    "\n",
    "---\n",
    "\n",
    "### M√©trica objetivo (minimizar)\n",
    "\n",
    "$$\n",
    "\\textbf{Objetivo}\n",
    "= \\mathrm{MAE}_{\\text{tarea final}}\n",
    "+ \\alpha \\cdot \\max\\!\\bigl(0,\\, \\text{OlvidoRelativo}\\,\\%\\bigr)\n",
    "$$\n",
    "\n",
    "\n",
    "- **MAE_tarea final**: error en la **√∫ltima** tarea (queremos aprender bien lo nuevo).\n",
    "- **OlvidoRelativo %**: cu√°nto **empeora** la primera tarea tras aprender la segunda.\n",
    "- **Œ±**: peso del olvido (por defecto 0.5). Sube Œ± si quieres penalizar m√°s el olvido.\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "- `pip install optuna`\n",
    "- Datos preparados (`tasks.json` o `tasks_balanced.json`).\n",
    "- Idealmente H5 offline si `use_offline_spikes: true` en el preset.\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "- [1) Imports y setup](#sec-01)\n",
    "- [2) Carga de preset y construcci√≥n de modelo/transform](#sec-02)\n",
    "- [3) Tareas y factory de loaders](#sec-03)\n",
    "- [4) M√©tricas y objetivo para Optuna](#sec-04)\n",
    "- [5) Espacios de b√∫squeda (por m√©todo)](#sec-05)\n",
    "- [6) Estudio Optuna ‚Äî un m√©todo concreto](#sec-06)\n",
    "- [7) Estudio Optuna conjunto (elige m√©todo + HPs)](#sec-07)\n",
    "- [8) Re-entrena con los mejores hiperpar√°metros](#sec-08)\n",
    "- [9) Resumen r√°pido de runs (tabla)](#sec-09)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> **Consejo**: empieza con el preset `fast` y `N_TRIALS` peque√±o; si todo va bien, sube `N_TRIALS` y/o las `epochs`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5bd35d",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "\n",
    "## 1) Imports y setup de entorno\n",
    "\n",
    "- Limitamos hilos BLAS (`OMP`, `MKL`, `OPENBLAS`) para evitar sobrecarga de CPU.\n",
    "- Configuramos **CUDA/TF32** para acelerar en GPUs NVIDIA.\n",
    "- Insertamos la **ra√≠z del repo** en `sys.path` para importar m√≥dulos locales.\n",
    "- Comprobamos el **dispositivo** (`cuda`/`cpu`).\n",
    "\n",
    "> Si notas que el equipo va justo de CPU, baja `torch.set_num_threads(4)` a `2`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbd7d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Limitar threads BLAS (opcional)\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, copy, time\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "# Ra√≠z del repo y sys.path\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Proyecto\n",
    "from src.utils import load_preset, build_make_loader_fn\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import build_model\n",
    "from src.runner import run_continual\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14b25c",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "\n",
    "## 2) Carga de preset y construcci√≥n de modelo/transform\n",
    "\n",
    "- `PRESET` se carga desde `configs/presets.yaml`.\n",
    "- Extraemos:\n",
    "  - **Modelo** y el **transform** de imagen (`ImageTransform`) acorde a `img_w`, `img_h`, `to_gray`.\n",
    "  - Par√°metros de **codificaci√≥n temporal** (`encoder`, `T`, `gain`) y **semilla**.\n",
    "  - Flags de **carga de datos**: `use_offline_spikes` (H5), `encode_runtime` (codifica en GPU), `use_offline_balanced`.\n",
    "  - Par√°metros del **DataLoader** (workers, prefetch, pin_memory, etc.) y **balanceo online**.\n",
    "\n",
    "- `make_model_fn(tfm)` devuelve el modelo (por ejemplo, `pilotnet_snn` con `beta/threshold`).\n",
    "\n",
    "> Mantener aqu√≠ la **fuente de la verdad** del experimento (preset) ahorra inconsistencias respecto a otros notebooks.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc61aef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRESET=fast] model=pilotnet_snn 200x66 gray=True\n",
      "[DATA] encoder=rate T=10 gain=0.5 seed=42\n",
      "[LOADER] workers=8 prefetch=2 pin=True persistent=True\n",
      "[BALANCE] online=False bins=50\n",
      "[RUNTIME_ENCODE] False | [OFFLINE_SPIKES] True\n"
     ]
    }
   ],
   "source": [
    "PRESET = \"fast\"  # fast | std | accurate\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# Modelo / tfm\n",
    "MODEL_NAME = CFG[\"model\"][\"name\"]\n",
    "tfm = ImageTransform(\n",
    "    CFG[\"model\"][\"img_w\"],\n",
    "    CFG[\"model\"][\"img_h\"],\n",
    "    to_gray=bool(CFG[\"model\"][\"to_gray\"]),\n",
    "    crop_top=None\n",
    ")\n",
    "\n",
    "# Datos / codificaci√≥n temporal\n",
    "ENCODER = CFG[\"data\"][\"encoder\"]\n",
    "T       = int(CFG[\"data\"][\"T\"])\n",
    "GAIN    = float(CFG[\"data\"][\"gain\"])\n",
    "SEED    = int(CFG[\"data\"][\"seed\"])\n",
    "\n",
    "# Flags & loader\n",
    "USE_OFFLINE_SPIKES = bool(CFG[\"data\"].get(\"use_offline_spikes\", False))\n",
    "RUNTIME_ENCODE     = bool(CFG[\"data\"].get(\"encode_runtime\", False))\n",
    "\n",
    "NUM_WORKERS = int(CFG[\"data\"].get(\"num_workers\") or 0)      # robusto\n",
    "PREFETCH    = int(CFG[\"data\"].get(\"prefetch_factor\") or 2)  # <- casteo robusto\n",
    "PIN_MEMORY  = bool(CFG[\"data\"].get(\"pin_memory\", True))\n",
    "PERSISTENT  = bool(CFG[\"data\"].get(\"persistent_workers\", True))\n",
    "\n",
    "AUG_CFG = AugmentConfig(**(CFG[\"data\"].get(\"aug_train\") or {})) \\\n",
    "          if CFG[\"data\"].get(\"aug_train\") else None\n",
    "\n",
    "USE_ONLINE_BAL = bool(CFG[\"data\"].get(\"balance_online\", False))\n",
    "BAL_BINS = int(CFG[\"data\"].get(\"balance_bins\") or 50)\n",
    "BAL_EPS  = float(CFG[\"data\"].get(\"balance_smooth_eps\") or 1e-3)\n",
    "\n",
    "print(f\"[PRESET={PRESET}] model={MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] encoder={ENCODER} T={T} gain={GAIN} seed={SEED}\")\n",
    "print(f\"[LOADER] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "print(f\"[BALANCE] online={USE_ONLINE_BAL} bins={BAL_BINS}\")\n",
    "print(f\"[RUNTIME_ENCODE] {RUNTIME_ENCODE} | [OFFLINE_SPIKES] {USE_OFFLINE_SPIKES}\")\n",
    "\n",
    "def make_model_fn(tfm):\n",
    "    # kwargs espec√≠ficos de pilotnet_snn; ignorados para otros\n",
    "    return build_model(MODEL_NAME, tfm, beta=0.9, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b9209",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "\n",
    "## 3) Tareas y factory de loaders\n",
    "\n",
    "- Leemos `tasks.json` o `tasks_balanced.json` desde `data/processed/`.\n",
    "- Cada tarea apunta a CSV/H5 de `train/val/test`.\n",
    "- Si `use_offline_spikes: true`, `build_make_loader_fn` **elige H5**; si no, usa **CSV + runtime encode** en GPU.\n",
    "\n",
    "El **wrapper** `make_loader_fn(...)` simplemente pasa argumentos al factory real; as√≠ el `runner` puede inyectar kwargs (augment, balanceo online, etc.) sin reescribir nada aqu√≠.\n",
    "\n",
    "> Si activas **offline balanceado**, el **train** deber√≠a ser `train_balanced.csv` o el H5 derivado. El notebook advierte si no coincide.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86ce050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando: tasks_balanced.json\n",
      "Tareas y TRAIN CSV/H5 a usar:\n",
      " - circuito1: train_balanced.csv\n",
      " - circuito2: train_balanced.csv\n",
      "make_loader_fn listo.\n"
     ]
    }
   ],
   "source": [
    "# Leer tasks.json / tasks_balanced.json (elige seg√∫n el preset)\n",
    "from pathlib import Path as _P\n",
    "import json\n",
    "\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "USE_BALANCED = bool(CFG.get(\"prep_offline\", {}).get(\"use_balanced_tasks\", False))\n",
    "tb_name = (CFG.get(\"prep\", {}).get(\"tasks_balanced_file_name\") or \"tasks_balanced.json\")\n",
    "t_name  = (CFG.get(\"prep\", {}).get(\"tasks_file_name\")           or \"tasks.json\")\n",
    "\n",
    "cand_bal = PROC / tb_name\n",
    "cand_std = PROC / t_name\n",
    "TASKS_FILE = cand_bal if (USE_BALANCED and cand_bal.exists()) else cand_std\n",
    "\n",
    "with open(TASKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "print(\"Usando:\", TASKS_FILE.name)\n",
    "print(\"Tareas y TRAIN CSV/H5 a usar:\")\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {_P(t['paths']['train']).name}\")\n",
    "\n",
    "# Guardarra√≠l: si balanced, exigir train_balanced.csv\n",
    "if USE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = _P(tasks_json[\"splits\"][t[\"name\"]][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' en modo balanced, pero encontr√© '{train_path.name}'.\"\n",
    "            )\n",
    "\n",
    "# Si usas H5 offline, chequear que existan\n",
    "if USE_OFFLINE_SPIKES:\n",
    "    mw, mh = CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"]\n",
    "    color = \"gray\" if CFG[\"model\"][\"to_gray\"] else \"rgb\"\n",
    "    gain_tag = (GAIN if ENCODER == \"rate\" else 0)\n",
    "    missing = []\n",
    "    for t in task_list:\n",
    "        base = PROC / t[\"name\"]\n",
    "        for split in (\"train\", \"val\", \"test\"):\n",
    "            p = base / f\"{split}_{ENCODER}_T{T}_gain{gain_tag}_{color}_{mw}x{mh}.h5\"\n",
    "            if not p.exists():\n",
    "                missing.append(str(p))\n",
    "    if missing:\n",
    "        print(\"[WARN] Faltan H5. Genera primero con 02_ENCODE_OFFLINE.ipynb (o tools/encode_tasks.py).\")\n",
    "\n",
    "# Factory de loaders con kwargs del preset\n",
    "from src.utils import build_make_loader_fn\n",
    "\n",
    "_raw_make_loader_fn = build_make_loader_fn(\n",
    "    root=ROOT, use_offline_spikes=USE_OFFLINE_SPIKES, encode_runtime=RUNTIME_ENCODE,\n",
    ")\n",
    "\n",
    "_DL_KW = dict(\n",
    "    num_workers=NUM_WORKERS,\n",
    "    prefetch_factor=PREFETCH,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers=PERSISTENT,\n",
    "    aug_train=AUG_CFG,\n",
    "    balance_train=USE_ONLINE_BAL,\n",
    "    balance_bins=BAL_BINS,\n",
    "    balance_smooth_eps=BAL_EPS,\n",
    ")\n",
    "\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed, **dl_kwargs):\n",
    "    \"\"\"Wrapper pass-through: el runner a√±ade dl_kwargs; aqu√≠ solo los propagamos.\"\"\"\n",
    "    return _raw_make_loader_fn(\n",
    "        task=task, batch_size=batch_size, encoder=encoder, T=T, gain=gain, tfm=tfm, seed=seed,\n",
    "        **{**_DL_KW, **dl_kwargs}\n",
    "    )\n",
    "\n",
    "print(\"make_loader_fn listo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7c6f6",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "\n",
    "## 4) M√©tricas y objetivo para Optuna\n",
    "\n",
    "**C√≥mo se calcula:**\n",
    "1. Cargamos `continual_results.json` del run.\n",
    "2. Detectamos **primera** y **√∫ltima** tarea (heur√≠stica simple: la √∫ltima no tiene claves `after_*`).\n",
    "3. Extraemos:\n",
    "   - `c1_mae`: MAE en la **primera** tarea en su propio test.\n",
    "   - `c1_after_c2_mae`: MAE de la **primera** *despu√©s* de aprender la segunda (olvido).\n",
    "   - `c2_mae`: MAE de la **√∫ltima** tarea.\n",
    "4. **Olvido relativo %** = \\((c1\\_after\\_c2 - c1\\_mae) / c1\\_mae \\times 100\\).\n",
    "\n",
    "**Objetivo** = `c2_mae + ALPHA_FORGET * max(0, olvido_relativo_%)`  \n",
    "- **Minimizar** este valor favorece: buen rendimiento en la **tarea final** y **poco olvido** de la primera.\n",
    "- Ajusta `ALPHA_FORGET` si quieres **penalizar m√°s** el olvido (sube Œ±) o **priorizar** la tarea nueva (baja Œ±).\n",
    "\n",
    "> Si el JSON no existe o faltan m√©tricas, devolvemos `inf` para que ese trial no gane.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f05f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === M√©tricas y objetivo: usa utilidades del repo ===\n",
    "from src.utils_exp import extract_metrics, safe_read_json\n",
    "from src.hpo import objective_value, composite_objective\n",
    "from pathlib import Path\n",
    "\n",
    "ALPHA_FORGET = 0.5  # peso del olvido relativo en el objetivo compuesto\n",
    "\n",
    "def _load_results(out_dir: Path) -> dict:\n",
    "    \"\"\"Lee outputs/<exp>/continual_results.json con manejo robusto.\"\"\"\n",
    "    return safe_read_json(Path(out_dir) / \"continual_results.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e35e7",
   "metadata": {},
   "source": [
    "<a id=\"sec-05\"></a>\n",
    "\n",
    "## 5) Espacios de b√∫squeda (por m√©todo)\n",
    "\n",
    "Definimos qu√© hiperpar√°metros explora **Optuna** en cada m√©todo:\n",
    "\n",
    "- **ewc**:\n",
    "  - `lam` (*lambda*): [3e8, 2e9] (log-uniform). Penalizaci√≥n de estabilidad (evita olvidar).\n",
    "  - `fisher_batches`: [200, 1200]. Cu√°nta info de Fisher acumulamos (coste ‚Üë).\n",
    "\n",
    "- **rehearsal**:\n",
    "  - `buffer_size`: [1000, 8000]. Tama√±o de memoria de rejuego.\n",
    "  - `replay_ratio`: [0.05, 0.4]. Fracci√≥n de muestras de memoria por minibatch.\n",
    "\n",
    "- **rehearsal+ewc**: combina ambos sets.\n",
    "\n",
    "- **naive**: sin hiperpar√°metros (sirve como l√≠nea base).\n",
    "\n",
    "> Rango amplio = m√°s tiempo pero m√°s opciones. Ajusta rangos cuando tengas intuici√≥n.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e2b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_params_for_method(trial: optuna.Trial, method: str) -> dict:\n",
    "    method = method.lower()\n",
    "    if method == \"ewc\":\n",
    "        lam = trial.suggest_float(\"lam\", 3e8, 2e9, log=True)\n",
    "        fisher_batches = trial.suggest_int(\"fisher_batches\", 200, 1200, step=100)\n",
    "        return {\"lam\": lam, \"fisher_batches\": fisher_batches}\n",
    "    elif method == \"rehearsal\":\n",
    "        buffer_size  = trial.suggest_int(\"buffer_size\", 1000, 8000, step=1000)\n",
    "        replay_ratio = trial.suggest_float(\"replay_ratio\", 0.05, 0.4, step=0.05)\n",
    "        return {\"buffer_size\": buffer_size, \"replay_ratio\": replay_ratio}\n",
    "    elif method == \"rehearsal+ewc\":\n",
    "        buffer_size  = trial.suggest_int(\"buffer_size\", 1000, 8000, step=1000)\n",
    "        replay_ratio = trial.suggest_float(\"replay_ratio\", 0.05, 0.4, step=0.05)\n",
    "        lam = trial.suggest_float(\"lam\", 3e8, 2e9, log=True)\n",
    "        fisher_batches = trial.suggest_int(\"fisher_batches\", 200, 1200, step=100)\n",
    "        return {\"buffer_size\": buffer_size, \"replay_ratio\": replay_ratio, \"lam\": lam, \"fisher_batches\": fisher_batches}\n",
    "    else:  # naive (sin HPs)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841fd521",
   "metadata": {},
   "source": [
    "<a id=\"sec-06\"></a>\n",
    "\n",
    "## 6) Estudio Optuna ‚Äî un m√©todo concreto\n",
    "\n",
    "- **Study**: contenedor de la b√∫squeda.\n",
    "- **Trial**: una configuraci√≥n (punto) en el espacio de HPs.\n",
    "- **Objective**: funci√≥n que entrena/eval√∫a y devuelve un **valor a minimizar**.\n",
    "\n",
    "Par√°metros clave:\n",
    "- `METHOD_TO_OPTIMIZE`: `\"ewc\"`, `\"rehearsal\"`, `\"rehearsal+ewc\"` o `\"naive\"`.\n",
    "- `N_TRIALS`: n¬∫ de configuraciones a probar.\n",
    "- `HPO_EPOCHS`: si no es `None`, **sobrescribe** las `epochs` del preset **solo durante HPO** (acelera la b√∫squeda). Luego reentrenas a tope en la Secci√≥n 8.\n",
    "\n",
    "**Qu√© hace cada trial:**\n",
    "1. Sugerir HPs (`suggest_*`).\n",
    "2. Construir `cfg` con esos HPs (y `epochs` reducidas si `HPO_EPOCHS`).\n",
    "3. Ejecutar `run_continual(...)`.\n",
    "4. Leer `continual_results.json`, calcular m√©trica objetivo y devolv√©rsela a Optuna.\n",
    "\n",
    "**Salida:**\n",
    "- `study.best_params`: mejores HPs.\n",
    "- `study.best_value`: valor objetivo m√≠nimo.\n",
    "- `study.best_trial.user_attrs`: metadatos (ruta del experimento, m√©tricas) que guardamos nosotros.\n",
    "\n",
    "> **Tip:** Para runs largos a√±ade *pruning* o una base de datos (`optuna.create_study(storage=...)`) si quieres **reanudar** b√∫squedas en varias sesiones.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f92711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 21:02:16,985] Using an existing study with name 'HPO_ewc_fast_rate_T10' instead of creating a new one.\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.227432:  12%|‚ñà‚ñé        | 1/8 [21:42<2:32:00, 1302.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 21:23:59,912] Trial 8 finished with value: 0.22743245650098898 and parameters: {'lam': 719635936.6959424, 'fisher_batches': 900}. Best is trial 8 with value: 0.22743245650098898.\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_3e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_3e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.227432:  25%|‚ñà‚ñà‚ñå       | 2/8 [43:19<2:09:55, 1299.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 21:45:36,652] Trial 9 finished with value: 0.25385994703538955 and parameters: {'lam': 311846256.45778006, 'fisher_batches': 700}. Best is trial 8 with value: 0.22743245650098898.\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_2e+09 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_2e+09 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Configuraci√≥n del estudio\n",
    "METHOD_TO_OPTIMIZE = \"ewc\"   # \"naive\" | \"ewc\" | \"rehearsal\" | \"rehearsal+ewc\"\n",
    "N_TRIALS = 8                 # s√∫belo cuando est√©s satisfecho con tiempos/estabilidad\n",
    "HPO_EPOCHS = None            # None -> usar epochs del preset; o pon un int (ej. 3) para acelerar\n",
    "REHEARSAL_NAMES = (\"rehearsal\", \"rehearsal+ewc\")\n",
    "\n",
    "def build_cfg_with_method(base_cfg: dict, method_name: str, params: dict, hpo_epochs: int|None):\n",
    "    cfg = copy.deepcopy(base_cfg)\n",
    "    cfg[\"continual\"][\"method\"] = method_name\n",
    "    cfg[\"continual\"][\"params\"] = params or {}\n",
    "\n",
    "    if hpo_epochs is not None:\n",
    "        cfg[\"optim\"][\"epochs\"] = int(hpo_epochs)\n",
    "    return cfg\n",
    "\n",
    "def run_one_cfg(cfg: dict) -> tuple[Path, dict, dict]:\n",
    "    out_dir, res = run_continual(\n",
    "        task_list=task_list,\n",
    "        make_loader_fn=make_loader_fn,\n",
    "        make_model_fn=make_model_fn,\n",
    "        tfm=tfm,\n",
    "        cfg=cfg,\n",
    "        preset_name=PRESET,\n",
    "        out_root=ROOT / \"outputs\",\n",
    "        verbose=True,\n",
    "    )\n",
    "    results = _load_results(out_dir) or (res if isinstance(res, dict) else {})\n",
    "    return out_dir, res, results\n",
    "\n",
    "def optuna_objective(trial: optuna.Trial):\n",
    "    params = suggest_params_for_method(trial, METHOD_TO_OPTIMIZE)\n",
    "    cfg_i  = build_cfg_with_method(CFG, METHOD_TO_OPTIMIZE, params, HPO_EPOCHS)\n",
    "\n",
    "    # === Hotfix selectivo para estabilidad con replay ===\n",
    "    if METHOD_TO_OPTIMIZE.lower() in REHEARSAL_NAMES:\n",
    "        cfg_i[\"data\"][\"persistent_workers\"] = False\n",
    "        # Opcionales si vieras inestabilidad puntual:\n",
    "        # cfg_i[\"optim\"][\"amp\"] = False\n",
    "        # cfg_i[\"data\"][\"pin_memory\"] = False\n",
    "        # cfg_i[\"data\"][\"num_workers\"] = min(int(cfg_i[\"data\"].get(\"num_workers\") or 0), 2)\n",
    "\n",
    "    cfg_i.setdefault(\"naming\", {})\n",
    "    tag = f\"{METHOD_TO_OPTIMIZE}_hpo_t{trial.number}\"\n",
    "    if METHOD_TO_OPTIMIZE in (\"ewc\", \"rehearsal+ewc\") and \"lam\" in params:\n",
    "        tag += f\"_lam_{params['lam']:.1e}\"\n",
    "    cfg_i[\"naming\"][\"tag\"] = tag\n",
    "\n",
    "    try:\n",
    "        out_dir, _, results = run_one_cfg(cfg_i)\n",
    "        metrics = extract_metrics(results)\n",
    "        val = composite_objective(metrics, ALPHA_FORGET)\n",
    "        trial.set_user_attr(\"out_dir\", str(out_dir))\n",
    "        trial.set_user_attr(\"metrics\", metrics)\n",
    "        trial.set_user_attr(\"method\", METHOD_TO_OPTIMIZE)\n",
    "        trial.set_user_attr(\"params\", params)\n",
    "        return val\n",
    "    except Exception as e:\n",
    "        # No tires abajo todo el estudio por un trial problem√°tico\n",
    "        trial.set_user_attr(\"error\", repr(e))\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        # Limpieza ligera entre trials (evita fragmentaci√≥n de memoria GPU)\n",
    "        import gc, time\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "\n",
    "\n",
    "# --- Persistencia Optuna en SQLite ---\n",
    "OPTUNA_DIR = ROOT / \"outputs\" / \"optuna\"\n",
    "OPTUNA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DB_PATH = OPTUNA_DIR / f\"hpo_{METHOD_TO_OPTIMIZE}_{PRESET}_{MODEL_NAME}_{ENCODER}_T{T}_g{GAIN}.sqlite\"\n",
    "STORAGE = f\"sqlite:///{DB_PATH}\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=f\"HPO_{METHOD_TO_OPTIMIZE}_{PRESET}_{ENCODER}_T{T}\",\n",
    "    storage=STORAGE,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# Opcional: sampler/pruner (puedes a√±adirlos si quieres)\n",
    "# from optuna.samplers import TPESampler\n",
    "# from optuna.pruners import MedianPruner\n",
    "# study.sampler = TPESampler(seed=SEED)\n",
    "# study.pruner  = MedianPruner(n_startup_trials=3)\n",
    "\n",
    "study.optimize(optuna_objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(\"SQLite:\", DB_PATH)\n",
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best attrs:\", study.best_trial.user_attrs)\n",
    "\n",
    "# Guardar trazabilidad de intentos a CSV\n",
    "df_trials = study.trials_dataframe(attrs=(\"number\",\"value\",\"state\",\"params\",\"user_attrs\"))\n",
    "df_trials.to_csv(OPTUNA_DIR / f\"{DB_PATH.stem}_trials.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best attrs:\", study.best_trial.user_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48b08b",
   "metadata": {},
   "source": [
    "<a id=\"sec-07\"></a>\n",
    "\n",
    "## 7) Estudio Optuna conjunto (elige m√©todo + HPs)\n",
    "\n",
    "Si `RUN_JOINT=True`, el **trial** tambi√©n elige el **m√©todo**:\n",
    "- `method ‚àà {naive, ewc, rehearsal, rehearsal+ewc}`\n",
    "- Y luego sus HPs correspondientes.\n",
    "\n",
    "√ötil cuando:\n",
    "- No sabes qu√© m√©todo es mejor en tu dataset.\n",
    "- Quieres una **comparativa autom√°tica** con el mismo presupuesto de c√≥mputo.\n",
    "\n",
    "> Empieza con `RUN_JOINT=False` para validar el flujo con un √∫nico m√©todo. Luego enci√©ndelo y sube `N_TRIALS_JOINT`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e7f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_JOINT=False ‚Äî omitido.\n"
     ]
    }
   ],
   "source": [
    "RUN_JOINT = False   # Pon True si quieres lanzar el estudio conjunto\n",
    "N_TRIALS_JOINT = 10\n",
    "\n",
    "def optuna_objective_joint(trial: optuna.Trial):\n",
    "    method = trial.suggest_categorical(\"method\", [\"naive\",\"ewc\",\"rehearsal\",\"rehearsal+ewc\"])\n",
    "    params = suggest_params_for_method(trial, method)\n",
    "    cfg_i  = build_cfg_with_method(CFG, method, params, HPO_EPOCHS)\n",
    "\n",
    "    # === Hotfix selectivo (solo m√©todos con replay) ===\n",
    "    if method.lower() in REHEARSAL_NAMES:\n",
    "        cfg_i[\"data\"][\"persistent_workers\"] = False\n",
    "        # Opcionales si hiciera falta:\n",
    "        # cfg_i[\"optim\"][\"amp\"] = False\n",
    "        # cfg_i[\"data\"][\"pin_memory\"] = False\n",
    "        # cfg_i[\"data\"][\"num_workers\"] = min(int(cfg_i[\"data\"].get(\"num_workers\") or 0), 2)\n",
    "\n",
    "    cfg_i.setdefault(\"naming\", {})\n",
    "    tag = f\"{method}_hpo_t{trial.number}\"\n",
    "    if method in (\"ewc\", \"rehearsal+ewc\") and \"lam\" in params:\n",
    "        tag += f\"_lam_{params['lam']:.1e}\"\n",
    "    cfg_i[\"naming\"][\"tag\"] = tag\n",
    "\n",
    "    try:\n",
    "        out_dir, _, results = run_one_cfg(cfg_i)\n",
    "        metrics = extract_metrics(results)\n",
    "        val = objective_value(metrics, ALPHA_FORGET)  # tu versi√≥n conjunta\n",
    "        trial.set_user_attr(\"out_dir\", str(out_dir))\n",
    "        trial.set_user_attr(\"metrics\", metrics)\n",
    "        trial.set_user_attr(\"method\", method)\n",
    "        trial.set_user_attr(\"params\", params)\n",
    "        return val\n",
    "    except Exception as e:\n",
    "        trial.set_user_attr(\"error\", repr(e))\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        import gc, time\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "\n",
    "\n",
    "if RUN_JOINT:\n",
    "    study_joint = optuna.create_study(direction=\"minimize\", study_name=\"HPO_joint\")\n",
    "    study_joint.optimize(optuna_objective_joint, n_trials=N_TRIALS_JOINT, show_progress_bar=True)\n",
    "    print(\"Best value:\", study_joint.best_value)\n",
    "    print(\"Best params:\", study_joint.best_params)\n",
    "    print(\"Best attrs:\", study_joint.best_trial.user_attrs)\n",
    "else:\n",
    "    print(\"RUN_JOINT=False ‚Äî omitido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cdc9f",
   "metadata": {},
   "source": [
    "<a id=\"sec-08\"></a>\n",
    "\n",
    "## 8) Re-entrena con los mejores hiperpar√°metros\n",
    "\n",
    "- Coge `study.best_params` y `METHOD_TO_OPTIMIZE`.\n",
    "- Reconstruye `cfg_best` con el **m√©todo ganador + HPs**.\n",
    "- (Opcional) Restablece `epochs` del preset si usaste `HPO_EPOCHS` para acelerar.\n",
    "- Lanza `run_continual(...)` **a pleno rendimiento**.\n",
    "- Muestra m√©tricas finales y la **carpeta de salida**.\n",
    "\n",
    "> As√≠ separas la **b√∫squeda r√°pida** (pocas epochs) del **entrenamiento serio** (epochs del preset).\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40464ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor m√©todo: ewc\n",
      "Mejores HPs: {'lam': 740438758.1891335, 'fisher_batches': 500}\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_7e+08 | B=64 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados finales (re-train): {'c1': 'circuito1', 'c2': 'circuito2', 'c1_mae': 0.14293317359107352, 'c1_after_c2_mae': 0.14407188493681106, 'forget_rel_%': 0.7966739400856985, 'c2_mae': 0.26833168388694845}\n",
      "Guardado en: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_7e+08_lam_7e+08_rate_model-PilotNetSNN_66x200_gray_seed_42\n"
     ]
    }
   ],
   "source": [
    "# Usa el mejor del estudio por m√©todo (arriba)\n",
    "BEST_PARAMS = study.best_params\n",
    "BEST_METHOD = METHOD_TO_OPTIMIZE\n",
    "\n",
    "print(\"Mejor m√©todo:\", BEST_METHOD)\n",
    "print(\"Mejores HPs:\", BEST_PARAMS)\n",
    "\n",
    "cfg_best = copy.deepcopy(CFG)\n",
    "cfg_best[\"continual\"][\"method\"] = BEST_METHOD\n",
    "cfg_best[\"continual\"][\"params\"] = BEST_PARAMS\n",
    "\n",
    "# (Opcional) restablecer epochs al valor del preset si redujiste para HPO\n",
    "# cfg_best[\"optim\"][\"epochs\"] = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)[\"optim\"][\"epochs\"]\n",
    "\n",
    "out_dir, _, results = run_one_cfg(cfg_best)\n",
    "metrics = extract_metrics(results)\n",
    "print(\"Resultados finales (re-train):\", metrics)\n",
    "print(\"Guardado en:\", out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99cf26e",
   "metadata": {},
   "source": [
    "<a id=\"sec-09\"></a>\n",
    "\n",
    "## 9) Resumen r√°pido de runs (tabla)\n",
    "\n",
    "- Recorremos `outputs/continual_*` y leemos `continual_results.json`.\n",
    "- Extraemos y tabulamos:\n",
    "  - `preset`, `method`, `encoder`, `seed`, (y `lambda` si aplica),\n",
    "  - `c1_mae`, `c1_after_c2_mae`, `forget_rel_%`, `c2_mae`.\n",
    "\n",
    "**C√≥mo leerla:**\n",
    "- **`c2_mae`** bajo ‚Üí aprende bien la √∫ltima tarea.\n",
    "- **`forget_rel_%`** bajo ‚Üí **poco olvido** de la primera.\n",
    "- Filtra por preset/m√©todo para comparar **manzanas con manzanas**.\n",
    "\n",
    "> Consejo: Exporta a CSV/Parquet si quieres hacer gr√°ficas comparativas a posteriori.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca61bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs en resumen: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>preset</th>\n",
       "      <th>method</th>\n",
       "      <th>lambda</th>\n",
       "      <th>encoder</th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>c1_mae</th>\n",
       "      <th>c1_after_c2_mae</th>\n",
       "      <th>forget_rel_%</th>\n",
       "      <th>c2_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.143431</td>\n",
       "      <td>0.147171</td>\n",
       "      <td>2.607426</td>\n",
       "      <td>0.257968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>43</td>\n",
       "      <td>0.174228</td>\n",
       "      <td>0.170924</td>\n",
       "      <td>-1.896875</td>\n",
       "      <td>0.222932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continual_fast_ewc_lam_2e+09_lam_2e+09_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>2e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.155467</td>\n",
       "      <td>0.146814</td>\n",
       "      <td>-5.565735</td>\n",
       "      <td>0.270587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>continual_fast_ewc_lam_3e+08_lam_3e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>3e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.155467</td>\n",
       "      <td>0.152690</td>\n",
       "      <td>-1.786268</td>\n",
       "      <td>0.239508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>continual_fast_ewc_lam_4e+08_lam_4e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>4e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.155516</td>\n",
       "      <td>0.157668</td>\n",
       "      <td>1.384201</td>\n",
       "      <td>0.263156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>continual_fast_ewc_lam_6e+08_lam_6e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>6e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.156865</td>\n",
       "      <td>0.173882</td>\n",
       "      <td>10.848712</td>\n",
       "      <td>0.286293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>continual_fast_ewc_lam_7e+08_lam_7e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.142933</td>\n",
       "      <td>0.144072</td>\n",
       "      <td>0.796674</td>\n",
       "      <td>0.268332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>continual_fast_ewc_lam_8e+08_lam_8e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>8e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.155467</td>\n",
       "      <td>0.145578</td>\n",
       "      <td>-6.360858</td>\n",
       "      <td>0.257729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>continual_fast_ewc_lam_9e+08_lam_9e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>9e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.155467</td>\n",
       "      <td>0.147286</td>\n",
       "      <td>-5.262219</td>\n",
       "      <td>0.261564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>continual_fast_ewc_lam_4e+08_lam_4e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t0_lam_4.3e+08</td>\n",
       "      <td>4e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.170480</td>\n",
       "      <td>17.248765</td>\n",
       "      <td>0.248004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>continual_fast_ewc_lam_8e+08_lam_8e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t1_lam_7.9e+08</td>\n",
       "      <td>8e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.142933</td>\n",
       "      <td>0.145396</td>\n",
       "      <td>1.723117</td>\n",
       "      <td>0.267379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>continual_fast_ewc_lam_6e+08_lam_6e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t2_lam_6.4e+08</td>\n",
       "      <td>6e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.142933</td>\n",
       "      <td>0.145333</td>\n",
       "      <td>1.679194</td>\n",
       "      <td>0.264787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t3_lam_1.3e+09</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.142933</td>\n",
       "      <td>0.144831</td>\n",
       "      <td>1.327926</td>\n",
       "      <td>0.287223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>continual_fast_ewc_lam_6e+08_lam_6e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t4_lam_6.4e+08</td>\n",
       "      <td>6e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.142933</td>\n",
       "      <td>0.145183</td>\n",
       "      <td>1.574015</td>\n",
       "      <td>0.265599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t5_lam_1.0e+09</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.142933</td>\n",
       "      <td>0.145336</td>\n",
       "      <td>1.680960</td>\n",
       "      <td>0.279295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>continual_fast_ewc_lam_3e+08_lam_3e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t6_lam_3.1e+08</td>\n",
       "      <td>3e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.142933</td>\n",
       "      <td>0.146351</td>\n",
       "      <td>2.391513</td>\n",
       "      <td>0.256720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>continual_fast_ewc_lam_7e+08_lam_7e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t7_lam_7.4e+08</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.142933</td>\n",
       "      <td>0.144074</td>\n",
       "      <td>0.797916</td>\n",
       "      <td>0.268332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>continual_fast_naive_rate_model-PilotNetSNN_66...</td>\n",
       "      <td>fast</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.172229</td>\n",
       "      <td>0.171840</td>\n",
       "      <td>-0.225759</td>\n",
       "      <td>0.223342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>continual_fast_naive_rate_model-PilotNetSNN_66...</td>\n",
       "      <td>fast</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>43</td>\n",
       "      <td>0.161234</td>\n",
       "      <td>0.252817</td>\n",
       "      <td>56.801521</td>\n",
       "      <td>0.204764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>continual_fast_rehearsal_buf_5000_rr_20_rate_m...</td>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_5000_rr_20</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.143431</td>\n",
       "      <td>0.177949</td>\n",
       "      <td>24.065498</td>\n",
       "      <td>0.185561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>continual_fast_rehearsal_buf_5000_rr_20+ewc_la...</td>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_5000_rr_20+ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.172229</td>\n",
       "      <td>0.172206</td>\n",
       "      <td>-0.013494</td>\n",
       "      <td>0.223997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  exp preset  \\\n",
       "0   continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...   fast   \n",
       "1   continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...   fast   \n",
       "2   continual_fast_ewc_lam_2e+09_lam_2e+09_rate_mo...   fast   \n",
       "3   continual_fast_ewc_lam_3e+08_lam_3e+08_rate_mo...   fast   \n",
       "4   continual_fast_ewc_lam_4e+08_lam_4e+08_rate_mo...   fast   \n",
       "5   continual_fast_ewc_lam_6e+08_lam_6e+08_rate_mo...   fast   \n",
       "6   continual_fast_ewc_lam_7e+08_lam_7e+08_rate_mo...   fast   \n",
       "7   continual_fast_ewc_lam_8e+08_lam_8e+08_rate_mo...   fast   \n",
       "8   continual_fast_ewc_lam_9e+08_lam_9e+08_rate_mo...   fast   \n",
       "9   continual_fast_ewc_lam_4e+08_lam_4e+08_ewc_hpo...   fast   \n",
       "10  continual_fast_ewc_lam_8e+08_lam_8e+08_ewc_hpo...   fast   \n",
       "11  continual_fast_ewc_lam_6e+08_lam_6e+08_ewc_hpo...   fast   \n",
       "12  continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...   fast   \n",
       "13  continual_fast_ewc_lam_6e+08_lam_6e+08_ewc_hpo...   fast   \n",
       "14  continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...   fast   \n",
       "15  continual_fast_ewc_lam_3e+08_lam_3e+08_ewc_hpo...   fast   \n",
       "16  continual_fast_ewc_lam_7e+08_lam_7e+08_ewc_hpo...   fast   \n",
       "17  continual_fast_naive_rate_model-PilotNetSNN_66...   fast   \n",
       "18  continual_fast_naive_rate_model-PilotNetSNN_66...   fast   \n",
       "19  continual_fast_rehearsal_buf_5000_rr_20_rate_m...   fast   \n",
       "20  continual_fast_rehearsal_buf_5000_rr_20+ewc_la...   fast   \n",
       "\n",
       "                          method lambda encoder                    model  \\\n",
       "0                            ewc  1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "1                            ewc  1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "2                            ewc  2e+09    rate  PilotNetSNN_66x200_gray   \n",
       "3                            ewc  3e+08    rate  PilotNetSNN_66x200_gray   \n",
       "4                            ewc  4e+08    rate  PilotNetSNN_66x200_gray   \n",
       "5                            ewc  6e+08    rate  PilotNetSNN_66x200_gray   \n",
       "6                            ewc  7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "7                            ewc  8e+08    rate  PilotNetSNN_66x200_gray   \n",
       "8                            ewc  9e+08    rate  PilotNetSNN_66x200_gray   \n",
       "9     ewc_ewc_hpo_t0_lam_4.3e+08  4e+08    rate  PilotNetSNN_66x200_gray   \n",
       "10    ewc_ewc_hpo_t1_lam_7.9e+08  8e+08    rate  PilotNetSNN_66x200_gray   \n",
       "11    ewc_ewc_hpo_t2_lam_6.4e+08  6e+08    rate  PilotNetSNN_66x200_gray   \n",
       "12    ewc_ewc_hpo_t3_lam_1.3e+09  1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "13    ewc_ewc_hpo_t4_lam_6.4e+08  6e+08    rate  PilotNetSNN_66x200_gray   \n",
       "14    ewc_ewc_hpo_t5_lam_1.0e+09  1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "15    ewc_ewc_hpo_t6_lam_3.1e+08  3e+08    rate  PilotNetSNN_66x200_gray   \n",
       "16    ewc_ewc_hpo_t7_lam_7.4e+08  7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "17                         naive   None    rate  PilotNetSNN_66x200_gray   \n",
       "18                         naive   None    rate  PilotNetSNN_66x200_gray   \n",
       "19      rehearsal_buf_5000_rr_20   None    rate  PilotNetSNN_66x200_gray   \n",
       "20  rehearsal_buf_5000_rr_20+ewc  7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "\n",
       "    seed    c1_mae  c1_after_c2_mae  forget_rel_%    c2_mae  \n",
       "0     42  0.143431         0.147171      2.607426  0.257968  \n",
       "1     43  0.174228         0.170924     -1.896875  0.222932  \n",
       "2     42  0.155467         0.146814     -5.565735  0.270587  \n",
       "3     42  0.155467         0.152690     -1.786268  0.239508  \n",
       "4     42  0.155516         0.157668      1.384201  0.263156  \n",
       "5     42  0.156865         0.173882     10.848712  0.286293  \n",
       "6     42  0.142933         0.144072      0.796674  0.268332  \n",
       "7     42  0.155467         0.145578     -6.360858  0.257729  \n",
       "8     42  0.155467         0.147286     -5.262219  0.261564  \n",
       "9     42  0.145400         0.170480     17.248765  0.248004  \n",
       "10    42  0.142933         0.145396      1.723117  0.267379  \n",
       "11    42  0.142933         0.145333      1.679194  0.264787  \n",
       "12    42  0.142933         0.144831      1.327926  0.287223  \n",
       "13    42  0.142933         0.145183      1.574015  0.265599  \n",
       "14    42  0.142933         0.145336      1.680960  0.279295  \n",
       "15    42  0.142933         0.146351      2.391513  0.256720  \n",
       "16    42  0.142933         0.144074      0.797916  0.268332  \n",
       "17    42  0.172229         0.171840     -0.225759  0.223342  \n",
       "18    43  0.161234         0.252817     56.801521  0.204764  \n",
       "19    42  0.143431         0.177949     24.065498  0.185561  \n",
       "20    42  0.172229         0.172206     -0.013494  0.223997  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Tabla m√≠nima para HPO / inspecci√≥n r√°pida ===\n",
    "from src.utils_exp import build_runs_df\n",
    "import pandas as pd\n",
    "\n",
    "outputs_root = ROOT / \"outputs\"\n",
    "df = build_runs_df(outputs_root)\n",
    "\n",
    "print(f\"runs en resumen: {len(df)}\")\n",
    "if df.empty:\n",
    "    print(\"No hay filas (¬øno existen JSONs o solo hubo 1 tarea por run?).\")\n",
    "else:\n",
    "    # columnas clave para tuning; mantiene el nombre 'forget_rel_%' por compatibilidad\n",
    "    view = df.rename(columns={\"c1_forgetting_mae_rel_%\": \"forget_rel_%\"}).loc[:, [\n",
    "        \"exp\",\"preset\",\"method\",\"lambda\",\"encoder\",\"model\",\"seed\",\n",
    "        \"c1_mae\",\"c1_after_c2_mae\",\"forget_rel_%\",\"c2_mae\"\n",
    "    ]]\n",
    "    display(view.sort_values([\"preset\",\"method\",\"encoder\",\"lambda\"], na_position=\"last\", ignore_index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716c060",
   "metadata": {},
   "source": [
    "## Ap√©ndice ‚Äî Optuna en 90 segundos\n",
    "\n",
    "- **Study**: el proyecto de HPO (contiene todos los trials).\n",
    "- **Trial**: una evaluaci√≥n con un conjunto de HPs (`suggest_int`, `suggest_float`, etc.).\n",
    "- **Sampler**: estrategia para elegir el siguiente punto (por defecto, TPE).\n",
    "- **Pruner**: **corta** trials que pintan mal (acelera b√∫squedas largas).\n",
    "- **Storage**: base de datos (SQLite, PostgreSQL) para **reanudar** y/o **paralelizar**.\n",
    "\n",
    "### Reanudar b√∫squedas\n",
    "Puedes crear el estudio con almacenamiento:\n",
    "```python\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"HPO_ewc\",\n",
    "    storage=f\"sqlite:///{ROOT/'outputs'/'optuna_ewc.sqlite'}\",\n",
    "    load_if_exists=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1b431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5\n",
      "12.5\n",
      "6.41\n"
     ]
    }
   ],
   "source": [
    "from src.hpo import objective_value, composite_objective\n",
    "m = {\"c2_mae\": 0.16, \"forget_rel_%\": 12.5}\n",
    "print(objective_value(m, key=\"forget_rel_%\"))         # 12.5\n",
    "print(objective_value(m, key=\"c1_forgetting_mae_rel_%\"))  # 12.5 (alias OK)\n",
    "print(composite_objective(m, alpha=0.5))              # 0.16 + 0.5*12.5 = 6.41\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
