{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9f0dc7",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# 03B ‚Äî B√∫squeda de hiperpar√°metros con Optuna (Continual Learning)\n",
    "\n",
    "**Qu√© hace este notebook**  \n",
    "Automatiza la **optimizaci√≥n de hiperpar√°metros (HPO)** para m√©todos de aprendizaje continuo manteniendo **coherencia total** con `configs/presets.yaml`. Permite afinar, entre otros:\n",
    "\n",
    "- **naive** (l√≠nea base),\n",
    "- **ewc** (Elastic Weight Consolidation),\n",
    "- **rehearsal** (rejuego con buffer),\n",
    "- **rehearsal+ewc** (combinaci√≥n),\n",
    "- **as-snn** (bio-inspirado; espacio de b√∫squeda incluido).\n",
    "\n",
    "Se apoya en:\n",
    "- `configs/presets.yaml` (misma configuraci√≥n que el resto de cuadernos),\n",
    "- `build_make_loader_fn` (elige **H5 offline** o **CSV + codificaci√≥n en runtime**),\n",
    "- `run_continual` (entrena, eval√∫a y guarda m√©tricas en `outputs/`).\n",
    "\n",
    "---\n",
    "\n",
    "### M√©trica objetivo (minimizar)\n",
    "\n",
    "\\[\n",
    "\\textbf{Objetivo}= \\mathrm{MAE}_{\\text{tarea final}} + \\alpha \\cdot \\max\\!\\bigl(0,\\; \\text{OlvidoRelativo}\\,\\%\\bigr)\n",
    "\\]\n",
    "\n",
    "- **MAE de la tarea final**: rendimiento en la **√∫ltima** tarea de la secuencia.  \n",
    "- **Olvido relativo (%)**: degradaci√≥n de la **primera** tarea tras aprender la/s siguiente/s.  \n",
    "- **Œ±**: peso del olvido (por defecto **0.5**). S√∫belo si quieres penalizar m√°s el olvido.\n",
    "\n",
    "> La extracci√≥n de m√©tricas se realiza desde `continual_results.json`. Si falta informaci√≥n, ese *trial* se considera peor (valor infinito) para no sesgar el estudio.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "- `pip install optuna`  \n",
    "- **Datos** preparados (`tasks.json` o `tasks_balanced.json` desde 01/01A).  \n",
    "- Si el preset usa **offline** (`use_offline_spikes: true`), tener los **H5** generados con **02_ENCODE_OFFLINE** (mismo `encoder/T/gain/size/to_gray`).\n",
    "\n",
    "> **Consejo**: empieza con el preset `fast` y pocos *trials*; si todo es estable, sube `N_TRIALS` y/o `epochs`.\n",
    "\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "- [1) Imports y setup de entorno](#sec-01)  \n",
    "- [2) Carga de preset y construcci√≥n de modelo/transform](#sec-02)  \n",
    "- [3) Tareas y factory de loaders](#sec-03)  \n",
    "- [4) M√©tricas y objetivo para Optuna](#sec-04)  \n",
    "- [5) Espacios de b√∫squeda (por m√©todo)](#sec-05)  \n",
    "- [6) Estudio Optuna ‚Äî un m√©todo concreto](#sec-06)  \n",
    "- [7) Estudio Optuna conjunto (elige m√©todo + HPs)](#sec-07)  \n",
    "- [8) Re-entrena con los mejores hiperpar√°metros](#sec-08)  \n",
    "- [9) Resumen r√°pido de *runs* (tabla)](#sec-09)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5bd35d",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "## 1) Imports y setup de entorno\n",
    "\n",
    "**Objetivo**  \n",
    "Configurar el entorno de HPO de forma reproducible y eficiente:\n",
    "\n",
    "- Limitar hilos BLAS (`OMP/MKL/OPENBLAS`) para evitar sobrecarga de CPU.  \n",
    "- Detectar `ROOT` (ra√≠z del repo) y a√±adirlo a `sys.path`.  \n",
    "- Importar utilidades del proyecto (`load_preset`, `build_make_loader_fn`, `run_continual`, etc.).  \n",
    "- Seleccionar dispositivo (`cuda` si est√° disponible) y activar optimizaciones de PyTorch (TF32/cuDNN).\n",
    "\n",
    "> Si tu CPU va justa, baja `torch.set_num_threads(4)` a `2`.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbd7d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/proyectos/TFM_SNN/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Limitar threads BLAS (opcional)\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "# Para fragmentaci√≥n de memoria (PyTorch 2.x):\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "os.environ[\"TRAIN_LOG_ITPS\"] = \"1\"   # quita esta l√≠nea si no quieres logs de it/s\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, copy, time\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "# Ra√≠z del repo y sys.path\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Proyecto\n",
    "from src.utils import load_preset, build_make_loader_fn\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import build_model\n",
    "from src.runner import run_continual\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14b25c",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "## 2) Carga de preset y construcci√≥n de modelo/transform\n",
    "\n",
    "**Objetivo**  \n",
    "Tomar la **fuente de la verdad** del experimento desde `configs/presets.yaml` y derivar:\n",
    "\n",
    "- **Modelo/transform** (`ImageTransform`) seg√∫n `img_w`, `img_h`, `to_gray`.  \n",
    "- **Codificaci√≥n temporal** (`encoder` ‚àà `{rate, latency, raw}`, `T`, `gain`, `seed`).  \n",
    "- **Flags de datos**: `use_offline_spikes` (H5 offline) y/o `encode_runtime` (codificaci√≥n en GPU).  \n",
    "- **DataLoader**: `num_workers`, `prefetch_factor`, `pin_memory`, `persistent_workers`.  \n",
    "- **Augment** (`aug_train`) y **balanceo online** si procede.\n",
    "\n",
    "Se define `make_model_fn(tfm)` para instanciar el modelo con los par√°metros adecuados.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc61aef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRESET=fast] model=pilotnet_snn 200x66 gray=True\n",
      "[DATA] encoder=rate T=10 gain=0.5 seed=42\n",
      "[LOADER] workers=8 prefetch=2 pin=True persistent=True\n",
      "[BALANCE] online=False bins=50\n",
      "[RUNTIME_ENCODE] False | [OFFLINE_SPIKES] True\n"
     ]
    }
   ],
   "source": [
    "PRESET = \"fast\"  # fast | std | accurate\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# Modelo / tfm\n",
    "MODEL_NAME = CFG[\"model\"][\"name\"]\n",
    "tfm = ImageTransform(\n",
    "    CFG[\"model\"][\"img_w\"],\n",
    "    CFG[\"model\"][\"img_h\"],\n",
    "    to_gray=bool(CFG[\"model\"][\"to_gray\"]),\n",
    "    crop_top=None\n",
    ")\n",
    "\n",
    "# Datos / codificaci√≥n temporal\n",
    "ENCODER = CFG[\"data\"][\"encoder\"]\n",
    "T       = int(CFG[\"data\"][\"T\"])\n",
    "GAIN    = float(CFG[\"data\"][\"gain\"])\n",
    "SEED    = int(CFG[\"data\"][\"seed\"])\n",
    "\n",
    "# Flags & loader\n",
    "USE_OFFLINE_SPIKES = bool(CFG[\"data\"].get(\"use_offline_spikes\", False))\n",
    "RUNTIME_ENCODE     = bool(CFG[\"data\"].get(\"encode_runtime\", False))\n",
    "\n",
    "NUM_WORKERS = int(CFG[\"data\"].get(\"num_workers\") or 0)      # robusto\n",
    "PREFETCH    = int(CFG[\"data\"].get(\"prefetch_factor\") or 2)  # <- casteo robusto\n",
    "PIN_MEMORY  = bool(CFG[\"data\"].get(\"pin_memory\", True))\n",
    "PERSISTENT  = bool(CFG[\"data\"].get(\"persistent_workers\", True))\n",
    "\n",
    "AUG_CFG = AugmentConfig(**(CFG[\"data\"].get(\"aug_train\") or {})) \\\n",
    "          if CFG[\"data\"].get(\"aug_train\") else None\n",
    "\n",
    "USE_ONLINE_BAL = bool(CFG[\"data\"].get(\"balance_online\", False))\n",
    "BAL_BINS = int(CFG[\"data\"].get(\"balance_bins\") or 50)\n",
    "BAL_EPS  = float(CFG[\"data\"].get(\"balance_smooth_eps\") or 1e-3)\n",
    "\n",
    "print(f\"[PRESET={PRESET}] model={MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] encoder={ENCODER} T={T} gain={GAIN} seed={SEED}\")\n",
    "print(f\"[LOADER] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "print(f\"[BALANCE] online={USE_ONLINE_BAL} bins={BAL_BINS}\")\n",
    "print(f\"[RUNTIME_ENCODE] {RUNTIME_ENCODE} | [OFFLINE_SPIKES] {USE_OFFLINE_SPIKES}\")\n",
    "\n",
    "def make_model_fn(tfm):\n",
    "    # kwargs espec√≠ficos de pilotnet_snn; ignorados para otros\n",
    "    return build_model(MODEL_NAME, tfm, beta=0.9, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b9209",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "## 3) Tareas y factory de loaders\n",
    "\n",
    "**Objetivo**  \n",
    "Construir la lista de tareas y un **factory de DataLoaders** coherente con el preset:\n",
    "\n",
    "- Se elige `tasks_balanced.json` si `prep.use_balanced_tasks: true` y existe; si no, `tasks.json`.  \n",
    "- Si `use_offline_spikes: true`, se verifican los **H5** esperados (nomenclatura fija con `encoder/T/gain/size/color`).  \n",
    "- `build_make_loader_fn(...)` selecciona autom√°ticamente **H5** (offline) o **CSV + runtime encode** en GPU.  \n",
    "- El *wrapper* `make_loader_fn(...)` solo **propaga kwargs** (augment, balanceo online, *workers*, etc.) para que el *runner* no cambie.\n",
    "\n",
    "> Si usas *tasks* balanceadas, el **train** debe ser `train_balanced.csv` (o su H5 derivado). El notebook lo comprueba.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86ce050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando: tasks_balanced.json\n",
      "Tareas y TRAIN CSV/H5 a usar:\n",
      " - circuito1: train_balanced.csv\n",
      " - circuito2: train_balanced.csv\n",
      "make_loader_fn listo.\n"
     ]
    }
   ],
   "source": [
    "# Leer tasks.json / tasks_balanced.json (elige seg√∫n el preset)\n",
    "from pathlib import Path as _P\n",
    "import json\n",
    "\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "USE_BALANCED = bool(CFG.get(\"prep\", {}).get(\"use_balanced_tasks\", False))\n",
    "tb_name = (CFG.get(\"prep\", {}).get(\"tasks_balanced_file_name\") or \"tasks_balanced.json\")\n",
    "t_name  = (CFG.get(\"prep\", {}).get(\"tasks_file_name\")           or \"tasks.json\")\n",
    "\n",
    "cand_bal = PROC / tb_name\n",
    "cand_std = PROC / t_name\n",
    "TASKS_FILE = cand_bal if (USE_BALANCED and cand_bal.exists()) else cand_std\n",
    "\n",
    "with open(TASKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "print(\"Usando:\", TASKS_FILE.name)\n",
    "print(\"Tareas y TRAIN CSV/H5 a usar:\")\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {_P(t['paths']['train']).name}\")\n",
    "\n",
    "# Guardarra√≠l: si balanced, exigir train_balanced.csv\n",
    "if USE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = _P(tasks_json[\"splits\"][t[\"name\"]][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' en modo balanced, pero encontr√© '{train_path.name}'.\"\n",
    "            )\n",
    "\n",
    "# Si usas H5 offline, chequear que existan\n",
    "if USE_OFFLINE_SPIKES:\n",
    "    mw, mh = CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"]\n",
    "    color = \"gray\" if CFG[\"model\"][\"to_gray\"] else \"rgb\"\n",
    "    gain_tag = (GAIN if ENCODER == \"rate\" else 0)\n",
    "    missing = []\n",
    "    for t in task_list:\n",
    "        base = PROC / t[\"name\"]\n",
    "        for split in (\"train\", \"val\", \"test\"):\n",
    "            p = base / f\"{split}_{ENCODER}_T{T}_gain{gain_tag}_{color}_{mw}x{mh}.h5\"\n",
    "            if not p.exists():\n",
    "                missing.append(str(p))\n",
    "    if missing:\n",
    "        print(\"[WARN] Faltan H5. Genera primero con 02_ENCODE_OFFLINE.ipynb (o tools/encode_tasks.py).\")\n",
    "\n",
    "# Factory de loaders con kwargs del preset\n",
    "from src.utils import build_make_loader_fn\n",
    "\n",
    "_raw_make_loader_fn = build_make_loader_fn(\n",
    "    root=ROOT, use_offline_spikes=USE_OFFLINE_SPIKES, encode_runtime=RUNTIME_ENCODE,\n",
    ")\n",
    "\n",
    "_DL_KW = dict(\n",
    "    num_workers=NUM_WORKERS,\n",
    "    prefetch_factor=PREFETCH,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers=PERSISTENT,\n",
    "    aug_train=AUG_CFG,\n",
    "    balance_train=USE_ONLINE_BAL,\n",
    "    balance_bins=BAL_BINS,\n",
    "    balance_smooth_eps=BAL_EPS,\n",
    ")\n",
    "\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed, **dl_kwargs):\n",
    "    \"\"\"Wrapper pass-through: el runner a√±ade dl_kwargs; aqu√≠ solo los propagamos.\"\"\"\n",
    "    return _raw_make_loader_fn(\n",
    "        task=task, batch_size=batch_size, encoder=encoder, T=T, gain=gain, tfm=tfm, seed=seed,\n",
    "        **{**_DL_KW, **dl_kwargs}\n",
    "    )\n",
    "\n",
    "print(\"make_loader_fn listo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7c6f6",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "## 4) M√©tricas y objetivo para Optuna\n",
    "\n",
    "**Objetivo**  \n",
    "Definir la **funci√≥n objetivo** del HPO a partir de las m√©tricas almacenadas:\n",
    "\n",
    "1. Leer `continual_results.json` del *run*.  \n",
    "2. Identificar **primera** y **√∫ltima** tarea.  \n",
    "3. Extraer:\n",
    "   - `c1_mae`: MAE de la primera tarea en su propio test.  \n",
    "   - `c1_after_c2_mae`: MAE de la primera **tras** aprender la √∫ltima (olvido).  \n",
    "   - `c2_mae`: MAE de la **√∫ltima** tarea.  \n",
    "4. Calcular **Olvido relativo (%)** = \\((c1\\_after\\_c2 - c1\\_mae)/c1\\_mae \\times 100\\).\n",
    "\n",
    "La **p√©rdida** a minimizar es:  \n",
    "\\[\n",
    "\\text{Objetivo}= \\mathrm{MAE}_{\\text{tarea final}} + \\alpha \\cdot \\max(0, \\text{olvido rel. } \\%)\n",
    "\\]\n",
    "\n",
    "> Ajusta `ALPHA_FORGET` para priorizar estabilidad (olvido bajo) vs. desempe√±o en la √∫ltima tarea.  \n",
    "\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f05f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === M√©tricas y objetivo: usa utilidades del repo ===\n",
    "from src.utils_exp import extract_metrics, safe_read_json\n",
    "from src.hpo import objective_value, composite_objective\n",
    "from pathlib import Path\n",
    "\n",
    "ALPHA_FORGET = 0.5  # peso del olvido relativo en el objetivo compuesto\n",
    "\n",
    "def _load_results(out_dir: Path) -> dict:\n",
    "    \"\"\"Lee outputs/<exp>/continual_results.json con manejo robusto.\"\"\"\n",
    "    return safe_read_json(Path(out_dir) / \"continual_results.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e35e7",
   "metadata": {},
   "source": [
    "<a id=\"sec-05\"></a>\n",
    "## 5) Espacios de b√∫squeda (por m√©todo)\n",
    "\n",
    "**Objetivo**  \n",
    "Declarar qu√© hiperpar√°metros explora Optuna:\n",
    "\n",
    "- **ewc**  \n",
    "  - `lam` \\(\\in [3\\cdot 10^8, 2\\cdot 10^9]\\) (log-uniform).  \n",
    "  - `fisher_batches` ‚àà {200, ‚Ä¶, 1200}.  \n",
    "- **rehearsal**  \n",
    "  - `buffer_size` ‚àà {1000, ‚Ä¶, 8000}.  \n",
    "  - `replay_ratio` ‚àà [0.05, 0.4].  \n",
    "- **rehearsal+ewc**: combina ambos.  \n",
    "- **as-snn**  \n",
    "  - `gamma_ratio` ‚àà [0.3, 0.8], `lambda_a` ‚àà [1.0, 4.0], `ema` ‚àà [0.70, 0.98].  \n",
    "- **naive**: sin HPs.\n",
    "\n",
    "> Puedes extender a otros m√©todos (p. ej., `sa-snn`, `sca-snn`, `colanet`) a√±adiendo su espacio de b√∫squeda y registrando el nombre.  \n",
    "\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e2b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_params_for_method(trial: optuna.Trial, method: str, preset: str) -> dict:\n",
    "    method = method.lower()\n",
    "    preset = preset.lower()\n",
    "\n",
    "    if method == \"ewc\":\n",
    "        lam_grid = {\n",
    "            \"fast\":     [7e8, 1e9],\n",
    "            \"std\":      [1.5e8, 4e8, 1e9],     # mant√©n la rejilla estrecha 1.0e9\n",
    "            \"accurate\": [5e8, 7e8, 1e9],\n",
    "        }\n",
    "        fisher_grid = {\n",
    "            \"fast\":     [300, 1000],               # ‚Üì\n",
    "            \"std\":      [500, 1000],               # ‚Üì\n",
    "            \"accurate\": [800, 1200],               # si llegas a accurate, ya afinas aqu√≠\n",
    "        }\n",
    "        lam = trial.suggest_categorical(\"lam\", lam_grid.get(preset, lam_grid[\"std\"]))\n",
    "        fb  = trial.suggest_categorical(\"fisher_batches\", fisher_grid.get(preset, fisher_grid[\"std\"]))\n",
    "        return {\"lam\": float(lam), \"fisher_batches\": int(fb)}\n",
    "\n",
    "    elif method == \"rehearsal\":\n",
    "        buffer_size  = trial.suggest_int(\"buffer_size\", 1000, 8000, step=1000)\n",
    "        replay_ratio = trial.suggest_float(\"replay_ratio\", 0.05, 0.4, step=0.05)\n",
    "        return {\"buffer_size\": buffer_size, \"replay_ratio\": replay_ratio}\n",
    "\n",
    "    elif method == \"rehearsal+ewc\":\n",
    "        # igual que arriba pero preset-aware para lam/fisher\n",
    "        lam = trial.suggest_categorical(\"lam\", lam_grid.get(preset, lam_grid[\"std\"]))\n",
    "        fisher_batches = trial.suggest_categorical(\"fisher_batches\", fisher_grid.get(preset, fisher_grid[\"std\"]))\n",
    "        buffer_size  = trial.suggest_int(\"buffer_size\", 1000, 8000, step=1000)\n",
    "        replay_ratio = trial.suggest_float(\"replay_ratio\", 0.05, 0.4, step=0.05)\n",
    "        return {\n",
    "            \"buffer_size\": buffer_size,\n",
    "            \"replay_ratio\": replay_ratio,\n",
    "            \"lam\": float(lam),\n",
    "            \"fisher_batches\": int(fisher_batches),\n",
    "        }\n",
    "\n",
    "    elif method == \"as-snn\":\n",
    "        gamma_ratio = trial.suggest_float(\"gamma_ratio\", 0.3, 0.8, step=0.1)\n",
    "        lambda_a    = trial.suggest_float(\"lambda_a\", 1.0, 4.0)\n",
    "        ema         = trial.suggest_float(\"ema\", 0.70, 0.98)\n",
    "        return {\"gamma_ratio\": gamma_ratio, \"lambda_a\": lambda_a, \"ema\": ema}\n",
    "\n",
    "    else:\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841fd521",
   "metadata": {},
   "source": [
    "<a id=\"sec-06\"></a>\n",
    "## 6) Estudio Optuna ‚Äî un m√©todo concreto\n",
    "\n",
    "**Objetivo**  \n",
    "Optimizar **un m√©todo** espec√≠fico (`METHOD_TO_OPTIMIZE`) durante `N_TRIALS`.\n",
    "\n",
    "Flujo de cada *trial*:\n",
    "1. Sugerir HPs (`suggest_*`).  \n",
    "2. Construir `cfg` con esos HPs (y, si `HPO_EPOCHS` est√° definido, **reducir epochs** solo para HPO).  \n",
    "3. Ejecutar `run_continual(...)`.  \n",
    "4. Leer resultados, computar la **p√©rdida objetivo** y devolverla a Optuna.\n",
    "\n",
    "**Persistencia**  \n",
    "Se usa **SQLite** en `outputs/optuna/` para reanudar estudios y registrar todos los *trials* (`*_trials.csv`).\n",
    "\n",
    "> Para m√©todos con *replay* se desactiva `persistent_workers` por estabilidad de DataLoader (puedes ajustar *AMP/pin_memory/workers* si lo necesitas).  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f92711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 09:06:44,067] Using an existing study with name 'HPO_ewc_fast_rate_T10_space_5dcfb0c744' instead of creating a new one.\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_1e+09 | B=128 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.04334 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.06307 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 1/2: 3.0 it/s  (196 iters en 65.52s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.05678 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.04419 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 2/2: 3.2 it/s  (196 iters en 61.70s)\n",
      "[EWC] after_task: estimando Fisher en TRAIN (len=196), cap=300...\n",
      "[EWC] Fisher listo: batches_usados=196 | sum=8.250e-02 | max=4.498e-03\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_1e+09 | B=128 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.09044 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 1/2: 2.7 it/s  (85 iters en 31.60s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.06674 | pen=0.245 | pen/base=3.672 | Œª_actual=1.000e+09 ‚Üí Œª_sugerido‚âà2.723e+08 (target pen/base=1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 2/2: 2.8 it/s  (85 iters en 29.92s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.224217:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [04:53<04:53, 293.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 09:11:37,100] Trial 8 finished with value: 0.6691589161970558 and parameters: {'lam': 1000000000.0, 'fisher_batches': 300}. Best is trial 7 with value: 0.22421700749346005.\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_7e+08 | B=128 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.1437 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.06306 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 1/2: 3.0 it/s  (196 iters en 65.36s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.05649 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.04436 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 2/2: 3.2 it/s  (196 iters en 61.05s)\n",
      "[EWC] after_task: estimando Fisher en TRAIN (len=196), cap=1000...\n",
      "[EWC] Fisher listo: batches_usados=196 | sum=1.275e-01 | max=5.140e-03\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_7e+08 | B=128 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.09029 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 1/2: 2.9 it/s  (85 iters en 29.78s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.06645 | pen=0.2742 | pen/base=4.127 | Œª_actual=7.000e+08 ‚Üí Œª_sugerido‚âà1.696e+08 (target pen/base=1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 2/2: 3.0 it/s  (85 iters en 28.62s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.224217: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [09:32<00:00, 286.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 09:16:16,682] Trial 9 finished with value: 0.2578052141620393 and parameters: {'lam': 700000000.0, 'fisher_batches': 1000}. Best is trial 7 with value: 0.22421700749346005.\n",
      "HPO_TAG: space_5dcfb0c744\n",
      "SQLite: /home/cesar/proyectos/TFM_SNN/outputs/optuna/hpo_ewc_fast_pilotnet_snn_rate_T10_g0.5_space_5dcfb0c744.sqlite\n",
      "Best value: 0.22421700749346005\n",
      "Best params: {'lam': 700000000.0, 'fisher_batches': 300}\n",
      "Best attrs: {'emissions_kg': 0.0007389964991478321, 'method': 'ewc', 'metrics': {'c1': 'circuito1', 'c2': 'circuito2', 'c1_mae': 0.17821959343851895, 'c1_after_c2_mae': 0.17328747620376578, 'forget_rel_%': -2.7674382707278617, 'c2_mae': 0.22421700749346005}, 'out_dir': '/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_7e+08_lam_7e+08_ewc_hpo_t7_lam_7.0e+08_rate_model-PilotNetSNN_66x200_gray_seed_42', 'params': {'lam': 700000000.0, 'fisher_batches': 300}}\n",
      "Best value: 0.22421700749346005\n",
      "Best params: {'lam': 700000000.0, 'fisher_batches': 300}\n",
      "Best attrs: {'emissions_kg': 0.0007389964991478321, 'method': 'ewc', 'metrics': {'c1': 'circuito1', 'c2': 'circuito2', 'c1_mae': 0.17821959343851895, 'c1_after_c2_mae': 0.17328747620376578, 'forget_rel_%': -2.7674382707278617, 'c2_mae': 0.22421700749346005}, 'out_dir': '/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_7e+08_lam_7e+08_ewc_hpo_t7_lam_7.0e+08_rate_model-PilotNetSNN_66x200_gray_seed_42', 'params': {'lam': 700000000.0, 'fisher_batches': 300}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Celda 6: Configuraci√≥n del estudio + objetivo Optuna (con TAG autom√°tico) ===\n",
    "import copy, json, inspect, hashlib, os\n",
    "from pathlib import Path\n",
    "import optuna, torch, gc, time\n",
    "from src.telemetry import read_emissions_kg  # registra emisiones en user_attrs si hay CodeCarbon\n",
    "\n",
    "# --- Par√°metros del estudio ---\n",
    "METHOD_TO_OPTIMIZE = \"ewc\"   # \"naive\" | \"ewc\" | \"rehearsal\" | \"rehearsal+ewc\" | \"as-snn\"\n",
    "N_TRIALS = 2                 # s√∫belo cuando est√©s satisfecho con tiempos/estabilidad\n",
    "HPO_EPOCHS = None               # None -> epochs del preset; o un int (p.ej. 1‚Äì3) para acelerar\n",
    "REHEARSAL_NAMES = (\"rehearsal\", \"rehearsal+ewc\")\n",
    "\n",
    "def build_cfg_with_method(base_cfg: dict, method_name: str, params: dict, hpo_epochs: int|None):\n",
    "    cfg = copy.deepcopy(base_cfg)\n",
    "    cfg[\"continual\"][\"method\"] = method_name\n",
    "    cfg[\"continual\"][\"params\"] = params or {}\n",
    "\n",
    "    # Perfil equilibrado-r√°pido para HPO (seguro en EWC/naive/AS-SNN)\n",
    "    cfg[\"optim\"][\"amp\"] = True\n",
    "    cfg[\"data\"][\"pin_memory\"] = True\n",
    "    cfg[\"data\"][\"persistent_workers\"] = False  # evita fugas/hangs entre trials\n",
    "    cfg[\"data\"][\"num_workers\"] = min(max(2, int(cfg[\"data\"].get(\"num_workers\") or 2)), 4)\n",
    "\n",
    "    cfg.setdefault(\"logging\", {}).setdefault(\"telemetry\", {})[\"codecarbon\"] = False\n",
    "\n",
    "    # Si HPO de replay, baja un poco el riesgo\n",
    "    if method_name.lower() in REHEARSAL_NAMES:\n",
    "        cfg[\"optim\"][\"amp\"] = False\n",
    "        cfg[\"data\"][\"pin_memory\"] = False\n",
    "        cfg[\"data\"][\"num_workers\"] = min(int(cfg[\"data\"].get(\"num_workers\") or 0), 2)\n",
    "\n",
    "    if hpo_epochs is not None:\n",
    "        cfg[\"optim\"][\"epochs\"] = int(hpo_epochs)\n",
    "    return cfg\n",
    "\n",
    "def run_one_cfg(cfg: dict) -> tuple[Path, dict, dict]:\n",
    "    out_dir, res = run_continual(\n",
    "        task_list=task_list,\n",
    "        make_loader_fn=make_loader_fn,\n",
    "        make_model_fn=make_model_fn,\n",
    "        tfm=tfm,\n",
    "        cfg=cfg,\n",
    "        preset_name=PRESET,\n",
    "        out_root=ROOT / \"outputs\",\n",
    "        verbose=True,\n",
    "    )\n",
    "    # results guardado por runner en continual_results.json\n",
    "    results = _load_results(out_dir) or (res if isinstance(res, dict) else {})\n",
    "    return out_dir, res, results\n",
    "\n",
    "def optuna_objective(trial: optuna.Trial):\n",
    "    params = suggest_params_for_method(trial, METHOD_TO_OPTIMIZE, PRESET)\n",
    "    cfg_i  = build_cfg_with_method(CFG, METHOD_TO_OPTIMIZE, params, HPO_EPOCHS)\n",
    "\n",
    "    # Etiqueta del run\n",
    "    cfg_i.setdefault(\"naming\", {})\n",
    "    tag = f\"{METHOD_TO_OPTIMIZE}_hpo_t{trial.number}\"\n",
    "    if METHOD_TO_OPTIMIZE in (\"ewc\", \"rehearsal+ewc\") and \"lam\" in params:\n",
    "        tag += f\"_lam_{params['lam']:.1e}\"\n",
    "    cfg_i[\"naming\"][\"tag\"] = tag\n",
    "\n",
    "    try:\n",
    "        out_dir, _, results = run_one_cfg(cfg_i)\n",
    "        metrics = extract_metrics(results)\n",
    "        val = composite_objective(metrics, ALPHA_FORGET)\n",
    "\n",
    "        # Telemetr√≠a por trial (si existe el archivo de CodeCarbon)\n",
    "        emissions = read_emissions_kg(out_dir)\n",
    "        if emissions is not None:\n",
    "            trial.set_user_attr(\"emissions_kg\", float(emissions))\n",
    "\n",
    "        trial.set_user_attr(\"out_dir\", str(out_dir))\n",
    "        trial.set_user_attr(\"metrics\", metrics)\n",
    "        trial.set_user_attr(\"method\", METHOD_TO_OPTIMIZE)\n",
    "        trial.set_user_attr(\"params\", params)\n",
    "        return val\n",
    "    except Exception as e:\n",
    "        # No tires abajo todo el estudio por un trial problem√°tico\n",
    "        trial.set_user_attr(\"error\", repr(e))\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        # Limpieza ligera entre trials (evita fragmentaci√≥n de memoria GPU)\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# -------------------------------\n",
    "# TAG AUTOM√ÅTICO DEL ESPACIO HPO\n",
    "# -------------------------------\n",
    "def _space_fingerprint() -> str:\n",
    "    \"\"\"\n",
    "    Huella estable del espacio de b√∫squeda:\n",
    "    - M√©todo y preset actuales\n",
    "    - C√≥digo fuente de suggest_params_for_method (cambia si cambias la rejilla)\n",
    "    - Versiones relevantes y algunos knobs clave del experimento\n",
    "    - (Best effort) Intenta capturar grids globales si existen (lam_grid, fisher_grid, etc.)\n",
    "    \"\"\"\n",
    "    bits = {\n",
    "        \"method\": METHOD_TO_OPTIMIZE,\n",
    "        \"preset\": PRESET,\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"encoder\": ENCODER,\n",
    "        \"T\": T,\n",
    "        \"gain\": GAIN,\n",
    "        \"torch\": torch.__version__,\n",
    "        \"optuna\": optuna.__version__,\n",
    "        \"suggest_src\": inspect.getsource(suggest_params_for_method),\n",
    "    }\n",
    "    # Si definiste variables globales para los grids, intenta incluirlas\n",
    "    g = suggest_params_for_method.__globals__\n",
    "    for k in (\"lam_grid\", \"fisher_grid\", \"replay_grid\", \"as_snn_grid\"):\n",
    "        if k in g:\n",
    "            try:\n",
    "                bits[k] = g[k]\n",
    "            except Exception:\n",
    "                bits[k] = str(g[k])\n",
    "\n",
    "    raw = json.dumps(bits, sort_keys=True, default=str)\n",
    "    return hashlib.sha1(raw.encode(\"utf-8\")).hexdigest()[:10]\n",
    "\n",
    "HPO_TAG = os.getenv(\"HPO_TAG_OVERRIDE\") or f\"space_{_space_fingerprint()}\"\n",
    "\n",
    "# --- Persistencia Optuna en SQLite ---\n",
    "OPTUNA_DIR = ROOT / \"outputs\" / \"optuna\"\n",
    "OPTUNA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DB_PATH = OPTUNA_DIR / f\"hpo_{METHOD_TO_OPTIMIZE}_{PRESET}_{MODEL_NAME}_{ENCODER}_T{T}_g{GAIN}_{HPO_TAG}.sqlite\"\n",
    "STORAGE = f\"sqlite:///{DB_PATH}\"\n",
    "STUDY_NAME = f\"HPO_{METHOD_TO_OPTIMIZE}_{PRESET}_{ENCODER}_T{T}_{HPO_TAG}\"\n",
    "\n",
    "# Reutiliza el estudio si el TAG (espacio) no ha cambiado; si cambias la rejilla, el TAG cambia solo\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=STUDY_NAME,\n",
    "    storage=STORAGE,\n",
    "    load_if_exists=True,   # <<‚Äî reutiliza si existe el mismo espacio; evita el error de dynamic value space\n",
    ")\n",
    "\n",
    "study.optimize(optuna_objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(\"HPO_TAG:\", HPO_TAG)\n",
    "print(\"SQLite:\", DB_PATH)\n",
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best attrs:\", study.best_trial.user_attrs)\n",
    "\n",
    "# Guardar trazabilidad de intentos a CSV\n",
    "df_trials = study.trials_dataframe(attrs=(\"number\",\"value\",\"state\",\"params\",\"user_attrs\"))\n",
    "df_trials.to_csv(OPTUNA_DIR / f\"{DB_PATH.stem}_trials.csv\", index=False)\n",
    "\n",
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best attrs:\", study.best_trial.user_attrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48b08b",
   "metadata": {},
   "source": [
    "<a id=\"sec-07\"></a>\n",
    "## 7) Estudio Optuna conjunto (elige m√©todo + HPs)\n",
    "\n",
    "**Objetivo**  \n",
    "Permitir que **cada *trial*** elija tambi√©n el **m√©todo** (`naive`, `ewc`, `rehearsal`, `rehearsal+ewc`, `as-snn`) adem√°s de sus HPs. √ötil cuando:\n",
    "\n",
    "- No tienes claro qu√© m√©todo se adapta mejor a tu conjunto de datos.  \n",
    "- Quieres una **comparativa autom√°tica** con el mismo presupuesto de c√≥mputo.\n",
    "\n",
    "> Activa `RUN_JOINT=True` para lanzar este estudio y eleva `N_TRIALS_JOINT` cuando el flujo sea estable.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e7f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_JOINT=False ‚Äî omitido.\n"
     ]
    }
   ],
   "source": [
    "RUN_JOINT = False   # Pon True si quieres lanzar el estudio conjunto\n",
    "N_TRIALS_JOINT = 10\n",
    "\n",
    "def optuna_objective_joint(trial: optuna.Trial):\n",
    "    method = trial.suggest_categorical(\"method\", [\"naive\",\"ewc\",\"rehearsal\",\"rehearsal+ewc\",\"as_snn\"])\n",
    "    params = suggest_params_for_method(trial, method)\n",
    "    cfg_i  = build_cfg_with_method(CFG, method, params, HPO_EPOCHS)\n",
    "\n",
    "    # === Hotfix selectivo (solo m√©todos con replay) ===\n",
    "    if method.lower() in REHEARSAL_NAMES:\n",
    "        cfg_i[\"data\"][\"persistent_workers\"] = False\n",
    "        # Opcionales si hiciera falta:\n",
    "        # cfg_i[\"optim\"][\"amp\"] = False\n",
    "        # cfg_i[\"data\"][\"pin_memory\"] = False\n",
    "        # cfg_i[\"data\"][\"num_workers\"] = min(int(cfg_i[\"data\"].get(\"num_workers\") or 0), 2)\n",
    "\n",
    "    cfg_i.setdefault(\"naming\", {})\n",
    "    tag = f\"{method}_hpo_t{trial.number}\"\n",
    "    if method in (\"ewc\", \"rehearsal+ewc\") and \"lam\" in params:\n",
    "        tag += f\"_lam_{params['lam']:.1e}\"\n",
    "    cfg_i[\"naming\"][\"tag\"] = tag\n",
    "\n",
    "    try:\n",
    "        out_dir, _, results = run_one_cfg(cfg_i)\n",
    "        metrics = extract_metrics(results)\n",
    "        val = objective_value(metrics, ALPHA_FORGET)  # tu versi√≥n conjunta\n",
    "        trial.set_user_attr(\"out_dir\", str(out_dir))\n",
    "        trial.set_user_attr(\"metrics\", metrics)\n",
    "        trial.set_user_attr(\"method\", method)\n",
    "        trial.set_user_attr(\"params\", params)\n",
    "        return val\n",
    "    except Exception as e:\n",
    "        trial.set_user_attr(\"error\", repr(e))\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        import gc, time\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "\n",
    "\n",
    "if RUN_JOINT:\n",
    "    study_joint = optuna.create_study(direction=\"minimize\", study_name=\"HPO_joint\")\n",
    "    study_joint.optimize(optuna_objective_joint, n_trials=N_TRIALS_JOINT, show_progress_bar=True)\n",
    "    print(\"Best value:\", study_joint.best_value)\n",
    "    print(\"Best params:\", study_joint.best_params)\n",
    "    print(\"Best attrs:\", study_joint.best_trial.user_attrs)\n",
    "else:\n",
    "    print(\"RUN_JOINT=False ‚Äî omitido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cdc9f",
   "metadata": {},
   "source": [
    "<a id=\"sec-08\"></a>\n",
    "## 8) Re-entrena con los mejores hiperpar√°metros\n",
    "\n",
    "**Objetivo**  \n",
    "Tomar `study.best_params` (y el m√©todo ganador) y **re-entrenar a pleno rendimiento**:\n",
    "\n",
    "- Reconstruir `cfg_best` con los HPs √≥ptimos.  \n",
    "- (Opcional) Restaurar `optim.epochs` del preset si usaste `HPO_EPOCHS` reducido durante la b√∫squeda.  \n",
    "- Ejecutar `run_continual(...)` y mostrar las **m√©tricas finales** y la **carpeta de salida**.\n",
    "\n",
    "> Separa la **b√∫squeda r√°pida** (menos epochs) del **entrenamiento definitivo** (epochs del preset).  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40464ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor m√©todo: ewc\n",
      "Mejores HPs: {'lam': 700000000.0, 'fisher_batches': 300}\n",
      "\n",
      "--- Tarea 1/2: circuito1 | preset=fast | method=ewc_lam_7e+08 | B=128 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.1749 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 101/196 [00:34<00:29,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.05958 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 1/2: 3.1 it/s  (196 iters en 63.98s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2:   3%|‚ñé         | 5/196 [00:01<01:05,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.04822 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/196 [00:32<00:27,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.05835 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 2/2: 3.2 it/s  (196 iters en 60.90s)\n",
      "[EWC] after_task: estimando Fisher en TRAIN (len=196), cap=300...\n",
      "[EWC] Fisher listo: batches_usados=196 | sum=4.310e-02 | max=1.838e-03\n",
      "\n",
      "--- Tarea 2/2: circuito2 | preset=fast | method=ewc_lam_7e+08 | B=128 T=10 AMP=True | enc=rate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/85 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.072 | pen=0 | pen/base=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 1/2: 3.1 it/s  (85 iters en 27.27s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2:  19%|‚ñà‚ñâ        | 16/85 [00:05<00:22,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EWC] base=0.09541 | pen=0.04606 | pen/base=0.483 | Œª_actual=7.000e+08 ‚Üí Œª_sugerido‚âà1.450e+09 (target pen/base=1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN it/s] epoch 2/2: 3.1 it/s  (85 iters en 27.48s)\n",
      "Resultados finales (re-train): {'c1': 'circuito1', 'c2': 'circuito2', 'c1_mae': 0.17048350355548014, 'c1_after_c2_mae': 0.1704544307127921, 'forget_rel_%': -0.017053170589369195, 'c2_mae': 0.22250960403232165}\n",
      "Guardado en: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_7e+08_lam_7e+08_rate_model-PilotNetSNN_66x200_gray_seed_42\n"
     ]
    }
   ],
   "source": [
    "# Usa el mejor del estudio por m√©todo (arriba)\n",
    "BEST_PARAMS = study.best_params\n",
    "BEST_METHOD = METHOD_TO_OPTIMIZE\n",
    "\n",
    "print(\"Mejor m√©todo:\", BEST_METHOD)\n",
    "print(\"Mejores HPs:\", BEST_PARAMS)\n",
    "\n",
    "cfg_best = copy.deepcopy(CFG)\n",
    "cfg_best[\"continual\"][\"method\"] = BEST_METHOD\n",
    "cfg_best[\"continual\"][\"params\"] = BEST_PARAMS\n",
    "\n",
    "# (Opcional) restablecer epochs al valor del preset si redujiste para HPO\n",
    "# cfg_best[\"optim\"][\"epochs\"] = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)[\"optim\"][\"epochs\"]\n",
    "\n",
    "# Reponer ajustes del preset para el re-train (r√°pido y estable)\n",
    "cfg_best[\"optim\"][\"amp\"] = True\n",
    "cfg_best[\"data\"][\"persistent_workers\"] = CFG[\"data\"][\"persistent_workers\"]\n",
    "cfg_best[\"data\"][\"pin_memory\"] = CFG[\"data\"][\"pin_memory\"]\n",
    "cfg_best[\"data\"][\"num_workers\"] = CFG[\"data\"][\"num_workers\"]\n",
    "\n",
    "# (opcional) si a√∫n va justo de memoria:\n",
    "# cfg_best[\"optim\"][\"batch_size\"] = min(int(cfg_best[\"optim\"][\"batch_size\"]), 64)\n",
    "\n",
    "out_dir, _, results = run_one_cfg(cfg_best)\n",
    "metrics = extract_metrics(results)\n",
    "print(\"Resultados finales (re-train):\", metrics)\n",
    "print(\"Emisiones totales (kg CO2e):\", read_emissions_kg(out_dir))\n",
    "print(\"Guardado en:\", out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99cf26e",
   "metadata": {},
   "source": [
    "<a id=\"sec-09\"></a>\n",
    "## 9) Resumen r√°pido de *runs* (tabla)\n",
    "\n",
    "**Objetivo**  \n",
    "Inspeccionar resultados de `outputs/continual_*`:\n",
    "\n",
    "- Construir una tabla con `preset`, `method`, `encoder`, `seed` (y `lambda` si aplica),  \n",
    "  junto a `c1_mae`, `c1_after_c2_mae`, `forget_rel_%`, `c2_mae`.  \n",
    "- Ordenar/filtrar para comparar **manzanas con manzanas** (mismo preset/encoder).\n",
    "\n",
    "> Exporta a CSV/Parquet para gr√°ficas comparativas. Si la tabla sale vac√≠a, revisa que existan `continual_results.json`.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca61bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs en resumen: 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>preset</th>\n",
       "      <th>method</th>\n",
       "      <th>lambda</th>\n",
       "      <th>encoder</th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>c1_mae</th>\n",
       "      <th>c1_after_c2_mae</th>\n",
       "      <th>forget_rel_%</th>\n",
       "      <th>c2_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continual_accurate_as-snn_gr_0.3_lam_1.59168_r...</td>\n",
       "      <td>accurate</td>\n",
       "      <td>as-snn_gr_0.3</td>\n",
       "      <td>1.59168</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.165532</td>\n",
       "      <td>0.200847</td>\n",
       "      <td>21.333848</td>\n",
       "      <td>0.217257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continual_accurate_ewc_lam_7e+08_lam_7e+08_rat...</td>\n",
       "      <td>accurate</td>\n",
       "      <td>ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.165532</td>\n",
       "      <td>0.166002</td>\n",
       "      <td>0.283758</td>\n",
       "      <td>0.221053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continual_accurate_naive_rate_model-PilotNetSN...</td>\n",
       "      <td>accurate</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.177562</td>\n",
       "      <td>0.239561</td>\n",
       "      <td>34.916516</td>\n",
       "      <td>0.220103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>continual_accurate_rehearsal_buf_3000_rr_20+ew...</td>\n",
       "      <td>accurate</td>\n",
       "      <td>rehearsal_buf_3000_rr_20+ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.173464</td>\n",
       "      <td>0.173046</td>\n",
       "      <td>-0.241270</td>\n",
       "      <td>0.206640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>continual_fast_as-snn_gr_0.3_lam_1.59168_rate_...</td>\n",
       "      <td>fast</td>\n",
       "      <td>as-snn_gr_0.3</td>\n",
       "      <td>1.59168</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.171290</td>\n",
       "      <td>0.172986</td>\n",
       "      <td>0.990284</td>\n",
       "      <td>0.224034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>continual_fast_as-snn_gr_0.3_lam_1.59168_rate_...</td>\n",
       "      <td>fast</td>\n",
       "      <td>as-snn_gr_0.3</td>\n",
       "      <td>1.59168</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>43</td>\n",
       "      <td>0.172936</td>\n",
       "      <td>0.172952</td>\n",
       "      <td>0.009722</td>\n",
       "      <td>0.224013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.171993</td>\n",
       "      <td>0.172596</td>\n",
       "      <td>0.350517</td>\n",
       "      <td>0.223798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>continual_fast_ewc_lam_3e+08_lam_3e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>3e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.116735</td>\n",
       "      <td>0.311041</td>\n",
       "      <td>166.450838</td>\n",
       "      <td>0.186258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>continual_fast_ewc_lam_5e+08_lam_5e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>5e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.172764</td>\n",
       "      <td>0.170332</td>\n",
       "      <td>-1.408158</td>\n",
       "      <td>0.222444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>continual_fast_ewc_lam_7e+08_lam_7e+08_rate_mo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.170484</td>\n",
       "      <td>0.170454</td>\n",
       "      <td>-0.017053</td>\n",
       "      <td>0.222510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t0_lam_1.0e+09</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.132683</td>\n",
       "      <td>0.136797</td>\n",
       "      <td>3.100668</td>\n",
       "      <td>0.179152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>continual_fast_ewc_lam_5e+08_lam_5e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t1_lam_5.0e+08</td>\n",
       "      <td>5e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.178656</td>\n",
       "      <td>0.178617</td>\n",
       "      <td>-0.022027</td>\n",
       "      <td>0.227651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t2_lam_1.0e+09</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.178892</td>\n",
       "      <td>0.175648</td>\n",
       "      <td>-1.813424</td>\n",
       "      <td>0.225721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>continual_fast_ewc_lam_3e+08_lam_3e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t3_lam_3.0e+08</td>\n",
       "      <td>3e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.178959</td>\n",
       "      <td>0.175338</td>\n",
       "      <td>-2.023015</td>\n",
       "      <td>0.225520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>continual_fast_ewc_lam_2e+09_lam_2e+09_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t4_lam_2.0e+09</td>\n",
       "      <td>2e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.175580</td>\n",
       "      <td>0.175498</td>\n",
       "      <td>-0.046826</td>\n",
       "      <td>0.225624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>continual_fast_ewc_lam_5e+08_lam_5e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t5_lam_5.0e+08</td>\n",
       "      <td>5e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.177776</td>\n",
       "      <td>0.172751</td>\n",
       "      <td>-2.826680</td>\n",
       "      <td>0.223892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>continual_fast_ewc_lam_3e+08_lam_3e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t6_lam_3.0e+08</td>\n",
       "      <td>3e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.176647</td>\n",
       "      <td>0.176640</td>\n",
       "      <td>-0.003886</td>\n",
       "      <td>0.226356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>continual_fast_ewc_lam_7e+08_lam_7e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t6_lam_7.0e+08</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.107802</td>\n",
       "      <td>0.112593</td>\n",
       "      <td>4.443691</td>\n",
       "      <td>0.177569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t7_lam_1.0e+09</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.175205</td>\n",
       "      <td>0.175201</td>\n",
       "      <td>-0.002208</td>\n",
       "      <td>0.225430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>continual_fast_ewc_lam_7e+08_lam_7e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t7_lam_7.0e+08</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.178220</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>-2.767438</td>\n",
       "      <td>0.224217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t8_lam_1.0e+09</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.176341</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.883970</td>\n",
       "      <td>0.227174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>continual_fast_ewc_lam_7e+08_lam_7e+08_ewc_hpo...</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc_ewc_hpo_t9_lam_7.0e+08</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.177222</td>\n",
       "      <td>0.177332</td>\n",
       "      <td>0.062007</td>\n",
       "      <td>0.226802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>continual_fast_naive_rate_model-PilotNetSNN_66...</td>\n",
       "      <td>fast</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.171290</td>\n",
       "      <td>0.172986</td>\n",
       "      <td>0.990284</td>\n",
       "      <td>0.224034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>continual_fast_rehearsal_buf_3000_rr_10_rate_m...</td>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_3000_rr_10</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.175333</td>\n",
       "      <td>0.174515</td>\n",
       "      <td>-0.466733</td>\n",
       "      <td>0.224983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>continual_fast_rehearsal_buf_3000_rr_10+ewc_la...</td>\n",
       "      <td>fast</td>\n",
       "      <td>rehearsal_buf_3000_rr_10+ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.174054</td>\n",
       "      <td>0.173953</td>\n",
       "      <td>-0.058274</td>\n",
       "      <td>0.224627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>continual_std_as-snn_gr_0.3_lam_1.59168_rate_m...</td>\n",
       "      <td>std</td>\n",
       "      <td>as-snn_gr_0.3</td>\n",
       "      <td>1.59168</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.127417</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>28.681195</td>\n",
       "      <td>0.139246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>continual_std_as-snn_gr_0.3_lam_1.59168_rate_m...</td>\n",
       "      <td>std</td>\n",
       "      <td>as-snn_gr_0.3</td>\n",
       "      <td>1.59168</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>43</td>\n",
       "      <td>0.130181</td>\n",
       "      <td>0.185526</td>\n",
       "      <td>42.513851</td>\n",
       "      <td>0.143218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>continual_std_ewc_lam_1e+07_lam_1e+07_rate_mod...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+07</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.125187</td>\n",
       "      <td>0.157762</td>\n",
       "      <td>26.021310</td>\n",
       "      <td>0.170013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>continual_std_ewc_lam_1e+09_lam_1e+09_rate_mod...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.133004</td>\n",
       "      <td>0.134998</td>\n",
       "      <td>1.499257</td>\n",
       "      <td>0.191898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>continual_std_ewc_lam_2e+08_lam_2e+08_rate_mod...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>2e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.121223</td>\n",
       "      <td>0.211772</td>\n",
       "      <td>74.696547</td>\n",
       "      <td>0.196612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>continual_std_ewc_lam_3e+08_lam_3e+08_rate_mod...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>3e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.133297</td>\n",
       "      <td>0.236797</td>\n",
       "      <td>77.645420</td>\n",
       "      <td>0.227228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>continual_std_ewc_lam_4e+08_lam_4e+08_rate_mod...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>4e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.123999</td>\n",
       "      <td>0.272357</td>\n",
       "      <td>119.644976</td>\n",
       "      <td>0.214979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>continual_std_ewc_lam_7e+08_lam_7e+08_rate_mod...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.127536</td>\n",
       "      <td>0.138721</td>\n",
       "      <td>8.770236</td>\n",
       "      <td>0.215947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>continual_std_ewc_lam_1e+09_lam_1e+09_ewc_hpo_...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc_ewc_hpo_t0_lam_1.0e+09</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.124347</td>\n",
       "      <td>0.129874</td>\n",
       "      <td>4.445017</td>\n",
       "      <td>0.195803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>continual_std_ewc_lam_2e+08_lam_2e+08_ewc_hpo_...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc_ewc_hpo_t0_lam_2.0e+08</td>\n",
       "      <td>2e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.130145</td>\n",
       "      <td>0.275401</td>\n",
       "      <td>111.610632</td>\n",
       "      <td>0.197894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>continual_std_ewc_lam_4e+08_lam_4e+08_ewc_hpo_...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc_ewc_hpo_t0_lam_4.0e+08</td>\n",
       "      <td>4e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.150774</td>\n",
       "      <td>0.208656</td>\n",
       "      <td>38.389647</td>\n",
       "      <td>0.219551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>continual_std_ewc_lam_4e+08_lam_4e+08_ewc_hpo_...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc_ewc_hpo_t1_lam_4.0e+08</td>\n",
       "      <td>4e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.123754</td>\n",
       "      <td>0.203949</td>\n",
       "      <td>64.801522</td>\n",
       "      <td>0.192281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>continual_std_ewc_lam_7e+08_lam_7e+08_ewc_hpo_...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc_ewc_hpo_t2_lam_7.0e+08</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.140915</td>\n",
       "      <td>0.172076</td>\n",
       "      <td>22.113324</td>\n",
       "      <td>0.201512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>continual_std_ewc_lam_4e+08_lam_4e+08_ewc_hpo_...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc_ewc_hpo_t3_lam_4.0e+08</td>\n",
       "      <td>4e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.134433</td>\n",
       "      <td>0.201120</td>\n",
       "      <td>49.606041</td>\n",
       "      <td>0.192421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>continual_std_ewc_lam_5e+07_lam_5e+07_ewc_hpo_...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc_ewc_hpo_t4_lam_5.0e+07</td>\n",
       "      <td>5e+07</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.137016</td>\n",
       "      <td>0.181936</td>\n",
       "      <td>32.785247</td>\n",
       "      <td>0.181667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>continual_std_ewc_lam_1e+08_lam_1e+08_ewc_hpo_...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc_ewc_hpo_t5_lam_1.0e+08</td>\n",
       "      <td>1e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.141217</td>\n",
       "      <td>0.189929</td>\n",
       "      <td>34.494705</td>\n",
       "      <td>0.185412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>continual_std_ewc_lam_2e+08_fb_1000_lam_2e+08_...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc_fb_1000</td>\n",
       "      <td>2e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.124993</td>\n",
       "      <td>0.224264</td>\n",
       "      <td>79.422151</td>\n",
       "      <td>0.189055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>continual_std_ewc_lam_1e+07_fb_500_lam_1e+07_r...</td>\n",
       "      <td>std</td>\n",
       "      <td>ewc_fb_500</td>\n",
       "      <td>1e+07</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.131940</td>\n",
       "      <td>0.220770</td>\n",
       "      <td>67.325868</td>\n",
       "      <td>0.172120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>continual_std_naive_rate_model-PilotNetSNN_66x...</td>\n",
       "      <td>std</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.127417</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>28.681195</td>\n",
       "      <td>0.139246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>continual_std_rehearsal_buf_3000_rr_10_rate_mo...</td>\n",
       "      <td>std</td>\n",
       "      <td>rehearsal_buf_3000_rr_10</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.128092</td>\n",
       "      <td>0.151696</td>\n",
       "      <td>18.427187</td>\n",
       "      <td>0.143461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>continual_std_rehearsal_buf_3000_rr_10+ewc_lam...</td>\n",
       "      <td>std</td>\n",
       "      <td>rehearsal_buf_3000_rr_10+ewc</td>\n",
       "      <td>7e+08</td>\n",
       "      <td>rate</td>\n",
       "      <td>PilotNetSNN_66x200_gray</td>\n",
       "      <td>42</td>\n",
       "      <td>0.125205</td>\n",
       "      <td>0.173030</td>\n",
       "      <td>38.197197</td>\n",
       "      <td>0.229081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  exp    preset  \\\n",
       "0   continual_accurate_as-snn_gr_0.3_lam_1.59168_r...  accurate   \n",
       "1   continual_accurate_ewc_lam_7e+08_lam_7e+08_rat...  accurate   \n",
       "2   continual_accurate_naive_rate_model-PilotNetSN...  accurate   \n",
       "3   continual_accurate_rehearsal_buf_3000_rr_20+ew...  accurate   \n",
       "4   continual_fast_as-snn_gr_0.3_lam_1.59168_rate_...      fast   \n",
       "5   continual_fast_as-snn_gr_0.3_lam_1.59168_rate_...      fast   \n",
       "6   continual_fast_ewc_lam_1e+09_lam_1e+09_rate_mo...      fast   \n",
       "7   continual_fast_ewc_lam_3e+08_lam_3e+08_rate_mo...      fast   \n",
       "8   continual_fast_ewc_lam_5e+08_lam_5e+08_rate_mo...      fast   \n",
       "9   continual_fast_ewc_lam_7e+08_lam_7e+08_rate_mo...      fast   \n",
       "10  continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...      fast   \n",
       "11  continual_fast_ewc_lam_5e+08_lam_5e+08_ewc_hpo...      fast   \n",
       "12  continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...      fast   \n",
       "13  continual_fast_ewc_lam_3e+08_lam_3e+08_ewc_hpo...      fast   \n",
       "14  continual_fast_ewc_lam_2e+09_lam_2e+09_ewc_hpo...      fast   \n",
       "15  continual_fast_ewc_lam_5e+08_lam_5e+08_ewc_hpo...      fast   \n",
       "16  continual_fast_ewc_lam_3e+08_lam_3e+08_ewc_hpo...      fast   \n",
       "17  continual_fast_ewc_lam_7e+08_lam_7e+08_ewc_hpo...      fast   \n",
       "18  continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...      fast   \n",
       "19  continual_fast_ewc_lam_7e+08_lam_7e+08_ewc_hpo...      fast   \n",
       "20  continual_fast_ewc_lam_1e+09_lam_1e+09_ewc_hpo...      fast   \n",
       "21  continual_fast_ewc_lam_7e+08_lam_7e+08_ewc_hpo...      fast   \n",
       "22  continual_fast_naive_rate_model-PilotNetSNN_66...      fast   \n",
       "23  continual_fast_rehearsal_buf_3000_rr_10_rate_m...      fast   \n",
       "24  continual_fast_rehearsal_buf_3000_rr_10+ewc_la...      fast   \n",
       "25  continual_std_as-snn_gr_0.3_lam_1.59168_rate_m...       std   \n",
       "26  continual_std_as-snn_gr_0.3_lam_1.59168_rate_m...       std   \n",
       "27  continual_std_ewc_lam_1e+07_lam_1e+07_rate_mod...       std   \n",
       "28  continual_std_ewc_lam_1e+09_lam_1e+09_rate_mod...       std   \n",
       "29  continual_std_ewc_lam_2e+08_lam_2e+08_rate_mod...       std   \n",
       "30  continual_std_ewc_lam_3e+08_lam_3e+08_rate_mod...       std   \n",
       "31  continual_std_ewc_lam_4e+08_lam_4e+08_rate_mod...       std   \n",
       "32  continual_std_ewc_lam_7e+08_lam_7e+08_rate_mod...       std   \n",
       "33  continual_std_ewc_lam_1e+09_lam_1e+09_ewc_hpo_...       std   \n",
       "34  continual_std_ewc_lam_2e+08_lam_2e+08_ewc_hpo_...       std   \n",
       "35  continual_std_ewc_lam_4e+08_lam_4e+08_ewc_hpo_...       std   \n",
       "36  continual_std_ewc_lam_4e+08_lam_4e+08_ewc_hpo_...       std   \n",
       "37  continual_std_ewc_lam_7e+08_lam_7e+08_ewc_hpo_...       std   \n",
       "38  continual_std_ewc_lam_4e+08_lam_4e+08_ewc_hpo_...       std   \n",
       "39  continual_std_ewc_lam_5e+07_lam_5e+07_ewc_hpo_...       std   \n",
       "40  continual_std_ewc_lam_1e+08_lam_1e+08_ewc_hpo_...       std   \n",
       "41  continual_std_ewc_lam_2e+08_fb_1000_lam_2e+08_...       std   \n",
       "42  continual_std_ewc_lam_1e+07_fb_500_lam_1e+07_r...       std   \n",
       "43  continual_std_naive_rate_model-PilotNetSNN_66x...       std   \n",
       "44  continual_std_rehearsal_buf_3000_rr_10_rate_mo...       std   \n",
       "45  continual_std_rehearsal_buf_3000_rr_10+ewc_lam...       std   \n",
       "\n",
       "                          method   lambda encoder                    model  \\\n",
       "0                  as-snn_gr_0.3  1.59168    rate  PilotNetSNN_66x200_gray   \n",
       "1                            ewc    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "2                          naive     None    rate  PilotNetSNN_66x200_gray   \n",
       "3   rehearsal_buf_3000_rr_20+ewc    1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "4                  as-snn_gr_0.3  1.59168    rate  PilotNetSNN_66x200_gray   \n",
       "5                  as-snn_gr_0.3  1.59168    rate  PilotNetSNN_66x200_gray   \n",
       "6                            ewc    1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "7                            ewc    3e+08    rate  PilotNetSNN_66x200_gray   \n",
       "8                            ewc    5e+08    rate  PilotNetSNN_66x200_gray   \n",
       "9                            ewc    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "10    ewc_ewc_hpo_t0_lam_1.0e+09    1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "11    ewc_ewc_hpo_t1_lam_5.0e+08    5e+08    rate  PilotNetSNN_66x200_gray   \n",
       "12    ewc_ewc_hpo_t2_lam_1.0e+09    1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "13    ewc_ewc_hpo_t3_lam_3.0e+08    3e+08    rate  PilotNetSNN_66x200_gray   \n",
       "14    ewc_ewc_hpo_t4_lam_2.0e+09    2e+09    rate  PilotNetSNN_66x200_gray   \n",
       "15    ewc_ewc_hpo_t5_lam_5.0e+08    5e+08    rate  PilotNetSNN_66x200_gray   \n",
       "16    ewc_ewc_hpo_t6_lam_3.0e+08    3e+08    rate  PilotNetSNN_66x200_gray   \n",
       "17    ewc_ewc_hpo_t6_lam_7.0e+08    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "18    ewc_ewc_hpo_t7_lam_1.0e+09    1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "19    ewc_ewc_hpo_t7_lam_7.0e+08    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "20    ewc_ewc_hpo_t8_lam_1.0e+09    1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "21    ewc_ewc_hpo_t9_lam_7.0e+08    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "22                         naive     None    rate  PilotNetSNN_66x200_gray   \n",
       "23      rehearsal_buf_3000_rr_10     None    rate  PilotNetSNN_66x200_gray   \n",
       "24  rehearsal_buf_3000_rr_10+ewc    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "25                 as-snn_gr_0.3  1.59168    rate  PilotNetSNN_66x200_gray   \n",
       "26                 as-snn_gr_0.3  1.59168    rate  PilotNetSNN_66x200_gray   \n",
       "27                           ewc    1e+07    rate  PilotNetSNN_66x200_gray   \n",
       "28                           ewc    1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "29                           ewc    2e+08    rate  PilotNetSNN_66x200_gray   \n",
       "30                           ewc    3e+08    rate  PilotNetSNN_66x200_gray   \n",
       "31                           ewc    4e+08    rate  PilotNetSNN_66x200_gray   \n",
       "32                           ewc    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "33    ewc_ewc_hpo_t0_lam_1.0e+09    1e+09    rate  PilotNetSNN_66x200_gray   \n",
       "34    ewc_ewc_hpo_t0_lam_2.0e+08    2e+08    rate  PilotNetSNN_66x200_gray   \n",
       "35    ewc_ewc_hpo_t0_lam_4.0e+08    4e+08    rate  PilotNetSNN_66x200_gray   \n",
       "36    ewc_ewc_hpo_t1_lam_4.0e+08    4e+08    rate  PilotNetSNN_66x200_gray   \n",
       "37    ewc_ewc_hpo_t2_lam_7.0e+08    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "38    ewc_ewc_hpo_t3_lam_4.0e+08    4e+08    rate  PilotNetSNN_66x200_gray   \n",
       "39    ewc_ewc_hpo_t4_lam_5.0e+07    5e+07    rate  PilotNetSNN_66x200_gray   \n",
       "40    ewc_ewc_hpo_t5_lam_1.0e+08    1e+08    rate  PilotNetSNN_66x200_gray   \n",
       "41                   ewc_fb_1000    2e+08    rate  PilotNetSNN_66x200_gray   \n",
       "42                    ewc_fb_500    1e+07    rate  PilotNetSNN_66x200_gray   \n",
       "43                         naive     None    rate  PilotNetSNN_66x200_gray   \n",
       "44      rehearsal_buf_3000_rr_10     None    rate  PilotNetSNN_66x200_gray   \n",
       "45  rehearsal_buf_3000_rr_10+ewc    7e+08    rate  PilotNetSNN_66x200_gray   \n",
       "\n",
       "    seed    c1_mae  c1_after_c2_mae  forget_rel_%    c2_mae  \n",
       "0     42  0.165532         0.200847     21.333848  0.217257  \n",
       "1     42  0.165532         0.166002      0.283758  0.221053  \n",
       "2     42  0.177562         0.239561     34.916516  0.220103  \n",
       "3     42  0.173464         0.173046     -0.241270  0.206640  \n",
       "4     42  0.171290         0.172986      0.990284  0.224034  \n",
       "5     43  0.172936         0.172952      0.009722  0.224013  \n",
       "6     42  0.171993         0.172596      0.350517  0.223798  \n",
       "7     42  0.116735         0.311041    166.450838  0.186258  \n",
       "8     42  0.172764         0.170332     -1.408158  0.222444  \n",
       "9     42  0.170484         0.170454     -0.017053  0.222510  \n",
       "10    42  0.132683         0.136797      3.100668  0.179152  \n",
       "11    42  0.178656         0.178617     -0.022027  0.227651  \n",
       "12    42  0.178892         0.175648     -1.813424  0.225721  \n",
       "13    42  0.178959         0.175338     -2.023015  0.225520  \n",
       "14    42  0.175580         0.175498     -0.046826  0.225624  \n",
       "15    42  0.177776         0.172751     -2.826680  0.223892  \n",
       "16    42  0.176647         0.176640     -0.003886  0.226356  \n",
       "17    42  0.107802         0.112593      4.443691  0.177569  \n",
       "18    42  0.175205         0.175201     -0.002208  0.225430  \n",
       "19    42  0.178220         0.173287     -2.767438  0.224217  \n",
       "20    42  0.176341         0.177900      0.883970  0.227174  \n",
       "21    42  0.177222         0.177332      0.062007  0.226802  \n",
       "22    42  0.171290         0.172986      0.990284  0.224034  \n",
       "23    42  0.175333         0.174515     -0.466733  0.224983  \n",
       "24    42  0.174054         0.173953     -0.058274  0.224627  \n",
       "25    42  0.127417         0.163961     28.681195  0.139246  \n",
       "26    43  0.130181         0.185526     42.513851  0.143218  \n",
       "27    42  0.125187         0.157762     26.021310  0.170013  \n",
       "28    42  0.133004         0.134998      1.499257  0.191898  \n",
       "29    42  0.121223         0.211772     74.696547  0.196612  \n",
       "30    42  0.133297         0.236797     77.645420  0.227228  \n",
       "31    42  0.123999         0.272357    119.644976  0.214979  \n",
       "32    42  0.127536         0.138721      8.770236  0.215947  \n",
       "33    42  0.124347         0.129874      4.445017  0.195803  \n",
       "34    42  0.130145         0.275401    111.610632  0.197894  \n",
       "35    42  0.150774         0.208656     38.389647  0.219551  \n",
       "36    42  0.123754         0.203949     64.801522  0.192281  \n",
       "37    42  0.140915         0.172076     22.113324  0.201512  \n",
       "38    42  0.134433         0.201120     49.606041  0.192421  \n",
       "39    42  0.137016         0.181936     32.785247  0.181667  \n",
       "40    42  0.141217         0.189929     34.494705  0.185412  \n",
       "41    42  0.124993         0.224264     79.422151  0.189055  \n",
       "42    42  0.131940         0.220770     67.325868  0.172120  \n",
       "43    42  0.127417         0.163961     28.681195  0.139246  \n",
       "44    42  0.128092         0.151696     18.427187  0.143461  \n",
       "45    42  0.125205         0.173030     38.197197  0.229081  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Tabla m√≠nima para HPO / inspecci√≥n r√°pida ===\n",
    "from src.utils_exp import build_runs_df\n",
    "import pandas as pd\n",
    "\n",
    "outputs_root = ROOT / \"outputs\"\n",
    "df = build_runs_df(outputs_root)\n",
    "\n",
    "print(f\"runs en resumen: {len(df)}\")\n",
    "if df.empty:\n",
    "    print(\"No hay filas (¬øno existen JSONs o solo hubo 1 tarea por run?).\")\n",
    "else:\n",
    "    # columnas clave para tuning; mantiene el nombre 'forget_rel_%' por compatibilidad\n",
    "    view = df.rename(columns={\"c1_forgetting_mae_rel_%\": \"forget_rel_%\"}).loc[:, [\n",
    "        \"exp\",\"preset\",\"method\",\"lambda\",\"encoder\",\"model\",\"seed\",\n",
    "        \"c1_mae\",\"c1_after_c2_mae\",\"forget_rel_%\",\"c2_mae\"\n",
    "    ]]\n",
    "    display(view.sort_values([\"preset\",\"method\",\"encoder\",\"lambda\"], na_position=\"last\", ignore_index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716c060",
   "metadata": {},
   "source": [
    "## Ap√©ndice ‚Äî Optuna en 90 segundos\n",
    "\n",
    "- **Study**: el proyecto de HPO (contiene todos los trials).\n",
    "- **Trial**: una evaluaci√≥n con un conjunto de HPs (`suggest_int`, `suggest_float`, etc.).\n",
    "- **Sampler**: estrategia para elegir el siguiente punto (por defecto, TPE).\n",
    "- **Pruner**: **corta** trials que pintan mal (acelera b√∫squedas largas).\n",
    "- **Storage**: base de datos (SQLite, PostgreSQL) para **reanudar** y/o **paralelizar**.\n",
    "\n",
    "### Reanudar b√∫squedas\n",
    "Puedes crear el estudio con almacenamiento:\n",
    "```python\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"HPO_ewc\",\n",
    "    storage=f\"sqlite:///{ROOT/'outputs'/'optuna_ewc.sqlite'}\",\n",
    "    load_if_exists=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c1b431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5\n",
      "12.5\n",
      "6.41\n"
     ]
    }
   ],
   "source": [
    "from src.hpo import objective_value, composite_objective\n",
    "m = {\"c2_mae\": 0.16, \"forget_rel_%\": 12.5}\n",
    "print(objective_value(m, key=\"forget_rel_%\"))         # 12.5\n",
    "print(objective_value(m, key=\"c1_forgetting_mae_rel_%\"))  # 12.5 (alias OK)\n",
    "print(composite_objective(m, alpha=0.5))              # 0.16 + 0.5*12.5 = 6.41\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
