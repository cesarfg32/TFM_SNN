{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9f0dc7",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# 03B ‚Äî B√∫squeda de hiperpar√°metros con Optuna (Continual Learning)\n",
    "\n",
    "**Qu√© hace este notebook**  \n",
    "Automatiza la **optimizaci√≥n de hiperpar√°metros (HPO)** para m√©todos de aprendizaje continuo manteniendo **coherencia total** con `configs/presets.yaml`. Permite afinar, entre otros:\n",
    "\n",
    "- **naive** (l√≠nea base),\n",
    "- **ewc** (Elastic Weight Consolidation),\n",
    "- **rehearsal** (rejuego con buffer),\n",
    "- **rehearsal+ewc** (combinaci√≥n),\n",
    "- **as-snn** (bio-inspirado; espacio de b√∫squeda incluido).\n",
    "\n",
    "Se apoya en:\n",
    "- `configs/presets.yaml` (misma configuraci√≥n que el resto de cuadernos),\n",
    "- `build_make_loader_fn` (elige **H5 offline** o **CSV + codificaci√≥n en runtime**),\n",
    "- `run_continual` (entrena, eval√∫a y guarda m√©tricas en `outputs/`).\n",
    "\n",
    "---\n",
    "\n",
    "### M√©trica objetivo (minimizar)\n",
    "\n",
    "\\[\n",
    "\\textbf{Objetivo}= \\mathrm{MAE}_{\\text{tarea final}} + \\alpha \\cdot \\max\\!\\bigl(0,\\; \\text{OlvidoRelativo}\\,\\%\\bigr)\n",
    "\\]\n",
    "\n",
    "- **MAE de la tarea final**: rendimiento en la **√∫ltima** tarea de la secuencia.  \n",
    "- **Olvido relativo (%)**: degradaci√≥n de la **primera** tarea tras aprender la/s siguiente/s.  \n",
    "- **Œ±**: peso del olvido (por defecto **0.5**). S√∫belo si quieres penalizar m√°s el olvido.\n",
    "\n",
    "> La extracci√≥n de m√©tricas se realiza desde `continual_results.json`. Si falta informaci√≥n, ese *trial* se considera peor (valor infinito) para no sesgar el estudio.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "- `pip install optuna`  \n",
    "- **Datos** preparados (`tasks.json` o `tasks_balanced.json` desde 01/01A).  \n",
    "- Si el preset usa **offline** (`use_offline_spikes: true`), tener los **H5** generados con **02_ENCODE_OFFLINE** (mismo `encoder/T/gain/size/to_gray`).\n",
    "\n",
    "> **Consejo**: empieza con el preset `fast` y pocos *trials*; si todo es estable, sube `N_TRIALS` y/o `epochs`.\n",
    "\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "- [1) Imports y setup de entorno](#sec-01)  \n",
    "- [2) Carga de preset y construcci√≥n de modelo/transform](#sec-02)  \n",
    "- [3) Tareas y factory de loaders](#sec-03)  \n",
    "- [4) M√©tricas y objetivo para Optuna](#sec-04)  \n",
    "- [5) Espacios de b√∫squeda (por m√©todo)](#sec-05)  \n",
    "- [6) Estudio Optuna ‚Äî un m√©todo concreto](#sec-06)  \n",
    "- [7) Estudio Optuna conjunto (elige m√©todo + HPs)](#sec-07)  \n",
    "- [8) Re-entrena con los mejores hiperpar√°metros](#sec-08)  \n",
    "- [9) Resumen r√°pido de *runs* (tabla)](#sec-09)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5bd35d",
   "metadata": {},
   "source": [
    "<a id=\"sec-01\"></a>\n",
    "## 1) Imports y setup de entorno\n",
    "\n",
    "**Objetivo**  \n",
    "Configurar el entorno de HPO de forma reproducible y eficiente:\n",
    "\n",
    "- Limitar hilos BLAS (`OMP/MKL/OPENBLAS`) para evitar sobrecarga de CPU.  \n",
    "- Detectar `ROOT` (ra√≠z del repo) y a√±adirlo a `sys.path`.  \n",
    "- Importar utilidades del proyecto (`load_preset`, `build_make_loader_fn`, `run_continual`, etc.).  \n",
    "- Seleccionar dispositivo (`cuda` si est√° disponible) y activar optimizaciones de PyTorch (TF32/cuDNN).\n",
    "\n",
    "> Si tu CPU va justa, baja `torch.set_num_threads(4)` a `2`.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd7d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitar threads BLAS (opcional)\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TRAIN_LOG_ITPS\"] = \"1\"   # logs it/s\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json, copy, time\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "# Ra√≠z del repo y sys.path\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Proyecto\n",
    "from src.config import load_preset, build_make_loader_fn\n",
    "from src.datasets import ImageTransform, AugmentConfig\n",
    "from src.models import build_model\n",
    "from src.runner import run_continual\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14b25c",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "## 2) Carga de preset y construcci√≥n de modelo/transform\n",
    "\n",
    "**Objetivo**  \n",
    "Tomar la **fuente de la verdad** del experimento desde `configs/presets.yaml` y derivar:\n",
    "\n",
    "- **Modelo/transform** (`ImageTransform`) seg√∫n `img_w`, `img_h`, `to_gray`.  \n",
    "- **Codificaci√≥n temporal** (`encoder` ‚àà `{rate, latency, raw}`, `T`, `gain`, `seed`).  \n",
    "- **Flags de datos**: `use_offline_spikes` (H5 offline) y/o `encode_runtime` (codificaci√≥n en GPU).  \n",
    "- **DataLoader**: `num_workers`, `prefetch_factor`, `pin_memory`, `persistent_workers`.  \n",
    "- **Augment** (`aug_train`) y **balanceo online** si procede.\n",
    "\n",
    "Se define `make_model_fn(tfm)` para instanciar el modelo con los par√°metros adecuados.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRESET = \"accurate\"  # fast | std | accurate\n",
    "CFG = load_preset(ROOT / \"configs\" / \"presets.yaml\", PRESET)\n",
    "\n",
    "# Modelo / tfm\n",
    "MODEL_NAME = CFG[\"model\"][\"name\"]\n",
    "tfm = ImageTransform(\n",
    "    CFG[\"model\"][\"img_w\"],\n",
    "    CFG[\"model\"][\"img_h\"],\n",
    "    to_gray=bool(CFG[\"model\"][\"to_gray\"]),\n",
    "    crop_top=None\n",
    ")\n",
    "\n",
    "# Datos / codificaci√≥n temporal\n",
    "ENCODER = CFG[\"data\"][\"encoder\"]\n",
    "T       = int(CFG[\"data\"][\"T\"])\n",
    "GAIN    = float(CFG[\"data\"][\"gain\"])\n",
    "SEED    = int(CFG[\"data\"][\"seed\"])\n",
    "\n",
    "# Flags & loader\n",
    "USE_OFFLINE_SPIKES = bool(CFG[\"data\"].get(\"use_offline_spikes\", False))\n",
    "RUNTIME_ENCODE     = bool(CFG[\"data\"].get(\"encode_runtime\", False))\n",
    "\n",
    "NUM_WORKERS = int(CFG[\"data\"].get(\"num_workers\") or 0)\n",
    "PREFETCH    = int(CFG[\"data\"].get(\"prefetch_factor\") or 2)\n",
    "PIN_MEMORY  = bool(CFG[\"data\"].get(\"pin_memory\", True))\n",
    "PERSISTENT  = bool(CFG[\"data\"].get(\"persistent_workers\", True))\n",
    "\n",
    "AUG_CFG = AugmentConfig(**(CFG[\"data\"].get(\"aug_train\") or {})) \\\n",
    "          if CFG[\"data\"].get(\"aug_train\") else None\n",
    "\n",
    "USE_ONLINE_BAL = bool(CFG[\"data\"].get(\"balance_online\", False))\n",
    "BAL_BINS = int(CFG[\"data\"].get(\"balance_bins\") or 50)\n",
    "BAL_EPS  = float(CFG[\"data\"].get(\"balance_smooth_eps\") or 1e-3)\n",
    "\n",
    "print(f\"[PRESET={PRESET}] model={MODEL_NAME} {tfm.w}x{tfm.h} gray={tfm.to_gray}\")\n",
    "print(f\"[DATA] encoder={ENCODER} T={T} gain={GAIN} seed={SEED}\")\n",
    "print(f\"[LOADER] workers={NUM_WORKERS} prefetch={PREFETCH} pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "print(f\"[BALANCE] online={USE_ONLINE_BAL} bins={BAL_BINS}\")\n",
    "print(f\"[RUNTIME_ENCODE] {RUNTIME_ENCODE} | [OFFLINE_SPIKES] {USE_OFFLINE_SPIKES}\")\n",
    "\n",
    "def make_model_fn(tfm):\n",
    "    # kwargs espec√≠ficos de pilotnet_snn; ignora para otros\n",
    "    return build_model(MODEL_NAME, tfm, beta=0.9, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b9209",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "## 3) Tareas y factory de loaders\n",
    "\n",
    "**Objetivo**  \n",
    "Construir la lista de tareas y un **factory de DataLoaders** coherente con el preset:\n",
    "\n",
    "- Se elige `tasks_balanced.json` si `prep.use_balanced_tasks: true` y existe; si no, `tasks.json`.  \n",
    "- Si `use_offline_spikes: true`, se verifican los **H5** esperados (nomenclatura fija con `encoder/T/gain/size/color`).  \n",
    "- `build_make_loader_fn(...)` selecciona autom√°ticamente **H5** (offline) o **CSV + runtime encode** en GPU.  \n",
    "- El *wrapper* `make_loader_fn(...)` solo **propaga kwargs** (augment, balanceo online, *workers*, etc.) para que el *runner* no cambie.\n",
    "\n",
    "> Si usas *tasks* balanceadas, el **train** debe ser `train_balanced.csv` (o su H5 derivado). El notebook lo comprueba.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ce050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path as _P\n",
    "import json\n",
    "\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "USE_BALANCED = bool(CFG.get(\"prep\", {}).get(\"use_balanced_tasks\", False))\n",
    "tb_name = (CFG.get(\"prep\", {}).get(\"tasks_balanced_file_name\") or \"tasks_balanced.json\")\n",
    "t_name  = (CFG.get(\"prep\", {}).get(\"tasks_file_name\")            or \"tasks.json\")\n",
    "\n",
    "cand_bal = PROC / tb_name\n",
    "cand_std = PROC / t_name\n",
    "TASKS_FILE = cand_bal if (USE_BALANCED and cand_bal.exists()) else cand_std\n",
    "\n",
    "with open(TASKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "print(\"Usando:\", TASKS_FILE.name)\n",
    "print(\"Tareas y TRAIN CSV/H5 a usar:\")\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {_P(t['paths']['train']).name}\")\n",
    "\n",
    "# Guardarra√≠l: si balanced, exigir train_balanced.csv\n",
    "if USE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = _P(tasks_json[\"splits\"][t[\"name\"]][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' en modo balanced, pero encontr√© '{train_path.name}'.\"\n",
    "            )\n",
    "\n",
    "# Si usas H5 offline, chequear que existan\n",
    "if USE_OFFLINE_SPIKES:\n",
    "    mw, mh = CFG[\"model\"][\"img_w\"], CFG[\"model\"][\"img_h\"]\n",
    "    color = \"gray\" if CFG[\"model\"][\"to_gray\"] else \"rgb\"\n",
    "    gain_tag = (GAIN if ENCODER == \"rate\" else 0)\n",
    "    missing = []\n",
    "    for t in task_list:\n",
    "        base = PROC / t[\"name\"]\n",
    "        for split in (\"train\", \"val\", \"test\"):\n",
    "            p = base / f\"{split}_{ENCODER}_T{T}_gain{gain_tag}_{color}_{mw}x{mh}.h5\"\n",
    "            if not p.exists():\n",
    "                missing.append(str(p))\n",
    "    if missing:\n",
    "        print(\"[WARN] Faltan H5. Genera primero con 02_ENCODE_OFFLINE.ipynb (o tools/encode_tasks.py).\")\n",
    "\n",
    "# Factory de loaders con kwargs del preset\n",
    "from src.utils import build_make_loader_fn\n",
    "\n",
    "_raw_make_loader_fn = build_make_loader_fn(\n",
    "    root=ROOT, use_offline_spikes=USE_OFFLINE_SPIKES, encode_runtime=RUNTIME_ENCODE,\n",
    ")\n",
    "_DL_KW = dict(\n",
    "    num_workers=NUM_WORKERS,\n",
    "    prefetch_factor=PREFETCH,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers=PERSISTENT,\n",
    "    aug_train=AUG_CFG,\n",
    "    balance_train=USE_ONLINE_BAL,\n",
    "    balance_bins=BAL_BINS,\n",
    "    balance_smooth_eps=BAL_EPS,\n",
    ")\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed, **dl_kwargs):\n",
    "    \"\"\"Wrapper pass-through: el runner a√±ade dl_kwargs; aqu√≠ solo los propagamos.\"\"\"\n",
    "    return _raw_make_loader_fn(\n",
    "        task=task, batch_size=batch_size, encoder=encoder, T=T, gain=gain, tfm=tfm, seed=seed,\n",
    "        **{**_DL_KW, **dl_kwargs}\n",
    "    )\n",
    "print(\"make_loader_fn listo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7c6f6",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "## 4) M√©tricas y objetivo para Optuna\n",
    "\n",
    "**Objetivo**  \n",
    "Definir la **funci√≥n objetivo** del HPO a partir de las m√©tricas almacenadas:\n",
    "\n",
    "1. Leer `continual_results.json` del *run*.  \n",
    "2. Identificar **primera** y **√∫ltima** tarea.  \n",
    "3. Extraer:\n",
    "   - `c1_mae`: MAE de la primera tarea en su propio test.  \n",
    "   - `c1_after_c2_mae`: MAE de la primera **tras** aprender la √∫ltima (olvido).  \n",
    "   - `c2_mae`: MAE de la **√∫ltima** tarea.  \n",
    "4. Calcular **Olvido relativo (%)** = \\((c1\\_after\\_c2 - c1\\_mae)/c1\\_mae \\times 100\\).\n",
    "\n",
    "La **p√©rdida** a minimizar es:  \n",
    "\\[\n",
    "\\text{Objetivo}= \\mathrm{MAE}_{\\text{tarea final}} + \\alpha \\cdot \\max(0, \\text{olvido rel. } \\%)\n",
    "\\]\n",
    "\n",
    "> Ajusta `ALPHA_FORGET` para priorizar estabilidad (olvido bajo) vs. desempe√±o en la √∫ltima tarea.  \n",
    "\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === M√©tricas y objetivo: usa utilidades del repo ===\n",
    "from src.hpo import objective_value, composite_objective, extract_metrics, safe_read_json\n",
    "from pathlib import Path\n",
    "ALPHA_FORGET = 0.5  # peso del olvido relativo en el objetivo compuesto\n",
    "\n",
    "def _load_results(out_dir: Path) -> dict:\n",
    "    \"\"\"Lee outputs/<exp>/continual_results.json con manejo robusto.\"\"\"\n",
    "    return safe_read_json(Path(out_dir) / \"continual_results.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e35e7",
   "metadata": {},
   "source": [
    "<a id=\"sec-05\"></a>\n",
    "## 5) Espacios de b√∫squeda (por m√©todo)\n",
    "\n",
    "**Objetivo**  \n",
    "Declarar qu√© hiperpar√°metros explora Optuna:\n",
    "\n",
    "- **ewc**  \n",
    "  - `lam` \\(\\in [3\\cdot 10^8, 2\\cdot 10^9]\\) (log-uniform).  \n",
    "  - `fisher_batches` ‚àà {200, ‚Ä¶, 1200}.  \n",
    "- **rehearsal**  \n",
    "  - `buffer_size` ‚àà {1000, ‚Ä¶, 8000}.  \n",
    "  - `replay_ratio` ‚àà [0.05, 0.4].  \n",
    "- **rehearsal+ewc**: combina ambos.  \n",
    "- **as-snn**  \n",
    "  - `gamma_ratio` ‚àà [0.3, 0.8], `lambda_a` ‚àà [1.0, 4.0], `ema` ‚àà [0.70, 0.98].  \n",
    "- **naive**: sin HPs.\n",
    "\n",
    "> Puedes extender a otros m√©todos (p. ej., `sa-snn`, `sca-snn`, `colanet`) a√±adiendo su espacio de b√∫squeda y registrando el nombre.  \n",
    "\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_params_for_method(trial: optuna.Trial, method: str, preset: str) -> dict:\n",
    "    method = method.lower()\n",
    "    preset = preset.lower()\n",
    "\n",
    "    if method == \"ewc\":\n",
    "        lam_grid = {\n",
    "            \"fast\":     [7e8, 1e9],\n",
    "            \"std\":      [1.5e8, 4e8, 1e9],\n",
    "            \"accurate\": [5e8, 7e8, 1e9],\n",
    "        }\n",
    "        fisher_grid = {\n",
    "            \"fast\":     [300, 1000],\n",
    "            \"std\":      [500, 1000],\n",
    "            \"accurate\": [800, 1200],\n",
    "        }\n",
    "        lam = trial.suggest_categorical(\"lam\", lam_grid.get(preset, lam_grid[\"std\"]))\n",
    "        fb  = trial.suggest_categorical(\"fisher_batches\", fisher_grid.get(preset, fisher_grid[\"std\"]))\n",
    "        return {\"lam\": float(lam), \"fisher_batches\": int(fb)}\n",
    "\n",
    "    elif method == \"rehearsal\":\n",
    "        buffer_size  = trial.suggest_int(\"buffer_size\", 1000, 8000, step=1000)\n",
    "        replay_ratio = trial.suggest_float(\"replay_ratio\", 0.05, 0.4, step=0.05)\n",
    "        return {\"buffer_size\": buffer_size, \"replay_ratio\": replay_ratio}\n",
    "\n",
    "    elif method == \"rehearsal+ewc\":\n",
    "        # Igual que arriba pero preset-aware para lam/fisher\n",
    "        lam_grid = {\n",
    "            \"fast\":     [7e8, 1e9],\n",
    "            \"std\":      [1.5e8, 4e8, 1e9],\n",
    "            \"accurate\": [5e8, 7e8, 1e9],\n",
    "        }\n",
    "        fisher_grid = {\n",
    "            \"fast\":     [300, 1000],\n",
    "            \"std\":      [500, 1000],\n",
    "            \"accurate\": [800, 1200],\n",
    "        }\n",
    "        lam = trial.suggest_categorical(\"lam\", lam_grid.get(preset, lam_grid[\"std\"]))\n",
    "        fisher_batches = trial.suggest_categorical(\"fisher_batches\", fisher_grid.get(preset, fisher_grid[\"std\"]))\n",
    "        buffer_size  = trial.suggest_int(\"buffer_size\", 1000, 8000, step=1000)\n",
    "        replay_ratio = trial.suggest_float(\"replay_ratio\", 0.05, 0.4, step=0.05)\n",
    "        return {\n",
    "            \"buffer_size\": buffer_size,\n",
    "            \"replay_ratio\": replay_ratio,\n",
    "            \"lam\": float(lam),\n",
    "            \"fisher_batches\": int(fisher_batches),\n",
    "        }\n",
    "\n",
    "    elif method == \"as-snn\":\n",
    "        gamma_ratio = trial.suggest_float(\"gamma_ratio\", 0.3, 0.8, step=0.1)\n",
    "        lambda_a    = trial.suggest_float(\"lambda_a\", 1.0, 4.0)\n",
    "        ema         = trial.suggest_float(\"ema\", 0.70, 0.98)\n",
    "        return {\"gamma_ratio\": gamma_ratio, \"lambda_a\": lambda_a, \"ema\": ema}\n",
    "\n",
    "    else:\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841fd521",
   "metadata": {},
   "source": [
    "<a id=\"sec-06\"></a>\n",
    "## 6) Estudio Optuna ‚Äî un m√©todo concreto\n",
    "\n",
    "**Objetivo**  \n",
    "Optimizar **un m√©todo** espec√≠fico (`METHOD_TO_OPTIMIZE`) durante `N_TRIALS`.\n",
    "\n",
    "Flujo de cada *trial*:\n",
    "1. Sugerir HPs (`suggest_*`).  \n",
    "2. Construir `cfg` con esos HPs (y, si `HPO_EPOCHS` est√° definido, **reducir epochs** solo para HPO).  \n",
    "3. Ejecutar `run_continual(...)`.  \n",
    "4. Leer resultados, computar la **p√©rdida objetivo** y devolverla a Optuna.\n",
    "\n",
    "**Persistencia**  \n",
    "Se usa **SQLite** en `outputs/optuna/` para reanudar estudios y registrar todos los *trials* (`*_trials.csv`).\n",
    "\n",
    "> Para m√©todos con *replay* se desactiva `persistent_workers` por estabilidad de DataLoader (puedes ajustar *AMP/pin_memory/workers* si lo necesitas).  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f92711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 6: Configuraci√≥n del estudio + objetivo Optuna (con TAG autom√°tico) ===\n",
    "import copy, json, inspect, hashlib, os\n",
    "from pathlib import Path\n",
    "import optuna, torch, gc, time\n",
    "from src.telemetry import read_emissions_kg  # registra emisiones si hay CodeCarbon\n",
    "\n",
    "# --- Par√°metros del estudio ---\n",
    "METHOD_TO_OPTIMIZE = \"ewc\"   # \"naive\" | \"ewc\" | \"rehearsal\" | \"rehearsal+ewc\" | \"as-snn\"\n",
    "N_TRIALS = 2                 # s√∫belo cuando est√©s satisfecho\n",
    "HPO_EPOCHS = None            # None -> epochs del preset; o int para acelerar\n",
    "REHEARSAL_NAMES = (\"rehearsal\", \"rehearsal+ewc\")\n",
    "\n",
    "def build_cfg_with_method(base_cfg: dict, method_name: str, params: dict, hpo_epochs: int|None):\n",
    "    cfg = copy.deepcopy(base_cfg)\n",
    "    cfg[\"continual\"][\"method\"] = method_name\n",
    "    cfg[\"continual\"][\"params\"] = params or {}\n",
    "\n",
    "    # Perfil equilibrado-r√°pido para HPO\n",
    "    cfg[\"optim\"][\"amp\"] = True\n",
    "    cfg[\"data\"][\"pin_memory\"] = True\n",
    "    cfg[\"data\"][\"persistent_workers\"] = False  # evita fugas/hangs entre trials\n",
    "    cfg[\"data\"][\"num_workers\"] = min(max(2, int(cfg[\"data\"].get(\"num_workers\") or 2)), 4)\n",
    "\n",
    "    cfg.setdefault(\"logging\", {}).setdefault(\"telemetry\", {})[\"codecarbon\"] = False\n",
    "\n",
    "    # Si HPO de replay, baja un poco el riesgo\n",
    "    if method_name.lower() in REHEARSAL_NAMES:\n",
    "        cfg[\"optim\"][\"amp\"] = False\n",
    "        cfg[\"data\"][\"pin_memory\"] = False\n",
    "        cfg[\"data\"][\"num_workers\"] = min(int(cfg[\"data\"].get(\"num_workers\") or 0), 2)\n",
    "\n",
    "    if hpo_epochs is not None:\n",
    "        cfg[\"optim\"][\"epochs\"] = int(hpo_epochs)\n",
    "    return cfg\n",
    "\n",
    "def run_one_cfg(cfg: dict) -> tuple[Path, dict, dict]:\n",
    "    out_dir, res = run_continual(\n",
    "        task_list=task_list,\n",
    "        make_loader_fn=make_loader_fn,\n",
    "        make_model_fn=make_model_fn,\n",
    "        tfm=tfm,\n",
    "        cfg=cfg,\n",
    "        preset_name=PRESET,\n",
    "        out_root=ROOT / \"outputs\",\n",
    "        verbose=True,\n",
    "    )\n",
    "    results = _load_results(out_dir) or (res if isinstance(res, dict) else {})\n",
    "    return out_dir, res, results\n",
    "\n",
    "def optuna_objective(trial: optuna.Trial):\n",
    "    params = suggest_params_for_method(trial, METHOD_TO_OPTIMIZE, PRESET)\n",
    "    cfg_i  = build_cfg_with_method(CFG, METHOD_TO_OPTIMIZE, params, HPO_EPOCHS)\n",
    "\n",
    "    # Etiqueta del run\n",
    "    cfg_i.setdefault(\"naming\", {})\n",
    "    tag = f\"{METHOD_TO_OPTIMIZE}_hpo_t{trial.number}\"\n",
    "    if METHOD_TO_OPTIMIZE in (\"ewc\", \"rehearsal+ewc\") and \"lam\" in params:\n",
    "        tag += f\"_lam_{params['lam']:.1e}\"\n",
    "    cfg_i[\"naming\"][\"tag\"] = tag\n",
    "\n",
    "    try:\n",
    "        out_dir, _, results = run_one_cfg(cfg_i)\n",
    "        metrics = extract_metrics(results)\n",
    "        val = composite_objective(metrics, ALPHA_FORGET)\n",
    "\n",
    "        emissions = read_emissions_kg(out_dir)\n",
    "        if emissions is not None:\n",
    "            trial.set_user_attr(\"emissions_kg\", float(emissions))\n",
    "\n",
    "        trial.set_user_attr(\"out_dir\", str(out_dir))\n",
    "        trial.set_user_attr(\"metrics\", metrics)\n",
    "        trial.set_user_attr(\"method\", METHOD_TO_OPTIMIZE)\n",
    "        trial.set_user_attr(\"params\", params)\n",
    "        return val\n",
    "    except Exception as e:\n",
    "        trial.set_user_attr(\"error\", repr(e))\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# -------------------------------\n",
    "# TAG AUTOM√ÅTICO DEL ESPACIO HPO\n",
    "# -------------------------------\n",
    "def _space_fingerprint() -> str:\n",
    "    bits = {\n",
    "        \"method\": METHOD_TO_OPTIMIZE,\n",
    "        \"preset\": PRESET,\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"encoder\": ENCODER,\n",
    "        \"T\": T,\n",
    "        \"gain\": GAIN,\n",
    "        \"torch\": torch.__version__,\n",
    "        \"optuna\": optuna.__version__,\n",
    "        \"suggest_src\": inspect.getsource(suggest_params_for_method),\n",
    "    }\n",
    "    g = suggest_params_for_method.__globals__\n",
    "    for k in (\"lam_grid\", \"fisher_grid\", \"replay_grid\", \"as_snn_grid\"):\n",
    "        if k in g:\n",
    "            try:\n",
    "                bits[k] = g[k]\n",
    "            except Exception:\n",
    "                bits[k] = str(g[k])\n",
    "\n",
    "    raw = json.dumps(bits, sort_keys=True, default=str)\n",
    "    return hashlib.sha1(raw.encode(\"utf-8\")).hexdigest()[:10]\n",
    "\n",
    "HPO_TAG = os.getenv(\"HPO_TAG_OVERRIDE\") or f\"space_{_space_fingerprint()}\"\n",
    "\n",
    "# --- Persistencia Optuna en SQLite ---\n",
    "OPTUNA_DIR = ROOT / \"outputs\" / \"optuna\"\n",
    "OPTUNA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DB_PATH = OPTUNA_DIR / f\"hpo_{METHOD_TO_OPTIMIZE}_{PRESET}_{MODEL_NAME}_{ENCODER}_T{T}_g{GAIN}_{HPO_TAG}.sqlite\"\n",
    "STORAGE = f\"sqlite:///{DB_PATH}\"\n",
    "STUDY_NAME = f\"HPO_{METHOD_TO_OPTIMIZE}_{PRESET}_{ENCODER}_T{T}_{HPO_TAG}\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=STUDY_NAME,\n",
    "    storage=STORAGE,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(optuna_objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(\"HPO_TAG:\", HPO_TAG)\n",
    "print(\"SQLite:\", DB_PATH)\n",
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best attrs:\", study.best_trial.user_attrs)\n",
    "\n",
    "# Guardar trazabilidad de intentos a CSV\n",
    "df_trials = study.trials_dataframe(attrs=(\"number\",\"value\",\"state\",\"params\",\"user_attrs\"))\n",
    "df_trials.to_csv(OPTUNA_DIR / f\"{DB_PATH.stem}_trials.csv\", index=False)\n",
    "\n",
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best attrs:\", study.best_trial.user_attrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48b08b",
   "metadata": {},
   "source": [
    "<a id=\"sec-07\"></a>\n",
    "## 7) Estudio Optuna conjunto (elige m√©todo + HPs)\n",
    "\n",
    "**Objetivo**  \n",
    "Permitir que **cada *trial*** elija tambi√©n el **m√©todo** (`naive`, `ewc`, `rehearsal`, `rehearsal+ewc`, `as-snn`) adem√°s de sus HPs. √ötil cuando:\n",
    "\n",
    "- No tienes claro qu√© m√©todo se adapta mejor a tu conjunto de datos.  \n",
    "- Quieres una **comparativa autom√°tica** con el mismo presupuesto de c√≥mputo.\n",
    "\n",
    "> Activa `RUN_JOINT=True` para lanzar este estudio y eleva `N_TRIALS_JOINT` cuando el flujo sea estable.  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e7f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_JOINT = False   # Pon True si quieres lanzar el estudio conjunto\n",
    "N_TRIALS_JOINT = 10\n",
    "\n",
    "def optuna_objective_joint(trial: optuna.Trial):\n",
    "    method = trial.suggest_categorical(\"method\", [\"naive\",\"ewc\",\"rehearsal\",\"rehearsal+ewc\",\"as_snn\"])\n",
    "    params = suggest_params_for_method(trial, method, PRESET)\n",
    "    cfg_i  = build_cfg_with_method(CFG, method, params, HPO_EPOCHS)\n",
    "\n",
    "    if method.lower() in (\"rehearsal\",\"rehearsal+ewc\"):\n",
    "        cfg_i[\"data\"][\"persistent_workers\"] = False\n",
    "\n",
    "    cfg_i.setdefault(\"naming\", {})\n",
    "    tag = f\"{method}_hpo_t{trial.number}\"\n",
    "    if method in (\"ewc\", \"rehearsal+ewc\") and \"lam\" in params:\n",
    "        tag += f\"_lam_{params['lam']:.1e}\"\n",
    "    cfg_i[\"naming\"][\"tag\"] = tag\n",
    "\n",
    "    try:\n",
    "        out_dir, _, results = run_one_cfg(cfg_i)\n",
    "        metrics = extract_metrics(results)\n",
    "        val = objective_value(metrics, ALPHA_FORGET)\n",
    "        trial.set_user_attr(\"out_dir\", str(out_dir))\n",
    "        trial.set_user_attr(\"metrics\", metrics)\n",
    "        trial.set_user_attr(\"method\", method)\n",
    "        trial.set_user_attr(\"params\", params)\n",
    "        return val\n",
    "    except Exception as e:\n",
    "        trial.set_user_attr(\"error\", repr(e))\n",
    "        return float(\"inf\")\n",
    "    finally:\n",
    "        import gc, time\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "if RUN_JOINT:\n",
    "    study_joint = optuna.create_study(direction=\"minimize\", study_name=\"HPO_joint\")\n",
    "    study_joint.optimize(optuna_objective_joint, n_trials=N_TRIALS_JOINT, show_progress_bar=True)\n",
    "    print(\"Best value:\", study_joint.best_value)\n",
    "    print(\"Best params:\", study_joint.best_params)\n",
    "    print(\"Best attrs:\", study_joint.best_trial.user_attrs)\n",
    "else:\n",
    "    print(\"RUN_JOINT=False ‚Äî omitido.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cdc9f",
   "metadata": {},
   "source": [
    "<a id=\"sec-08\"></a>\n",
    "## 8) Re-entrena con los mejores hiperpar√°metros\n",
    "\n",
    "**Objetivo**  \n",
    "Tomar `study.best_params` (y el m√©todo ganador) y **re-entrenar a pleno rendimiento**:\n",
    "\n",
    "- Reconstruir `cfg_best` con los HPs √≥ptimos.  \n",
    "- (Opcional) Restaurar `optim.epochs` del preset si usaste `HPO_EPOCHS` reducido durante la b√∫squeda.  \n",
    "- Ejecutar `run_continual(...)` y mostrar las **m√©tricas finales** y la **carpeta de salida**.\n",
    "\n",
    "> Separa la **b√∫squeda r√°pida** (menos epochs) del **entrenamiento definitivo** (epochs del preset).  \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40464ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa el mejor del estudio por m√©todo (arriba)\n",
    "BEST_PARAMS = study.best_params\n",
    "BEST_METHOD = METHOD_TO_OPTIMIZE\n",
    "print(\"Mejor m√©todo:\", BEST_METHOD)\n",
    "print(\"Mejores HPs:\", BEST_PARAMS)\n",
    "\n",
    "cfg_best = copy.deepcopy(CFG)\n",
    "cfg_best[\"continual\"][\"method\"] = BEST_METHOD\n",
    "cfg_best[\"continual\"][\"params\"] = BEST_PARAMS\n",
    "\n",
    "# Reponer ajustes del preset para el re-train\n",
    "cfg_best[\"optim\"][\"amp\"] = True\n",
    "cfg_best[\"data\"][\"persistent_workers\"] = CFG[\"data\"][\"persistent_workers\"]\n",
    "cfg_best[\"data\"][\"pin_memory\"] = CFG[\"data\"][\"pin_memory\"]\n",
    "cfg_best[\"data\"][\"num_workers\"] = CFG[\"data\"][\"num_workers\"]\n",
    "\n",
    "from src.telemetry import read_emissions_kg\n",
    "out_dir, _, results = run_one_cfg(cfg_best)\n",
    "metrics = extract_metrics(results)\n",
    "print(\"Resultados finales (re-train):\", metrics)\n",
    "print(\"Emisiones totales (kg CO2e):\", read_emissions_kg(out_dir))\n",
    "print(\"Guardado en:\", out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97b9ce",
   "metadata": {},
   "source": [
    "<a id=\"sec-09\"></a>\n",
    "## 9) Resumen r√°pido de runs (tabla)\n",
    "\n",
    "**Objetivo**  \n",
    "Inspeccionar resultados de outputs/continual_*:\n",
    "\n",
    "- Construir una tabla con `preset`, `method`, `encoder`, `seed` (y `lambda` si aplica),\n",
    "junto a `c1_mae`, `c1_after_c2_mae`, `forget_rel_%`, `c2_mae`. \n",
    "- Ordenar/filtrar para comparar manzanas con manzanas (mismo preset/encoder).\n",
    "\n",
    "> Exporta a CSV/Parquet para gr√°ficas comparativas. Si la tabla sale vac√≠a, revisa que existan `continual_results.json`. \n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Lanzador ligero sin Optuna (accurate) ===\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.runner import run_continual\n",
    "from src.models import build_model as _build_model\n",
    "\n",
    "def build_model(tfm):\n",
    "    return _build_model(MODEL_NAME, tfm, beta=0.9, threshold=0.5)\n",
    "\n",
    "EXPS = [\n",
    "    dict(method=\"naive\", params={}, tag=\"grid01\"),\n",
    "    dict(method=\"rehearsal\", params={\"buffer_size\": 3000, \"replay_ratio\": 0.10}, tag=\"grid02_rr10\"),\n",
    "    dict(method=\"rehearsal\", params={\"buffer_size\": 3000, \"replay_ratio\": 0.15}, tag=\"grid03_rr15\"),\n",
    "    dict(method=\"rehearsal\", params={\"buffer_size\": 3000, \"replay_ratio\": 0.20}, tag=\"grid04_rr20\"),\n",
    "    dict(method=\"rehearsal\", params={\"buffer_size\": 3000, \"replay_ratio\": 0.25}, tag=\"grid05_rr25\"),\n",
    "    dict(method=\"sca-snn\", params={\"attach_to\": \"f6\",\"flatten_spatial\": False,\"num_bins\": 50,\n",
    "                                   \"bin_lo\": -1.0,\"bin_hi\": 1.0,\"anchor_batches\": 12,\n",
    "                                   \"max_per_bin\": 512,\"beta\": 0.65,\"bias\": 0.0,\n",
    "                                   \"soft_mask_temp\": 0.75,\"habit_decay\": 0.995,\"verbose\": True,\"log_every\": 750},\n",
    "         tag=\"grid06_sca_b065\"),\n",
    "    dict(method=\"sca-snn\", params={\"attach_to\": \"f6\",\"flatten_spatial\": False,\"num_bins\": 50,\n",
    "                                   \"bin_lo\": -1.0,\"bin_hi\": 1.0,\"anchor_batches\": 12,\n",
    "                                   \"max_per_bin\": 512,\"beta\": 0.60,\"bias\": 0.0,\n",
    "                                   \"soft_mask_temp\": 0.75,\"habit_decay\": 0.995,\"verbose\": True,\"log_every\": 750},\n",
    "         tag=\"grid07_sca_b060\"),\n",
    "    dict(method=\"sca-snn\", params={\"attach_to\": \"f6\",\"flatten_spatial\": False,\"num_bins\": 50,\n",
    "                                   \"bin_lo\": -1.0,\"bin_hi\": 1.0,\"anchor_batches\": 12,\n",
    "                                   \"max_per_bin\": 512,\"beta\": 0.70,\"bias\": 0.0,\n",
    "                                   \"soft_mask_temp\": 0.75,\"habit_decay\": 0.995,\"verbose\": True,\"log_every\": 750},\n",
    "         tag=\"grid08_sca_b070\"),\n",
    "    dict(method=\"as-snn\", params={\"gamma_ratio\": 0.3, \"lambda_a\": 1.6, \"ema\": 0.9}, tag=\"grid09_as\"),\n",
    "    dict(method=\"sa-snn\", params={\"k\": 8, \"tau\": 28, \"thresh_lo\": 1.2, \"period\": 200000}, tag=\"grid10_sa\"),\n",
    "    dict(method=\"ewc\", params={\"lam\": 7e8, \"fisher_batches\": 1000}, tag=\"grid11_ewc\"),\n",
    "]\n",
    "\n",
    "OUTS = []\n",
    "for i, e in enumerate(EXPS, 1):\n",
    "    cfg_i = deepcopy(CFG)\n",
    "    cfg_i[\"continual\"][\"method\"] = e[\"method\"]\n",
    "    cfg_i[\"continual\"][\"params\"] = e[\"params\"]\n",
    "    cfg_i.setdefault(\"naming\", {})[\"tag\"] = e.get(\"tag\", f\"grid{i:02d}\")\n",
    "    cfg_i[\"optim\"][\"es_patience\"] = None\n",
    "\n",
    "    print(f\"\\n>>> {i}/{len(EXPS)} :: {e['method']} :: {e['params']}\")\n",
    "    out_dir, _ = run_continual(task_list, make_loader_fn, build_model, tfm, cfg_i, PRESET, out_root=ROOT/\"outputs\", verbose=True)\n",
    "    OUTS.append(out_dir)\n",
    "    print(\"Guardado en:\", out_dir)\n",
    "\n",
    "import pandas as pd, glob, os, json\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Combinar todas las filas resumen (run_row.csv)\n",
    "rows = []\n",
    "for f in glob.glob(str(ROOT / \"outputs\" / \"continual_*\" / \"run_row.csv\")):\n",
    "    try:\n",
    "        rows.append(pd.read_csv(f))\n",
    "    except Exception:\n",
    "        pass\n",
    "df_all = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n",
    "if df_all.empty:\n",
    "    print(\"No se encontraron run_row.csv\")\n",
    "else:\n",
    "    df_all = df_all[df_all[\"preset\"]==\"accurate\"].copy()\n",
    "    out_all = ROOT / \"outputs\" / \"all_runs_accurate.csv\"\n",
    "    df_all.to_csv(out_all, index=False)\n",
    "    print(\"Guardado:\", out_all)\n",
    "\n",
    "# 2) Elegir el mejor por m√©todo (score simple)\n",
    "def _pick_best(g):\n",
    "    g = g.copy()\n",
    "    g[\"r1\"] = g[\"c2_final_mae\"]\n",
    "    g[\"r2\"] = g[\"avg_forget_rel\"]\n",
    "    g[\"r3\"] = g[\"emissions_kg\"].fillna(0)\n",
    "    return g.sort_values([\"r1\",\"r2\",\"r3\"], na_position=\"last\").head(1).drop(columns=[\"r1\",\"r2\",\"r3\"])\n",
    "\n",
    "df_best = (df_all.groupby(\"method\", group_keys=False)\n",
    "           .apply(_pick_best)\n",
    "           .reset_index(drop=True))\n",
    "out_best = ROOT / \"outputs\" / \"best_by_method_accurate.csv\"\n",
    "df_best.to_csv(out_best, index=False)\n",
    "print(\"Guardado:\", out_best)\n",
    "\n",
    "# 3) Tabla Œî% vs naive (emisiones y tiempo)\n",
    "if \"naive\" in df_best[\"method\"].values:\n",
    "    base = df_best[df_best[\"method\"]==\"naive\"].iloc[0]\n",
    "    base_e = float(base[\"emissions_kg\"]) if pd.notna(base[\"emissions_kg\"]) else None\n",
    "    base_t = float(base[\"elapsed_sec\"])\n",
    "    def pct(x, base):\n",
    "        if base in (None, 0) or pd.isna(x):\n",
    "            return None\n",
    "        return 100.0 * (float(x) - float(base)) / float(base)\n",
    "    table_rows = []\n",
    "    for _, r in df_best.iterrows():\n",
    "        table_rows.append({\n",
    "            \"method\": r[\"method\"],\n",
    "            \"c2_final_mae\": r[\"c2_final_mae\"],\n",
    "            \"avg_forget_rel\": r[\"avg_forget_rel\"],\n",
    "            \"emissions_kg\": r[\"emissions_kg\"],\n",
    "            \"elapsed_sec\": r[\"elapsed_sec\"],\n",
    "            \"Œî%_emissions_vs_naive\": None if base_e is None else pct(r[\"emissions_kg\"], base_e),\n",
    "            \"Œî%_tiempo_vs_naive\": pct(r[\"elapsed_sec\"], base_t),\n",
    "        })\n",
    "    df_delta = pd.DataFrame(table_rows).sort_values([\"c2_final_mae\",\"avg_forget_rel\"], na_position=\"last\")\n",
    "    out_delta = ROOT / \"outputs\" / \"delta_vs_naive.csv\"\n",
    "    df_delta.to_csv(out_delta, index=False)\n",
    "    print(\"Guardado:\", out_delta)\n",
    "else:\n",
    "    print(\"No hay baseline naive en df_best; no puedo calcular Œî% vs naive.\")\n",
    "\n",
    "# 4) Recoger curvas de Rehearsal (C2) para figuras\n",
    "reh_curves = []\n",
    "for d in glob.glob(str(ROOT / \"outputs\" / \"continual_*rehearsal*\" )):\n",
    "    for f in glob.glob(os.path.join(d, \"task_*_*\", \"loss_curves.csv\")):\n",
    "        if any(k in f.lower() for k in [\"c2\",\"circuito2\",\"task_2\",\"track2\"]):\n",
    "            reh_curves.append(f)\n",
    "print(\"Curvas C2 (Rehearsal) encontradas:\", len(reh_curves))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716c060",
   "metadata": {},
   "source": [
    "## Ap√©ndice ‚Äî Optuna en 90 segundos\n",
    "\n",
    "- **Study**: el proyecto de HPO (contiene todos los trials).\n",
    "- **Trial**: una evaluaci√≥n con un conjunto de HPs (`suggest_int`, `suggest_float`, etc.).\n",
    "- **Sampler**: estrategia para elegir el siguiente punto (por defecto, TPE).\n",
    "- **Pruner**: **corta** trials que pintan mal (acelera b√∫squedas largas).\n",
    "- **Storage**: base de datos (SQLite, PostgreSQL) para **reanudar** y/o **paralelizar**.\n",
    "\n",
    "### Reanudar b√∫squedas\n",
    "Puedes crear el estudio con almacenamiento:\n",
    "```python\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"HPO_ewc\",\n",
    "    storage=f\"sqlite:///{ROOT/'outputs'/'optuna_ewc.sqlite'}\",\n",
    "    load_if_exists=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpo import objective_value, composite_objective\n",
    "m = {\"c2_mae\": 0.16, \"forget_rel_%\": 12.5}\n",
    "print(objective_value(m, key=\"forget_rel_%\"))         # 12.5\n",
    "print(objective_value(m, key=\"c1_forgetting_mae_rel_%\"))  # 12.5 (alias OK)\n",
    "print(composite_objective(m, alpha=0.5))              # 0.16 + 0.5*12.5 = 6.41\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
