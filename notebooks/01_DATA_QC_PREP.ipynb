{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 · Preparación de datos (QC + splits + tasks.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: /home/cesar/proyectos/TFM_SNN/data/processed/tasks.json\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Prepara los splits (train/val/test) de los recorridos del simulador de Udacity\n",
    "y genera un manifiesto \"tasks.json\" para el pipeline continual.\n",
    "\n",
    "Qué hace:\n",
    "1) Lee el driving_log.csv de cada recorrido (RUNS).\n",
    "2) Normaliza rutas de imágenes (soporta rutas con barras invertidas y/o comillas).\n",
    "3) Verifica que existan las imágenes de las tres cámaras (center/left/right).\n",
    "4) Realiza un split estratificado por rangos de 'steering' para evitar sesgo.\n",
    "5) Guarda:\n",
    "   - data/processed/<run>/canonical.csv\n",
    "   - data/processed/<run>/{train,val,test}.csv\n",
    "   - data/processed/tasks.json   (orden de tareas y rutas a CSV por split)\n",
    "\n",
    "Notas:\n",
    "- La estratificación por bins de 'steering' reduce el sesgo a \"recta\".\n",
    "- El seed fija la reproducibilidad del muestreo.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Raíz del repo (asume que este script vive en notebooks/ o similar)\n",
    "ROOT = Path.cwd().parent\n",
    "RAW  = ROOT / \"data\" / \"raw\" / \"udacity\"     # Carpeta con los recorridos originales\n",
    "PROC = ROOT / \"data\" / \"processed\"           # Salidas procesadas\n",
    "\n",
    "# Lista de recorridos a preparar (debe haber un driving_log.csv en cada uno)\n",
    "RUNS = [\"circuito1\", \"circuito2\"]\n",
    "\n",
    "\n",
    "def _fix(p: str) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza una ruta de imagen proveniente del CSV.\n",
    "\n",
    "    - Elimina espacios y comillas al borde.\n",
    "    - Cambia barras invertidas '\\' por barras '/' (compatibilidad Windows→Linux).\n",
    "    - Si la ruta contiene 'IMG/' (en cualquier mayúscula/minúscula), la recorta\n",
    "      desde ese punto para dejarla relativa al directorio IMG/.\n",
    "\n",
    "    Ejemplos:\n",
    "        r'C:\\\\data\\\\udacity\\\\IMG\\\\center_1.jpg' -> 'IMG/center_1.jpg'\n",
    "        'img/LEFT.JPG' -> 'img/LEFT.JPG' (se recorta desde 'img/')\n",
    "    \"\"\"\n",
    "    p = str(p).strip().strip('\"').strip(\"'\").replace(\"\\\\\", \"/\")\n",
    "    # Buscamos 'img/' en minúsculas para no depender de mayúsculas/minúsculas\n",
    "    low = p.lower()\n",
    "    i = low.rfind(\"img/\")\n",
    "    if i != -1:\n",
    "        # Usamos el índice calculado sobre la versión minúscula (misma longitud)\n",
    "        # para cortar la ruta original preservando su caso original.\n",
    "        return p[i:]\n",
    "    return p\n",
    "\n",
    "\n",
    "def load_csv(csv_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga un driving_log.csv con los nombres de columnas esperados\n",
    "    y normaliza las rutas de las tres cámaras.\n",
    "\n",
    "    driving_log.csv (Udacity) columnas:\n",
    "      [center, left, right, steering, throttle, brake, speed]\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        csv_path,\n",
    "        header=None,\n",
    "        names=[\"center\", \"left\", \"right\", \"steering\", \"throttle\", \"brake\", \"speed\"],\n",
    "    )\n",
    "\n",
    "    # Normalizamos rutas y las recortamos para que queden relativas a 'IMG/...'\n",
    "    for cam in [\"center\", \"left\", \"right\"]:\n",
    "        df[cam] = df[cam].map(_fix)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def stratified(\n",
    "    df: pd.DataFrame,\n",
    "    bins: int = 21,\n",
    "    train: float = 0.70,\n",
    "    val: float = 0.15,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Split estratificado por bins de 'steering' para evitar sesgo.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame con al menos 'steering'.\n",
    "        bins: número de cortes (p. ej., 21 → 20 rangos). Cuantos más, más fina la estratificación.\n",
    "        train/val: proporciones de train y val; test se infiere como 1 - train - val.\n",
    "        seed: fija la reproducibilidad del muestreo.\n",
    "\n",
    "    Detalles:\n",
    "        - Calculamos bordes de bining entre min/max de 'steering' (acotando a [-1, 1] por robustez).\n",
    "        - En cada bin barajamos los índices y cortamos según proporciones.\n",
    "        - Concatenamos los trozos de cada bin para formar los splits finales.\n",
    "\n",
    "    Returns:\n",
    "        (train_df, val_df, test_df)\n",
    "    \"\"\"\n",
    "    # Aseguramos tipo float y acotamos los extremos a [-1, 1] por robustez\n",
    "    s = df[\"steering\"].astype(float)\n",
    "    lo = min(float(s.min()), -1.0)\n",
    "    hi = max(float(s.max()),  1.0)\n",
    "\n",
    "    # Definimos los bordes de los bins uniformemente en [lo, hi]\n",
    "    edges = np.linspace(lo, hi, bins)\n",
    "\n",
    "    # Asignamos a cada fila el índice de bin (0..bins-2); NaN si cae fuera (no debería)\n",
    "    labels = pd.cut(s, bins=edges, include_lowest=True, labels=False)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"_b\"] = labels  # columna temporal con el bin asignado\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    parts = []  # acumulamos (tr, va, te) de cada bin por separado\n",
    "\n",
    "    # Para cada bin presente en los datos…\n",
    "    for b in sorted(df[\"_b\"].dropna().unique()):\n",
    "        g   = df[df[\"_b\"] == b]            # filas del bin b\n",
    "        idx = np.arange(len(g))            # índices relativos dentro del grupo\n",
    "        rng.shuffle(idx)                   # barajamos con RNG reproducible\n",
    "\n",
    "        n   = len(idx)\n",
    "        ntr = int(round(n * train))\n",
    "        nva = int(round(n * val))\n",
    "\n",
    "        # Cortamos (train, val, test) dentro del bin\n",
    "        parts.append((\n",
    "            g.iloc[idx[:ntr]],\n",
    "            g.iloc[idx[ntr : ntr + nva]],\n",
    "            g.iloc[idx[ntr + nva :]],\n",
    "        ))\n",
    "\n",
    "    # Unimos todos los bins para formar los splits finales\n",
    "    tr = pd.concat([a for a, _, _ in parts], ignore_index=True)\n",
    "    va = pd.concat([b for _, b, _ in parts], ignore_index=True)\n",
    "    te = pd.concat([c for _, _, c in parts], ignore_index=True)\n",
    "\n",
    "    # Limpiamos la columna temporal\n",
    "    for p in (tr, va, te):\n",
    "        p.drop(columns=[\"_b\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    return tr, va, te\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Ejecución \"script-like\": prepara splits por cada run y genera tasks.json\n",
    "# --------------------------------------------------------------------------\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "manif = []  # recopilación de rutas a splits por cada recorrido\n",
    "\n",
    "for run in RUNS:\n",
    "    base = RAW / run\n",
    "    csv  = base / \"driving_log.csv\"\n",
    "    assert csv.exists(), f\"No existe el CSV esperado: {csv}\"\n",
    "\n",
    "    # 1) Cargar y normalizar rutas\n",
    "    df = load_csv(csv)\n",
    "\n",
    "    # 2) Filtrar filas donde *no* existan imágenes (exigimos las 3 cámaras)\n",
    "    #    Nota: este filtro es AND: se descarta la fila si falta cualquiera de las tres.\n",
    "    for cam in [\"center\", \"left\", \"right\"]:\n",
    "        df = df[(base / df[cam]).apply(lambda p: p.exists())]\n",
    "\n",
    "    # 3) Guardar una versión canónica del CSV (rutas normalizadas y filtradas)\n",
    "    out = PROC / run\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out / \"canonical.csv\", index=False)\n",
    "\n",
    "    # 4) Split estratificado y guardado a disco\n",
    "    tr, va, te = stratified(df)\n",
    "    tr.to_csv(out / \"train.csv\", index=False)\n",
    "    va.to_csv(out / \"val.csv\",   index=False)\n",
    "    te.to_csv(out / \"test.csv\",  index=False)\n",
    "\n",
    "    # 5) Añadir al manifiesto para continual (orden y rutas)\n",
    "    manif.append({\n",
    "        \"run\": run,\n",
    "        \"paths\": {\n",
    "            \"train\": str(out / \"train.csv\"),\n",
    "            \"val\":   str(out / \"val.csv\"),\n",
    "            \"test\":  str(out / \"test.csv\"),\n",
    "        },\n",
    "    })\n",
    "\n",
    "# 6) tasks.json con el orden y los splits (lo usa 03_TRAIN_EVAL.ipynb)\n",
    "with open(PROC / \"tasks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"tasks_order\": RUNS,                                   # e.g., [\"circuito1\", \"circuito2\"]\n",
    "            \"splits\": {m[\"run\"]: m[\"paths\"] for m in manif},       # rutas a CSV por run\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "        ensure_ascii=False,\n",
    "    )\n",
    "\n",
    "print(\"OK:\", PROC / \"tasks.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
