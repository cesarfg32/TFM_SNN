{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_DATA_QC_PREP ‚Äî Quality Check y Splits Estratificados\n",
    "\n",
    "**Qu√© hace este notebook (QC b√°sico):**\n",
    "1. **Carga** cada `driving_log.csv` de los recorridos seleccionados (`RUNS`), admitiendo estructuras con **subcarpetas** (p. ej., `circuito1/vuelta1`, `circuito1/vuelta2`, ‚Ä¶).\n",
    "2. **Normaliza rutas** de imagen (corrige barras invertidas y reduce a rutas relativas tipo `IMG/...`).\n",
    "3. **Filtra filas inv√°lidas** (im√°genes inexistentes en `center/left/right`).\n",
    "4. Realiza **split estratificado por bins de `steering`** con semilla fija (reproducible).\n",
    "5. **Escribe**:\n",
    "   - `data/processed/<run>/canonical.csv`\n",
    "   - `data/processed/<run>/{train,val,test}.csv`\n",
    "   - `data/processed/tasks.json` (orden de tareas y rutas a CSV)\n",
    "\n",
    "\n",
    "> **QC = *Quality Check***: validaci√≥n y normalizaci√≥n de datos **sin balanceo ni aumentaci√≥n offline**.  \n",
    "> Si quieres **balancear** el `train` por bins (con generaci√≥n de im√°genes aumentadas) y **activar la expansi√≥n left/right con correcci√≥n de `steer_shift`**, usa el cuaderno [`01A_PREP_BALANCED.ipynb`]. **Puedes ejecutar 01A directamente**: incluye su propia fase de *prep* antes de balancear.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Preparar los *splits* `train/val/test` por recorrido\n",
    "- Generar `tasks.json` para el pipeline *continual*.\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "- Estructura de datos RAW del simulador Udacity, p. ej.:\n",
    "   - `data/raw/udacity/circuito1/vuelta1/{driving_log.csv, IMG/}`\n",
    "   - `data/raw/udacity/circuito1/vuelta2/{driving_log.csv, IMG/}`\n",
    "   - `data/raw/udacity/circuito2/vuelta1/{driving_log.csv, IMG/}`\n",
    "\n",
    "*(las vueltas pueden variar; el notebook detecta y consolida sus rutas en `canonical.csv`).*\n",
    "\n",
    "## ‚ö†Ô∏è Salidas\n",
    "- CSVs can√≥nicos y de split en `data/processed/<run>/`.\n",
    "- `tasks.json` apuntando a esos CSVs  (orden de tareas para *continual learning*).\n",
    "\n",
    "> Si m√°s adelante quieres **balanceo offline de `train` por bins** (con aumentaci√≥n fotom√©trica) y/o **expansi√≥n por c√°maras izquierda/derecha (L/R)** con correcci√≥n de √°ngulo, usa `01A_PREP_BALANCED.ipynb` (no requiere ejecutar este notebook previamente).\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "1. [Entorno y API de preparaci√≥n](#sec-01)\n",
    "2. [Par√°metros de la preparaci√≥n](#sec-02)\n",
    "3. [Ejecutar pipeline y verificar](#sec-03)\n",
    "4. [Resumen de rutas de splits (vista r√°pida)](#sec-04)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94aa62",
   "metadata": {},
   "source": [
    "## <a id=\"sec-01\"></a>\n",
    "\n",
    "## 1) Entorno y API de preparaci√≥n\n",
    "\n",
    "**Objetivo:** preparar el entorno y cargar la API de *prep*.\n",
    "\n",
    "Esta celda:\n",
    "- Detecta la ra√≠z del repo (`ROOT`) y la a√±ade a `sys.path`.\n",
    "- Importa la API de `src.prep.data_prep`:\n",
    "  - `PrepConfig` ‚Äî configuraci√≥n declarativa de la preparaci√≥n.\n",
    "  - `run_prep` ‚Äî ejecuta QC + *splits* estratificados y crea `tasks.json`.\n",
    "  - `verify_processed_splits` ‚Äî comprueba que `train/val/test.csv` existen por *run*.\n",
    "- Define rutas base:\n",
    "  - `RAW = data/raw/udacity`\n",
    "  - `PROC = data/processed`\n",
    "\n",
    "> Aqu√≠ **no se ejecuta** todav√≠a la preparaci√≥n; s√≥lo se deja el entorno listo.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %% setup & imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.prep.data_prep import PrepConfig, run_prep, verify_processed_splits\n",
    "RAW  = ROOT / \"data\" / \"raw\" / \"udacity\"\n",
    "PROC = ROOT / \"data\" / \"processed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80049984",
   "metadata": {},
   "source": [
    "## <a id=\"sec-02\"></a>\n",
    "\n",
    "## 2) Par√°metros de la preparaci√≥n\n",
    "\n",
    "**Objetivo:** declarar los *runs* y la configuraci√≥n del *split* (QC b√°sico).\n",
    "\n",
    "- `RUNS`: lista de recorridos a procesar (p. ej., `[\"circuito1\", \"circuito2\"]`).  \n",
    "  Cada recorrido puede contener **m√∫ltiples subcarpetas de vueltas** (`vuelta1/`, `vuelta2/`, ‚Ä¶) que el *prep* consolidar√° en `canonical.csv`.\n",
    "- `use_left_right=False`: en este cuaderno mantenemos un **QC sin expansi√≥n L/R** (no triplica filas ni aplica `steer_shift`).  \n",
    "  > Si deseas activar **expansi√≥n L/R + correcci√≥n de √°ngulo** y **balanceo offline por bins**, emplea `01A_PREP_BALANCED.ipynb` (recomendado para comparativas).\n",
    "- `bins`: n√∫mero de contenedores para **estratificar `steering`** en los *splits* (mitiga sesgo a ‚Äúrecta‚Äù).\n",
    "- `train/val`: proporciones del *split* (test se infiere).\n",
    "- `seed`: fija reproducibilidad del *split*.\n",
    "\n",
    "> `target_per_bin` y `cap_per_bin` **no se usan aqu√≠**. Son par√°metros del **balanceo offline por im√°genes** en `01A_PREP_BALANCED.ipynb`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d8e4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrepConfig(root=PosixPath('/home/cesar/proyectos/TFM_SNN'), runs=['circuito1', 'circuito2'], use_left_right=False, steer_shift=0.2, bins=21, train=0.7, val=0.15, seed=42, target_per_bin=None, cap_per_bin=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Par√°metros de la preparaci√≥n\n",
    "RUNS = [\"circuito1\", \"circuito2\"]\n",
    "\n",
    "CFG = PrepConfig(\n",
    "    root=ROOT,\n",
    "    runs=RUNS,\n",
    "    use_left_right=False,  # QC + split b√°sico (sin expansi√≥n)\n",
    "    steer_shift=0.2,       # no aplica si use_left_right=False\n",
    "    bins=50,\n",
    "    train=0.70,\n",
    "    val=0.15,\n",
    "    seed=42,\n",
    "    target_per_bin=None,   # <- no balancea aqu√≠\n",
    "    cap_per_bin=None,\n",
    ")\n",
    "CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e5525",
   "metadata": {},
   "source": [
    "## <a id=\"sec-03\"></a>\n",
    "## 3) Ejecutar *prep* y verificar\n",
    "\n",
    "**Objetivo:** correr el pipeline de QC + *splits* y validar la existencia de los CSV.\n",
    "\n",
    "Qu√© hace `run_prep(CFG)`:\n",
    "- Lee y **normaliza** cada `driving_log.csv` (admite subcarpetas de vueltas) ‚Üí genera `canonical.csv`.\n",
    "- Crea *splits* **estratificados** (`train.csv`, `val.csv`, `test.csv`) con semilla fija.\n",
    "- Construye/actualiza `data/processed/tasks.json` con el **orden de tareas** y rutas a CSV por *run*.\n",
    "\n",
    "Qu√© hace `verify_processed_splits(PROC, RUNS)`:\n",
    "- Comprueba que `train/val/test.csv` **existen** para cada *run*.\n",
    "- Si falta algo, **lanza una excepci√≥n** con detalle (ayuda a detectar problemas de rutas o im√°genes faltantes).\n",
    "\n",
    "> **Idempotencia:** puedes **re-ejecutar** esta celda tantas veces como quieras. Se regenerar√°n los CSVs y se actualizar√° `tasks.json` de forma consistente con lo indicado en `RUNS`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12bc0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: /home/cesar/proyectos/TFM_SNN/data/processed/prep_manifest.json\n",
      "OK: splits 'train/val/test' encontrados.\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar prep + verificar\n",
    "manifest = run_prep(CFG)\n",
    "print(\"OK:\", PROC/\"prep_manifest.json\")\n",
    "\n",
    "# Verificaci√≥n: existen train/val/test por run\n",
    "verify_processed_splits(PROC, RUNS)\n",
    "print(\"OK: splits 'train/val/test' encontrados.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad3c0c",
   "metadata": {},
   "source": [
    "## <a id=\"sec-04\"></a>\n",
    "## 4) Resumen de rutas de *splits* (vista r√°pida)\n",
    "\n",
    "**Objetivo:** visualizar de un vistazo qu√© ficheros usar√° el pipeline *continual*.\n",
    "\n",
    "Esta celda:\n",
    "- Lee `data/processed/tasks.json`.\n",
    "- Muestra una tabla con columnas `run`, `train_csv`, `val_csv` y `test_csv`.\n",
    "\n",
    "> Si las rutas no son las esperadas, revisa:\n",
    "> - La **lista `RUNS`** de la celda 2,\n",
    "> - La **estructura** de `data/raw/udacity/<run>/vuelta*/`,\n",
    "> - Y que `IMG/` contenga las im√°genes referenciadas.\n",
    "\n",
    "> **Nota sobre balanceo:** este notebook **no** crea `tasks_balanced.json`.  \n",
    "> Si quieres usar *splits* balanceados y/o expansi√≥n L/R, ejecuta `01A_PREP_BALANCED.ipynb` (puedes lanzarlo directamente; incluye su propia fase de *prep* antes del balanceo).\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f048e3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>train_csv</th>\n",
       "      <th>val_csv</th>\n",
       "      <th>test_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>circuito1</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>circuito2</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         run                                          train_csv  \\\n",
       "0  circuito1  /home/cesar/proyectos/TFM_SNN/data/processed/c...   \n",
       "1  circuito2  /home/cesar/proyectos/TFM_SNN/data/processed/c...   \n",
       "\n",
       "                                             val_csv  \\\n",
       "0  /home/cesar/proyectos/TFM_SNN/data/processed/c...   \n",
       "1  /home/cesar/proyectos/TFM_SNN/data/processed/c...   \n",
       "\n",
       "                                            test_csv  \n",
       "0  /home/cesar/proyectos/TFM_SNN/data/processed/c...  \n",
       "1  /home/cesar/proyectos/TFM_SNN/data/processed/c...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resumen de rutas de splits (visualizaci√≥n)\n",
    "tasks_json = json.loads((PROC/\"tasks.json\").read_text(encoding=\"utf-8\"))\n",
    "pd.DataFrame({\n",
    "    \"run\": tasks_json[\"tasks_order\"],\n",
    "    \"train_csv\": [tasks_json[\"splits\"][r][\"train\"] for r in tasks_json[\"tasks_order\"]],\n",
    "    \"val_csv\":   [tasks_json[\"splits\"][r][\"val\"]   for r in tasks_json[\"tasks_order\"]],\n",
    "    \"test_csv\":  [tasks_json[\"splits\"][r][\"test\"]  for r in tasks_json[\"tasks_order\"]],\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
