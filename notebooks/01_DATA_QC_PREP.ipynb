{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_DATA_QC_PREP ‚Äî Quality Check y Splits Estratificados\n",
    "\n",
    "**Qu√© hace este notebook:**\n",
    "1. Carga y normaliza cada `driving_log.csv` de los recorridos seleccionados (`RUNS`).\n",
    "2. Normaliza rutas de im√°genes (soporta barras invertidas y recorta a `IMG/...`).\n",
    "3. Filtra filas sin im√°genes v√°lidas (`center/left/right`).\n",
    "4. Hace **split estratificado por bins de `steering`** (reproducible).\n",
    "5. Escribe:\n",
    "   - `data/processed/<run>/canonical.csv`\n",
    "   - `data/processed/<run>/{train,val,test}.csv`\n",
    "   - `data/processed/tasks.json`\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Preparar los *splits* `train/val/test` por recorrido\n",
    "- Generar `tasks.json` para el pipeline *continual*.\n",
    "\n",
    "## ‚úÖ Prerrequisitos\n",
    "- `data/raw/udacity/<run>/driving_log.csv`\n",
    "- Directorio `data/raw/udacity/<run>/IMG/` con las im√°genes.\n",
    "\n",
    "## ‚ö†Ô∏è Salidas\n",
    "- CSVs can√≥nicos y de split en `data/processed/<run>/`.\n",
    "- `tasks.json` apuntando a esos CSVs.\n",
    "\n",
    "> Si m√°s adelante quieres **balanceo offline** de `train` por bins, usa el notebook `01A_PREP_BALANCED.ipynb`.\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## üß≠ √çndice\n",
    "1. [Entorno y API de preparaci√≥n](#sec-01)\n",
    "2. [Par√°metros de la preparaci√≥n](#sec-02)\n",
    "3. [Ejecutar pipeline y verificar](#sec-03)\n",
    "4. [Resumen de rutas de splits (vista r√°pida)](#sec-04)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94aa62",
   "metadata": {},
   "source": [
    "## <a id=\"sec-01\"></a>\n",
    "\n",
    "## 1) Entorno y API de preparaci√≥n\n",
    "\n",
    "**Objetivo:** preparar el entorno y cargar la API de *prep*.\n",
    "\n",
    "- Detecta la ra√≠z del repo (`ROOT`) y la a√±ade a `sys.path`.\n",
    "- Importa funciones del m√≥dulo `src.prep.data_prep`:\n",
    "  - `PrepConfig` ‚Äî configuraci√≥n declarativa del *prep*.\n",
    "  - `run_prep` ‚Äî ejecuta la preparaci√≥n y genera splits + `tasks.json`.\n",
    "  - `verify_processed_splits` ‚Äî comprueba que los CSVs `train/val/test` existen por *run*.\n",
    "- Define rutas base:\n",
    "  - `RAW = data/raw/udacity`\n",
    "  - `PROC = data/processed`\n",
    "\n",
    "> Esta celda **no ejecuta** el *prep* a√∫n; s√≥lo deja listo el entorno.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %% setup & imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.prep.data_prep import PrepConfig, run_prep, verify_processed_splits\n",
    "RAW  = ROOT / \"data\" / \"raw\" / \"udacity\"\n",
    "PROC = ROOT / \"data\" / \"processed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80049984",
   "metadata": {},
   "source": [
    "<a id=\"sec-02\"></a>\n",
    "\n",
    "## 2) Par√°metros de la preparaci√≥n\n",
    "\n",
    "**Objetivo:** declarar los *runs* y la configuraci√≥n del *split*.\n",
    "\n",
    "- `RUNS`: lista de recorridos a procesar (ej. `[\"circuito1\", \"circuito2\"]`).\n",
    "- `use_left_right=False`: modo QC/split b√°sico, **sin** expansi√≥n de c√°maras.  \n",
    "  > Si quieres triplicar datos con *left/right* y correcci√≥n de `steer_shift`, usa `01A_PREP_BALANCED.ipynb` o cambia aqu√≠ a `True` (no recomendado en este notebook de QC).\n",
    "- `bins`: n¬∫ de contenedores para estratificar por `steering`.\n",
    "- `train/val`: proporciones del split (test se infiere).\n",
    "- `seed`: reproducibilidad del split.\n",
    "\n",
    "> `target_per_bin` y `cap_per_bin` **no se usan** en este notebook (se usan en el balanceo offline de `01A_PREP_BALANCED`).\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d8e4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrepConfig(root=PosixPath('/home/cesar/proyectos/TFM_SNN'), runs=['circuito1', 'circuito2'], use_left_right=False, steer_shift=0.2, bins=21, train=0.7, val=0.15, seed=42, target_per_bin=None, cap_per_bin=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Par√°metros de la preparaci√≥n\n",
    "RUNS = [\"circuito1\", \"circuito2\"]\n",
    "\n",
    "CFG = PrepConfig(\n",
    "    root=ROOT,\n",
    "    runs=RUNS,\n",
    "    use_left_right=False,  # QC + split b√°sico (sin expansi√≥n)\n",
    "    steer_shift=0.2,       # no aplica si use_left_right=False\n",
    "    bins=21,\n",
    "    train=0.70,\n",
    "    val=0.15,\n",
    "    seed=42,\n",
    "    target_per_bin=None,   # <- no balancea aqu√≠\n",
    "    cap_per_bin=None,\n",
    ")\n",
    "CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e5525",
   "metadata": {},
   "source": [
    "<a id=\"sec-03\"></a>\n",
    "\n",
    "## 3) Ejecutar *prep* y verificar\n",
    "\n",
    "**Objetivo:** correr el pipeline y validar que los *splits* existen.\n",
    "\n",
    "Acciones que realiza `run_prep(CFG)`:\n",
    "- Lee y normaliza `driving_log.csv` ‚Üí `canonical.csv`.\n",
    "- Genera *splits* estratificados: `train.csv`, `val.csv`, `test.csv`.\n",
    "- Construye/actualiza `data/processed/tasks.json` con la lista de *runs* y rutas a sus CSVs.\n",
    "\n",
    "Luego, `verify_processed_splits(PROC, RUNS)`:\n",
    "- Comprueba que `train/val/test.csv` existen para cada *run*.\n",
    "- Si falta algo, lanza una excepci√≥n con detalle.\n",
    "\n",
    "> **Idempotencia:** si vuelves a ejecutar esta celda, se regenerar√°n los CSVs y se actualizar√° `tasks.json` de forma consistente con lo que haya ahora en `RUNS`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12bc0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: /home/cesar/proyectos/TFM_SNN/data/processed/prep_manifest.json\n",
      "OK: splits 'train/val/test' encontrados.\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar prep + verificar\n",
    "manifest = run_prep(CFG)\n",
    "print(\"OK:\", PROC/\"prep_manifest.json\")\n",
    "\n",
    "# Verificaci√≥n: existen train/val/test por run\n",
    "verify_processed_splits(PROC, RUNS)\n",
    "print(\"OK: splits 'train/val/test' encontrados.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad3c0c",
   "metadata": {},
   "source": [
    "<a id=\"sec-04\"></a>\n",
    "\n",
    "## 4) Resumen de rutas de *splits* (vista r√°pida)\n",
    "\n",
    "**Objetivo:** visualizar de un vistazo qu√© ficheros usar√° el pipeline *continual*.\n",
    "\n",
    "- Lee `data/processed/tasks.json`.\n",
    "- Muestra una tabla con `run`, `train_csv`, `val_csv` y `test_csv`.\n",
    "\n",
    "> Si los paths no son los esperados, revisa la config de la celda 2 o el estado de `data/raw/udacity/<run>/`.\n",
    "\n",
    "[‚Üë Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f048e3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>train_csv</th>\n",
       "      <th>val_csv</th>\n",
       "      <th>test_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>circuito1</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>circuito2</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "      <td>/home/cesar/proyectos/TFM_SNN/data/processed/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         run                                          train_csv  \\\n",
       "0  circuito1  /home/cesar/proyectos/TFM_SNN/data/processed/c...   \n",
       "1  circuito2  /home/cesar/proyectos/TFM_SNN/data/processed/c...   \n",
       "\n",
       "                                             val_csv  \\\n",
       "0  /home/cesar/proyectos/TFM_SNN/data/processed/c...   \n",
       "1  /home/cesar/proyectos/TFM_SNN/data/processed/c...   \n",
       "\n",
       "                                            test_csv  \n",
       "0  /home/cesar/proyectos/TFM_SNN/data/processed/c...  \n",
       "1  /home/cesar/proyectos/TFM_SNN/data/processed/c...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resumen de rutas de splits (visualizaci√≥n)\n",
    "tasks_json = json.loads((PROC/\"tasks.json\").read_text(encoding=\"utf-8\"))\n",
    "pd.DataFrame({\n",
    "    \"run\": tasks_json[\"tasks_order\"],\n",
    "    \"train_csv\": [tasks_json[\"splits\"][r][\"train\"] for r in tasks_json[\"tasks_order\"]],\n",
    "    \"val_csv\":   [tasks_json[\"splits\"][r][\"val\"]   for r in tasks_json[\"tasks_order\"]],\n",
    "    \"test_csv\":  [tasks_json[\"splits\"][r][\"test\"]  for r in tasks_json[\"tasks_order\"]],\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
