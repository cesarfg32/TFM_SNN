{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f92b39",
   "metadata": {},
   "source": [
    "# 03 — Entrenamiento y Evaluación (SUPERVISED y CONTINUAL con EWC)\n",
    "\n",
    "Este notebook entrena un modelo SNN para **regresión de dirección (steering)** en:\n",
    "- **Supervised**: circuito1\n",
    "- **Continual**: `circuito1 → circuito2` con **EWC** (baseline)\n",
    "\n",
    "Asegúrate de haber ejecutado antes `01_DATA_QC_PREP.ipynb` para generar los splits y `tasks.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbefbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports y setup\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "# permite importar desde src/\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.utils import set_seeds, load_preset, make_loaders_from_csvs, ImageTransform\n",
    "from src.models import SNNVisionRegressor\n",
    "from src.training import TrainConfig, train_supervised, _permute_if_needed\n",
    "from src.methods.ewc import EWC, EWCConfig\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ROOT, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecciona preset\n",
    "preset = \"fast\"   # 'fast' | 'std' | 'accurate'\n",
    "cfg = load_preset(ROOT/\"configs\"/\"presets.yaml\", preset)\n",
    "print(\"Preset:\", cfg)\n",
    "\n",
    "# Transformación de imagen (ajusta a tus necesidades si cambias el preprocesado)\n",
    "tfm = ImageTransform(target_w=160, target_h=80, to_gray=True, crop_top=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rutas de datos\n",
    "RAW = ROOT/\"data\"/\"raw\"/\"udacity\"\n",
    "PROC = ROOT/\"data\"/\"processed\"\n",
    "\n",
    "# Comprobación rápida\n",
    "for run in [\"circuito1\",\"circuito2\"]:\n",
    "    for part in [\"train\",\"val\",\"test\"]:\n",
    "        path = PROC/run/f\"{part}.csv\"\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Falta {path}. Ejecuta 01_DATA_QC_PREP.ipynb primero.\")\n",
    "print(\"OK splits encontrados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === SUPERVISED: circuito1 ===\n",
    "set_seeds(42)\n",
    "train_loader, val_loader, test_loader = make_loaders_from_csvs(\n",
    "    base_dir=RAW/\"circuito1\",\n",
    "    train_csv=PROC/\"circuito1\"/\"train.csv\",\n",
    "    val_csv=PROC/\"circuito1\"/\"val.csv\",\n",
    "    test_csv=PROC/\"circuito1\"/\"test.csv\",\n",
    "    batch_size=cfg[\"batch_size\"],\n",
    "    encoder=cfg[\"encoder\"],   # 'rate' o 'latency'\n",
    "    T=cfg[\"T\"],\n",
    "    gain=cfg[\"gain\"],\n",
    "    tfm=tfm\n",
    ")\n",
    "\n",
    "model = SNNVisionRegressor(in_channels=1, lif_beta=0.95)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "tcfg = TrainConfig(epochs=cfg[\"epochs\"], batch_size=cfg[\"batch_size\"], lr=cfg[\"lr\"], amp=cfg[\"amp\"])\n",
    "\n",
    "out_dir = ROOT/\"outputs\"/f\"supervised_{preset}_ewc0\"\n",
    "print(\"Entrenando SUPERVISED...\")\n",
    "_ = train_supervised(model, train_loader, val_loader, loss_fn, tcfg, out_dir, method=None)\n",
    "print(\"OK:\", out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ee189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper para evaluar loaders asegurando la forma correcta (T,B,C,H,W)\n",
    "def eval_loader(loader, model, device):\n",
    "    mae_sum = mse_sum = 0.0\n",
    "    n = 0\n",
    "    for x, y in loader:\n",
    "        x = _permute_if_needed(x.to(device))  # (B,T,C,H,W) -> (T,B,C,H,W)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(x)\n",
    "        mae_sum += torch.mean(torch.abs(y_hat - y)).item() * len(y)\n",
    "        mse_sum += torch.mean((y_hat - y) ** 2).item() * len(y)\n",
    "        n += len(y)\n",
    "    return mae_sum / max(n, 1), mse_sum / max(n, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57718a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === CONTINUAL: circuito1 → circuito2 con EWC ===\n",
    "# Leemos tasks.json para el orden de tareas\n",
    "with open(PROC/\"tasks.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "task_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f895e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para crear loaders de una tarea dada\n",
    "def make_loader_fn(task, batch_size):\n",
    "    name = task[\"name\"]\n",
    "    base = RAW/name\n",
    "    paths = task[\"paths\"]\n",
    "    return make_loaders_from_csvs(\n",
    "        base_dir=base,\n",
    "        train_csv=Path(paths[\"train\"]),\n",
    "        val_csv=Path(paths[\"val\"]),\n",
    "        test_csv=Path(paths[\"test\"]),\n",
    "        batch_size=batch_size,\n",
    "        encoder=cfg[\"encoder\"],\n",
    "        T=cfg[\"T\"],\n",
    "        gain=cfg[\"gain\"],\n",
    "        tfm=tfm\n",
    "    )\n",
    "\n",
    "# Instanciamos modelo y EWC\n",
    "model2 = SNNVisionRegressor(in_channels=1, lif_beta=0.95)\n",
    "ewc = EWC(model2, EWCConfig(lambd=1e10, fisher_batches=25))\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "tcfg2 = TrainConfig(epochs=cfg[\"epochs\"], batch_size=cfg[\"batch_size\"], lr=cfg[\"lr\"], amp=cfg[\"amp\"])\n",
    "\n",
    "outc = ROOT/\"outputs\"/f\"continual_{preset}_ewc\"\n",
    "outc.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5fee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bucle continual con EWC (entrena tarea, estima Fisher, evalúa test y tareas pasadas)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "results = {}\n",
    "seen = []\n",
    "\n",
    "for i, t in enumerate(task_list):\n",
    "    name = t[\"name\"]\n",
    "    print(f\"Tarea {i+1}: {name}\")\n",
    "    tr, va, te = make_loader_fn(t, tcfg2.batch_size)\n",
    "    \n",
    "    # Entrena esta tarea con EWC (el penalty se aplica dentro de train_supervised)\n",
    "    _ = train_supervised(model2, tr, va, loss_fn, tcfg2, outc/f\"task_{i+1}_{name}\", method=ewc)\n",
    "    \n",
    "    # Estima Fisher sobre validación para consolidar esta tarea\n",
    "    print(\"Estimando Fisher...\")\n",
    "    ewc.estimate_fisher(va, loss_fn, device=device)\n",
    "    \n",
    "    # Eval post-tarea\n",
    "    te_mae, te_mse = eval_loader(te, model2, device)\n",
    "    results[name] = {\"test_mae\": te_mae, \"test_mse\": te_mse}\n",
    "    seen.append((name, te))\n",
    "    \n",
    "    # Evalúa tareas previas para medir olvido (BWT)\n",
    "    for pname, p_loader in seen[:-1]:\n",
    "        p_mae, p_mse = eval_loader(p_loader, model2, device)\n",
    "        results[pname][f\"after_{name}_mae\"] = p_mae\n",
    "        results[pname][f\"after_{name}_mse\"] = p_mse\n",
    "\n",
    "# Guarda resultados\n",
    "with open(outc/\"continual_results.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"OK:\", outc/\"continual_results.json\")\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
