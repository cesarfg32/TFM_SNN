{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9d8f4d",
   "metadata": {},
   "source": [
    "# 03 — Entrenamiento y Evaluación (SUPERVISED y CONTINUAL con EWC/NAIVE)\n",
    "\n",
    "Este notebook entrena un modelo **SNN** para **regresión del ángulo de dirección (steering)** en dos protocolos:\n",
    "\n",
    "- **Supervised** sobre `circuito1`.\n",
    "- **Continual** con dos tareas secuenciales `circuito1 → circuito2` usando:\n",
    "  - **EWC** (consolidación elástica de pesos), o\n",
    "  - **NAIVE** (baseline sin penalización; equivalente a λ=0).\n",
    "\n",
    "> **Requisitos previos**: Ejecuta `01_DATA_QC_PREP.ipynb` para generar `train/val/test.csv` y `tasks.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fb7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/cesar/proyectos/TFM_SNN'), device(type='cuda'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "# Detecta la raíz del repo (si estás dentro de notebooks/, sube un nivel)\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Utilidades y módulos del proyecto\n",
    "from src.utils import set_seeds, load_preset, make_loaders_from_csvs, ImageTransform\n",
    "from src.models import SNNVisionRegressor\n",
    "from src.training import TrainConfig, train_supervised, _permute_if_needed\n",
    "from src.methods.ewc import EWC, EWCConfig\n",
    "\n",
    "# Dispositivo (CUDA si disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ROOT, device\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0be0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preset: {'epochs': 2, 'batch_size': 8, 'T': 10, 'gain': 0.5, 'encoder': 'rate', 'lr': 0.001, 'amp': True}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Selecciona preset de ejecución\n",
    "#   - 'fast': corridas rápidas (sanity check)\n",
    "#   - 'std': equilibrio calidad/tiempo\n",
    "#   - 'accurate': más épocas/T (finales)\n",
    "# =============================================================================\n",
    "preset = \"fast\"   # 'fast' | 'std' | 'accurate'\n",
    "cfg = load_preset(ROOT/\"configs\"/\"presets.yaml\", preset)\n",
    "print(\"Preset:\", cfg)\n",
    "\n",
    "# Transformación de imagen\n",
    "# IMPORTANTE: usa argumentos **posicionales** (w, h, to_gray, crop_top)\n",
    "# Evita keywords tipo target_w/target_h porque la clase no los define.\n",
    "tfm = ImageTransform(160, 80, True, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5592e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK splits encontrados\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Verificación de datos\n",
    "# =============================================================================\n",
    "RAW = ROOT/\"data\"/\"raw\"/\"udacity\"\n",
    "PROC = ROOT/\"data\"/\"processed\"\n",
    "\n",
    "# Comprueba que existen los CSV por split de cada circuito\n",
    "for run in [\"circuito1\",\"circuito2\"]:\n",
    "    for part in [\"train\",\"val\",\"test\"]:\n",
    "        path = PROC/run/f\"{part}.csv\"\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Falta {path}. Ejecuta 01_DATA_QC_PREP.ipynb primero.\")\n",
    "print(\"OK splits encontrados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c0475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando SUPERVISED...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 437/437 [00:07<00:00, 58.63it/s, loss=0.00615] \n",
      "Epoch 2/2: 100%|██████████| 437/437 [00:09<00:00, 45.93it/s, loss=0.0121]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/supervised_fast_ewc0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SUPERVISED: entrenamiento en circuito1\n",
    "# =============================================================================\n",
    "set_seeds(SEED)  # reproducibilidad\n",
    "\n",
    "# DataLoaders con codificación temporal on-the-fly (cfg['encoder'], T, gain)\n",
    "train_loader, val_loader, test_loader = make_loaders_from_csvs(\n",
    "    base_dir=RAW/\"circuito1\",\n",
    "    train_csv=PROC/\"circuito1\"/\"train.csv\",\n",
    "    val_csv=PROC/\"circuito1\"/\"val.csv\",\n",
    "    test_csv=PROC/\"circuito1\"/\"test.csv\",\n",
    "    batch_size=cfg[\"batch_size\"],\n",
    "    encoder=cfg[\"encoder\"],   # 'rate' | 'latency' | 'raw'\n",
    "    T=cfg[\"T\"],\n",
    "    gain=cfg[\"gain\"],\n",
    "    tfm=tfm,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Modelo SNN (1 canal → gris), pérdida y configuración de entrenamiento\n",
    "model = SNNVisionRegressor(in_channels=1, lif_beta=0.95)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "tcfg = TrainConfig(epochs=cfg[\"epochs\"], batch_size=cfg[\"batch_size\"], lr=cfg[\"lr\"], amp=cfg[\"amp\"])\n",
    "\n",
    "# Carpeta de salida para supervised\n",
    "out_dir = ROOT/\"outputs\"/f\"supervised_{preset}_ewc0\"\n",
    "print(\"Entrenando SUPERVISED...\")\n",
    "_ = train_supervised(model, train_loader, val_loader, loss_fn, tcfg, out_dir, method=None)\n",
    "print(\"OK:\", out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173dd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper de evaluación (asegura forma correcta (T,B,C,H,W) antes del modelo)\n",
    "# =============================================================================\n",
    "def eval_loader(loader, model, device):\n",
    "    \"\"\"Calcula MAE/MSE promediados sobre todo el loader.\n",
    "\n",
    "    - El DataLoader produce (B, T, C, H, W)\n",
    "\n",
    "    - El modelo espera (T, B, C, H, W)\n",
    "\n",
    "    \"\"\"\n",
    "    mae_sum = mse_sum = 0.0\n",
    "    n = 0\n",
    "    for x, y in loader:\n",
    "        # (B,T,C,H,W) -> (T,B,C,H,W) si aplica\n",
    "        x = _permute_if_needed(x.to(device))\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(x)\n",
    "        mae_sum += torch.mean(torch.abs(y_hat - y)).item() * len(y)\n",
    "        mse_sum += torch.mean((y_hat - y) ** 2).item() * len(y)\n",
    "        n += len(y)\n",
    "    return mae_sum / max(n, 1), mse_sum / max(n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf988a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'circuito1',\n",
       "  'paths': {'train': '/home/cesar/proyectos/TFM_SNN/data/processed/circuito1/train.csv',\n",
       "   'val': '/home/cesar/proyectos/TFM_SNN/data/processed/circuito1/val.csv',\n",
       "   'test': '/home/cesar/proyectos/TFM_SNN/data/processed/circuito1/test.csv'}},\n",
       " {'name': 'circuito2',\n",
       "  'paths': {'train': '/home/cesar/proyectos/TFM_SNN/data/processed/circuito2/train.csv',\n",
       "   'val': '/home/cesar/proyectos/TFM_SNN/data/processed/circuito2/val.csv',\n",
       "   'test': '/home/cesar/proyectos/TFM_SNN/data/processed/circuito2/test.csv'}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cargar orden de tareas (continual) desde tasks.json\n",
    "# =============================================================================\n",
    "with open(PROC/\"tasks.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "# task_list = [{'name': 'circuito1', 'paths': {...}}, {'name': 'circuito2', 'paths': {...}}]\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d4fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Función para crear loaders de una tarea dada (respeta cfg del preset)\n",
    "# =============================================================================\n",
    "def make_loader_fn(task, batch_size, seed):\n",
    "    name = task[\"name\"]\n",
    "    base = RAW/name\n",
    "    paths = task[\"paths\"]\n",
    "    return make_loaders_from_csvs(\n",
    "        base_dir=base,\n",
    "        train_csv=Path(paths[\"train\"]),\n",
    "        val_csv=Path(paths[\"val\"]),\n",
    "        test_csv=Path(paths[\"test\"]),\n",
    "        batch_size=batch_size,\n",
    "        encoder=cfg[\"encoder\"],\n",
    "        T=cfg[\"T\"],\n",
    "        gain=cfg[\"gain\"],\n",
    "        tfm=tfm,\n",
    "        seed=seed,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c456523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Método: naive | λ: 0.0 | tag: fast_naive_rate\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Toggle del método a ejecutar: 'ewc' o 'naive'\n",
    "#   - EWC: usa lambda > 0 (p.ej., 1e10)\n",
    "#   - NAIVE: lambda = 0 (sin penalización)\n",
    "# =============================================================================\n",
    "METHOD = \"ewc\"   # \"ewc\" | \"naive\"\n",
    "EWC_LAMBDA = 1e11 if METHOD == \"ewc\" else 0.0\n",
    "\n",
    "# Siembra global para que NAIVE y EWC arranquen igual\n",
    "set_seeds(SEED)\n",
    "\n",
    "# Etiqueta de salida única para no pisar resultados previos\n",
    "RUN_TAG = f\"{preset}_{METHOD}\" + (f\"_lam_{EWC_LAMBDA:.0e}\" if METHOD==\"ewc\" else \"\")\n",
    "RUN_TAG += f\"_{cfg['encoder']}\"\n",
    "RUN_TAG += f\"_seed_{SEED}\"\n",
    "\n",
    "print(\"Método:\", METHOD, \"| λ:\", EWC_LAMBDA, \"| tag:\", RUN_TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cecef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/cesar/proyectos/TFM_SNN/outputs/continual_fast_naive_rate')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Instanciación del modelo, método y carpeta de salida\n",
    "# =============================================================================\n",
    "model2 = SNNVisionRegressor(in_channels=1, lif_beta=0.95)\n",
    "ewc = EWC(model2, EWCConfig(lambd=float(EWC_LAMBDA), fisher_batches=25))\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "tcfg2 = TrainConfig(epochs=cfg[\"epochs\"], batch_size=cfg[\"batch_size\"], lr=cfg[\"lr\"], amp=cfg[\"amp\"])\n",
    "\n",
    "outc = ROOT / \"outputs\" / f\"continual_{RUN_TAG}\"\n",
    "outc.mkdir(parents=True, exist_ok=True)\n",
    "outc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a6e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1: circuito1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 437/437 [00:07<00:00, 54.84it/s, loss=0.0729]  \n",
      "Epoch 2/2: 100%|██████████| 437/437 [00:07<00:00, 57.18it/s, loss=4.11e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 2: circuito2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 129/129 [00:02<00:00, 56.95it/s, loss=0.0485]\n",
      "Epoch 2/2: 100%|██████████| 129/129 [00:02<00:00, 47.99it/s, loss=0.0381] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_naive_rate/continual_results.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'circuito1': {'test_mae': 0.06532558528406004,\n",
       "  'test_mse': 0.019158605222068588,\n",
       "  'after_circuito2_mae': 0.1160996605552012,\n",
       "  'after_circuito2_mse': 0.020342665440302783},\n",
       " 'circuito2': {'test_mae': 0.1860753110552256,\n",
       "  'test_mse': 0.06933023987453332}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Bucle continual: circuito1 -> circuito2 (entrenar, consolidar si EWC, evaluar)\n",
    "# =============================================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "results = {}\n",
    "seen = []\n",
    "\n",
    "for i, t in enumerate(task_list):\n",
    "    name = t[\"name\"]\n",
    "    print(f\"Tarea {i+1}: {name}\")\n",
    "    tr, va, te = make_loader_fn(t, tcfg2.batch_size, seed=SEED)\n",
    "\n",
    "    # Entrenamiento de la tarea actual (aplica penalty solo si METHOD == 'ewc')\n",
    "    _ = train_supervised(\n",
    "        model2, tr, va, loss_fn, tcfg2,\n",
    "        outc/f\"task_{i+1}_{name}\",\n",
    "        method=ewc if METHOD == \"ewc\" else None\n",
    "    )\n",
    "\n",
    "    # Consolidación por Fisher (solo EWC)\n",
    "    if METHOD == \"ewc\":\n",
    "        print(\"Estimando Fisher...\")\n",
    "        ewc.estimate_fisher(va, loss_fn, device=device)\n",
    "\n",
    "    # Evaluación post-tarea en su test\n",
    "    te_mae, te_mse = eval_loader(te, model2, device)\n",
    "    results[name] = {\"test_mae\": te_mae, \"test_mse\": te_mse}\n",
    "    seen.append((name, te))\n",
    "\n",
    "    # Evaluación de tareas previas para medir olvido (BWT)\n",
    "    for pname, p_loader in seen[:-1]:\n",
    "        p_mae, p_mse = eval_loader(p_loader, model2, device)\n",
    "        results[pname][f\"after_{name}_mae\"] = p_mae\n",
    "        results[pname][f\"after_{name}_mse\"] = p_mse\n",
    "\n",
    "# Guarda resultados del continual\n",
    "with open(outc/\"continual_results.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"OK:\", outc/\"continual_results.json\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9835a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>preset</th>\n",
       "      <th>method</th>\n",
       "      <th>lambda</th>\n",
       "      <th>encoder</th>\n",
       "      <th>c1_mae</th>\n",
       "      <th>c1_after_c2_mae</th>\n",
       "      <th>c1_forgetting_mae_abs</th>\n",
       "      <th>c1_forgetting_mae_rel_%</th>\n",
       "      <th>c2_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continual_fast_ewc_lam_1e+09_rate</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+09</td>\n",
       "      <td>rate</td>\n",
       "      <td>0.080127</td>\n",
       "      <td>0.080117</td>\n",
       "      <td>-9.480523e-06</td>\n",
       "      <td>-0.011832</td>\n",
       "      <td>0.179358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continual_fast_ewc_lam_1e+10_rate</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+10</td>\n",
       "      <td>rate</td>\n",
       "      <td>0.082520</td>\n",
       "      <td>0.082522</td>\n",
       "      <td>1.299926e-06</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.178743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continual_fast_ewc_lam_1e+11_rate</td>\n",
       "      <td>fast</td>\n",
       "      <td>ewc</td>\n",
       "      <td>1e+11</td>\n",
       "      <td>rate</td>\n",
       "      <td>0.082494</td>\n",
       "      <td>0.082493</td>\n",
       "      <td>-3.586093e-07</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>0.178792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>continual_fast_naive_rate</td>\n",
       "      <td>fast</td>\n",
       "      <td>naive</td>\n",
       "      <td>None</td>\n",
       "      <td>rate</td>\n",
       "      <td>0.105127</td>\n",
       "      <td>0.090398</td>\n",
       "      <td>-1.472912e-02</td>\n",
       "      <td>-14.010812</td>\n",
       "      <td>0.183966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 exp preset method lambda encoder    c1_mae  \\\n",
       "0  continual_fast_ewc_lam_1e+09_rate   fast    ewc  1e+09    rate  0.080127   \n",
       "1  continual_fast_ewc_lam_1e+10_rate   fast    ewc  1e+10    rate  0.082520   \n",
       "2  continual_fast_ewc_lam_1e+11_rate   fast    ewc  1e+11    rate  0.082494   \n",
       "3          continual_fast_naive_rate   fast  naive   None    rate  0.105127   \n",
       "\n",
       "   c1_after_c2_mae  c1_forgetting_mae_abs  c1_forgetting_mae_rel_%    c2_mae  \n",
       "0         0.080117          -9.480523e-06                -0.011832  0.179358  \n",
       "1         0.082522           1.299926e-06                 0.001575  0.178743  \n",
       "2         0.082493          -3.586093e-07                -0.000435  0.178792  \n",
       "3         0.090398          -1.472912e-02               -14.010812  0.183966  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# (Opcional) Resumen comparativo de todos los continual_* en outputs/\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import json, re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_exp_name(name: str):\n",
    "    \"\"\"Extrae preset, método, lambda y encoder desde el nombre de carpeta de salida.\"\"\"\n",
    "    m = re.match(r\"continual_(?P<preset>\\w+)_(?P<method>ewc|naive)(?:_lam_(?P<lambda>[^_]+))?_(?P<enc>\\w+)\", name)\n",
    "    if not m:\n",
    "        return {\"preset\": None, \"method\": None, \"lambda\": None, \"encoder\": None}\n",
    "    d = m.groupdict()\n",
    "    return {\"preset\": d[\"preset\"], \"method\": d[\"method\"], \"lambda\": d.get(\"lambda\"), \"encoder\": d[\"enc\"]}\n",
    "\n",
    "rows = []\n",
    "for d in sorted((ROOT/\"outputs\").glob(\"continual_*\")):\n",
    "    f = d/\"continual_results.json\"\n",
    "    if not f.exists():\n",
    "        continue\n",
    "    meta = parse_exp_name(d.name)\n",
    "    res = json.loads(f.read_text())\n",
    "\n",
    "    c1_mae = res[\"circuito1\"][\"test_mae\"]\n",
    "    c1_after = res[\"circuito1\"].get(\"after_circuito2_mae\")\n",
    "    c1_forget = None if c1_after is None else (c1_after - c1_mae)\n",
    "    c1_forget_rel = None if (c1_after is None or c1_mae == 0) else (c1_forget / c1_mae * 100.0)\n",
    "\n",
    "    c2_mae = res[\"circuito2\"][\"test_mae\"]\n",
    "\n",
    "    rows.append({\n",
    "        \"exp\": d.name, **meta,\n",
    "        \"c1_mae\": c1_mae,\n",
    "        \"c1_after_c2_mae\": c1_after,\n",
    "        \"c1_forgetting_mae_abs\": c1_forget,\n",
    "        \"c1_forgetting_mae_rel_%\": c1_forget_rel,\n",
    "        \"c2_mae\": c2_mae\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values([\"preset\",\"encoder\",\"method\",\"lambda\"], na_position=\"last\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
