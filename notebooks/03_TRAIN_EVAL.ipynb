{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9d8f4d",
   "metadata": {},
   "source": [
    "# 03 — Entrenamiento y Evaluación (SUPERVISED y CONTINUAL con EWC/NAIVE)\n",
    "\n",
    "Este notebook entrena un modelo **SNN** para **regresión del ángulo de dirección (steering)** en dos protocolos:\n",
    "\n",
    "- **Supervised** sobre `circuito1`.\n",
    "- **Continual** con dos tareas secuenciales `circuito1 → circuito2` usando:\n",
    "  - **EWC** (consolidación elástica de pesos), o\n",
    "  - **NAIVE** (baseline sin penalización; equivalente a λ=0).\n",
    "\n",
    "> **Requisitos previos**: Ejecuta `01_DATA_QC_PREP.ipynb` para generar `train/val/test.csv` y `tasks.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6fb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports y setup\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import sys, json, torch\n",
    "\n",
    "# Detecta la raíz del repo (si estás dentro de notebooks/, sube un nivel)\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Utilidades y módulos del proyecto\n",
    "from src.datasets import AugmentConfig\n",
    "from src.utils import set_seeds, load_preset, make_loaders_from_csvs, ImageTransform\n",
    "from src.models import SNNVisionRegressor\n",
    "from src.training import TrainConfig, train_supervised, _permute_if_needed\n",
    "from src.methods.ewc import EWC, EWCConfig\n",
    "\n",
    "# Dispositivo (CUDA si disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ROOT, device\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Transformación de imagen\n",
    "# IMPORTANTE: usa argumentos **posicionales** (w, h, to_gray, crop_top)\n",
    "# Evita keywords tipo target_w/target_h porque la clase no los define.\n",
    "tfm = ImageTransform(160, 80, True, None)\n",
    "\n",
    "def make_snn_model(tfm):\n",
    "    # C = 1 si gris, 3 si color\n",
    "    return SNNVisionRegressor(in_channels=(1 if tfm.to_gray else 3), lif_beta=0.95)\n",
    "\n",
    "torch.set_num_threads(4)               # evita sobre-contención de CPU al decodificar\n",
    "torch.backends.cudnn.benchmark = True  # selecciona la mejor impl. de convs para tamaño fijo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0be0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAFE_MODE=False] workers=4 prefetch=4 pin=False persistent=False\n"
     ]
    }
   ],
   "source": [
    "# --- SAFE MODE: desactiva todo lo pesado para estabilizar ---\n",
    "SAFE_MODE = False  # o False cuando quieras rendimiento\n",
    "\n",
    "NUM_WORKERS   = 4\n",
    "PREFETCH      = 4\n",
    "PIN_MEMORY    = False\n",
    "PERSISTENT    = False\n",
    "\n",
    "# AUG_CFG = None\n",
    "from src.datasets import AugmentConfig\n",
    "# --- Augment: perfiles ---\n",
    "AUG_CFG_LIGHT = AugmentConfig(prob_hflip=0.5, brightness=None, gamma=None, noise_std=0.0)\n",
    "AUG_CFG_FULL  = AugmentConfig(prob_hflip=0.5, brightness=(0.9, 1.1), gamma=(0.95, 1.05), noise_std=0.005)\n",
    "\n",
    "AUG_CFG = AUG_CFG_LIGHT   # ← usa LIGHT ahora; luego prueba FULL\n",
    "\n",
    "USE_OFFLINE_BALANCED  = True\n",
    "USE_ONLINE_BALANCING  = False\n",
    "\n",
    "if SAFE_MODE:\n",
    "    NUM_WORKERS  = 0\n",
    "    PREFETCH     = None   # ← IMPORTANTÍSIMO con num_workers=0\n",
    "    PIN_MEMORY   = False\n",
    "    PERSISTENT   = False  # ← también obligatorio con num_workers=0\n",
    "    USE_OFFLINE_BALANCED = False\n",
    "    USE_ONLINE_BALANCING = False\n",
    "    AUG_CFG = None\n",
    "\n",
    "print(f\"[SAFE_MODE={SAFE_MODE}] workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "      f\"pin={PIN_MEMORY} persistent={PERSISTENT}\")\n",
    "\n",
    "RUN_BENCH = False   # pon True para ejecutar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5592e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ /home/cesar/proyectos/TFM_SNN/data/processed/circuito1/train_balanced.csv OK\n",
      "✓ /home/cesar/proyectos/TFM_SNN/data/processed/circuito2/train_balanced.csv OK\n",
      "OK: splits 'train/val/test' encontrados.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Verificación de datos (normal y, si existe, balanceado offline)\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "RAW  = ROOT/\"data\"/\"raw\"/\"udacity\"\n",
    "PROC = ROOT/\"data\"/\"processed\"\n",
    "\n",
    "RUNS = [\"circuito1\",\"circuito2\"]  # ajusta si hace falta\n",
    "\n",
    "missing = []\n",
    "for run in RUNS:\n",
    "    base = PROC / run\n",
    "\n",
    "    # Comprobación obligatoria: splits normales\n",
    "    for part in [\"train\",\"val\",\"test\"]:\n",
    "        p = base / f\"{part}.csv\"\n",
    "        if not p.exists():\n",
    "            missing.append(str(p))\n",
    "\n",
    "    # Comprobación opcional: train_balanced.csv (para modo OFFLINE balanceado)\n",
    "    p_bal = base / \"train_balanced.csv\"\n",
    "    if p_bal.exists():\n",
    "        print(f\"✓ {p_bal} OK\")\n",
    "    else:\n",
    "        print(f\"⚠️  Falta {p_bal}. Si más abajo pones USE_OFFLINE_BALANCED=True, \"\n",
    "              f\"ejecuta 01A_PREP_BALANCED.ipynb o el script tools/make_splits_balanced.py\")\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Faltan CSV obligatorios (ejecuta 01A_PREP_BALANCED.ipynb o tu pipeline de prep):\\n\"\n",
    "        + \"\\n\".join(\" - \" + m for m in missing)\n",
    "    )\n",
    "\n",
    "print(\"OK: splits 'train/val/test' encontrados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e27aff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo balanceo: OFFLINE (tasks_balanced.json) | Balanceo ONLINE: False\n"
     ]
    }
   ],
   "source": [
    "# ===================== Balanceo: helper =====================\n",
    "print(\n",
    "    \"Modo balanceo:\",\n",
    "    \"OFFLINE (tasks_balanced.json)\" if USE_OFFLINE_BALANCED else \"ORIGINAL (tasks.json)\",\n",
    "    \"| Balanceo ONLINE:\", USE_ONLINE_BALANCING\n",
    ")\n",
    "\n",
    "# Seguridad anti doble balanceo:\n",
    "if USE_OFFLINE_BALANCED and USE_ONLINE_BALANCING:\n",
    "    raise RuntimeError(\"Doble balanceo detectado: OFFLINE y ONLINE a la vez. \"\n",
    "                       \"Pon USE_ONLINE_BALANCING=False cuando uses train_balanced.csv.\")\n",
    "\n",
    "from pathlib import Path  # (omite esta línea si ya importaste Path arriba)\n",
    "\n",
    "def _balance_flag(train_csv_path: str | Path) -> bool:\n",
    "    \"\"\"\n",
    "    Activa balanceo ONLINE solo si:\n",
    "    - USE_ONLINE_BALANCING == True\n",
    "    - Y el CSV de train NO es 'train_balanced.csv'\n",
    "    \"\"\"\n",
    "    is_balanced_csv = Path(train_csv_path).name == \"train_balanced.csv\"\n",
    "    return bool(USE_ONLINE_BALANCING and not is_balanced_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fee3eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaders] workers=4 prefetch=4 pin=False persistent=False offline_bal=True online_bal=False\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Función para crear loaders de una tarea dada (respeta cfg del preset)\n",
    "# =============================================================================\n",
    "def make_loader_fn(task, batch_size, encoder, T, gain, tfm, seed,\n",
    "                   num_workers=NUM_WORKERS, prefetch_factor=PREFETCH,\n",
    "                   pin_memory=PIN_MEMORY, persistent_workers=PERSISTENT):\n",
    "    from pathlib import Path\n",
    "    name  = task[\"name\"]\n",
    "    paths = task[\"paths\"]\n",
    "\n",
    "    pw = persistent_workers and (num_workers > 0)\n",
    "    pf = prefetch_factor if (num_workers > 0) else None\n",
    "\n",
    "    return make_loaders_from_csvs(\n",
    "        base_dir=RAW/name,\n",
    "        train_csv=Path(paths[\"train\"]),\n",
    "        val_csv=Path(paths[\"val\"]),\n",
    "        test_csv=Path(paths[\"test\"]),\n",
    "        batch_size=batch_size,\n",
    "        encoder=encoder,\n",
    "        T=T,\n",
    "        gain=gain,\n",
    "        tfm=tfm,\n",
    "        seed=seed,\n",
    "        # ---- Parche estabilidad WSL ----\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        persistent_workers=pw,\n",
    "        prefetch_factor=pf,\n",
    "        aug_train=AUG_CFG,\n",
    "        balance_train=_balance_flag(paths[\"train\"]),\n",
    "        balance_bins=21,\n",
    "    )\n",
    "\n",
    "print(f\"[Loaders] workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "      f\"pin={PIN_MEMORY} persistent={PERSISTENT} \"\n",
    "      f\"offline_bal={USE_OFFLINE_BALANCED} online_bal={USE_ONLINE_BALANCING}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173dd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import _permute_if_needed  # importa el helper del modelo\n",
    "\n",
    "# =============================================================================\n",
    "# Helper de evaluación (permuta a (T,B,C,H,W) y usa copias no bloqueantes)\n",
    "# =============================================================================\n",
    "def eval_loader(loader, model, device):\n",
    "    \"\"\"Calcula MAE/MSE promediados sobre todo el loader.\n",
    "\n",
    "    - El DataLoader produce (B, T, C, H, W)\n",
    "    - El modelo espera      (T, B, C, H, W)\n",
    "    \"\"\"\n",
    "    model.eval()  # modo evaluación: desactiva dropout/batchnorm, etc.\n",
    "    mae_sum = 0.0\n",
    "    mse_sum = 0.0\n",
    "    n = 0\n",
    "\n",
    "    # Un solo no_grad() fuera del bucle para minimizar overhead\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            # (B,T,C,H,W) -> (T,B,C,H,W), y luego a GPU con non_blocking=True\n",
    "            x = _permute_if_needed(x).to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            y_hat = model(x)\n",
    "\n",
    "            # Acumula MAE/MSE ponderados por el tamaño real del batch\n",
    "            mae_sum += torch.mean(torch.abs(y_hat - y)).item() * len(y)\n",
    "            mse_sum += torch.mean((y_hat - y) ** 2).item() * len(y)\n",
    "            n += len(y)\n",
    "\n",
    "    return (mae_sum / max(n, 1)), (mse_sum / max(n, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf988a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tareas y su TRAIN CSV:\n",
      " - circuito1: train_balanced.csv\n",
      " - circuito2: train_balanced.csv\n",
      "✔ Verificación OFFLINE balanceado superada (train_balanced.csv por tarea).\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Elegir split: normal (tasks.json) o balanceado offline (tasks_balanced.json)\n",
    "# =============================================================================\n",
    "with open(PROC / (\"tasks_balanced.json\" if USE_OFFLINE_BALANCED else \"tasks.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks_json = json.load(f)\n",
    "\n",
    "task_list = [{\"name\": n, \"paths\": tasks_json[\"splits\"][n]} for n in tasks_json[\"tasks_order\"]]\n",
    "\n",
    "# Vista rápida: muestra el CSV de train que se usará por cada tarea\n",
    "print(\"Tareas y su TRAIN CSV:\")\n",
    "for t in task_list:\n",
    "    print(f\" - {t['name']}: {Path(t['paths']['train']).name}\")\n",
    "\n",
    "task_list[:2]  # vista rápida\n",
    "\n",
    "# Guardarraíl extra: si has activado el OFFLINE balanceado,\n",
    "# exige que el 'train' sea train_balanced.csv y que exista.\n",
    "if USE_OFFLINE_BALANCED:\n",
    "    for t in task_list:\n",
    "        train_path = Path(t[\"paths\"][\"train\"])\n",
    "        if train_path.name != \"train_balanced.csv\":\n",
    "            raise RuntimeError(\n",
    "                f\"[{t['name']}] Esperaba 'train_balanced.csv' pero encontré '{train_path.name}'. \"\n",
    "                \"Repite 01A_PREP_BALANCED.ipynb o ajusta USE_OFFLINE_BALANCED=False.\"\n",
    "            )\n",
    "        if not train_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"[{t['name']}] No existe {train_path}. Genera los balanceados con 01A_PREP_BALANCED.ipynb.\"\n",
    "            )\n",
    "    print(\"✔ Verificación OFFLINE balanceado superada (train_balanced.csv por tarea).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a3a229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bench RUN_BENCH=False] workers=4 prefetch=4 pin=False persistent=False | offline_bal=True online_bal=False\n"
     ]
    }
   ],
   "source": [
    "# ===================== BENCH: toggle y eco de configuración =====================\n",
    "# Usa el RUN_BENCH que ya defines en la Celda 2\n",
    "print(\n",
    "    f\"[Bench RUN_BENCH={RUN_BENCH}] workers={NUM_WORKERS} prefetch={PREFETCH} \"\n",
    "    f\"pin={PIN_MEMORY} persistent={PERSISTENT} \"\n",
    "    f\"| offline_bal={USE_OFFLINE_BALANCED} online_bal={USE_ONLINE_BALANCING}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca499849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== BENCH: utilidades (no pisa tus helpers) =====================\n",
    "import time, torch\n",
    "from time import perf_counter\n",
    "from contextlib import nullcontext\n",
    "from pathlib import Path\n",
    "\n",
    "def _bench_smoke_loader(task, bs, encoder, T, gain, tfm, seed):\n",
    "    \"\"\"Crea loader pequeño y mide el primer batch.\"\"\"\n",
    "    tr, va, te = make_loader_fn(\n",
    "        task=task, batch_size=bs, encoder=encoder, T=T, gain=gain, tfm=tfm, seed=seed,\n",
    "        num_workers=NUM_WORKERS, prefetch_factor=PREFETCH,\n",
    "        pin_memory=PIN_MEMORY, persistent_workers=PERSISTENT\n",
    "    )\n",
    "    t0 = perf_counter()\n",
    "    _ = next(iter(tr))\n",
    "    dt = perf_counter() - t0\n",
    "    return tr, va, te, dt\n",
    "\n",
    "def _bench_forward_once(model, xb, use_amp=True):\n",
    "    \"\"\"Mide un forward único (ms). xb: (T,B,C,H,W) ya en device.\"\"\"\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "    ctx = torch.amp.autocast('cuda', enabled=use_amp) if torch.cuda.is_available() else nullcontext()\n",
    "    with torch.inference_mode(), ctx:\n",
    "        _ = model(xb)\n",
    "    torch.cuda.synchronize()\n",
    "    return (time.perf_counter() - t0) * 1000.0\n",
    "\n",
    "def _bench_loop_gpu_only(model, xb, iters=100, use_amp=True):\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "    ctx = torch.amp.autocast('cuda', enabled=use_amp) if torch.cuda.is_available() else nullcontext()\n",
    "    with torch.inference_mode(), ctx:\n",
    "        for _ in range(iters):\n",
    "            _ = model(xb)\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.perf_counter()\n",
    "    return iters / (t1 - t0)\n",
    "\n",
    "def _bench_pipeline_loader_model(model, tr, iters=100, use_amp=True, device=None):\n",
    "    it_tr = iter(tr)\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "    ctx = torch.amp.autocast('cuda', enabled=use_amp) if torch.cuda.is_available() else nullcontext()\n",
    "    with torch.inference_mode(), ctx:\n",
    "        for _ in range(iters):\n",
    "            try:\n",
    "                xb, yb = next(it_tr)\n",
    "            except StopIteration:\n",
    "                it_tr = iter(tr)\n",
    "                xb, yb = next(it_tr)\n",
    "            xb = xb.permute(1,0,2,3,4).contiguous().to(device, non_blocking=True)\n",
    "            _ = model(xb)\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.perf_counter()\n",
    "    return iters / (t1 - t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78c34c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bench desactivado]\n"
     ]
    }
   ],
   "source": [
    "# ===================== BENCH: ejecución unificada =====================\n",
    "if not RUN_BENCH:\n",
    "    print(\"[Bench desactivado]\")\n",
    "else:\n",
    "    from src.utils import load_preset\n",
    "\n",
    "    # --- preset y tarea de referencia (como en tu entrenamiento) ---\n",
    "    task0 = task_list[0]\n",
    "    preset_name = \"std\"  # cambia a \"fast\" si quieres medir ese preset\n",
    "    cfgp = load_preset(ROOT/\"configs\"/\"presets.yaml\", preset_name)\n",
    "\n",
    "    B = int(cfgp[\"batch_size\"])\n",
    "    T = int(cfgp[\"T\"])\n",
    "    GAIN = float(cfgp[\"gain\"])\n",
    "    ENCODER = cfgp[\"encoder\"]\n",
    "    USE_AMP = bool(cfgp[\"amp\"])\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # --- 1) Smoke test del loader (batch mini) ---\n",
    "    tr_mini, _, _, t_first = _bench_smoke_loader(task0, bs=4, encoder=ENCODER, T=5, gain=0.5, tfm=tfm, seed=SEED)\n",
    "    print(f\"Primer batch pequeño: {t_first:.3f}s\")\n",
    "\n",
    "    # --- 2) Loader real de preset + modelo (usa tu helper make_snn_model) ---\n",
    "    tr_big, _, _ = make_loader_fn(\n",
    "        task=task0, batch_size=B, encoder=ENCODER, T=T, gain=GAIN, tfm=tfm, seed=SEED,\n",
    "        num_workers=NUM_WORKERS, prefetch_factor=PREFETCH,\n",
    "        pin_memory=PIN_MEMORY, persistent_workers=PERSISTENT\n",
    "    )\n",
    "    xb, yb = next(iter(tr_big))                         # (B,T,C,H,W)\n",
    "    xb = xb.permute(1,0,2,3,4).contiguous().to(device, non_blocking=True)\n",
    "\n",
    "    model = make_snn_model(tfm).to(device).eval()\n",
    "\n",
    "    # --- 3) Forward único (ms) ---\n",
    "    ms = _bench_forward_once(model, xb, use_amp=USE_AMP)\n",
    "    print(f\"Preset {preset_name} | B={B}, T={T}, AMP={USE_AMP} | Forward 1x: {ms:.1f} ms\")\n",
    "\n",
    "    # --- 4) GPU-only it/s (techo computacional) ---\n",
    "    its_gpu = _bench_loop_gpu_only(model, xb, iters=100, use_amp=USE_AMP)\n",
    "    print(f\"[GPU-only] 100 iters -> {its_gpu:.1f} it/s\")\n",
    "\n",
    "    # --- 5) Loader+modelo it/s (pipeline real) ---\n",
    "    its_pipe = _bench_pipeline_loader_model(model, tr_big, iters=100, use_amp=USE_AMP, device=device)\n",
    "    print(f\"[Loader+modelo] 100 iters -> {its_pipe:.1f} it/s\")\n",
    "\n",
    "    # --- 6) Grid corto de (workers, prefetch) para tu preset real ---\n",
    "    combos = [(4,2), (4,4), (6,2), (6,4), (8,2), (8,4), (12,2)]\n",
    "    print(\"\\nGrid (workers, prefetch):\")\n",
    "    best = None\n",
    "    for nw, pf in combos:\n",
    "        tr_try, _, _ = make_loader_fn(\n",
    "            task=task0, batch_size=B, encoder=ENCODER, T=T, gain=GAIN, tfm=tfm, seed=SEED,\n",
    "            num_workers=nw, prefetch_factor=pf, pin_memory=PIN_MEMORY, persistent_workers=PERSISTENT\n",
    "        )\n",
    "        ips = _bench_pipeline_loader_model(model, tr_try, iters=80, use_amp=USE_AMP, device=device)\n",
    "        print(f\"  nw={nw:>2} pf={pf:>2} -> {ips:5.1f} it/s\")\n",
    "        if best is None or ips > best[2]:\n",
    "            best = (nw, pf, ips)\n",
    "\n",
    "    if best:\n",
    "        print(f\"\\nMejor combinación observada: workers={best[0]} prefetch={best[1]} -> {best[2]:.2f} it/s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82bcff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== run_continual que carga el preset internamente ======================\n",
    "from pathlib import Path\n",
    "import json, torch\n",
    "from src.utils import load_preset, set_seeds\n",
    "from src.training import TrainConfig, train_supervised\n",
    "from src.models import SNNVisionRegressor\n",
    "from src.methods.ewc import EWC, EWCConfig\n",
    "\n",
    "def run_continual(\n",
    "    preset: str,                  # \"fast\" | \"std\" | \"accurate\"\n",
    "    method: str,                  # \"ewc\" | \"naive\"\n",
    "    lam: float | None,            # λ si EWC; None si naive\n",
    "    seed: int,\n",
    "    encoder: str,                 # \"rate\" | \"latency\"\n",
    "    tfm,                          # ImageTransform a usar\n",
    "    fisher_batches_by_preset: dict[str,int] | None = None,\n",
    "):\n",
    "    # Carga del preset específico para ESTE run\n",
    "    cfg = load_preset(ROOT/\"configs\"/\"presets.yaml\", preset)\n",
    "    T      = int(cfg[\"T\"])\n",
    "    gain   = float(cfg[\"gain\"])\n",
    "    lr     = float(cfg[\"lr\"])\n",
    "    epochs = int(cfg[\"epochs\"])\n",
    "    bs     = int(cfg[\"batch_size\"])\n",
    "    use_amp= bool(cfg[\"amp\"])\n",
    "\n",
    "    # Fisher batches según preset (si no se da, usa 100 por defecto)\n",
    "    fb = 100\n",
    "    if fisher_batches_by_preset and preset in fisher_batches_by_preset:\n",
    "        fb = int(fisher_batches_by_preset[preset])\n",
    "\n",
    "    set_seeds(seed)\n",
    "\n",
    "    # Modelo y método\n",
    "    model = make_snn_model(tfm)\n",
    "    ewc = None\n",
    "    if method == \"ewc\":\n",
    "        assert lam is not None, \"Para EWC debes pasar λ (lam)\"\n",
    "        ewc = EWC(model, EWCConfig(lambd=float(lam), fisher_batches=fb))\n",
    "\n",
    "    # Tareas (asumimos task_list ya existe en el notebook)\n",
    "    out_tag = f\"continual_{preset}_{method}\" + (f\"_lam_{lam:.0e}\" if method==\"ewc\" else \"\") + f\"_{encoder}_seed_{seed}\"\n",
    "    out_dir = ROOT/\"outputs\"/out_tag\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # entrenamiento secuencial\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    tcfg = TrainConfig(epochs=epochs, batch_size=bs, lr=lr, amp=use_amp, seed=seed)\n",
    "\n",
    "    results = {}\n",
    "    seen = []\n",
    "\n",
    "    for i, t in enumerate(task_list):\n",
    "        name = t[\"name\"]\n",
    "\n",
    "        # ⬇️ AHORA usamos SIEMPRE tu helper de la celda 4\n",
    "        tr, va, te = make_loader_fn(\n",
    "            task=t,\n",
    "            batch_size=bs,\n",
    "            encoder=encoder,\n",
    "            T=T,\n",
    "            gain=gain,\n",
    "            tfm=tfm,\n",
    "            seed=seed,\n",
    "        )\n",
    "\n",
    "        _ = train_supervised(\n",
    "            model, tr, va, loss_fn, tcfg,\n",
    "            out_dir/f\"task_{i+1}_{name}\",\n",
    "            method=ewc if method==\"ewc\" else None\n",
    "        )\n",
    "\n",
    "        if method==\"ewc\":\n",
    "            print(\"Estimando Fisher…\")\n",
    "            ewc.estimate_fisher(va, loss_fn, device=device)\n",
    "\n",
    "        # evaluación tarea actual\n",
    "        te_mae, te_mse = eval_loader(te, model, device)\n",
    "        results[name] = {\"test_mae\": te_mae, \"test_mse\": te_mse}\n",
    "        seen.append((name, te))\n",
    "\n",
    "        # reevaluación tareas previas (olvido)\n",
    "        for pname, p_loader in seen[:-1]:\n",
    "            p_mae, p_mse = eval_loader(p_loader, model, device)\n",
    "            results[pname][f\"after_{name}_mae\"] = p_mae\n",
    "            results[pname][f\"after_{name}_mse\"] = p_mse\n",
    "\n",
    "    (out_dir/\"continual_results.json\").write_text(json.dumps(results, indent=2), encoding=\"utf-8\")\n",
    "    return out_dir, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9f4e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Demo opcional (1 corrida) =====================\n",
    "RUN_DEMO = False  # pon True para probar 1 run rápido\n",
    "\n",
    "if RUN_DEMO:\n",
    "    preset_demo  = \"fast\"\n",
    "    method_demo  = \"ewc\"     # \"ewc\" | \"naive\"\n",
    "    lam_demo     = 1e9       # si method_demo==\"ewc\"\n",
    "    seed_demo    = 42\n",
    "\n",
    "    demo_cfg = load_preset(ROOT / \"configs\" / \"presets.yaml\", preset_demo)\n",
    "    encoder_demo = demo_cfg[\"encoder\"]   # \"rate\" o \"latency\"\n",
    "\n",
    "    out_path, res = run_continual(\n",
    "        preset=preset_demo,\n",
    "        method=method_demo,\n",
    "        lam=(lam_demo if method_demo == \"ewc\" else None),\n",
    "        seed=seed_demo,\n",
    "        encoder=encoder_demo,\n",
    "        tfm=tfm,\n",
    "        fisher_batches_by_preset={\"fast\": 200, \"std\": 200},\n",
    "    )\n",
    "    print(\"OK:\", out_path)\n",
    "    res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d378658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan de runs (preset, método, λ):\n",
      "     fast    ewc  λ=1000000000.0\n",
      "     fast    ewc  λ=300000000.0\n",
      "     fast    ewc  λ=3000000000.0\n",
      "     fast  naive  λ=None\n",
      "      std    ewc  λ=300000000.0\n",
      "      std    ewc  λ=100000000.0\n",
      "      std    ewc  λ=1000000000.0\n",
      "      std  naive  λ=None\n",
      "  accurate    ewc  λ=30000000.0\n",
      "  accurate    ewc  λ=100000000.0\n",
      "  accurate    ewc  λ=300000000.0\n",
      "  accurate  naive  λ=None\n",
      "Semillas: [42, 43, 44]  | Encoders: ['rate']\n",
      "Fisher batches por preset: {'fast': 800, 'std': 1200, 'accurate': 1500}\n"
     ]
    }
   ],
   "source": [
    "# ====================== CONFIG POR DEFECTO PARA LAS COMPARATIVAS ======================\n",
    "# Recomendaciones acordadas:\n",
    "# - fast: EWC λ=1e9 (estable). Extra: λ=1e8 (mejor T2, algo más de olvido)\n",
    "# - std : EWC λ=1e7 (baseline estable). Extra: λ=3e7 (mejor T2, más olvido)\n",
    "\n",
    "EWC_DEFAULTS = {\n",
    "    \"fast\":     {\"primary\": [1e9, 3e8],      \"extra\": [3e9]},\n",
    "    \"std\":      {\"primary\": [3e8, 1e8],      \"extra\": [1e9]},\n",
    "    \"accurate\": {\"primary\": [3e7, 1e8],      \"extra\": [3e8]},  # ← mucho más bajo que 1e9\n",
    "}\n",
    "\n",
    "INCLUDE_NAIVE    = True          # añade baseline sin EWC\n",
    "INCLUDE_EXTRAS   = True          # activa los λ \"extra\" por preset\n",
    "SEEDS            = [42, 43, 44]  # multisemillas para medias/σ\n",
    "ENCODERS         = [\"rate\"]      # luego podrás añadir \"latency\"\n",
    "# FISHER_BY_PRESET = {\"fast\": 200, \"std\": 600, \"accurate\": 600}  # estabiliza el cálculo de Fisher\n",
    "# FISHER_BY_PRESET = {\"fast\": 800, \"std\": 1000}  # estabiliza el cálculo de Fisher\n",
    "# Endurecemos Fisher para estabilidad; accurate necesita más por ser más largo\n",
    "FISHER_BY_PRESET = {\"fast\": 800, \"std\": 1200, \"accurate\": 1500}\n",
    "\n",
    "# Elige qué presets lanzar\n",
    "PRESETS_TO_RUN = [\"fast\", \"std\", \"accurate\"]  # añade \"accurate\" si lo necesitas más adelante\n",
    "# PRESETS_TO_RUN = [\"accurate\"]  # añade \"accurate\" si lo necesitas más adelante\n",
    "\n",
    "# ---- Construcción del plan de ejecuciones ----\n",
    "runs_plan = []\n",
    "for preset_i in PRESETS_TO_RUN:\n",
    "    # EWC primary\n",
    "    for lam in EWC_DEFAULTS[preset_i][\"primary\"]:\n",
    "        runs_plan.append((preset_i, \"ewc\", lam))\n",
    "    # EWC extras (opcionales)\n",
    "    if INCLUDE_EXTRAS:\n",
    "        for lam in EWC_DEFAULTS[preset_i][\"extra\"]:\n",
    "            runs_plan.append((preset_i, \"ewc\", lam))\n",
    "    # Baseline sin EWC\n",
    "    if INCLUDE_NAIVE:\n",
    "        runs_plan.append((preset_i, \"naive\", None))\n",
    "\n",
    "print(\"Plan de runs (preset, método, λ):\")\n",
    "for preset_i, method_i, lam_i in runs_plan:\n",
    "    print(f\"  {preset_i:>7}  {method_i:>5}  λ={lam_i}\")\n",
    "print(\"Semillas:\", SEEDS, \" | Encoders:\", ENCODERS)\n",
    "print(\"Fisher batches por preset:\", FISHER_BY_PRESET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN: preset=fast | method=ewc | λ=1000000000.0 | seed=42 | encoder=rate ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_1e+09_rate_seed_42\n",
      "\n",
      "=== RUN: preset=fast | method=ewc | λ=300000000.0 | seed=42 | encoder=rate ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_3e+08_rate_seed_42\n",
      "\n",
      "=== RUN: preset=fast | method=ewc | λ=3000000000.0 | seed=42 | encoder=rate ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_ewc_lam_3e+09_rate_seed_42\n",
      "\n",
      "=== RUN: preset=fast | method=naive | λ=None | seed=42 | encoder=rate ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_fast_naive_rate_seed_42\n",
      "\n",
      "=== RUN: preset=std | method=ewc | λ=300000000.0 | seed=42 | encoder=rate ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_std_ewc_lam_3e+08_rate_seed_42\n",
      "\n",
      "=== RUN: preset=std | method=ewc | λ=100000000.0 | seed=42 | encoder=rate ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_std_ewc_lam_1e+08_rate_seed_42\n",
      "\n",
      "=== RUN: preset=std | method=ewc | λ=1000000000.0 | seed=42 | encoder=rate ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimando Fisher…\n",
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_std_ewc_lam_1e+09_rate_seed_42\n",
      "\n",
      "=== RUN: preset=std | method=naive | λ=None | seed=42 | encoder=rate ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: /home/cesar/proyectos/TFM_SNN/outputs/continual_std_naive_rate_seed_42\n",
      "\n",
      "=== RUN: preset=accurate | method=ewc | λ=30000000.0 | seed=42 | encoder=rate ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20:  96%|█████████▌| 873/909 [00:58<00:02, 15.63it/s]"
     ]
    }
   ],
   "source": [
    "# ====================== DRIVER MULTISEMILLAS (usa la CONFIG de arriba) ======================\n",
    "for enc in ENCODERS:\n",
    "    for seed in SEEDS:\n",
    "        for preset_i, method_i, lam_i in runs_plan:\n",
    "            print(f\"\\n=== RUN: preset={preset_i} | method={method_i} | λ={lam_i} | seed={seed} | encoder={enc} ===\")\n",
    "            out_path, _ = run_continual(\n",
    "                preset=preset_i,\n",
    "                method=method_i,\n",
    "                lam=(lam_i if method_i == \"ewc\" else None),\n",
    "                seed=seed,\n",
    "                encoder=enc,\n",
    "                tfm=tfm,  # definido en tu celda de setup\n",
    "                fisher_batches_by_preset=FISHER_BY_PRESET,\n",
    "            )\n",
    "            print(\"OK:\", out_path)\n",
    "print(\"\\n✅ Listo. Ejecuta las celdas de resumen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9835a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Resumen comparativo de todos los continual_* en outputs/\n",
    "# =============================================================================\n",
    "import re, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def parse_exp_name(name: str):\n",
    "    \"\"\"\n",
    "    Extrae preset, método, lambda, encoder y seed del nombre de carpeta:\n",
    "\n",
    "      continual_<preset>_<method>[_lam_<lambda>]_<_encoder>[_seed_<seed>]\n",
    "\n",
    "    Ejemplos:\n",
    "      continual_fast_naive_rate_seed_42\n",
    "      continual_fast_ewc_lam_1e+08_rate_seed_42\n",
    "      continual_std_ewc_lam_3e+07_latency_seed_43\n",
    "    \"\"\"\n",
    "    m = re.match(\n",
    "        r\"continual_(?P<preset>\\w+)_(?P<method>ewc|naive)\"\n",
    "        r\"(?:_lam_(?P<lambda>[^_]+))?_(?P<enc>[^_]+)\"\n",
    "        r\"(?:_seed_(?P<seed>\\d+))?$\",\n",
    "        name\n",
    "    )\n",
    "    meta = {\"preset\": None, \"method\": None, \"lambda\": None, \"encoder\": None, \"seed\": None}\n",
    "    if m:\n",
    "        d = m.groupdict()\n",
    "        meta.update({\n",
    "            \"preset\": d[\"preset\"],\n",
    "            \"method\": d[\"method\"],\n",
    "            \"lambda\": d.get(\"lambda\"),\n",
    "            \"encoder\": d.get(\"enc\"),\n",
    "            \"seed\": d.get(\"seed\"),\n",
    "        })\n",
    "    return meta\n",
    "\n",
    "rows = []\n",
    "root_out = ROOT / \"outputs\"\n",
    "\n",
    "for exp_dir in sorted(root_out.glob(\"continual_*\")):\n",
    "    name = exp_dir.name\n",
    "    meta = parse_exp_name(name)\n",
    "\n",
    "    # Saltar nombres no reconocidos (runs muy antiguos)\n",
    "    if meta[\"preset\"] is None:\n",
    "        continue\n",
    "\n",
    "    results_path = exp_dir / \"continual_results.json\"\n",
    "    if not results_path.exists():\n",
    "        continue\n",
    "\n",
    "    with open(results_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        res = json.load(f)\n",
    "\n",
    "    # Detectar tareas: la \"última\" es la que NO tiene claves 'after_*'\n",
    "    task_names = list(res.keys())\n",
    "    if len(task_names) < 2:\n",
    "        continue\n",
    "\n",
    "    def is_last(d):  # no tiene after_*\n",
    "        return not any(k.startswith(\"after_\") for k in d.keys())\n",
    "\n",
    "    last_task = None\n",
    "    first_task = None\n",
    "    for tn in task_names:\n",
    "        if is_last(res[tn]):\n",
    "            last_task = tn\n",
    "        else:\n",
    "            first_task = tn\n",
    "\n",
    "    # Fallback por si no se identifica bien\n",
    "    if first_task is None or last_task is None:\n",
    "        task_names_sorted = sorted(task_names)\n",
    "        first_task = task_names_sorted[0]\n",
    "        last_task  = task_names_sorted[-1]\n",
    "\n",
    "    c1, c2 = first_task, last_task\n",
    "\n",
    "    c1_test_mae = float(res[c1].get(\"test_mae\", float(\"nan\")))\n",
    "    c2_test_mae = float(res[c2].get(\"test_mae\", float(\"nan\")))\n",
    "    after_key_mae = f\"after_{c2}_mae\"\n",
    "    c1_after_c2_mae = float(res[c1].get(after_key_mae, float(\"nan\")))\n",
    "\n",
    "    forgetting_abs = c1_after_c2_mae - c1_test_mae\n",
    "    forgetting_rel = (forgetting_abs / c1_test_mae * 100.0) if c1_test_mae == c1_test_mae else float(\"nan\")\n",
    "\n",
    "    rows.append({\n",
    "        \"exp\": name,\n",
    "        \"preset\": meta[\"preset\"],\n",
    "        \"method\": meta[\"method\"],\n",
    "        \"lambda\": meta[\"lambda\"] if meta[\"method\"] == \"ewc\" else None,\n",
    "        \"encoder\": meta[\"encoder\"],\n",
    "        \"seed\": int(meta[\"seed\"]) if meta[\"seed\"] is not None else None,\n",
    "        \"c1_name\": c1,\n",
    "        \"c2_name\": c2,\n",
    "        \"c1_mae\": c1_test_mae,\n",
    "        \"c1_after_c2_mae\": c1_after_c2_mae,\n",
    "        \"c1_forgetting_mae_abs\": forgetting_abs,\n",
    "        \"c1_forgetting_mae_rel_%\": forgetting_rel,\n",
    "        \"c2_mae\": c2_test_mae,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Asegura columnas numéricas auxiliares\n",
    "if \"lambda_num\" not in df.columns:\n",
    "    df[\"lambda_num\"] = pd.to_numeric(df[\"lambda\"], errors=\"coerce\")  # '1e+08' -> 1e+08 ; NAIVE -> NaN\n",
    "\n",
    "# Deja 'seed' como entero y elimina 'seed_num' si existe\n",
    "df[\"seed\"] = pd.to_numeric(df[\"seed\"], errors=\"coerce\").astype(\"Int64\")\n",
    "if \"seed_num\" in df.columns:\n",
    "    df = df.drop(columns=[\"seed_num\"])\n",
    "\n",
    "# Ordenar: preset, method, encoder, lambda_num (NaN al final), seed\n",
    "df = df.sort_values(\n",
    "    by=[\"preset\", \"method\", \"encoder\", \"lambda_num\", \"seed\"],\n",
    "    na_position=\"last\",\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Vista agregada (media±std por preset/method/λ/encoder) ======================\n",
    "import pandas as pd\n",
    "\n",
    "# Métricas a agregar\n",
    "cols_metrics = [\"c1_mae\", \"c1_after_c2_mae\", \"c1_forgetting_mae_abs\", \"c1_forgetting_mae_rel_%\", \"c2_mae\"]\n",
    "\n",
    "# Copia y asegura columna numérica auxiliar para ordenar por λ\n",
    "gdf = df.copy()\n",
    "if \"lambda_num\" not in gdf.columns:\n",
    "    gdf[\"lambda_num\"] = pd.to_numeric(gdf[\"lambda\"], errors=\"coerce\")  # NA para NAIVE\n",
    "\n",
    "# Agregación: media, std y número de corridas (semillas) por combinación\n",
    "agg = (\n",
    "    gdf\n",
    "    .groupby([\"preset\", \"method\", \"encoder\", \"lambda\", \"lambda_num\"], dropna=False)[cols_metrics]\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Aplanar nombres de columnas (de MultiIndex a una sola capa)\n",
    "agg.columns = [\n",
    "    \"_\".join(filter(None, map(str, col))).rstrip(\"_\")\n",
    "    for col in agg.columns.to_flat_index()\n",
    "]\n",
    "\n",
    "# Ordena por preset/method/encoder/λ_num (NaN al final ⇒ NAIVE al final de su grupo)\n",
    "agg = agg.sort_values(\n",
    "    by=[\"preset\", \"method\", \"encoder\", \"lambda_num\"],\n",
    "    na_position=\"last\",\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# (Opcional) guardar a CSV\n",
    "summary_dir = ROOT / \"outputs\" / \"summary\"\n",
    "summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "agg.to_csv(summary_dir / \"continual_summary_agg.csv\", index=False)\n",
    "print(\"Guardado:\", summary_dir / \"continual_summary_agg.csv\")\n",
    "\n",
    "agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821024ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Formateo para la memoria (tabla compacta) ======================\n",
    "\n",
    "def fmt(x, prec=4):\n",
    "    # Redondea y gestiona NaN de forma amigable\n",
    "    import pandas as pd\n",
    "    return \"\" if pd.isna(x) else f\"{x:.{prec}f}\"\n",
    "\n",
    "show = agg.copy()\n",
    "\n",
    "# 1) Crea 'count' a partir de cualquiera de las columnas *_count\n",
    "count_cols = [c for c in show.columns if c.endswith(\"_count\")]\n",
    "if count_cols:\n",
    "    show[\"count\"] = show[count_cols[0]].astype(\"Int64\")  # todas deberían coincidir\n",
    "    # (opcional) elimina las columnas *_count individuales\n",
    "    show = show.drop(columns=count_cols)\n",
    "\n",
    "# 2) Redondea columnas de medias/desviaciones\n",
    "for c in [c for c in show.columns if c.endswith(\"_mean\") or c.endswith(\"_std\")]:\n",
    "    show[c] = show[c].map(lambda v: fmt(v, 4))\n",
    "\n",
    "# 3) Selección de columnas clave (ajusta el orden a tu gusto)\n",
    "cols = [\n",
    "    \"preset\", \"method\", \"encoder\", \"lambda\",\n",
    "    \"c1_mae_mean\", \"c1_forgetting_mae_rel_%_mean\", \"c2_mae_mean\",\n",
    "    \"c1_mae_std\",  \"c1_forgetting_mae_rel_%_std\",  \"c2_mae_std\",\n",
    "    \"count\"\n",
    "]\n",
    "\n",
    "# Si alguna columna no existiera (según tus métricas), la ignoramos con aviso\n",
    "missing = [c for c in cols if c not in show.columns]\n",
    "if missing:\n",
    "    print(\"Aviso: faltan columnas en 'show':\", missing)\n",
    "    cols = [c for c in cols if c in show.columns]\n",
    "\n",
    "show = show[cols].rename(columns={\n",
    "    \"preset\": \"preset\",\n",
    "    \"method\": \"método\",\n",
    "    \"encoder\": \"codificador\",\n",
    "    \"lambda\": \"λ\",\n",
    "    \"c1_mae_mean\": \"MAE Tarea1 (media)\",\n",
    "    \"c1_forgetting_mae_rel_%_mean\": \"Olvido T1 (%) (media)\",\n",
    "    \"c2_mae_mean\": \"MAE Tarea2 (media)\",\n",
    "    \"c1_mae_std\": \"MAE Tarea1 (σ)\",\n",
    "    \"c1_forgetting_mae_rel_%_std\": \"Olvido T1 (%) (σ)\",\n",
    "    \"c2_mae_std\": \"MAE Tarea2 (σ)\",\n",
    "    \"count\": \"n (semillas)\"\n",
    "})\n",
    "\n",
    "show\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
