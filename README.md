# TFM ‚Äî SNN + Aprendizaje Continuo en SNN (steering Udacity)

Proyecto para investigar **aprendizaje continuo (Continual Learning, CL)** en **redes de impulsos (Spiking Neural Networks, SNN)** aplicadas a **regresi√≥n de √°ngulo de direcci√≥n (steering)** en conducci√≥n simulada (Udacity).  
Stack: **PyTorch + snnTorch**, ejecuci√≥n local en **Linux/WSL2 + CUDA** o CPU.

> üìÅ **Datos**: ver gu√≠a completa en [`data/README.md`](data/README.md).


## 1) Requisitos

- **Python 3.12** (recomendado) y `pip`.
- Linux o **WSL2 (Ubuntu 24.04)** en Windows 11.
- GPU NVIDIA opcional (recomendado). Para CUDA 12.9 en RTX 4080 se usa la build `+cu129` de PyTorch.
- Compilaci√≥n no requerida: todo el c√≥digo est√° en Python.

> Si trabajas en WSL2, aseg√∫rate de tener el driver NVIDIA actualizado en Windows y soporte CUDA en WSL (`nvidia-smi` dentro de WSL).


## 2) Instalaci√≥n r√°pida

```bash
# Clona el repo
git clone https://github.com/TU_GITHUB/TFM_SNN.git
cd TFM_SNN

# Crea y activa el entorno del proyecto
python3 -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip

# Instala PyTorch para tu GPU (ejemplo: CUDA 12.9)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129

# Resto de dependencias
pip install -r requirements.txt

# Comprobaci√≥n de entorno (versiones, CUDA, GPU, estructura)
python tools/check_env.py
```


## 3) Organizaci√≥n del proyecto

```
configs/
  presets.yaml           # perfiles de ejecuci√≥n (fast / std / accurate)
data/
  raw/udacity/...        # datos originales (ver data/README.md)
  processed/...          # splits y derivados generados por los notebooks
notebooks/
  01_DATA_QC_PREP.ipynb  # QC + normalizaci√≥n rutas + splits (train/val/test) + tasks.json
  02_ENCODE_OFFLINE.ipynb# (opcional) codificaci√≥n a spikes offline (HDF5)
  03_TRAIN_EVAL.ipynb    # entrenamiento supervised y continual (EWC baseline)
  04_RESULTS.ipynb       # agregaci√≥n de resultados y figuras
outputs/
  ...                    # m√©tricas, manifiestos y resultados por experimento
src/
  encoders.py            # codificadores rate/latency (on-the-fly)
  datasets.py            # dataloaders Udacity + HDF5 opcional
  models.py              # backbone SNNVisionRegressor (CNN + LIF)
  training.py            # bucles de entrenamiento (supervised y continual)
  metrics.py             # MAE/MSE y BWT (olvido)
  utils.py               # seeds, presets, dataloaders auxiliares
  methods/
    ewc.py               # Elastic Weight Consolidation (baseline)
    sa_snn.py            # stub (activaci√≥n selectiva escasa)
    as_snn.py            # stub (escalado sin√°ptico adaptativo)
    sca_snn.py           # stub (context-aware por similaridad)
    colanet.py           # stub (arquitectura columnar)
tools/
  check_env.py           # verifica entorno, CUDA y estructura
  smoke_train.py         # entrenamiento sint√©tico r√°pido (sin datos)
```


## 4) Flujo de trabajo

### 4.1 Preparar datos
Coloca tus recorridos del simulador Udacity as√≠ (ver detalles en `data/README.md`):
```
data/raw/udacity/circuito1/driving_log.csv  +  data/raw/udacity/circuito1/IMG/
data/raw/udacity/circuito2/driving_log.csv  +  data/raw/udacity/circuito2/IMG/
```

Ejecuta el notebook **01_DATA_QC_PREP.ipynb** (selecciona el kernel de `.venv`):
- Normaliza rutas a `IMG/...`, filtra im√°genes inexistentes y guarda `canonical.csv`.
- Genera **splits estratificados** por bins de `steering`: `train/val/test.csv`.
- Crea `data/processed/tasks.json` con el orden de tareas (p. ej., `["circuito1","circuito2"]`).

> *(Opcional)* Ejecuta **02_ENCODE_OFFLINE.ipynb** para crear HDF5 con spikes si quieres depurar E/S o medir diferencias offline vs on‚Äëthe‚Äëfly.


### 4.2 Entrenamiento y evaluaci√≥n
Abre **03_TRAIN_EVAL.ipynb** y ejecuta:
- **Supervised** en `circuito1` con preset `fast` (r√°pido para comprobar que todo funciona).
- **Continual** `circuito1 ‚Üí circuito2` con **EWC** (baseline).  
Se guardan m√©tricas en `outputs/` (ver estructura abajo).

Luego abre **04_RESULTS.ipynb** para ver:
- Tabla con MAE/MSE de validaci√≥n/tiempo final.
- Resumen de continual (`continual_results.json`) y gr√°fica simple.


## 5) Presets y configuraci√≥n

Archivo: `configs/presets.yaml`

- `fast`: pruebas r√°pidas (pocas √©pocas, T reducido).  
- `std`: equilibrio tiempo/calidad.  
- `accurate`: m√°s √©pocas y ventana temporal (T) mayor para resultados finales.

Cada preset define: `epochs`, `batch_size`, `T` (pasos temporales), `gain` (en rate), `encoder` (rate/latency), `lr`, `amp` (mixed precision).


## 6) Estructura de resultados (`outputs/`)

Por cada ejecuci√≥n se crea una carpeta con:
- `metrics.json`: hist√≥rico de MAE/MSE (train/val) por √©poca.
- `manifest.json`: metadatos m√≠nimos (modo, preset, device, tiempos, etc.).
- En continual: `continual_results.json` con m√©tricas por tarea y degradaciones tras nuevas tareas.

Ejemplo de carpeta:
```
outputs/
  supervised_fast_ewc0/
    metrics.json
    manifest.json
  continual_fast_ewc/
    task_1_circuito1/
      metrics.json
      manifest.json
    task_2_circuito2/
      metrics.json
      manifest.json
    continual_results.json
```


## 7) Scripts √∫tiles (sin notebooks)

- **Comprobaci√≥n de entorno**
  ```bash
  python tools/check_env.py
  ```

- **Smoke test de entrenamiento sint√©tico** (no requiere datos):
  ```bash
  python tools/smoke_train.py --steps 50 --T 10 --batch 8 --amp
  ```
  Si ves `Dispositivo: cuda` y la `loss` baja, tu stack est√° OK.


## 8) Resoluci√≥n de problemas frecuentes

- **`CUDA disponible: False`**  
  Revisa driver en Windows, soporte CUDA en WSL, y reinstala PyTorch con el √≠ndice de tu versi√≥n CUDA (`cu129` en RTX 4080).

- **`ModuleNotFoundError: No module named 'torch'`**  
  Aseg√∫rate de tener activado el entorno `.venv` y de haber ejecutado la instalaci√≥n de PyTorch y `requirements.txt`.

- **`FileNotFoundError: data/processed/tasks.json`**  
  Ejecuta antes `notebooks/01_DATA_QC_PREP.ipynb` para generar los splits y `tasks.json`.

- **OOM (falta VRAM)**  
  Usa preset `fast`, baja `batch_size` o `T`, y mant√©n `amp: true`.

- **Kernel equivocado en notebooks**  
  Selecciona el int√©rprete de `.venv` en VS Code (Ctrl+Shift+P ‚Üí *Python: Select Interpreter*).


## 9) Estado de m√©todos CL

- **EWC** (baseline) implementado en `src/methods/ewc.py` e integrado en el notebook 03.  
- **SA‚ÄëSNN / AS‚ÄëSNN / SCA‚ÄëSNN / CoLaNET** incluidos como *stubs* en `src/methods/` para su desarrollo incremental y comparaci√≥n bajo el mismo pipeline.


---

¬øDudas? Abre un issue o comenta sobre qu√© m√©todo quieres implementar primero (SA‚ÄëSNN o AS‚ÄëSNN son buenas opciones para continuar).
